/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 17:07:05 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__50;  // explode_generateTensors_arrayA > transposeTensor_1 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__0;  // explode_generateTensors_arrayB > multiplyTensors_49 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayB > multiplyTensors_36 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__7;  // explode_generateTensors_arrayB > multiplyTensors_27 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__61;  // explode_generateTensors_arrayB > multiplyTensors_15 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__30;  // explode_generateTensors_arrayB > multiplyTensors_13 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__22;  // explode_generateTensors_arrayB > multiplyTensors_8 size:= 131072*char defined in Core0
extern int *const arrayA_262144__input__0;  // explode_generateTensors_arrayA_arrayA_262144 > transposeTensor_1_input size:= 262144*int defined in Core0
extern int *const output__arrayA__1;  // transposeTensor_1_output > explode_transposeTensor_1_output_arrayA size:= 262144*int defined in Core0
extern int *const output_0__arrayA__0;  // explode_transposeTensor_1_output_output_0 > multiplyTensors_8_arrayA size:= 32768*int defined in Core0
extern int *const output_32768__arrayA__2;  // explode_transposeTensor_1_output_output_32768 > multiplyTensors_9_arrayA size:= 32768*int defined in Core0
extern int *const output_65536__arrayA__1;  // explode_transposeTensor_1_output_output_65536 > multiplyTensors_10_arrayA size:= 32768*int defined in Core0
extern int *const output_98304__arrayA__5;  // explode_transposeTensor_1_output_output_98304 > multiplyTensors_11_arrayA size:= 32768*int defined in Core0
extern int *const output_131072__arrayA__1;  // explode_transposeTensor_1_output_output_131072 > multiplyTensors_12_arrayA size:= 32768*int defined in Core0
extern int *const output_163840__arrayA__3;  // explode_transposeTensor_1_output_output_163840 > multiplyTensors_13_arrayA size:= 32768*int defined in Core0
extern int *const output_196608__arrayA__7;  // explode_transposeTensor_1_output_output_196608 > multiplyTensors_14_arrayA size:= 32768*int defined in Core0
extern int *const output_229376__arrayA__2;  // explode_transposeTensor_1_output_output_229376 > multiplyTensors_15_arrayA size:= 32768*int defined in Core0
extern char *const explode_transposeTensor_1_ou__7;  // explode_transposeTensor_1_output > multiplyTensors_14 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_1_ou__2;  // explode_transposeTensor_1_output > multiplyTensors_12 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_1_ou__5;  // explode_transposeTensor_1_output > multiplyTensors_11 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_1_ou__3;  // explode_transposeTensor_1_output > multiplyTensors_10 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_1_ou__4;  // explode_transposeTensor_1_output > multiplyTensors_9 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_3_ou__2;  // explode_transposeTensor_3_output > multiplyTensors_27 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_4_ou__4;  // explode_transposeTensor_4_output > multiplyTensors_36 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_6_ou__0;  // explode_transposeTensor_6_output > multiplyTensors_49 size:= 131072*char defined in Core0
extern char *const multiplyTensors_10__implode___0;  // multiplyTensors_10 > implode_sumResults_1_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_11__implode___0;  // multiplyTensors_11 > implode_sumResults_1_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_12__implode___0;  // multiplyTensors_12 > implode_sumResults_1_input size:= 1048576*char defined in Core0
extern int *const arrayB_425984__arrayB__0;  // explode_generateTensors_arrayB_arrayB_425984 > multiplyTensors_13_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1310720__0;  // multiplyTensors_13_arrayC > implode_sumResults_1_input_input_1310720 size:= 262144*long defined in Core0
extern char *const multiplyTensors_14__implode___0;  // multiplyTensors_14 > implode_sumResults_1_input size:= 1048576*char defined in Core0
extern int *const arrayB_491520__arrayB__0;  // explode_generateTensors_arrayB_arrayB_491520 > multiplyTensors_15_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1835008__0;  // multiplyTensors_15_arrayC > implode_sumResults_1_input_input_1835008 size:= 262144*long defined in Core0
extern int *const output_98304__arrayA__0;  // explode_transposeTensor_3_output_output_98304 > multiplyTensors_27_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_884736__arrayB__0;  // explode_generateTensors_arrayB_arrayB_884736 > multiplyTensors_27_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_786432__1;  // multiplyTensors_27_arrayC > implode_sumResults_3_input_input_786432 size:= 262144*long defined in Core0
extern char *const multiplyTensors_27__implode___0;  // multiplyTensors_27 > implode_sumResults_3_input size:= 1048576*char defined in Core0
extern int *const output_131072__arrayA__5;  // explode_transposeTensor_4_output_output_131072 > multiplyTensors_36_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_1179648__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1179648 > multiplyTensors_36_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1048576__4;  // multiplyTensors_36_arrayC > implode_sumResults_4_input_input_1048576 size:= 262144*long defined in Core0
extern char *const multiplyTensors_36__implode___0;  // multiplyTensors_36 > implode_sumResults_4_input size:= 1048576*char defined in Core0
extern int *const output_32768__arrayA__1;  // explode_transposeTensor_6_output_output_32768 > multiplyTensors_49_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_1605632__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1605632 > multiplyTensors_49_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_262144__1;  // multiplyTensors_49_arrayC > implode_sumResults_6_input_input_262144 size:= 262144*long defined in Core0
extern char *const multiplyTensors_49__implode___0;  // multiplyTensors_49 > implode_sumResults_6_input size:= 1048576*char defined in Core0
extern int *const arrayB_262144__arrayB__0;  // explode_generateTensors_arrayB_arrayB_262144 > multiplyTensors_8_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_0__5;  // multiplyTensors_8_arrayC > implode_sumResults_1_input_input_0 size:= 262144*long defined in Core0
extern char *const multiplyTensors_9__implode_s__0;  // multiplyTensors_9 > implode_sumResults_1_input size:= 1048576*char defined in Core0
extern long *const arrayC__input_262144__2;  // multiplyTensors_9_arrayC > implode_sumResults_1_input_input_262144 size:= 262144*long defined in Core0
extern long *const arrayC__input_524288__4;  // multiplyTensors_10_arrayC > implode_sumResults_1_input_input_524288 size:= 262144*long defined in Core0
extern long *const arrayC__input_786432__2;  // multiplyTensors_11_arrayC > implode_sumResults_1_input_input_786432 size:= 262144*long defined in Core0
extern long *const arrayC__input_1048576__6;  // multiplyTensors_12_arrayC > implode_sumResults_1_input_input_1048576 size:= 262144*long defined in Core0
extern long *const arrayC__input_1572864__6;  // multiplyTensors_14_arrayC > implode_sumResults_1_input_input_1572864 size:= 262144*long defined in Core0
extern long *const arrayC__input__4;  // implode_sumResults_1_input_arrayC > sumResults_1_input size:= 2097152*long defined in Core0
extern long *const output__arrayC_262144__0;  // sumResults_1_output > implode_displayTensor_arrayC_arrayC_262144 size:= 262144*long defined in Core0
extern char *const sumResults_1__implode_displa__0;  // sumResults_1 > implode_displayTensor_arrayC size:= 1048576*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__50 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__50 
		cache_inv(explode_generateTensors_arra__50, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__0 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__0 
		cache_inv(explode_generateTensors_arra__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__13 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__7 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__7 
		cache_inv(explode_generateTensors_arra__7, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__61 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__61 
		cache_inv(explode_generateTensors_arra__61, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__30 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__30 
		cache_inv(explode_generateTensors_arra__30, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__22 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__22 
		cache_inv(explode_generateTensors_arra__22, 131072*sizeof(char));
		transpose(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,arrayA_262144__input__0,output__arrayA__1); // transposeTensor_1
		cache_inv(arrayA_262144__input__0, 262144*sizeof(int));
		// Fork explode_transposeTensor_1_output
		{
			cache_wb(output__arrayA__1, 262144*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__1) + 0, 1048576);
		cache_inv(output__arrayA__1, 262144*sizeof(int));
		cache_wbInv(explode_transposeTensor_1_ou__7, 131072*sizeof(char));
		sendStart(0); // Core2 > Core0: explode_transposeTensor_1_ou__7 
		sendEnd(); // Core2 > Core0: explode_transposeTensor_1_ou__7 
		cache_wbInv(explode_transposeTensor_1_ou__2, 131072*sizeof(char));
		sendStart(6); // Core2 > Core6: explode_transposeTensor_1_ou__2 
		sendEnd(); // Core2 > Core6: explode_transposeTensor_1_ou__2 
		cache_wbInv(explode_transposeTensor_1_ou__5, 131072*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_1_ou__5 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_1_ou__5 
		cache_wbInv(explode_transposeTensor_1_ou__3, 131072*sizeof(char));
		sendStart(0); // Core2 > Core0: explode_transposeTensor_1_ou__3 
		sendEnd(); // Core2 > Core0: explode_transposeTensor_1_ou__3 
		cache_wbInv(explode_transposeTensor_1_ou__4, 131072*sizeof(char));
		sendStart(3); // Core2 > Core3: explode_transposeTensor_1_ou__4 
		sendEnd(); // Core2 > Core3: explode_transposeTensor_1_ou__4 
		receiveStart(); // Core3 > Core2: explode_transposeTensor_3_ou__2 
		receiveEnd(3); // Core3 > Core2: explode_transposeTensor_3_ou__2 
		cache_inv(explode_transposeTensor_3_ou__2, 131072*sizeof(char));
		receiveStart(); // Core6 > Core2: explode_transposeTensor_4_ou__4 
		receiveEnd(6); // Core6 > Core2: explode_transposeTensor_4_ou__4 
		cache_inv(explode_transposeTensor_4_ou__4, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_6_ou__0 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_6_ou__0 
		cache_inv(explode_transposeTensor_6_ou__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: multiplyTensors_10__implode___0 
		receiveEnd(0); // Core0 > Core2: multiplyTensors_10__implode___0 
		cache_inv(multiplyTensors_10__implode___0, 1048576*sizeof(char));
		receiveStart(); // Core1 > Core2: multiplyTensors_11__implode___0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_11__implode___0 
		cache_inv(multiplyTensors_11__implode___0, 1048576*sizeof(char));
		receiveStart(); // Core6 > Core2: multiplyTensors_12__implode___0 
		receiveEnd(6); // Core6 > Core2: multiplyTensors_12__implode___0 
		cache_inv(multiplyTensors_12__implode___0, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_163840__arrayA__3,arrayB_425984__arrayB__0,arrayC__input_1310720__0); // multiplyTensors_13
		cache_inv(output_163840__arrayA__3, 32768*sizeof(int));
		cache_inv(arrayB_425984__arrayB__0, 32768*sizeof(int));
		receiveStart(); // Core0 > Core2: multiplyTensors_14__implode___0 
		receiveEnd(0); // Core0 > Core2: multiplyTensors_14__implode___0 
		cache_inv(multiplyTensors_14__implode___0, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_229376__arrayA__2,arrayB_491520__arrayB__0,arrayC__input_1835008__0); // multiplyTensors_15
		cache_inv(output_229376__arrayA__2, 32768*sizeof(int));
		cache_inv(arrayB_491520__arrayB__0, 32768*sizeof(int));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_98304__arrayA__0,arrayB_884736__arrayB__0,arrayC__input_786432__1); // multiplyTensors_27
		cache_inv(output_98304__arrayA__0, 32768*sizeof(int));
		cache_inv(arrayB_884736__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_27__implode___0, 1048576*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_27__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_27__implode___0 
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_131072__arrayA__5,arrayB_1179648__arrayB__0,arrayC__input_1048576__4); // multiplyTensors_36
		cache_inv(output_131072__arrayA__5, 32768*sizeof(int));
		cache_inv(arrayB_1179648__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_36__implode___0, 1048576*sizeof(char));
		sendStart(4); // Core2 > Core4: multiplyTensors_36__implode___0 
		sendEnd(); // Core2 > Core4: multiplyTensors_36__implode___0 
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_32768__arrayA__1,arrayB_1605632__arrayB__0,arrayC__input_262144__1); // multiplyTensors_49
		cache_inv(output_32768__arrayA__1, 32768*sizeof(int));
		cache_inv(arrayB_1605632__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_49__implode___0, 1048576*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_49__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_49__implode___0 
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_0__arrayA__0,arrayB_262144__arrayB__0,arrayC__input_0__5); // multiplyTensors_8
		cache_inv(output_0__arrayA__0, 32768*sizeof(int));
		cache_inv(arrayB_262144__arrayB__0, 32768*sizeof(int));
		receiveStart(); // Core3 > Core2: multiplyTensors_9__implode_s__0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_9__implode_s__0 
		cache_inv(multiplyTensors_9__implode_s__0, 1048576*sizeof(char));
		// Join implode_sumResults_1_input
		{
			cache_wb(arrayC__input_0__5, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__4+262144),(void*)( arrayC__input_262144__2+0), 262144*sizeof(long));
			cache_wb(arrayC__input_524288__4, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__4+786432),(void*)( arrayC__input_786432__2+0), 262144*sizeof(long));
			cache_wb(arrayC__input_1048576__6, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__4+1310720),(void*)( arrayC__input_1310720__0+0), 262144*sizeof(long));
			cache_wb(arrayC__input_1572864__6, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__4+1835008),(void*)( arrayC__input_1835008__0+0), 262144*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__5) + 0, 1048576);
		cache_inv(arrayC__input_0__5, 262144*sizeof(long));
		cache_inv(arrayC__input_262144__2, 262144*sizeof(long));
		cache_wb(((char*)arrayC__input_524288__4) + 0, 1048576);
		cache_inv(arrayC__input_524288__4, 262144*sizeof(long));
		cache_inv(arrayC__input_786432__2, 262144*sizeof(long));
		cache_wb(((char*)arrayC__input_1048576__6) + 0, 1048576);
		cache_inv(arrayC__input_1048576__6, 262144*sizeof(long));
		cache_inv(arrayC__input_1310720__0, 262144*sizeof(long));
		cache_wb(((char*)arrayC__input_1572864__6) + 0, 1048576);
		cache_inv(arrayC__input_1572864__6, 262144*sizeof(long));
		cache_inv(arrayC__input_1835008__0, 262144*sizeof(long));
		sum(512/*rowsA*/,512/*columnsB*/,8/*depthA*/,arrayC__input__4,output__arrayC_262144__0); // sumResults_1
		cache_inv(arrayC__input__4, 2097152*sizeof(long));
		cache_wbInv(sumResults_1__implode_displa__0, 1048576*sizeof(char));
		sendStart(1); // Core2 > Core1: sumResults_1__implode_displa__0 
		sendEnd(); // Core2 > Core1: sumResults_1__implode_displa__0 
	}
}
