/** 
 * @file Core5.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 23:59:39 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__201;  // explode_generateTensors_arrayA > transposeTensor_31 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__98;  // explode_generateTensors_arrayA > transposeTensor_22 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__8;  // explode_generateTensors_arrayA > transposeTensor_21 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__47;  // explode_generateTensors_arrayA > transposeTensor_19 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__145;  // explode_generateTensors_arrayA > transposeTensor_6 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__167;  // explode_generateTensors_arrayB > multiplyTensors_253 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__48;  // explode_generateTensors_arrayB > multiplyTensors_248 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__256;  // explode_generateTensors_arrayB > multiplyTensors_247 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__33;  // explode_generateTensors_arrayB > multiplyTensors_239 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__0;  // explode_generateTensors_arrayB > multiplyTensors_238 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__16;  // explode_generateTensors_arrayB > multiplyTensors_232 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__9;  // explode_generateTensors_arrayB > multiplyTensors_215 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__194;  // explode_generateTensors_arrayB > multiplyTensors_212 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__135;  // explode_generateTensors_arrayB > multiplyTensors_210 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__176;  // explode_generateTensors_arrayB > multiplyTensors_209 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__184;  // explode_generateTensors_arrayB > multiplyTensors_208 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__115;  // explode_generateTensors_arrayB > multiplyTensors_190 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__14;  // explode_generateTensors_arrayB > multiplyTensors_189 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__182;  // explode_generateTensors_arrayB > multiplyTensors_188 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__133;  // explode_generateTensors_arrayB > multiplyTensors_187 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__152;  // explode_generateTensors_arrayB > multiplyTensors_185 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__274;  // explode_generateTensors_arrayB > multiplyTensors_175 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__210;  // explode_generateTensors_arrayB > multiplyTensors_172 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__246;  // explode_generateTensors_arrayB > multiplyTensors_171 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__178;  // explode_generateTensors_arrayB > multiplyTensors_167 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__235;  // explode_generateTensors_arrayB > multiplyTensors_165 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__150;  // explode_generateTensors_arrayB > multiplyTensors_163 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__155;  // explode_generateTensors_arrayB > multiplyTensors_160 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__22;  // explode_generateTensors_arrayB > multiplyTensors_158 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__257;  // explode_generateTensors_arrayB > multiplyTensors_157 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__103;  // explode_generateTensors_arrayB > multiplyTensors_155 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__130;  // explode_generateTensors_arrayB > multiplyTensors_151 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__26;  // explode_generateTensors_arrayB > multiplyTensors_146 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__64;  // explode_generateTensors_arrayB > multiplyTensors_145 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__54;  // explode_generateTensors_arrayB > multiplyTensors_82 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__73;  // explode_generateTensors_arrayB > multiplyTensors_80 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__36;  // explode_generateTensors_arrayB > multiplyTensors_62 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__77;  // explode_generateTensors_arrayB > multiplyTensors_61 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__147;  // explode_generateTensors_arrayB > multiplyTensors_58 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__38;  // explode_generateTensors_arrayB > multiplyTensors_51 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__239;  // explode_generateTensors_arrayB > multiplyTensors_48 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__123;  // explode_generateTensors_arrayB > multiplyTensors_36 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__204;  // explode_generateTensors_arrayB > multiplyTensors_24 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__50;  // explode_generateTensors_arrayB > multiplyTensors_20 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__181;  // explode_generateTensors_arrayB > multiplyTensors_18 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__21;  // explode_generateTensors_arrayB > multiplyTensors_16 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__252;  // explode_generateTensors_arrayB > multiplyTensors_4 size:= 32*char defined in Core0
extern char *const transposeTensor_10__explode___0;  // transposeTensor_10 > explode_transposeTensor_10_output size:= 256*char defined in Core0
extern int *const arrayA_1216__input__0;  // explode_generateTensors_arrayA_arrayA_1216 > transposeTensor_19_input size:= 64*int defined in Core0
extern int *const output__arrayA__18;  // transposeTensor_19_output > explode_transposeTensor_19_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_19__explode___0;  // transposeTensor_19 > explode_transposeTensor_19_output size:= 256*char defined in Core0
extern int *const arrayA_1344__input__0;  // explode_generateTensors_arrayA_arrayA_1344 > transposeTensor_21_input size:= 64*int defined in Core0
extern int *const output__arrayA__11;  // transposeTensor_21_output > explode_transposeTensor_21_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_21__explode___0;  // transposeTensor_21 > explode_transposeTensor_21_output size:= 256*char defined in Core0
extern int *const arrayA_1408__input__0;  // explode_generateTensors_arrayA_arrayA_1408 > transposeTensor_22_input size:= 64*int defined in Core0
extern int *const output__arrayA__1;  // transposeTensor_22_output > explode_transposeTensor_22_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_22__explode___0;  // transposeTensor_22 > explode_transposeTensor_22_output size:= 256*char defined in Core0
extern char *const transposeTensor_26__explode___0;  // transposeTensor_26 > explode_transposeTensor_26_output size:= 256*char defined in Core0
extern char *const transposeTensor_29__explode___0;  // transposeTensor_29 > explode_transposeTensor_29_output size:= 256*char defined in Core0
extern int *const arrayA_1984__input__0;  // explode_generateTensors_arrayA_arrayA_1984 > transposeTensor_31_input size:= 64*int defined in Core0
extern int *const output__arrayA__23;  // transposeTensor_31_output > explode_transposeTensor_31_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_31__explode___0;  // transposeTensor_31 > explode_transposeTensor_31_output size:= 256*char defined in Core0
extern int *const arrayA_384__input__0;  // explode_generateTensors_arrayA_arrayA_384 > transposeTensor_6_input size:= 64*int defined in Core0
extern int *const output__arrayA__0;  // transposeTensor_6_output > explode_transposeTensor_6_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_0_ou__6;  // explode_transposeTensor_0_output > multiplyTensors_4 size:= 32*char defined in Core0
extern int *const output_0__arrayA__8;  // explode_transposeTensor_10_output_output_0 > multiplyTensors_80_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__29;  // explode_transposeTensor_10_output_output_8 > multiplyTensors_81_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__28;  // explode_transposeTensor_10_output_output_16 > multiplyTensors_82_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__9;  // explode_transposeTensor_10_output_output_24 > multiplyTensors_83_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__26;  // explode_transposeTensor_10_output_output_32 > multiplyTensors_84_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__6;  // explode_transposeTensor_10_output_output_40 > multiplyTensors_85_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__24;  // explode_transposeTensor_10_output_output_48 > multiplyTensors_86_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__28;  // explode_transposeTensor_10_output_output_56 > multiplyTensors_87_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__5;  // transposeTensor_10_output > explode_transposeTensor_10_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_10_o__6;  // explode_transposeTensor_10_output > multiplyTensors_87 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__5;  // explode_transposeTensor_10_output > multiplyTensors_86 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__0;  // explode_transposeTensor_10_output > multiplyTensors_85 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__4;  // explode_transposeTensor_10_output > multiplyTensors_84 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__1;  // explode_transposeTensor_10_output > multiplyTensors_83 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__7;  // explode_transposeTensor_10_output > multiplyTensors_81 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_18_o__6;  // explode_transposeTensor_18_output > multiplyTensors_151 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_18_o__5;  // explode_transposeTensor_18_output > multiplyTensors_146 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_18_o__2;  // explode_transposeTensor_18_output > multiplyTensors_145 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_19_o__7;  // explode_transposeTensor_19_output > multiplyTensors_158 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_19_o__1;  // explode_transposeTensor_19_output > multiplyTensors_157 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_19_o__6;  // explode_transposeTensor_19_output > multiplyTensors_155 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_20_o__0;  // explode_transposeTensor_20_output > multiplyTensors_167 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_20_o__6;  // explode_transposeTensor_20_output > multiplyTensors_165 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_20_o__2;  // explode_transposeTensor_20_output > multiplyTensors_163 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_20_o__7;  // explode_transposeTensor_20_output > multiplyTensors_160 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_21_o__7;  // explode_transposeTensor_21_output > multiplyTensors_175 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_21_o__2;  // explode_transposeTensor_21_output > multiplyTensors_172 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_21_o__4;  // explode_transposeTensor_21_output > multiplyTensors_171 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_23_o__7;  // explode_transposeTensor_23_output > multiplyTensors_190 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_23_o__5;  // explode_transposeTensor_23_output > multiplyTensors_189 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_23_o__2;  // explode_transposeTensor_23_output > multiplyTensors_188 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_23_o__0;  // explode_transposeTensor_23_output > multiplyTensors_187 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_23_o__6;  // explode_transposeTensor_23_output > multiplyTensors_185 size:= 32*char defined in Core0
extern int *const output_0__arrayA__22;  // explode_transposeTensor_26_output_output_0 > multiplyTensors_208_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__30;  // explode_transposeTensor_26_output_output_8 > multiplyTensors_209_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__26;  // explode_transposeTensor_26_output_output_16 > multiplyTensors_210_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__22;  // explode_transposeTensor_26_output_output_24 > multiplyTensors_211_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__16;  // explode_transposeTensor_26_output_output_32 > multiplyTensors_212_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__10;  // explode_transposeTensor_26_output_output_40 > multiplyTensors_213_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__7;  // explode_transposeTensor_26_output_output_48 > multiplyTensors_214_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__25;  // explode_transposeTensor_26_output_output_56 > multiplyTensors_215_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__7;  // transposeTensor_26_output > explode_transposeTensor_26_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_26_o__0;  // explode_transposeTensor_26_output > multiplyTensors_214 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_26_o__1;  // explode_transposeTensor_26_output > multiplyTensors_213 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_26_o__5;  // explode_transposeTensor_26_output > multiplyTensors_211 size:= 32*char defined in Core0
extern int *const output_0__arrayA__7;  // explode_transposeTensor_29_output_output_0 > multiplyTensors_232_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__23;  // explode_transposeTensor_29_output_output_8 > multiplyTensors_233_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__0;  // explode_transposeTensor_29_output_output_16 > multiplyTensors_234_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__30;  // explode_transposeTensor_29_output_output_24 > multiplyTensors_235_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__17;  // explode_transposeTensor_29_output_output_32 > multiplyTensors_236_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__15;  // explode_transposeTensor_29_output_output_40 > multiplyTensors_237_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__23;  // explode_transposeTensor_29_output_output_48 > multiplyTensors_238_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__29;  // explode_transposeTensor_29_output_output_56 > multiplyTensors_239_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__22;  // transposeTensor_29_output > explode_transposeTensor_29_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_29_o__3;  // explode_transposeTensor_29_output > multiplyTensors_237 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_29_o__2;  // explode_transposeTensor_29_output > multiplyTensors_236 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_29_o__7;  // explode_transposeTensor_29_output > multiplyTensors_235 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_29_o__0;  // explode_transposeTensor_29_output > multiplyTensors_234 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_29_o__4;  // explode_transposeTensor_29_output > multiplyTensors_233 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__7;  // explode_transposeTensor_2_output > multiplyTensors_20 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__6;  // explode_transposeTensor_2_output > multiplyTensors_18 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__0;  // explode_transposeTensor_2_output > multiplyTensors_16 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_30_o__3;  // explode_transposeTensor_30_output > multiplyTensors_247 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_31_o__6;  // explode_transposeTensor_31_output > multiplyTensors_253 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_31_o__5;  // explode_transposeTensor_31_output > multiplyTensors_248 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__3;  // explode_transposeTensor_3_output > multiplyTensors_24 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__6;  // explode_transposeTensor_4_output > multiplyTensors_36 size:= 32*char defined in Core0
extern int *const output_0__arrayA__1;  // explode_transposeTensor_6_output_output_0 > multiplyTensors_48_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__17;  // explode_transposeTensor_6_output_output_8 > multiplyTensors_49_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__9;  // explode_transposeTensor_6_output_output_16 > multiplyTensors_50_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__15;  // explode_transposeTensor_6_output_output_24 > multiplyTensors_51_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__14;  // explode_transposeTensor_6_output_output_32 > multiplyTensors_52_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__7;  // explode_transposeTensor_6_output_output_40 > multiplyTensors_53_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__18;  // explode_transposeTensor_6_output_output_48 > multiplyTensors_54_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__3;  // explode_transposeTensor_6_output_output_56 > multiplyTensors_55_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_6_ou__1;  // explode_transposeTensor_6_output > multiplyTensors_55 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_6_ou__7;  // explode_transposeTensor_6_output > multiplyTensors_54 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_6_ou__2;  // explode_transposeTensor_6_output > multiplyTensors_53 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_6_ou__5;  // explode_transposeTensor_6_output > multiplyTensors_52 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_6_ou__4;  // explode_transposeTensor_6_output > multiplyTensors_50 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_6_ou__6;  // explode_transposeTensor_6_output > multiplyTensors_49 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_7_ou__0;  // explode_transposeTensor_7_output > multiplyTensors_62 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_7_ou__1;  // explode_transposeTensor_7_output > multiplyTensors_61 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_7_ou__6;  // explode_transposeTensor_7_output > multiplyTensors_58 size:= 32*char defined in Core0
extern char *const multiplyTensors_0__implode_s__0;  // multiplyTensors_0 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_1__implode_s__0;  // multiplyTensors_1 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_112__implode__0;  // multiplyTensors_112 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_113__implode__0;  // multiplyTensors_113 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_114__implode__0;  // multiplyTensors_114 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_115__implode__0;  // multiplyTensors_115 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_116__implode__0;  // multiplyTensors_116 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_117__implode__0;  // multiplyTensors_117 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_118__implode__0;  // multiplyTensors_118 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_119__implode__0;  // multiplyTensors_119 > implode_sumResults_14_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__18;  // explode_transposeTensor_18_output_output_8 > multiplyTensors_145_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1160__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1160 > multiplyTensors_145_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__17;  // multiplyTensors_145_arrayC > implode_sumResults_18_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_145__implode__0;  // multiplyTensors_145 > implode_sumResults_18_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__29;  // explode_transposeTensor_18_output_output_16 > multiplyTensors_146_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1168__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1168 > multiplyTensors_146_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__17;  // multiplyTensors_146_arrayC > implode_sumResults_18_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_146__implode__0;  // multiplyTensors_146 > implode_sumResults_18_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__30;  // explode_transposeTensor_18_output_output_56 > multiplyTensors_151_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1208__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1208 > multiplyTensors_151_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__2;  // multiplyTensors_151_arrayC > implode_sumResults_18_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_151__implode__0;  // multiplyTensors_151 > implode_sumResults_18_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__24;  // explode_transposeTensor_19_output_output_24 > multiplyTensors_155_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1240__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1240 > multiplyTensors_155_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__30;  // multiplyTensors_155_arrayC > implode_sumResults_19_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_155__implode__0;  // multiplyTensors_155 > implode_sumResults_19_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__9;  // explode_transposeTensor_19_output_output_40 > multiplyTensors_157_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1256__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1256 > multiplyTensors_157_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__16;  // multiplyTensors_157_arrayC > implode_sumResults_19_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_157__implode__0;  // multiplyTensors_157 > implode_sumResults_19_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__20;  // explode_transposeTensor_19_output_output_48 > multiplyTensors_158_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1264__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1264 > multiplyTensors_158_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__17;  // multiplyTensors_158_arrayC > implode_sumResults_19_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_158__implode__0;  // multiplyTensors_158 > implode_sumResults_19_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__0;  // explode_transposeTensor_2_output_output_0 > multiplyTensors_16_arrayA size:= 8*int defined in Core0
extern int *const arrayB_128__arrayB__0;  // explode_generateTensors_arrayB_arrayB_128 > multiplyTensors_16_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__26;  // multiplyTensors_16_arrayC > implode_sumResults_2_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_16__implode___0;  // multiplyTensors_16 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__27;  // explode_transposeTensor_20_output_output_0 > multiplyTensors_160_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1280__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1280 > multiplyTensors_160_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__20;  // multiplyTensors_160_arrayC > implode_sumResults_20_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_160__implode__0;  // multiplyTensors_160 > implode_sumResults_20_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__2;  // explode_transposeTensor_20_output_output_24 > multiplyTensors_163_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1304__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1304 > multiplyTensors_163_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__3;  // multiplyTensors_163_arrayC > implode_sumResults_20_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_163__implode__0;  // multiplyTensors_163 > implode_sumResults_20_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__17;  // explode_transposeTensor_20_output_output_40 > multiplyTensors_165_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1320__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1320 > multiplyTensors_165_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__22;  // multiplyTensors_165_arrayC > implode_sumResults_20_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_165__implode__0;  // multiplyTensors_165 > implode_sumResults_20_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__1;  // explode_transposeTensor_20_output_output_56 > multiplyTensors_167_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1336__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1336 > multiplyTensors_167_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__16;  // multiplyTensors_167_arrayC > implode_sumResults_20_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_167__implode__0;  // multiplyTensors_167 > implode_sumResults_20_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__17;  // explode_transposeTensor_21_output_output_24 > multiplyTensors_171_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1368__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1368 > multiplyTensors_171_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__27;  // multiplyTensors_171_arrayC > implode_sumResults_21_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_171__implode__0;  // multiplyTensors_171 > implode_sumResults_21_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__2;  // explode_transposeTensor_21_output_output_32 > multiplyTensors_172_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1376__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1376 > multiplyTensors_172_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__17;  // multiplyTensors_172_arrayC > implode_sumResults_21_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_172__implode__0;  // multiplyTensors_172 > implode_sumResults_21_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__26;  // explode_transposeTensor_21_output_output_56 > multiplyTensors_175_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1400__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1400 > multiplyTensors_175_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__7;  // multiplyTensors_175_arrayC > implode_sumResults_21_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_175__implode__0;  // multiplyTensors_175 > implode_sumResults_21_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__25;  // explode_transposeTensor_2_output_output_16 > multiplyTensors_18_arrayA size:= 8*int defined in Core0
extern int *const arrayB_144__arrayB__0;  // explode_generateTensors_arrayB_arrayB_144 > multiplyTensors_18_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__27;  // multiplyTensors_18_arrayC > implode_sumResults_2_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_18__implode___0;  // multiplyTensors_18 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__25;  // explode_transposeTensor_23_output_output_8 > multiplyTensors_185_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1480__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1480 > multiplyTensors_185_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__13;  // multiplyTensors_185_arrayC > implode_sumResults_23_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_185__implode__0;  // multiplyTensors_185 > implode_sumResults_23_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__4;  // explode_transposeTensor_23_output_output_24 > multiplyTensors_187_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1496__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1496 > multiplyTensors_187_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__14;  // multiplyTensors_187_arrayC > implode_sumResults_23_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_187__implode__0;  // multiplyTensors_187 > implode_sumResults_23_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__13;  // explode_transposeTensor_23_output_output_32 > multiplyTensors_188_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1504__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1504 > multiplyTensors_188_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__2;  // multiplyTensors_188_arrayC > implode_sumResults_23_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_188__implode__0;  // multiplyTensors_188 > implode_sumResults_23_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__14;  // explode_transposeTensor_23_output_output_40 > multiplyTensors_189_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1512__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1512 > multiplyTensors_189_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__3;  // multiplyTensors_189_arrayC > implode_sumResults_23_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_189__implode__0;  // multiplyTensors_189 > implode_sumResults_23_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__31;  // explode_transposeTensor_23_output_output_48 > multiplyTensors_190_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1520__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1520 > multiplyTensors_190_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__8;  // multiplyTensors_190_arrayC > implode_sumResults_23_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_190__implode__0;  // multiplyTensors_190 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_2__implode_s__0;  // multiplyTensors_2 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__31;  // explode_transposeTensor_2_output_output_32 > multiplyTensors_20_arrayA size:= 8*int defined in Core0
extern int *const arrayB_160__arrayB__0;  // explode_generateTensors_arrayB_arrayB_160 > multiplyTensors_20_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__15;  // multiplyTensors_20_arrayC > implode_sumResults_2_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_20__implode___0;  // multiplyTensors_20 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const arrayB_1664__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1664 > multiplyTensors_208_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__25;  // multiplyTensors_208_arrayC > implode_sumResults_26_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_208__implode__0;  // multiplyTensors_208 > implode_sumResults_26_input size:= 256*char defined in Core0
extern int *const arrayB_1672__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1672 > multiplyTensors_209_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__15;  // multiplyTensors_209_arrayC > implode_sumResults_26_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_209__implode__0;  // multiplyTensors_209 > implode_sumResults_26_input size:= 256*char defined in Core0
extern int *const arrayB_1680__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1680 > multiplyTensors_210_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__15;  // multiplyTensors_210_arrayC > implode_sumResults_26_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_210__implode__0;  // multiplyTensors_210 > implode_sumResults_26_input size:= 256*char defined in Core0
extern int *const arrayB_1696__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1696 > multiplyTensors_212_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__16;  // multiplyTensors_212_arrayC > implode_sumResults_26_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_212__implode__0;  // multiplyTensors_212 > implode_sumResults_26_input size:= 256*char defined in Core0
extern int *const arrayB_1720__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1720 > multiplyTensors_215_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__27;  // multiplyTensors_215_arrayC > implode_sumResults_26_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_215__implode__0;  // multiplyTensors_215 > implode_sumResults_26_input size:= 256*char defined in Core0
extern int *const arrayB_1856__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1856 > multiplyTensors_232_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__10;  // multiplyTensors_232_arrayC > implode_sumResults_29_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_232__implode__0;  // multiplyTensors_232 > implode_sumResults_29_input size:= 256*char defined in Core0
extern int *const arrayB_1904__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1904 > multiplyTensors_238_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__22;  // multiplyTensors_238_arrayC > implode_sumResults_29_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_238__implode__0;  // multiplyTensors_238 > implode_sumResults_29_input size:= 256*char defined in Core0
extern int *const arrayB_1912__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1912 > multiplyTensors_239_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__9;  // multiplyTensors_239_arrayC > implode_sumResults_29_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_239__implode__0;  // multiplyTensors_239 > implode_sumResults_29_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__9;  // explode_transposeTensor_3_output_output_0 > multiplyTensors_24_arrayA size:= 8*int defined in Core0
extern int *const arrayB_192__arrayB__0;  // explode_generateTensors_arrayB_arrayB_192 > multiplyTensors_24_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__5;  // multiplyTensors_24_arrayC > implode_sumResults_3_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_24__implode___0;  // multiplyTensors_24 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__12;  // explode_transposeTensor_30_output_output_56 > multiplyTensors_247_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1976__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1976 > multiplyTensors_247_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__14;  // multiplyTensors_247_arrayC > implode_sumResults_30_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_247__implode__0;  // multiplyTensors_247 > implode_sumResults_30_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__21;  // explode_transposeTensor_31_output_output_0 > multiplyTensors_248_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1984__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1984 > multiplyTensors_248_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__6;  // multiplyTensors_248_arrayC > implode_sumResults_31_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_248__implode__0;  // multiplyTensors_248 > implode_sumResults_31_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__20;  // explode_transposeTensor_31_output_output_40 > multiplyTensors_253_arrayA size:= 8*int defined in Core0
extern int *const arrayB_2024__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2024 > multiplyTensors_253_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__7;  // multiplyTensors_253_arrayC > implode_sumResults_31_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_253__implode__0;  // multiplyTensors_253 > implode_sumResults_31_input size:= 256*char defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_32__implode___0;  // multiplyTensors_32 > implode_sumResults_4_input size:= 256*char defined in Core0
extern char *const multiplyTensors_33__implode___0;  // multiplyTensors_33 > implode_sumResults_4_input size:= 256*char defined in Core0
extern char *const multiplyTensors_34__implode___0;  // multiplyTensors_34 > implode_sumResults_4_input size:= 256*char defined in Core0
extern char *const multiplyTensors_35__implode___0;  // multiplyTensors_35 > implode_sumResults_4_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__22;  // explode_transposeTensor_4_output_output_32 > multiplyTensors_36_arrayA size:= 8*int defined in Core0
extern int *const arrayB_288__arrayB__0;  // explode_generateTensors_arrayB_arrayB_288 > multiplyTensors_36_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__21;  // multiplyTensors_36_arrayC > implode_sumResults_4_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_37__implode___0;  // multiplyTensors_37 > implode_sumResults_4_input size:= 256*char defined in Core0
extern char *const multiplyTensors_38__implode___0;  // multiplyTensors_38 > implode_sumResults_4_input size:= 256*char defined in Core0
extern char *const multiplyTensors_39__implode___0;  // multiplyTensors_39 > implode_sumResults_4_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__28;  // explode_transposeTensor_0_output_output_32 > multiplyTensors_4_arrayA size:= 8*int defined in Core0
extern int *const arrayB_32__arrayB__0;  // explode_generateTensors_arrayB_arrayB_32 > multiplyTensors_4_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__9;  // multiplyTensors_4_arrayC > implode_sumResults_0_input_input_256 size:= 64*long defined in Core0
extern int *const arrayB_384__arrayB__0;  // explode_generateTensors_arrayB_arrayB_384 > multiplyTensors_48_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__3;  // multiplyTensors_48_arrayC > implode_sumResults_6_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_48__implode___0;  // multiplyTensors_48 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_5__implode_s__0;  // multiplyTensors_5 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const arrayB_408__arrayB__0;  // explode_generateTensors_arrayB_arrayB_408 > multiplyTensors_51_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__12;  // multiplyTensors_51_arrayC > implode_sumResults_6_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_51__implode___0;  // multiplyTensors_51 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__12;  // explode_transposeTensor_7_output_output_16 > multiplyTensors_58_arrayA size:= 8*int defined in Core0
extern int *const arrayB_464__arrayB__0;  // explode_generateTensors_arrayB_arrayB_464 > multiplyTensors_58_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__23;  // multiplyTensors_58_arrayC > implode_sumResults_7_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_58__implode___0;  // multiplyTensors_58 > implode_sumResults_7_input size:= 256*char defined in Core0
extern char *const multiplyTensors_6__implode_s__0;  // multiplyTensors_6 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__2;  // explode_transposeTensor_7_output_output_40 > multiplyTensors_61_arrayA size:= 8*int defined in Core0
extern int *const arrayB_488__arrayB__0;  // explode_generateTensors_arrayB_arrayB_488 > multiplyTensors_61_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__12;  // multiplyTensors_61_arrayC > implode_sumResults_7_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_61__implode___0;  // multiplyTensors_61 > implode_sumResults_7_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__1;  // explode_transposeTensor_7_output_output_48 > multiplyTensors_62_arrayA size:= 8*int defined in Core0
extern int *const arrayB_496__arrayB__0;  // explode_generateTensors_arrayB_arrayB_496 > multiplyTensors_62_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__11;  // multiplyTensors_62_arrayC > implode_sumResults_7_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_62__implode___0;  // multiplyTensors_62 > implode_sumResults_7_input size:= 256*char defined in Core0
extern char *const multiplyTensors_7__implode_s__0;  // multiplyTensors_7 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const arrayB_640__arrayB__0;  // explode_generateTensors_arrayB_arrayB_640 > multiplyTensors_80_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__11;  // multiplyTensors_80_arrayC > implode_sumResults_10_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_80__implode___0;  // multiplyTensors_80 > implode_sumResults_10_input size:= 256*char defined in Core0
extern int *const arrayB_656__arrayB__0;  // explode_generateTensors_arrayB_arrayB_656 > multiplyTensors_82_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__8;  // multiplyTensors_82_arrayC > implode_sumResults_10_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_82__implode___0;  // multiplyTensors_82 > implode_sumResults_10_input size:= 256*char defined in Core0
extern long *const arrayC__input_0__31;  // multiplyTensors_0_arrayC > implode_sumResults_0_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__23;  // multiplyTensors_1_arrayC > implode_sumResults_0_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__30;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__11;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_320__26;  // multiplyTensors_5_arrayC > implode_sumResults_0_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__1;  // multiplyTensors_6_arrayC > implode_sumResults_0_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__29;  // multiplyTensors_7_arrayC > implode_sumResults_0_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__2;  // implode_sumResults_0_input_arrayC > sumResults_0_input size:= 512*long defined in Core0
extern char *const implode_sumResults_0_input____0;  // implode_sumResults_0_input > sumResults_0 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__2;  // multiplyTensors_112_arrayC > implode_sumResults_14_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__21;  // multiplyTensors_113_arrayC > implode_sumResults_14_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__26;  // multiplyTensors_114_arrayC > implode_sumResults_14_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__28;  // multiplyTensors_115_arrayC > implode_sumResults_14_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__1;  // multiplyTensors_116_arrayC > implode_sumResults_14_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__18;  // multiplyTensors_117_arrayC > implode_sumResults_14_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__23;  // multiplyTensors_118_arrayC > implode_sumResults_14_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__21;  // multiplyTensors_119_arrayC > implode_sumResults_14_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__29;  // implode_sumResults_14_input_arrayC > sumResults_14_input size:= 512*long defined in Core0
extern char *const implode_sumResults_14_input___0;  // implode_sumResults_14_input > sumResults_14 size:= 2048*char defined in Core0
extern char *const implode_sumResults_19_input___0;  // implode_sumResults_19_input > sumResults_19 size:= 2048*char defined in Core0
extern char *const implode_sumResults_20_input___0;  // implode_sumResults_20_input > sumResults_20 size:= 2048*char defined in Core0
extern char *const implode_sumResults_22_input___0;  // implode_sumResults_22_input > sumResults_22 size:= 2048*char defined in Core0
extern char *const implode_sumResults_26_input___0;  // implode_sumResults_26_input > sumResults_26 size:= 2048*char defined in Core0
extern char *const implode_sumResults_29_input___0;  // implode_sumResults_29_input > sumResults_29 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__12;  // multiplyTensors_32_arrayC > implode_sumResults_4_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__1;  // multiplyTensors_33_arrayC > implode_sumResults_4_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__12;  // multiplyTensors_34_arrayC > implode_sumResults_4_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__6;  // multiplyTensors_35_arrayC > implode_sumResults_4_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_320__8;  // multiplyTensors_37_arrayC > implode_sumResults_4_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__0;  // multiplyTensors_38_arrayC > implode_sumResults_4_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__8;  // multiplyTensors_39_arrayC > implode_sumResults_4_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__21;  // implode_sumResults_4_input_arrayC > sumResults_4_input size:= 512*long defined in Core0
extern char *const implode_sumResults_5_input____0;  // implode_sumResults_5_input > sumResults_5 size:= 2048*char defined in Core0
extern long *const arrayC__input__11;  // implode_sumResults_19_input_arrayC > sumResults_19_input size:= 512*long defined in Core0
extern long *const output__arrayC_1216__0;  // sumResults_19_output > implode_displayTensor_arrayC_arrayC_1216 size:= 64*long defined in Core0
extern char *const sumResults_19__implode_displ__0;  // sumResults_19 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__1;  // implode_sumResults_20_input_arrayC > sumResults_20_input size:= 512*long defined in Core0
extern long *const output__arrayC_1280__0;  // sumResults_20_output > implode_displayTensor_arrayC_arrayC_1280 size:= 64*long defined in Core0
extern char *const sumResults_20__implode_displ__0;  // sumResults_20 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__18;  // implode_sumResults_22_input_arrayC > sumResults_22_input size:= 512*long defined in Core0
extern long *const output__arrayC_1408__0;  // sumResults_22_output > implode_displayTensor_arrayC_arrayC_1408 size:= 64*long defined in Core0
extern char *const sumResults_22__implode_displ__0;  // sumResults_22 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__6;  // implode_sumResults_26_input_arrayC > sumResults_26_input size:= 512*long defined in Core0
extern long *const output__arrayC_1664__0;  // sumResults_26_output > implode_displayTensor_arrayC_arrayC_1664 size:= 64*long defined in Core0
extern char *const sumResults_26__implode_displ__0;  // sumResults_26 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__17;  // implode_sumResults_29_input_arrayC > sumResults_29_input size:= 512*long defined in Core0
extern long *const output__arrayC_1856__0;  // sumResults_29_output > implode_displayTensor_arrayC_arrayC_1856 size:= 64*long defined in Core0
extern char *const sumResults_29__implode_displ__0;  // sumResults_29 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const output__arrayC_256__0;  // sumResults_4_output > implode_displayTensor_arrayC_arrayC_256 size:= 64*long defined in Core0
extern char *const sumResults_4__implode_displa__0;  // sumResults_4 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__7;  // implode_sumResults_5_input_arrayC > sumResults_5_input size:= 512*long defined in Core0
extern long *const output__arrayC_320__0;  // sumResults_5_output > implode_displayTensor_arrayC_arrayC_320 size:= 64*long defined in Core0
extern char *const sumResults_5__implode_displa__0;  // sumResults_5 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core5(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__201 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__201 
		cache_inv(explode_generateTensors_arra__201, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__98 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__98 
		cache_inv(explode_generateTensors_arra__98, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__8 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__8 
		cache_inv(explode_generateTensors_arra__8, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__47 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__47 
		cache_inv(explode_generateTensors_arra__47, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__145 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__145 
		cache_inv(explode_generateTensors_arra__145, 256*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__167 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__167 
		cache_inv(explode_generateTensors_arra__167, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__48 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__48 
		cache_inv(explode_generateTensors_arra__48, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__256 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__256 
		cache_inv(explode_generateTensors_arra__256, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__33 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__33 
		cache_inv(explode_generateTensors_arra__33, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__0 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__0 
		cache_inv(explode_generateTensors_arra__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__16 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__16 
		cache_inv(explode_generateTensors_arra__16, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__9 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__9 
		cache_inv(explode_generateTensors_arra__9, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__194 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__194 
		cache_inv(explode_generateTensors_arra__194, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__135 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__135 
		cache_inv(explode_generateTensors_arra__135, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__176 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__176 
		cache_inv(explode_generateTensors_arra__176, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__184 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__184 
		cache_inv(explode_generateTensors_arra__184, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__115 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__115 
		cache_inv(explode_generateTensors_arra__115, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__14 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__14 
		cache_inv(explode_generateTensors_arra__14, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__182 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__182 
		cache_inv(explode_generateTensors_arra__182, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__133 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__133 
		cache_inv(explode_generateTensors_arra__133, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__152 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__152 
		cache_inv(explode_generateTensors_arra__152, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__274 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__274 
		cache_inv(explode_generateTensors_arra__274, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__210 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__210 
		cache_inv(explode_generateTensors_arra__210, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__246 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__246 
		cache_inv(explode_generateTensors_arra__246, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__178 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__178 
		cache_inv(explode_generateTensors_arra__178, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__235 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__235 
		cache_inv(explode_generateTensors_arra__235, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__150 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__150 
		cache_inv(explode_generateTensors_arra__150, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__155 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__155 
		cache_inv(explode_generateTensors_arra__155, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__22 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__22 
		cache_inv(explode_generateTensors_arra__22, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__257 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__257 
		cache_inv(explode_generateTensors_arra__257, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__103 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__103 
		cache_inv(explode_generateTensors_arra__103, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__130 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__130 
		cache_inv(explode_generateTensors_arra__130, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__26 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__26 
		cache_inv(explode_generateTensors_arra__26, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__64 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__64 
		cache_inv(explode_generateTensors_arra__64, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__54 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__54 
		cache_inv(explode_generateTensors_arra__54, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__73 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__73 
		cache_inv(explode_generateTensors_arra__73, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__36 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__36 
		cache_inv(explode_generateTensors_arra__36, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__77 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__77 
		cache_inv(explode_generateTensors_arra__77, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__147 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__147 
		cache_inv(explode_generateTensors_arra__147, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__38 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__38 
		cache_inv(explode_generateTensors_arra__38, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__239 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__239 
		cache_inv(explode_generateTensors_arra__239, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__123 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__123 
		cache_inv(explode_generateTensors_arra__123, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__204 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__204 
		cache_inv(explode_generateTensors_arra__204, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__50 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__50 
		cache_inv(explode_generateTensors_arra__50, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__181 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__181 
		cache_inv(explode_generateTensors_arra__181, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__21 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__21 
		cache_inv(explode_generateTensors_arra__21, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__252 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__252 
		cache_inv(explode_generateTensors_arra__252, 32*sizeof(char));
		receiveStart(); // Core1 > Core5: transposeTensor_10__explode___0 
		receiveEnd(1); // Core1 > Core5: transposeTensor_10__explode___0 
		cache_inv(transposeTensor_10__explode___0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_1216__input__0,output__arrayA__18); // transposeTensor_19
		cache_inv(arrayA_1216__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_19__explode___0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: transposeTensor_19__explode___0 
		sendEnd(); // Core5 > Core1: transposeTensor_19__explode___0 
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_1344__input__0,output__arrayA__11); // transposeTensor_21
		cache_inv(arrayA_1344__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_21__explode___0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: transposeTensor_21__explode___0 
		sendEnd(); // Core5 > Core4: transposeTensor_21__explode___0 
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_1408__input__0,output__arrayA__1); // transposeTensor_22
		cache_inv(arrayA_1408__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_22__explode___0, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: transposeTensor_22__explode___0 
		sendEnd(); // Core5 > Core7: transposeTensor_22__explode___0 
		receiveStart(); // Core4 > Core5: transposeTensor_26__explode___0 
		receiveEnd(4); // Core4 > Core5: transposeTensor_26__explode___0 
		cache_inv(transposeTensor_26__explode___0, 256*sizeof(char));
		receiveStart(); // Core6 > Core5: transposeTensor_29__explode___0 
		receiveEnd(6); // Core6 > Core5: transposeTensor_29__explode___0 
		cache_inv(transposeTensor_29__explode___0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_1984__input__0,output__arrayA__23); // transposeTensor_31
		cache_inv(arrayA_1984__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_31__explode___0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: transposeTensor_31__explode___0 
		sendEnd(); // Core5 > Core3: transposeTensor_31__explode___0 
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_384__input__0,output__arrayA__0); // transposeTensor_6
		cache_inv(arrayA_384__input__0, 64*sizeof(int));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_0_ou__6 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_0_ou__6 
		cache_inv(explode_transposeTensor_0_ou__6, 32*sizeof(char));
		// Fork explode_transposeTensor_10_output
		{
			cache_wb(output__arrayA__5, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__5) + 0, 256);
		cache_inv(output__arrayA__5, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_10_o__6, 32*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_10_o__6 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_10_o__6 
		cache_wbInv(explode_transposeTensor_10_o__5, 32*sizeof(char));
		sendStart(2); // Core5 > Core2: explode_transposeTensor_10_o__5 
		sendEnd(); // Core5 > Core2: explode_transposeTensor_10_o__5 
		cache_wbInv(explode_transposeTensor_10_o__0, 32*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_10_o__0 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_10_o__0 
		cache_wbInv(explode_transposeTensor_10_o__4, 32*sizeof(char));
		sendStart(2); // Core5 > Core2: explode_transposeTensor_10_o__4 
		sendEnd(); // Core5 > Core2: explode_transposeTensor_10_o__4 
		cache_wbInv(explode_transposeTensor_10_o__1, 32*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_10_o__1 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_10_o__1 
		cache_wbInv(explode_transposeTensor_10_o__7, 32*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_10_o__7 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_10_o__7 
		receiveStart(); // Core1 > Core5: explode_transposeTensor_18_o__6 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_18_o__6 
		cache_inv(explode_transposeTensor_18_o__6, 32*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_18_o__5 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_18_o__5 
		cache_inv(explode_transposeTensor_18_o__5, 32*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_18_o__2 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_18_o__2 
		cache_inv(explode_transposeTensor_18_o__2, 32*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_19_o__7 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_19_o__7 
		cache_inv(explode_transposeTensor_19_o__7, 32*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_19_o__1 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_19_o__1 
		cache_inv(explode_transposeTensor_19_o__1, 32*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_19_o__6 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_19_o__6 
		cache_inv(explode_transposeTensor_19_o__6, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_20_o__0 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_20_o__0 
		cache_inv(explode_transposeTensor_20_o__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_20_o__6 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_20_o__6 
		cache_inv(explode_transposeTensor_20_o__6, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_20_o__2 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_20_o__2 
		cache_inv(explode_transposeTensor_20_o__2, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_20_o__7 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_20_o__7 
		cache_inv(explode_transposeTensor_20_o__7, 32*sizeof(char));
		receiveStart(); // Core4 > Core5: explode_transposeTensor_21_o__7 
		receiveEnd(4); // Core4 > Core5: explode_transposeTensor_21_o__7 
		cache_inv(explode_transposeTensor_21_o__7, 32*sizeof(char));
		receiveStart(); // Core4 > Core5: explode_transposeTensor_21_o__2 
		receiveEnd(4); // Core4 > Core5: explode_transposeTensor_21_o__2 
		cache_inv(explode_transposeTensor_21_o__2, 32*sizeof(char));
		receiveStart(); // Core4 > Core5: explode_transposeTensor_21_o__4 
		receiveEnd(4); // Core4 > Core5: explode_transposeTensor_21_o__4 
		cache_inv(explode_transposeTensor_21_o__4, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_transposeTensor_23_o__7 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_23_o__7 
		cache_inv(explode_transposeTensor_23_o__7, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_transposeTensor_23_o__5 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_23_o__5 
		cache_inv(explode_transposeTensor_23_o__5, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_transposeTensor_23_o__2 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_23_o__2 
		cache_inv(explode_transposeTensor_23_o__2, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_transposeTensor_23_o__0 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_23_o__0 
		cache_inv(explode_transposeTensor_23_o__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_transposeTensor_23_o__6 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_23_o__6 
		cache_inv(explode_transposeTensor_23_o__6, 32*sizeof(char));
		// Fork explode_transposeTensor_26_output
		{
			cache_wb(output__arrayA__7, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__7) + 0, 256);
		cache_inv(output__arrayA__7, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_26_o__0, 32*sizeof(char));
		sendStart(4); // Core5 > Core4: explode_transposeTensor_26_o__0 
		sendEnd(); // Core5 > Core4: explode_transposeTensor_26_o__0 
		cache_wbInv(explode_transposeTensor_26_o__1, 32*sizeof(char));
		sendStart(4); // Core5 > Core4: explode_transposeTensor_26_o__1 
		sendEnd(); // Core5 > Core4: explode_transposeTensor_26_o__1 
		cache_wbInv(explode_transposeTensor_26_o__5, 32*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_26_o__5 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_26_o__5 
		// Fork explode_transposeTensor_29_output
		{
			cache_wb(output__arrayA__22, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__22) + 0, 256);
		cache_inv(output__arrayA__22, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_29_o__3, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_29_o__3 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_29_o__3 
		cache_wbInv(explode_transposeTensor_29_o__2, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_29_o__2 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_29_o__2 
		cache_wbInv(explode_transposeTensor_29_o__7, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_29_o__7 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_29_o__7 
		cache_wbInv(explode_transposeTensor_29_o__0, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_29_o__0 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_29_o__0 
		cache_wbInv(explode_transposeTensor_29_o__4, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_29_o__4 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_29_o__4 
		receiveStart(); // Core7 > Core5: explode_transposeTensor_2_ou__7 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_2_ou__7 
		cache_inv(explode_transposeTensor_2_ou__7, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_transposeTensor_2_ou__6 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_2_ou__6 
		cache_inv(explode_transposeTensor_2_ou__6, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_transposeTensor_2_ou__0 
		receiveEnd(7); // Core7 > Core5: explode_transposeTensor_2_ou__0 
		cache_inv(explode_transposeTensor_2_ou__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core5: explode_transposeTensor_30_o__3 
		receiveEnd(2); // Core2 > Core5: explode_transposeTensor_30_o__3 
		cache_inv(explode_transposeTensor_30_o__3, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_31_o__6 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_31_o__6 
		cache_inv(explode_transposeTensor_31_o__6, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_31_o__5 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_31_o__5 
		cache_inv(explode_transposeTensor_31_o__5, 32*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_transposeTensor_3_ou__3 
		receiveEnd(0); // Core0 > Core5: explode_transposeTensor_3_ou__3 
		cache_inv(explode_transposeTensor_3_ou__3, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_4_ou__6 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_4_ou__6 
		cache_inv(explode_transposeTensor_4_ou__6, 32*sizeof(char));
		// Fork explode_transposeTensor_6_output
		{
			cache_wb(output__arrayA__0, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__0) + 0, 256);
		cache_inv(output__arrayA__0, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_6_ou__1, 32*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_6_ou__1 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_6_ou__1 
		cache_wbInv(explode_transposeTensor_6_ou__7, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_6_ou__7 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_6_ou__7 
		cache_wbInv(explode_transposeTensor_6_ou__2, 32*sizeof(char));
		sendStart(3); // Core5 > Core3: explode_transposeTensor_6_ou__2 
		sendEnd(); // Core5 > Core3: explode_transposeTensor_6_ou__2 
		cache_wbInv(explode_transposeTensor_6_ou__5, 32*sizeof(char));
		sendStart(2); // Core5 > Core2: explode_transposeTensor_6_ou__5 
		sendEnd(); // Core5 > Core2: explode_transposeTensor_6_ou__5 
		cache_wbInv(explode_transposeTensor_6_ou__4, 32*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_6_ou__4 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_6_ou__4 
		cache_wbInv(explode_transposeTensor_6_ou__6, 32*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_6_ou__6 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_6_ou__6 
		receiveStart(); // Core6 > Core5: explode_transposeTensor_7_ou__0 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_7_ou__0 
		cache_inv(explode_transposeTensor_7_ou__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_7_ou__1 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_7_ou__1 
		cache_inv(explode_transposeTensor_7_ou__1, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_7_ou__6 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_7_ou__6 
		cache_inv(explode_transposeTensor_7_ou__6, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: multiplyTensors_0__implode_s__0 
		receiveEnd(6); // Core6 > Core5: multiplyTensors_0__implode_s__0 
		cache_inv(multiplyTensors_0__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core5: multiplyTensors_1__implode_s__0 
		receiveEnd(6); // Core6 > Core5: multiplyTensors_1__implode_s__0 
		cache_inv(multiplyTensors_1__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_112__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_112__implode__0 
		cache_inv(multiplyTensors_112__implode__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_113__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_113__implode__0 
		cache_inv(multiplyTensors_113__implode__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_114__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_114__implode__0 
		cache_inv(multiplyTensors_114__implode__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_115__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_115__implode__0 
		cache_inv(multiplyTensors_115__implode__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_116__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_116__implode__0 
		cache_inv(multiplyTensors_116__implode__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_117__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_117__implode__0 
		cache_inv(multiplyTensors_117__implode__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_118__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_118__implode__0 
		cache_inv(multiplyTensors_118__implode__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_119__implode__0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_119__implode__0 
		cache_inv(multiplyTensors_119__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_8__arrayA__18,arrayB_1160__arrayB__0,arrayC__input_64__17); // multiplyTensors_145
		cache_inv(output_8__arrayA__18, 8*sizeof(int));
		cache_inv(arrayB_1160__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_145__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_145__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_145__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__29,arrayB_1168__arrayB__0,arrayC__input_128__17); // multiplyTensors_146
		cache_inv(output_16__arrayA__29, 8*sizeof(int));
		cache_inv(arrayB_1168__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_146__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_146__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_146__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__30,arrayB_1208__arrayB__0,arrayC__input_448__2); // multiplyTensors_151
		cache_inv(output_56__arrayA__30, 8*sizeof(int));
		cache_inv(arrayB_1208__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_151__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_151__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_151__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__24,arrayB_1240__arrayB__0,arrayC__input_192__30); // multiplyTensors_155
		cache_inv(output_24__arrayA__24, 8*sizeof(int));
		cache_inv(arrayB_1240__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_155__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_155__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_155__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__9,arrayB_1256__arrayB__0,arrayC__input_320__16); // multiplyTensors_157
		cache_inv(output_40__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_1256__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_157__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_157__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_157__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__20,arrayB_1264__arrayB__0,arrayC__input_384__17); // multiplyTensors_158
		cache_inv(output_48__arrayA__20, 8*sizeof(int));
		cache_inv(arrayB_1264__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_158__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_158__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_158__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__0,arrayB_128__arrayB__0,arrayC__input_0__26); // multiplyTensors_16
		cache_inv(output_0__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_128__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_16__implode___0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: multiplyTensors_16__implode___0 
		sendEnd(); // Core5 > Core2: multiplyTensors_16__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__27,arrayB_1280__arrayB__0,arrayC__input_0__20); // multiplyTensors_160
		cache_inv(output_0__arrayA__27, 8*sizeof(int));
		cache_inv(arrayB_1280__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_160__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_160__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_160__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__2,arrayB_1304__arrayB__0,arrayC__input_192__3); // multiplyTensors_163
		cache_inv(output_24__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_1304__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_163__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_163__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_163__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__17,arrayB_1320__arrayB__0,arrayC__input_320__22); // multiplyTensors_165
		cache_inv(output_40__arrayA__17, 8*sizeof(int));
		cache_inv(arrayB_1320__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_165__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_165__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_165__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__1,arrayB_1336__arrayB__0,arrayC__input_448__16); // multiplyTensors_167
		cache_inv(output_56__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_1336__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_167__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_167__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_167__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__17,arrayB_1368__arrayB__0,arrayC__input_192__27); // multiplyTensors_171
		cache_inv(output_24__arrayA__17, 8*sizeof(int));
		cache_inv(arrayB_1368__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_171__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_171__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_171__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__2,arrayB_1376__arrayB__0,arrayC__input_256__17); // multiplyTensors_172
		cache_inv(output_32__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_1376__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_172__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_172__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_172__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__26,arrayB_1400__arrayB__0,arrayC__input_448__7); // multiplyTensors_175
		cache_inv(output_56__arrayA__26, 8*sizeof(int));
		cache_inv(arrayB_1400__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_175__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_175__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_175__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__25,arrayB_144__arrayB__0,arrayC__input_128__27); // multiplyTensors_18
		cache_inv(output_16__arrayA__25, 8*sizeof(int));
		cache_inv(arrayB_144__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_18__implode___0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: multiplyTensors_18__implode___0 
		sendEnd(); // Core5 > Core2: multiplyTensors_18__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_8__arrayA__25,arrayB_1480__arrayB__0,arrayC__input_64__13); // multiplyTensors_185
		cache_inv(output_8__arrayA__25, 8*sizeof(int));
		cache_inv(arrayB_1480__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_185__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_185__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_185__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__4,arrayB_1496__arrayB__0,arrayC__input_192__14); // multiplyTensors_187
		cache_inv(output_24__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_1496__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_187__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_187__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_187__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__13,arrayB_1504__arrayB__0,arrayC__input_256__2); // multiplyTensors_188
		cache_inv(output_32__arrayA__13, 8*sizeof(int));
		cache_inv(arrayB_1504__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_188__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_188__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_188__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__14,arrayB_1512__arrayB__0,arrayC__input_320__3); // multiplyTensors_189
		cache_inv(output_40__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_1512__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_189__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_189__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_189__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__31,arrayB_1520__arrayB__0,arrayC__input_384__8); // multiplyTensors_190
		cache_inv(output_48__arrayA__31, 8*sizeof(int));
		cache_inv(arrayB_1520__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_190__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_190__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_190__implode__0 
		receiveStart(); // Core3 > Core5: multiplyTensors_2__implode_s__0 
		receiveEnd(3); // Core3 > Core5: multiplyTensors_2__implode_s__0 
		cache_inv(multiplyTensors_2__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__31,arrayB_160__arrayB__0,arrayC__input_256__15); // multiplyTensors_20
		cache_inv(output_32__arrayA__31, 8*sizeof(int));
		cache_inv(arrayB_160__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_20__implode___0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: multiplyTensors_20__implode___0 
		sendEnd(); // Core5 > Core2: multiplyTensors_20__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__22,arrayB_1664__arrayB__0,arrayC__input_0__25); // multiplyTensors_208
		cache_inv(output_0__arrayA__22, 8*sizeof(int));
		cache_inv(arrayB_1664__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_208__implode__0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_208__implode__0 
		sendEnd(); // Core5 > Core0: multiplyTensors_208__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_8__arrayA__30,arrayB_1672__arrayB__0,arrayC__input_64__15); // multiplyTensors_209
		cache_inv(output_8__arrayA__30, 8*sizeof(int));
		cache_inv(arrayB_1672__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_209__implode__0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_209__implode__0 
		sendEnd(); // Core5 > Core0: multiplyTensors_209__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__26,arrayB_1680__arrayB__0,arrayC__input_128__15); // multiplyTensors_210
		cache_inv(output_16__arrayA__26, 8*sizeof(int));
		cache_inv(arrayB_1680__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_210__implode__0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_210__implode__0 
		sendEnd(); // Core5 > Core0: multiplyTensors_210__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__16,arrayB_1696__arrayB__0,arrayC__input_256__16); // multiplyTensors_212
		cache_inv(output_32__arrayA__16, 8*sizeof(int));
		cache_inv(arrayB_1696__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_212__implode__0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_212__implode__0 
		sendEnd(); // Core5 > Core0: multiplyTensors_212__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__25,arrayB_1720__arrayB__0,arrayC__input_448__27); // multiplyTensors_215
		cache_inv(output_56__arrayA__25, 8*sizeof(int));
		cache_inv(arrayB_1720__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_215__implode__0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_215__implode__0 
		sendEnd(); // Core5 > Core0: multiplyTensors_215__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__7,arrayB_1856__arrayB__0,arrayC__input_0__10); // multiplyTensors_232
		cache_inv(output_0__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_1856__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_232__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_232__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_232__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__23,arrayB_1904__arrayB__0,arrayC__input_384__22); // multiplyTensors_238
		cache_inv(output_48__arrayA__23, 8*sizeof(int));
		cache_inv(arrayB_1904__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_238__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_238__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_238__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__29,arrayB_1912__arrayB__0,arrayC__input_448__9); // multiplyTensors_239
		cache_inv(output_56__arrayA__29, 8*sizeof(int));
		cache_inv(arrayB_1912__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_239__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_239__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_239__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__9,arrayB_192__arrayB__0,arrayC__input_0__5); // multiplyTensors_24
		cache_inv(output_0__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_192__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_24__implode___0, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_24__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_24__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__12,arrayB_1976__arrayB__0,arrayC__input_448__14); // multiplyTensors_247
		cache_inv(output_56__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_1976__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_247__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_247__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_247__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__21,arrayB_1984__arrayB__0,arrayC__input_0__6); // multiplyTensors_248
		cache_inv(output_0__arrayA__21, 8*sizeof(int));
		cache_inv(arrayB_1984__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_248__implode__0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: multiplyTensors_248__implode__0 
		sendEnd(); // Core5 > Core2: multiplyTensors_248__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__20,arrayB_2024__arrayB__0,arrayC__input_320__7); // multiplyTensors_253
		cache_inv(output_40__arrayA__20, 8*sizeof(int));
		cache_inv(arrayB_2024__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_253__implode__0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: multiplyTensors_253__implode__0 
		sendEnd(); // Core5 > Core2: multiplyTensors_253__implode__0 
		receiveStart(); // Core6 > Core5: multiplyTensors_3__implode_s__0 
		receiveEnd(6); // Core6 > Core5: multiplyTensors_3__implode_s__0 
		cache_inv(multiplyTensors_3__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core5: multiplyTensors_32__implode___0 
		receiveEnd(6); // Core6 > Core5: multiplyTensors_32__implode___0 
		cache_inv(multiplyTensors_32__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: multiplyTensors_33__implode___0 
		receiveEnd(1); // Core1 > Core5: multiplyTensors_33__implode___0 
		cache_inv(multiplyTensors_33__implode___0, 256*sizeof(char));
		receiveStart(); // Core6 > Core5: multiplyTensors_34__implode___0 
		receiveEnd(6); // Core6 > Core5: multiplyTensors_34__implode___0 
		cache_inv(multiplyTensors_34__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core5: multiplyTensors_35__implode___0 
		receiveEnd(3); // Core3 > Core5: multiplyTensors_35__implode___0 
		cache_inv(multiplyTensors_35__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__22,arrayB_288__arrayB__0,arrayC__input_256__21); // multiplyTensors_36
		cache_inv(output_32__arrayA__22, 8*sizeof(int));
		cache_inv(arrayB_288__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core1 > Core5: multiplyTensors_37__implode___0 
		receiveEnd(1); // Core1 > Core5: multiplyTensors_37__implode___0 
		cache_inv(multiplyTensors_37__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core5: multiplyTensors_38__implode___0 
		receiveEnd(3); // Core3 > Core5: multiplyTensors_38__implode___0 
		cache_inv(multiplyTensors_38__implode___0, 256*sizeof(char));
		receiveStart(); // Core2 > Core5: multiplyTensors_39__implode___0 
		receiveEnd(2); // Core2 > Core5: multiplyTensors_39__implode___0 
		cache_inv(multiplyTensors_39__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__28,arrayB_32__arrayB__0,arrayC__input_256__9); // multiplyTensors_4
		cache_inv(output_32__arrayA__28, 8*sizeof(int));
		cache_inv(arrayB_32__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__1,arrayB_384__arrayB__0,arrayC__input_0__3); // multiplyTensors_48
		cache_inv(output_0__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_384__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_48__implode___0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_48__implode___0 
		sendEnd(); // Core5 > Core0: multiplyTensors_48__implode___0 
		receiveStart(); // Core6 > Core5: multiplyTensors_5__implode_s__0 
		receiveEnd(6); // Core6 > Core5: multiplyTensors_5__implode_s__0 
		cache_inv(multiplyTensors_5__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__15,arrayB_408__arrayB__0,arrayC__input_192__12); // multiplyTensors_51
		cache_inv(output_24__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_408__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_51__implode___0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_51__implode___0 
		sendEnd(); // Core5 > Core0: multiplyTensors_51__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__12,arrayB_464__arrayB__0,arrayC__input_128__23); // multiplyTensors_58
		cache_inv(output_16__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_464__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_58__implode___0, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_58__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_58__implode___0 
		receiveStart(); // Core3 > Core5: multiplyTensors_6__implode_s__0 
		receiveEnd(3); // Core3 > Core5: multiplyTensors_6__implode_s__0 
		cache_inv(multiplyTensors_6__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__2,arrayB_488__arrayB__0,arrayC__input_320__12); // multiplyTensors_61
		cache_inv(output_40__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_488__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_61__implode___0, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_61__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_61__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__1,arrayB_496__arrayB__0,arrayC__input_384__11); // multiplyTensors_62
		cache_inv(output_48__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_496__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_62__implode___0, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_62__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_62__implode___0 
		receiveStart(); // Core6 > Core5: multiplyTensors_7__implode_s__0 
		receiveEnd(6); // Core6 > Core5: multiplyTensors_7__implode_s__0 
		cache_inv(multiplyTensors_7__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__8,arrayB_640__arrayB__0,arrayC__input_0__11); // multiplyTensors_80
		cache_inv(output_0__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_640__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_80__implode___0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: multiplyTensors_80__implode___0 
		sendEnd(); // Core5 > Core1: multiplyTensors_80__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__28,arrayB_656__arrayB__0,arrayC__input_128__8); // multiplyTensors_82
		cache_inv(output_16__arrayA__28, 8*sizeof(int));
		cache_inv(arrayB_656__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_82__implode___0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: multiplyTensors_82__implode___0 
		sendEnd(); // Core5 > Core1: multiplyTensors_82__implode___0 
		// Join implode_sumResults_0_input
		{
			cache_wb(arrayC__input_0__31, 64*sizeof(long));
			memcpy((void*)(arrayC__input__2+64),(void*)( arrayC__input_64__23+0), 64*sizeof(long));
			cache_wb(arrayC__input_128__30, 64*sizeof(long));
			memcpy((void*)(arrayC__input__2+192),(void*)( arrayC__input_192__11+0), 64*sizeof(long));
			cache_wb(arrayC__input_256__9, 64*sizeof(long));
			memcpy((void*)(arrayC__input__2+320),(void*)( arrayC__input_320__26+0), 64*sizeof(long));
			cache_wb(arrayC__input_384__1, 64*sizeof(long));
			memcpy((void*)(arrayC__input__2+448),(void*)( arrayC__input_448__29+0), 64*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__31) + 0, 256);
		cache_inv(arrayC__input_0__31, 64*sizeof(long));
		cache_inv(arrayC__input_64__23, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_128__30) + 0, 256);
		cache_inv(arrayC__input_128__30, 64*sizeof(long));
		cache_inv(arrayC__input_192__11, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_256__9) + 0, 256);
		cache_inv(arrayC__input_256__9, 64*sizeof(long));
		cache_inv(arrayC__input_320__26, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_384__1) + 0, 256);
		cache_inv(arrayC__input_384__1, 64*sizeof(long));
		cache_inv(arrayC__input_448__29, 64*sizeof(long));
		cache_wbInv(implode_sumResults_0_input____0, 2048*sizeof(char));
		sendStart(3); // Core5 > Core3: implode_sumResults_0_input____0 
		sendEnd(); // Core5 > Core3: implode_sumResults_0_input____0 
		// Join implode_sumResults_14_input
		{
			cache_wb(arrayC__input_0__2, 64*sizeof(long));
			memcpy((void*)(arrayC__input__29+64),(void*)( arrayC__input_64__21+0), 64*sizeof(long));
			cache_wb(arrayC__input_128__26, 64*sizeof(long));
			memcpy((void*)(arrayC__input__29+192),(void*)( arrayC__input_192__28+0), 64*sizeof(long));
			cache_wb(arrayC__input_256__1, 64*sizeof(long));
			memcpy((void*)(arrayC__input__29+320),(void*)( arrayC__input_320__18+0), 64*sizeof(long));
			cache_wb(arrayC__input_384__23, 64*sizeof(long));
			memcpy((void*)(arrayC__input__29+448),(void*)( arrayC__input_448__21+0), 64*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__2) + 0, 256);
		cache_inv(arrayC__input_0__2, 64*sizeof(long));
		cache_inv(arrayC__input_64__21, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_128__26) + 0, 256);
		cache_inv(arrayC__input_128__26, 64*sizeof(long));
		cache_inv(arrayC__input_192__28, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_256__1) + 0, 256);
		cache_inv(arrayC__input_256__1, 64*sizeof(long));
		cache_inv(arrayC__input_320__18, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_384__23) + 0, 256);
		cache_inv(arrayC__input_384__23, 64*sizeof(long));
		cache_inv(arrayC__input_448__21, 64*sizeof(long));
		cache_wbInv(implode_sumResults_14_input___0, 2048*sizeof(char));
		sendStart(3); // Core5 > Core3: implode_sumResults_14_input___0 
		sendEnd(); // Core5 > Core3: implode_sumResults_14_input___0 
		receiveStart(); // Core4 > Core5: implode_sumResults_19_input___0 
		receiveEnd(4); // Core4 > Core5: implode_sumResults_19_input___0 
		cache_inv(implode_sumResults_19_input___0, 2048*sizeof(char));
		receiveStart(); // Core4 > Core5: implode_sumResults_20_input___0 
		receiveEnd(4); // Core4 > Core5: implode_sumResults_20_input___0 
		cache_inv(implode_sumResults_20_input___0, 2048*sizeof(char));
		receiveStart(); // Core0 > Core5: implode_sumResults_22_input___0 
		receiveEnd(0); // Core0 > Core5: implode_sumResults_22_input___0 
		cache_inv(implode_sumResults_22_input___0, 2048*sizeof(char));
		receiveStart(); // Core0 > Core5: implode_sumResults_26_input___0 
		receiveEnd(0); // Core0 > Core5: implode_sumResults_26_input___0 
		cache_inv(implode_sumResults_26_input___0, 2048*sizeof(char));
		receiveStart(); // Core6 > Core5: implode_sumResults_29_input___0 
		receiveEnd(6); // Core6 > Core5: implode_sumResults_29_input___0 
		cache_inv(implode_sumResults_29_input___0, 2048*sizeof(char));
		// Join implode_sumResults_4_input
		{
			cache_wb(arrayC__input_0__12, 64*sizeof(long));
			memcpy((void*)(arrayC__input__21+64),(void*)( arrayC__input_64__1+0), 64*sizeof(long));
			cache_wb(arrayC__input_128__12, 64*sizeof(long));
			memcpy((void*)(arrayC__input__21+192),(void*)( arrayC__input_192__6+0), 64*sizeof(long));
			cache_wb(arrayC__input_256__21, 64*sizeof(long));
			memcpy((void*)(arrayC__input__21+320),(void*)( arrayC__input_320__8+0), 64*sizeof(long));
			cache_wb(arrayC__input_384__0, 64*sizeof(long));
			memcpy((void*)(arrayC__input__21+448),(void*)( arrayC__input_448__8+0), 64*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__12) + 0, 256);
		cache_inv(arrayC__input_0__12, 64*sizeof(long));
		cache_inv(arrayC__input_64__1, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_128__12) + 0, 256);
		cache_inv(arrayC__input_128__12, 64*sizeof(long));
		cache_inv(arrayC__input_192__6, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_256__21) + 0, 256);
		cache_inv(arrayC__input_256__21, 64*sizeof(long));
		cache_inv(arrayC__input_320__8, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_384__0) + 0, 256);
		cache_inv(arrayC__input_384__0, 64*sizeof(long));
		cache_inv(arrayC__input_448__8, 64*sizeof(long));
		receiveStart(); // Core4 > Core5: implode_sumResults_5_input____0 
		receiveEnd(4); // Core4 > Core5: implode_sumResults_5_input____0 
		cache_inv(implode_sumResults_5_input____0, 2048*sizeof(char));
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__11,output__arrayC_1216__0); // sumResults_19
		cache_inv(arrayC__input__11, 512*sizeof(long));
		cache_wbInv(sumResults_19__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: sumResults_19__implode_displ__0 
		sendEnd(); // Core5 > Core1: sumResults_19__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__1,output__arrayC_1280__0); // sumResults_20
		cache_inv(arrayC__input__1, 512*sizeof(long));
		cache_wbInv(sumResults_20__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: sumResults_20__implode_displ__0 
		sendEnd(); // Core5 > Core1: sumResults_20__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__18,output__arrayC_1408__0); // sumResults_22
		cache_inv(arrayC__input__18, 512*sizeof(long));
		cache_wbInv(sumResults_22__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: sumResults_22__implode_displ__0 
		sendEnd(); // Core5 > Core1: sumResults_22__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__6,output__arrayC_1664__0); // sumResults_26
		cache_inv(arrayC__input__6, 512*sizeof(long));
		cache_wbInv(sumResults_26__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: sumResults_26__implode_displ__0 
		sendEnd(); // Core5 > Core1: sumResults_26__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__17,output__arrayC_1856__0); // sumResults_29
		cache_inv(arrayC__input__17, 512*sizeof(long));
		cache_wbInv(sumResults_29__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: sumResults_29__implode_displ__0 
		sendEnd(); // Core5 > Core1: sumResults_29__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__21,output__arrayC_256__0); // sumResults_4
		cache_inv(arrayC__input__21, 512*sizeof(long));
		cache_wbInv(sumResults_4__implode_displa__0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: sumResults_4__implode_displa__0 
		sendEnd(); // Core5 > Core1: sumResults_4__implode_displa__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__7,output__arrayC_320__0); // sumResults_5
		cache_inv(arrayC__input__7, 512*sizeof(long));
		cache_wbInv(sumResults_5__implode_displa__0, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: sumResults_5__implode_displa__0 
		sendEnd(); // Core5 > Core1: sumResults_5__implode_displa__0 
	}
}
