/** 
 * @file Core3.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 23:59:39 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__227;  // explode_generateTensors_arrayA > transposeTensor_28 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__206;  // explode_generateTensors_arrayA > transposeTensor_14 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__5;  // explode_generateTensors_arrayA > transposeTensor_5 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__168;  // explode_generateTensors_arrayA > transposeTensor_0 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__280;  // explode_generateTensors_arrayB > multiplyTensors_254 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__30;  // explode_generateTensors_arrayB > multiplyTensors_250 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__106;  // explode_generateTensors_arrayB > multiplyTensors_241 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__267;  // explode_generateTensors_arrayB > multiplyTensors_230 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__282;  // explode_generateTensors_arrayB > multiplyTensors_229 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__40;  // explode_generateTensors_arrayB > multiplyTensors_228 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__189;  // explode_generateTensors_arrayB > multiplyTensors_227 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__263;  // explode_generateTensors_arrayB > multiplyTensors_225 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__68;  // explode_generateTensors_arrayB > multiplyTensors_222 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__228;  // explode_generateTensors_arrayB > multiplyTensors_199 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__71;  // explode_generateTensors_arrayB > multiplyTensors_192 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__240;  // explode_generateTensors_arrayB > multiplyTensors_140 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__249;  // explode_generateTensors_arrayB > multiplyTensors_139 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__109;  // explode_generateTensors_arrayB > multiplyTensors_138 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__195;  // explode_generateTensors_arrayB > multiplyTensors_136 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__140;  // explode_generateTensors_arrayB > multiplyTensors_125 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__209;  // explode_generateTensors_arrayB > multiplyTensors_120 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__80;  // explode_generateTensors_arrayB > multiplyTensors_111 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayB > multiplyTensors_107 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__158;  // explode_generateTensors_arrayB > multiplyTensors_105 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__62;  // explode_generateTensors_arrayB > multiplyTensors_53 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__278;  // explode_generateTensors_arrayB > multiplyTensors_47 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__200;  // explode_generateTensors_arrayB > multiplyTensors_46 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__18;  // explode_generateTensors_arrayB > multiplyTensors_43 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__19;  // explode_generateTensors_arrayB > multiplyTensors_42 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__243;  // explode_generateTensors_arrayB > multiplyTensors_40 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__156;  // explode_generateTensors_arrayB > multiplyTensors_38 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__146;  // explode_generateTensors_arrayB > multiplyTensors_35 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__224;  // explode_generateTensors_arrayB > multiplyTensors_29 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__65;  // explode_generateTensors_arrayB > multiplyTensors_10 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__260;  // explode_generateTensors_arrayB > multiplyTensors_9 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__112;  // explode_generateTensors_arrayB > multiplyTensors_6 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__75;  // explode_generateTensors_arrayB > multiplyTensors_2 size:= 32*char defined in Core0
extern int *const arrayA_0__input__0;  // explode_generateTensors_arrayA_arrayA_0 > transposeTensor_0_input size:= 64*int defined in Core0
extern int *const output__arrayA__20;  // transposeTensor_0_output > explode_transposeTensor_0_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_13__explode___0;  // transposeTensor_13 > explode_transposeTensor_13_output size:= 256*char defined in Core0
extern int *const arrayA_896__input__0;  // explode_generateTensors_arrayA_arrayA_896 > transposeTensor_14_input size:= 64*int defined in Core0
extern int *const output__arrayA__17;  // transposeTensor_14_output > explode_transposeTensor_14_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_17__explode___0;  // transposeTensor_17 > explode_transposeTensor_17_output size:= 256*char defined in Core0
extern int *const arrayA_1792__input__0;  // explode_generateTensors_arrayA_arrayA_1792 > transposeTensor_28_input size:= 64*int defined in Core0
extern int *const output__arrayA__29;  // transposeTensor_28_output > explode_transposeTensor_28_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_28__explode___0;  // transposeTensor_28 > explode_transposeTensor_28_output size:= 256*char defined in Core0
extern char *const transposeTensor_31__explode___0;  // transposeTensor_31 > explode_transposeTensor_31_output size:= 256*char defined in Core0
extern char *const transposeTensor_4__explode_t__0;  // transposeTensor_4 > explode_transposeTensor_4_output size:= 256*char defined in Core0
extern int *const arrayA_320__input__0;  // explode_generateTensors_arrayA_arrayA_320 > transposeTensor_5_input size:= 64*int defined in Core0
extern int *const output__arrayA__14;  // transposeTensor_5_output > explode_transposeTensor_5_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_5__explode_t__0;  // transposeTensor_5 > explode_transposeTensor_5_output size:= 256*char defined in Core0
extern int *const output_0__arrayA__29;  // explode_transposeTensor_0_output_output_0 > multiplyTensors_0_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__27;  // explode_transposeTensor_0_output_output_8 > multiplyTensors_1_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__19;  // explode_transposeTensor_0_output_output_16 > multiplyTensors_2_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__7;  // explode_transposeTensor_0_output_output_24 > multiplyTensors_3_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__28;  // explode_transposeTensor_0_output_output_32 > multiplyTensors_4_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__31;  // explode_transposeTensor_0_output_output_40 > multiplyTensors_5_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__9;  // explode_transposeTensor_0_output_output_48 > multiplyTensors_6_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__0;  // explode_transposeTensor_0_output_output_56 > multiplyTensors_7_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_0_ou__0;  // explode_transposeTensor_0_output > multiplyTensors_7 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__7;  // explode_transposeTensor_0_output > multiplyTensors_5 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__6;  // explode_transposeTensor_0_output > multiplyTensors_4 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__1;  // explode_transposeTensor_0_output > multiplyTensors_3 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__5;  // explode_transposeTensor_0_output > multiplyTensors_1 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__4;  // explode_transposeTensor_0_output > multiplyTensors_0 size:= 32*char defined in Core0
extern int *const output_0__arrayA__19;  // explode_transposeTensor_13_output_output_0 > multiplyTensors_104_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__4;  // explode_transposeTensor_13_output_output_8 > multiplyTensors_105_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__21;  // explode_transposeTensor_13_output_output_16 > multiplyTensors_106_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__25;  // explode_transposeTensor_13_output_output_24 > multiplyTensors_107_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__12;  // explode_transposeTensor_13_output_output_32 > multiplyTensors_108_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__29;  // explode_transposeTensor_13_output_output_40 > multiplyTensors_109_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__14;  // explode_transposeTensor_13_output_output_48 > multiplyTensors_110_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__2;  // explode_transposeTensor_13_output_output_56 > multiplyTensors_111_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__10;  // transposeTensor_13_output > explode_transposeTensor_13_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_13_o__4;  // explode_transposeTensor_13_output > multiplyTensors_110 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__7;  // explode_transposeTensor_13_output > multiplyTensors_109 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__2;  // explode_transposeTensor_13_output > multiplyTensors_108 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__5;  // explode_transposeTensor_13_output > multiplyTensors_106 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__3;  // explode_transposeTensor_13_output > multiplyTensors_104 size:= 32*char defined in Core0
extern int *const output_0__arrayA__18;  // explode_transposeTensor_14_output_output_0 > multiplyTensors_112_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__7;  // explode_transposeTensor_14_output_output_8 > multiplyTensors_113_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__15;  // explode_transposeTensor_14_output_output_16 > multiplyTensors_114_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__18;  // explode_transposeTensor_14_output_output_24 > multiplyTensors_115_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__25;  // explode_transposeTensor_14_output_output_32 > multiplyTensors_116_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__28;  // explode_transposeTensor_14_output_output_40 > multiplyTensors_117_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__10;  // explode_transposeTensor_14_output_output_48 > multiplyTensors_118_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__11;  // explode_transposeTensor_14_output_output_56 > multiplyTensors_119_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_14_o__2;  // explode_transposeTensor_14_output > multiplyTensors_119 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__0;  // explode_transposeTensor_14_output > multiplyTensors_118 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__7;  // explode_transposeTensor_14_output > multiplyTensors_117 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__6;  // explode_transposeTensor_14_output > multiplyTensors_116 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__4;  // explode_transposeTensor_14_output > multiplyTensors_115 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__5;  // explode_transposeTensor_14_output > multiplyTensors_114 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__1;  // explode_transposeTensor_14_output > multiplyTensors_113 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__3;  // explode_transposeTensor_14_output > multiplyTensors_112 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_15_o__4;  // explode_transposeTensor_15_output > multiplyTensors_125 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_15_o__5;  // explode_transposeTensor_15_output > multiplyTensors_120 size:= 32*char defined in Core0
extern int *const output_0__arrayA__14;  // explode_transposeTensor_17_output_output_0 > multiplyTensors_136_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__9;  // explode_transposeTensor_17_output_output_8 > multiplyTensors_137_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__18;  // explode_transposeTensor_17_output_output_16 > multiplyTensors_138_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__14;  // explode_transposeTensor_17_output_output_24 > multiplyTensors_139_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__20;  // explode_transposeTensor_17_output_output_32 > multiplyTensors_140_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__4;  // explode_transposeTensor_17_output_output_40 > multiplyTensors_141_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__13;  // explode_transposeTensor_17_output_output_48 > multiplyTensors_142_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__23;  // explode_transposeTensor_17_output_output_56 > multiplyTensors_143_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__19;  // transposeTensor_17_output > explode_transposeTensor_17_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_17_o__5;  // explode_transposeTensor_17_output > multiplyTensors_143 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_17_o__4;  // explode_transposeTensor_17_output > multiplyTensors_142 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_17_o__0;  // explode_transposeTensor_17_output > multiplyTensors_141 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_17_o__1;  // explode_transposeTensor_17_output > multiplyTensors_137 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_1_ou__1;  // explode_transposeTensor_1_output > multiplyTensors_10 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_1_ou__4;  // explode_transposeTensor_1_output > multiplyTensors_9 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_24_o__3;  // explode_transposeTensor_24_output > multiplyTensors_199 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_24_o__5;  // explode_transposeTensor_24_output > multiplyTensors_192 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_27_o__3;  // explode_transposeTensor_27_output > multiplyTensors_222 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_28_o__4;  // explode_transposeTensor_28_output > multiplyTensors_230 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_28_o__0;  // explode_transposeTensor_28_output > multiplyTensors_229 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_28_o__5;  // explode_transposeTensor_28_output > multiplyTensors_228 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_28_o__1;  // explode_transposeTensor_28_output > multiplyTensors_227 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_28_o__3;  // explode_transposeTensor_28_output > multiplyTensors_225 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_30_o__2;  // explode_transposeTensor_30_output > multiplyTensors_241 size:= 32*char defined in Core0
extern int *const output_0__arrayA__21;  // explode_transposeTensor_31_output_output_0 > multiplyTensors_248_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__5;  // explode_transposeTensor_31_output_output_8 > multiplyTensors_249_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__7;  // explode_transposeTensor_31_output_output_16 > multiplyTensors_250_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__28;  // explode_transposeTensor_31_output_output_24 > multiplyTensors_251_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__11;  // explode_transposeTensor_31_output_output_32 > multiplyTensors_252_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__20;  // explode_transposeTensor_31_output_output_40 > multiplyTensors_253_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__8;  // explode_transposeTensor_31_output_output_48 > multiplyTensors_254_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__6;  // explode_transposeTensor_31_output_output_56 > multiplyTensors_255_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__23;  // transposeTensor_31_output > explode_transposeTensor_31_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_31_o__1;  // explode_transposeTensor_31_output > multiplyTensors_255 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_31_o__6;  // explode_transposeTensor_31_output > multiplyTensors_253 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_31_o__4;  // explode_transposeTensor_31_output > multiplyTensors_252 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_31_o__7;  // explode_transposeTensor_31_output > multiplyTensors_251 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_31_o__0;  // explode_transposeTensor_31_output > multiplyTensors_249 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_31_o__5;  // explode_transposeTensor_31_output > multiplyTensors_248 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__6;  // explode_transposeTensor_3_output > multiplyTensors_29 size:= 32*char defined in Core0
extern int *const output_0__arrayA__25;  // explode_transposeTensor_4_output_output_0 > multiplyTensors_32_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__28;  // explode_transposeTensor_4_output_output_8 > multiplyTensors_33_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__8;  // explode_transposeTensor_4_output_output_16 > multiplyTensors_34_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__16;  // explode_transposeTensor_4_output_output_24 > multiplyTensors_35_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__22;  // explode_transposeTensor_4_output_output_32 > multiplyTensors_36_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__3;  // explode_transposeTensor_4_output_output_40 > multiplyTensors_37_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__12;  // explode_transposeTensor_4_output_output_48 > multiplyTensors_38_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__10;  // explode_transposeTensor_4_output_output_56 > multiplyTensors_39_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__3;  // transposeTensor_4_output > explode_transposeTensor_4_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_4_ou__1;  // explode_transposeTensor_4_output > multiplyTensors_39 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__0;  // explode_transposeTensor_4_output > multiplyTensors_37 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__6;  // explode_transposeTensor_4_output > multiplyTensors_36 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__2;  // explode_transposeTensor_4_output > multiplyTensors_34 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__7;  // explode_transposeTensor_4_output > multiplyTensors_33 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__5;  // explode_transposeTensor_4_output > multiplyTensors_32 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__7;  // explode_transposeTensor_5_output > multiplyTensors_47 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__1;  // explode_transposeTensor_5_output > multiplyTensors_46 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__0;  // explode_transposeTensor_5_output > multiplyTensors_43 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__5;  // explode_transposeTensor_5_output > multiplyTensors_42 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__3;  // explode_transposeTensor_5_output > multiplyTensors_40 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_6_ou__2;  // explode_transposeTensor_6_output > multiplyTensors_53 size:= 32*char defined in Core0
extern int *const output_16__arrayA__3;  // explode_transposeTensor_1_output_output_16 > multiplyTensors_10_arrayA size:= 8*int defined in Core0
extern int *const arrayB_80__arrayB__0;  // explode_generateTensors_arrayB_arrayB_80 > multiplyTensors_10_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__31;  // multiplyTensors_10_arrayC > implode_sumResults_1_input_input_128 size:= 64*long defined in Core0
extern int *const arrayB_840__arrayB__0;  // explode_generateTensors_arrayB_arrayB_840 > multiplyTensors_105_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__24;  // multiplyTensors_105_arrayC > implode_sumResults_13_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_105__implode__0;  // multiplyTensors_105 > implode_sumResults_13_input size:= 256*char defined in Core0
extern int *const arrayB_856__arrayB__0;  // explode_generateTensors_arrayB_arrayB_856 > multiplyTensors_107_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__10;  // multiplyTensors_107_arrayC > implode_sumResults_13_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_107__implode__0;  // multiplyTensors_107 > implode_sumResults_13_input size:= 256*char defined in Core0
extern char *const multiplyTensors_11__implode___0;  // multiplyTensors_11 > implode_sumResults_1_input size:= 256*char defined in Core0
extern int *const arrayB_888__arrayB__0;  // explode_generateTensors_arrayB_arrayB_888 > multiplyTensors_111_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__11;  // multiplyTensors_111_arrayC > implode_sumResults_13_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_111__implode__0;  // multiplyTensors_111 > implode_sumResults_13_input size:= 256*char defined in Core0
extern char *const multiplyTensors_12__implode___0;  // multiplyTensors_12 > implode_sumResults_1_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__30;  // explode_transposeTensor_15_output_output_0 > multiplyTensors_120_arrayA size:= 8*int defined in Core0
extern int *const arrayB_960__arrayB__0;  // explode_generateTensors_arrayB_arrayB_960 > multiplyTensors_120_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__27;  // multiplyTensors_120_arrayC > implode_sumResults_15_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_120__implode__0;  // multiplyTensors_120 > implode_sumResults_15_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__22;  // explode_transposeTensor_15_output_output_40 > multiplyTensors_125_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1000__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1000 > multiplyTensors_125_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__30;  // multiplyTensors_125_arrayC > implode_sumResults_15_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_125__implode__0;  // multiplyTensors_125 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_13__implode___0;  // multiplyTensors_13 > implode_sumResults_1_input size:= 256*char defined in Core0
extern int *const arrayB_1088__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1088 > multiplyTensors_136_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__8;  // multiplyTensors_136_arrayC > implode_sumResults_17_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_136__implode__0;  // multiplyTensors_136 > implode_sumResults_17_input size:= 256*char defined in Core0
extern int *const arrayB_1104__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1104 > multiplyTensors_138_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__2;  // multiplyTensors_138_arrayC > implode_sumResults_17_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_138__implode__0;  // multiplyTensors_138 > implode_sumResults_17_input size:= 256*char defined in Core0
extern int *const arrayB_1112__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1112 > multiplyTensors_139_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__29;  // multiplyTensors_139_arrayC > implode_sumResults_17_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_139__implode__0;  // multiplyTensors_139 > implode_sumResults_17_input size:= 256*char defined in Core0
extern char *const multiplyTensors_14__implode___0;  // multiplyTensors_14 > implode_sumResults_1_input size:= 256*char defined in Core0
extern int *const arrayB_1120__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1120 > multiplyTensors_140_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__12;  // multiplyTensors_140_arrayC > implode_sumResults_17_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_140__implode__0;  // multiplyTensors_140 > implode_sumResults_17_input size:= 256*char defined in Core0
extern char *const multiplyTensors_144__implode__0;  // multiplyTensors_144 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_145__implode__0;  // multiplyTensors_145 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_146__implode__0;  // multiplyTensors_146 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_147__implode__0;  // multiplyTensors_147 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_148__implode__0;  // multiplyTensors_148 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_149__implode__0;  // multiplyTensors_149 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_15__implode___0;  // multiplyTensors_15 > implode_sumResults_1_input size:= 256*char defined in Core0
extern char *const multiplyTensors_150__implode__0;  // multiplyTensors_150 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_151__implode__0;  // multiplyTensors_151 > implode_sumResults_18_input size:= 256*char defined in Core0
extern char *const multiplyTensors_184__implode__0;  // multiplyTensors_184 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_185__implode__0;  // multiplyTensors_185 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_186__implode__0;  // multiplyTensors_186 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_187__implode__0;  // multiplyTensors_187 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_188__implode__0;  // multiplyTensors_188 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_189__implode__0;  // multiplyTensors_189 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_190__implode__0;  // multiplyTensors_190 > implode_sumResults_23_input size:= 256*char defined in Core0
extern char *const multiplyTensors_191__implode__0;  // multiplyTensors_191 > implode_sumResults_23_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__24;  // explode_transposeTensor_24_output_output_0 > multiplyTensors_192_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1536__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1536 > multiplyTensors_192_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__13;  // multiplyTensors_192_arrayC > implode_sumResults_24_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_192__implode__0;  // multiplyTensors_192 > implode_sumResults_24_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__15;  // explode_transposeTensor_24_output_output_56 > multiplyTensors_199_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1592__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1592 > multiplyTensors_199_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__13;  // multiplyTensors_199_arrayC > implode_sumResults_24_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_199__implode__0;  // multiplyTensors_199 > implode_sumResults_24_input size:= 256*char defined in Core0
extern int *const arrayB_16__arrayB__0;  // explode_generateTensors_arrayB_arrayB_16 > multiplyTensors_2_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__30;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_2__implode_s__0;  // multiplyTensors_2 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_216__implode__0;  // multiplyTensors_216 > implode_sumResults_27_input size:= 256*char defined in Core0
extern char *const multiplyTensors_217__implode__0;  // multiplyTensors_217 > implode_sumResults_27_input size:= 256*char defined in Core0
extern char *const multiplyTensors_218__implode__0;  // multiplyTensors_218 > implode_sumResults_27_input size:= 256*char defined in Core0
extern char *const multiplyTensors_219__implode__0;  // multiplyTensors_219 > implode_sumResults_27_input size:= 256*char defined in Core0
extern char *const multiplyTensors_220__implode__0;  // multiplyTensors_220 > implode_sumResults_27_input size:= 256*char defined in Core0
extern char *const multiplyTensors_221__implode__0;  // multiplyTensors_221 > implode_sumResults_27_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__15;  // explode_transposeTensor_27_output_output_48 > multiplyTensors_222_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1776__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1776 > multiplyTensors_222_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__19;  // multiplyTensors_222_arrayC > implode_sumResults_27_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_223__implode__0;  // multiplyTensors_223 > implode_sumResults_27_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__24;  // explode_transposeTensor_28_output_output_8 > multiplyTensors_225_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1800__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1800 > multiplyTensors_225_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__29;  // multiplyTensors_225_arrayC > implode_sumResults_28_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_225__implode__0;  // multiplyTensors_225 > implode_sumResults_28_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__8;  // explode_transposeTensor_28_output_output_24 > multiplyTensors_227_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1816__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1816 > multiplyTensors_227_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__17;  // multiplyTensors_227_arrayC > implode_sumResults_28_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_227__implode__0;  // multiplyTensors_227 > implode_sumResults_28_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__27;  // explode_transposeTensor_28_output_output_32 > multiplyTensors_228_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1824__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1824 > multiplyTensors_228_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__30;  // multiplyTensors_228_arrayC > implode_sumResults_28_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_228__implode__0;  // multiplyTensors_228 > implode_sumResults_28_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__5;  // explode_transposeTensor_28_output_output_40 > multiplyTensors_229_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1832__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1832 > multiplyTensors_229_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__24;  // multiplyTensors_229_arrayC > implode_sumResults_28_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_229__implode__0;  // multiplyTensors_229 > implode_sumResults_28_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__21;  // explode_transposeTensor_28_output_output_48 > multiplyTensors_230_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1840__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1840 > multiplyTensors_230_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__24;  // multiplyTensors_230_arrayC > implode_sumResults_28_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_230__implode__0;  // multiplyTensors_230 > implode_sumResults_28_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__10;  // explode_transposeTensor_30_output_output_8 > multiplyTensors_241_arrayA size:= 8*int defined in Core0
extern int *const arrayB_1928__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1928 > multiplyTensors_241_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__10;  // multiplyTensors_241_arrayC > implode_sumResults_30_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_241__implode__0;  // multiplyTensors_241 > implode_sumResults_30_input size:= 256*char defined in Core0
extern int *const arrayB_2000__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2000 > multiplyTensors_250_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__0;  // multiplyTensors_250_arrayC > implode_sumResults_31_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_250__implode__0;  // multiplyTensors_250 > implode_sumResults_31_input size:= 256*char defined in Core0
extern int *const arrayB_2032__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2032 > multiplyTensors_254_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__3;  // multiplyTensors_254_arrayC > implode_sumResults_31_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_254__implode__0;  // multiplyTensors_254 > implode_sumResults_31_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__16;  // explode_transposeTensor_3_output_output_40 > multiplyTensors_29_arrayA size:= 8*int defined in Core0
extern int *const arrayB_232__arrayB__0;  // explode_generateTensors_arrayB_arrayB_232 > multiplyTensors_29_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__13;  // multiplyTensors_29_arrayC > implode_sumResults_3_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_29__implode___0;  // multiplyTensors_29 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const arrayB_280__arrayB__0;  // explode_generateTensors_arrayB_arrayB_280 > multiplyTensors_35_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__6;  // multiplyTensors_35_arrayC > implode_sumResults_4_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_35__implode___0;  // multiplyTensors_35 > implode_sumResults_4_input size:= 256*char defined in Core0
extern int *const arrayB_304__arrayB__0;  // explode_generateTensors_arrayB_arrayB_304 > multiplyTensors_38_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__0;  // multiplyTensors_38_arrayC > implode_sumResults_4_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_38__implode___0;  // multiplyTensors_38 > implode_sumResults_4_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__16;  // explode_transposeTensor_5_output_output_0 > multiplyTensors_40_arrayA size:= 8*int defined in Core0
extern int *const arrayB_320__arrayB__0;  // explode_generateTensors_arrayB_arrayB_320 > multiplyTensors_40_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__18;  // multiplyTensors_40_arrayC > implode_sumResults_5_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_40__implode___0;  // multiplyTensors_40 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__11;  // explode_transposeTensor_5_output_output_16 > multiplyTensors_42_arrayA size:= 8*int defined in Core0
extern int *const arrayB_336__arrayB__0;  // explode_generateTensors_arrayB_arrayB_336 > multiplyTensors_42_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__5;  // multiplyTensors_42_arrayC > implode_sumResults_5_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_42__implode___0;  // multiplyTensors_42 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__5;  // explode_transposeTensor_5_output_output_24 > multiplyTensors_43_arrayA size:= 8*int defined in Core0
extern int *const arrayB_344__arrayB__0;  // explode_generateTensors_arrayB_arrayB_344 > multiplyTensors_43_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__31;  // multiplyTensors_43_arrayC > implode_sumResults_5_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_43__implode___0;  // multiplyTensors_43 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__5;  // explode_transposeTensor_5_output_output_48 > multiplyTensors_46_arrayA size:= 8*int defined in Core0
extern int *const arrayB_368__arrayB__0;  // explode_generateTensors_arrayB_arrayB_368 > multiplyTensors_46_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__31;  // multiplyTensors_46_arrayC > implode_sumResults_5_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_46__implode___0;  // multiplyTensors_46 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__31;  // explode_transposeTensor_5_output_output_56 > multiplyTensors_47_arrayA size:= 8*int defined in Core0
extern int *const arrayB_376__arrayB__0;  // explode_generateTensors_arrayB_arrayB_376 > multiplyTensors_47_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__19;  // multiplyTensors_47_arrayC > implode_sumResults_5_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_47__implode___0;  // multiplyTensors_47 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__7;  // explode_transposeTensor_6_output_output_40 > multiplyTensors_53_arrayA size:= 8*int defined in Core0
extern int *const arrayB_424__arrayB__0;  // explode_generateTensors_arrayB_arrayB_424 > multiplyTensors_53_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__0;  // multiplyTensors_53_arrayC > implode_sumResults_6_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_53__implode___0;  // multiplyTensors_53 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const arrayB_48__arrayB__0;  // explode_generateTensors_arrayB_arrayB_48 > multiplyTensors_6_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__1;  // multiplyTensors_6_arrayC > implode_sumResults_0_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_6__implode_s__0;  // multiplyTensors_6 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_8__implode_s__0;  // multiplyTensors_8 > implode_sumResults_1_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__14;  // explode_transposeTensor_1_output_output_8 > multiplyTensors_9_arrayA size:= 8*int defined in Core0
extern int *const arrayB_72__arrayB__0;  // explode_generateTensors_arrayB_arrayB_72 > multiplyTensors_9_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__19;  // multiplyTensors_9_arrayC > implode_sumResults_1_input_input_64 size:= 64*long defined in Core0
extern char *const implode_sumResults_0_input____0;  // implode_sumResults_0_input > sumResults_0 size:= 2048*char defined in Core0
extern char *const implode_sumResults_14_input___0;  // implode_sumResults_14_input > sumResults_14 size:= 2048*char defined in Core0
extern char *const implode_sumResults_15_input___0;  // implode_sumResults_15_input > sumResults_15 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__7;  // multiplyTensors_144_arrayC > implode_sumResults_18_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__17;  // multiplyTensors_145_arrayC > implode_sumResults_18_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__17;  // multiplyTensors_146_arrayC > implode_sumResults_18_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__26;  // multiplyTensors_147_arrayC > implode_sumResults_18_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__28;  // multiplyTensors_148_arrayC > implode_sumResults_18_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__20;  // multiplyTensors_149_arrayC > implode_sumResults_18_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__4;  // multiplyTensors_150_arrayC > implode_sumResults_18_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__2;  // multiplyTensors_151_arrayC > implode_sumResults_18_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__22;  // implode_sumResults_18_input_arrayC > sumResults_18_input size:= 512*long defined in Core0
extern char *const implode_sumResults_18_input___0;  // implode_sumResults_18_input > sumResults_18 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__22;  // multiplyTensors_8_arrayC > implode_sumResults_1_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_192__4;  // multiplyTensors_11_arrayC > implode_sumResults_1_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__7;  // multiplyTensors_12_arrayC > implode_sumResults_1_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__21;  // multiplyTensors_13_arrayC > implode_sumResults_1_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__25;  // multiplyTensors_14_arrayC > implode_sumResults_1_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__4;  // multiplyTensors_15_arrayC > implode_sumResults_1_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__8;  // implode_sumResults_1_input_arrayC > sumResults_1_input size:= 512*long defined in Core0
extern long *const arrayC__input_0__14;  // multiplyTensors_184_arrayC > implode_sumResults_23_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__13;  // multiplyTensors_185_arrayC > implode_sumResults_23_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__3;  // multiplyTensors_186_arrayC > implode_sumResults_23_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__14;  // multiplyTensors_187_arrayC > implode_sumResults_23_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__2;  // multiplyTensors_188_arrayC > implode_sumResults_23_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__3;  // multiplyTensors_189_arrayC > implode_sumResults_23_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__8;  // multiplyTensors_190_arrayC > implode_sumResults_23_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__22;  // multiplyTensors_191_arrayC > implode_sumResults_23_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__15;  // implode_sumResults_23_input_arrayC > sumResults_23_input size:= 512*long defined in Core0
extern char *const implode_sumResults_23_input___0;  // implode_sumResults_23_input > sumResults_23 size:= 2048*char defined in Core0
extern char *const implode_sumResults_24_input___0;  // implode_sumResults_24_input > sumResults_24 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__24;  // multiplyTensors_216_arrayC > implode_sumResults_27_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__7;  // multiplyTensors_217_arrayC > implode_sumResults_27_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__21;  // multiplyTensors_218_arrayC > implode_sumResults_27_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__22;  // multiplyTensors_219_arrayC > implode_sumResults_27_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__27;  // multiplyTensors_220_arrayC > implode_sumResults_27_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__28;  // multiplyTensors_221_arrayC > implode_sumResults_27_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_448__26;  // multiplyTensors_223_arrayC > implode_sumResults_27_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__13;  // implode_sumResults_27_input_arrayC > sumResults_27_input size:= 512*long defined in Core0
extern char *const implode_sumResults_27_input___0;  // implode_sumResults_27_input > sumResults_27 size:= 2048*char defined in Core0
extern char *const implode_sumResults_28_input___0;  // implode_sumResults_28_input > sumResults_28 size:= 2048*char defined in Core0
extern char *const implode_sumResults_2_input____0;  // implode_sumResults_2_input > sumResults_2 size:= 2048*char defined in Core0
extern long *const arrayC__input__2;  // implode_sumResults_0_input_arrayC > sumResults_0_input size:= 512*long defined in Core0
extern long *const output__arrayC_0__0;  // sumResults_0_output > implode_displayTensor_arrayC_arrayC_0 size:= 64*long defined in Core0
extern char *const sumResults_0__implode_displa__0;  // sumResults_0 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const output__arrayC_64__0;  // sumResults_1_output > implode_displayTensor_arrayC_arrayC_64 size:= 64*long defined in Core0
extern char *const sumResults_1__implode_displa__0;  // sumResults_1 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__29;  // implode_sumResults_14_input_arrayC > sumResults_14_input size:= 512*long defined in Core0
extern long *const output__arrayC_896__0;  // sumResults_14_output > implode_displayTensor_arrayC_arrayC_896 size:= 64*long defined in Core0
extern char *const sumResults_14__implode_displ__0;  // sumResults_14 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__19;  // implode_sumResults_15_input_arrayC > sumResults_15_input size:= 512*long defined in Core0
extern long *const output__arrayC_960__0;  // sumResults_15_output > implode_displayTensor_arrayC_arrayC_960 size:= 64*long defined in Core0
extern char *const sumResults_15__implode_displ__0;  // sumResults_15 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__12;  // implode_sumResults_2_input_arrayC > sumResults_2_input size:= 512*long defined in Core0
extern long *const output__arrayC_128__0;  // sumResults_2_output > implode_displayTensor_arrayC_arrayC_128 size:= 64*long defined in Core0
extern char *const sumResults_2__implode_displa__0;  // sumResults_2 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__5;  // implode_sumResults_24_input_arrayC > sumResults_24_input size:= 512*long defined in Core0
extern long *const output__arrayC_1536__0;  // sumResults_24_output > implode_displayTensor_arrayC_arrayC_1536 size:= 64*long defined in Core0
extern char *const sumResults_24__implode_displ__0;  // sumResults_24 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__16;  // implode_sumResults_28_input_arrayC > sumResults_28_input size:= 512*long defined in Core0
extern long *const output__arrayC_1792__0;  // sumResults_28_output > implode_displayTensor_arrayC_arrayC_1792 size:= 64*long defined in Core0
extern char *const sumResults_28__implode_displ__0;  // sumResults_28 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core3(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core3: explode_generateTensors_arra__227 
		receiveEnd(0); // Core0 > Core3: explode_generateTensors_arra__227 
		cache_inv(explode_generateTensors_arra__227, 256*sizeof(char));
		receiveStart(); // Core0 > Core3: explode_generateTensors_arra__206 
		receiveEnd(0); // Core0 > Core3: explode_generateTensors_arra__206 
		cache_inv(explode_generateTensors_arra__206, 256*sizeof(char));
		receiveStart(); // Core0 > Core3: explode_generateTensors_arra__5 
		receiveEnd(0); // Core0 > Core3: explode_generateTensors_arra__5 
		cache_inv(explode_generateTensors_arra__5, 256*sizeof(char));
		receiveStart(); // Core0 > Core3: explode_generateTensors_arra__168 
		receiveEnd(0); // Core0 > Core3: explode_generateTensors_arra__168 
		cache_inv(explode_generateTensors_arra__168, 256*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__280 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__280 
		cache_inv(explode_generateTensors_arra__280, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__30 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__30 
		cache_inv(explode_generateTensors_arra__30, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__106 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__106 
		cache_inv(explode_generateTensors_arra__106, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__267 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__267 
		cache_inv(explode_generateTensors_arra__267, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__282 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__282 
		cache_inv(explode_generateTensors_arra__282, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__40 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__40 
		cache_inv(explode_generateTensors_arra__40, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__189 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__189 
		cache_inv(explode_generateTensors_arra__189, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__263 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__263 
		cache_inv(explode_generateTensors_arra__263, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__68 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__68 
		cache_inv(explode_generateTensors_arra__68, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__228 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__228 
		cache_inv(explode_generateTensors_arra__228, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__71 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__71 
		cache_inv(explode_generateTensors_arra__71, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__240 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__240 
		cache_inv(explode_generateTensors_arra__240, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__249 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__249 
		cache_inv(explode_generateTensors_arra__249, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__109 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__109 
		cache_inv(explode_generateTensors_arra__109, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__195 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__195 
		cache_inv(explode_generateTensors_arra__195, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__140 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__140 
		cache_inv(explode_generateTensors_arra__140, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__209 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__209 
		cache_inv(explode_generateTensors_arra__209, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__80 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__80 
		cache_inv(explode_generateTensors_arra__80, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__12 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__158 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__158 
		cache_inv(explode_generateTensors_arra__158, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__62 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__62 
		cache_inv(explode_generateTensors_arra__62, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__278 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__278 
		cache_inv(explode_generateTensors_arra__278, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__200 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__200 
		cache_inv(explode_generateTensors_arra__200, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__18 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__18 
		cache_inv(explode_generateTensors_arra__18, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__19 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__19 
		cache_inv(explode_generateTensors_arra__19, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__243 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__243 
		cache_inv(explode_generateTensors_arra__243, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__156 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__156 
		cache_inv(explode_generateTensors_arra__156, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__146 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__146 
		cache_inv(explode_generateTensors_arra__146, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__224 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__224 
		cache_inv(explode_generateTensors_arra__224, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__65 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__65 
		cache_inv(explode_generateTensors_arra__65, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__260 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__260 
		cache_inv(explode_generateTensors_arra__260, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__112 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__112 
		cache_inv(explode_generateTensors_arra__112, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__75 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__75 
		cache_inv(explode_generateTensors_arra__75, 32*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_0__input__0,output__arrayA__20); // transposeTensor_0
		cache_inv(arrayA_0__input__0, 64*sizeof(int));
		receiveStart(); // Core6 > Core3: transposeTensor_13__explode___0 
		receiveEnd(6); // Core6 > Core3: transposeTensor_13__explode___0 
		cache_inv(transposeTensor_13__explode___0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_896__input__0,output__arrayA__17); // transposeTensor_14
		cache_inv(arrayA_896__input__0, 64*sizeof(int));
		receiveStart(); // Core0 > Core3: transposeTensor_17__explode___0 
		receiveEnd(0); // Core0 > Core3: transposeTensor_17__explode___0 
		cache_inv(transposeTensor_17__explode___0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_1792__input__0,output__arrayA__29); // transposeTensor_28
		cache_inv(arrayA_1792__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_28__explode___0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: transposeTensor_28__explode___0 
		sendEnd(); // Core3 > Core7: transposeTensor_28__explode___0 
		receiveStart(); // Core5 > Core3: transposeTensor_31__explode___0 
		receiveEnd(5); // Core5 > Core3: transposeTensor_31__explode___0 
		cache_inv(transposeTensor_31__explode___0, 256*sizeof(char));
		receiveStart(); // Core6 > Core3: transposeTensor_4__explode_t__0 
		receiveEnd(6); // Core6 > Core3: transposeTensor_4__explode_t__0 
		cache_inv(transposeTensor_4__explode_t__0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,arrayA_320__input__0,output__arrayA__14); // transposeTensor_5
		cache_inv(arrayA_320__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_5__explode_t__0, 256*sizeof(char));
		sendStart(6); // Core3 > Core6: transposeTensor_5__explode_t__0 
		sendEnd(); // Core3 > Core6: transposeTensor_5__explode_t__0 
		// Fork explode_transposeTensor_0_output
		{
			cache_wb(output__arrayA__20, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__20) + 0, 256);
		cache_inv(output__arrayA__20, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_0_ou__0, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_0_ou__0 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_0_ou__0 
		cache_wbInv(explode_transposeTensor_0_ou__7, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_0_ou__7 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_0_ou__7 
		cache_wbInv(explode_transposeTensor_0_ou__6, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_0_ou__6 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_0_ou__6 
		cache_wbInv(explode_transposeTensor_0_ou__1, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_0_ou__1 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_0_ou__1 
		cache_wbInv(explode_transposeTensor_0_ou__5, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_0_ou__5 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_0_ou__5 
		cache_wbInv(explode_transposeTensor_0_ou__4, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_0_ou__4 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_0_ou__4 
		// Fork explode_transposeTensor_13_output
		{
			cache_wb(output__arrayA__10, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__10) + 0, 256);
		cache_inv(output__arrayA__10, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_13_o__4, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_13_o__4 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_13_o__4 
		cache_wbInv(explode_transposeTensor_13_o__7, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_13_o__7 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_13_o__7 
		cache_wbInv(explode_transposeTensor_13_o__2, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_13_o__2 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_13_o__2 
		cache_wbInv(explode_transposeTensor_13_o__5, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_13_o__5 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_13_o__5 
		cache_wbInv(explode_transposeTensor_13_o__3, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_13_o__3 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_13_o__3 
		// Fork explode_transposeTensor_14_output
		{
			cache_wb(output__arrayA__17, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__17) + 0, 256);
		cache_inv(output__arrayA__17, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_14_o__2, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__2 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__2 
		cache_wbInv(explode_transposeTensor_14_o__0, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__0 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__0 
		cache_wbInv(explode_transposeTensor_14_o__7, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__7 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__7 
		cache_wbInv(explode_transposeTensor_14_o__6, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__6 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__6 
		cache_wbInv(explode_transposeTensor_14_o__4, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__4 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__4 
		cache_wbInv(explode_transposeTensor_14_o__5, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__5 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__5 
		cache_wbInv(explode_transposeTensor_14_o__1, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__1 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__1 
		cache_wbInv(explode_transposeTensor_14_o__3, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_14_o__3 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_14_o__3 
		receiveStart(); // Core0 > Core3: explode_transposeTensor_15_o__4 
		receiveEnd(0); // Core0 > Core3: explode_transposeTensor_15_o__4 
		cache_inv(explode_transposeTensor_15_o__4, 32*sizeof(char));
		receiveStart(); // Core0 > Core3: explode_transposeTensor_15_o__5 
		receiveEnd(0); // Core0 > Core3: explode_transposeTensor_15_o__5 
		cache_inv(explode_transposeTensor_15_o__5, 32*sizeof(char));
		// Fork explode_transposeTensor_17_output
		{
			cache_wb(output__arrayA__19, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__19) + 0, 256);
		cache_inv(output__arrayA__19, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_17_o__5, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_17_o__5 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_17_o__5 
		cache_wbInv(explode_transposeTensor_17_o__4, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_17_o__4 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_17_o__4 
		cache_wbInv(explode_transposeTensor_17_o__0, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_17_o__0 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_17_o__0 
		cache_wbInv(explode_transposeTensor_17_o__1, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_17_o__1 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_17_o__1 
		receiveStart(); // Core1 > Core3: explode_transposeTensor_1_ou__1 
		receiveEnd(1); // Core1 > Core3: explode_transposeTensor_1_ou__1 
		cache_inv(explode_transposeTensor_1_ou__1, 32*sizeof(char));
		receiveStart(); // Core1 > Core3: explode_transposeTensor_1_ou__4 
		receiveEnd(1); // Core1 > Core3: explode_transposeTensor_1_ou__4 
		cache_inv(explode_transposeTensor_1_ou__4, 32*sizeof(char));
		receiveStart(); // Core1 > Core3: explode_transposeTensor_24_o__3 
		receiveEnd(1); // Core1 > Core3: explode_transposeTensor_24_o__3 
		cache_inv(explode_transposeTensor_24_o__3, 32*sizeof(char));
		receiveStart(); // Core1 > Core3: explode_transposeTensor_24_o__5 
		receiveEnd(1); // Core1 > Core3: explode_transposeTensor_24_o__5 
		cache_inv(explode_transposeTensor_24_o__5, 32*sizeof(char));
		receiveStart(); // Core1 > Core3: explode_transposeTensor_27_o__3 
		receiveEnd(1); // Core1 > Core3: explode_transposeTensor_27_o__3 
		cache_inv(explode_transposeTensor_27_o__3, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_transposeTensor_28_o__4 
		receiveEnd(7); // Core7 > Core3: explode_transposeTensor_28_o__4 
		cache_inv(explode_transposeTensor_28_o__4, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_transposeTensor_28_o__0 
		receiveEnd(7); // Core7 > Core3: explode_transposeTensor_28_o__0 
		cache_inv(explode_transposeTensor_28_o__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_transposeTensor_28_o__5 
		receiveEnd(7); // Core7 > Core3: explode_transposeTensor_28_o__5 
		cache_inv(explode_transposeTensor_28_o__5, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_transposeTensor_28_o__1 
		receiveEnd(7); // Core7 > Core3: explode_transposeTensor_28_o__1 
		cache_inv(explode_transposeTensor_28_o__1, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_transposeTensor_28_o__3 
		receiveEnd(7); // Core7 > Core3: explode_transposeTensor_28_o__3 
		cache_inv(explode_transposeTensor_28_o__3, 32*sizeof(char));
		receiveStart(); // Core2 > Core3: explode_transposeTensor_30_o__2 
		receiveEnd(2); // Core2 > Core3: explode_transposeTensor_30_o__2 
		cache_inv(explode_transposeTensor_30_o__2, 32*sizeof(char));
		// Fork explode_transposeTensor_31_output
		{
			cache_wb(output__arrayA__23, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__23) + 0, 256);
		cache_inv(output__arrayA__23, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_31_o__1, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_31_o__1 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_31_o__1 
		cache_wbInv(explode_transposeTensor_31_o__6, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_31_o__6 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_31_o__6 
		cache_wbInv(explode_transposeTensor_31_o__4, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_31_o__4 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_31_o__4 
		cache_wbInv(explode_transposeTensor_31_o__7, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_31_o__7 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_31_o__7 
		cache_wbInv(explode_transposeTensor_31_o__0, 32*sizeof(char));
		sendStart(0); // Core3 > Core0: explode_transposeTensor_31_o__0 
		sendEnd(); // Core3 > Core0: explode_transposeTensor_31_o__0 
		cache_wbInv(explode_transposeTensor_31_o__5, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_31_o__5 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_31_o__5 
		receiveStart(); // Core0 > Core3: explode_transposeTensor_3_ou__6 
		receiveEnd(0); // Core0 > Core3: explode_transposeTensor_3_ou__6 
		cache_inv(explode_transposeTensor_3_ou__6, 32*sizeof(char));
		// Fork explode_transposeTensor_4_output
		{
			cache_wb(output__arrayA__3, 64*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__3) + 0, 256);
		cache_inv(output__arrayA__3, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_4_ou__1, 32*sizeof(char));
		sendStart(2); // Core3 > Core2: explode_transposeTensor_4_ou__1 
		sendEnd(); // Core3 > Core2: explode_transposeTensor_4_ou__1 
		cache_wbInv(explode_transposeTensor_4_ou__0, 32*sizeof(char));
		sendStart(1); // Core3 > Core1: explode_transposeTensor_4_ou__0 
		sendEnd(); // Core3 > Core1: explode_transposeTensor_4_ou__0 
		cache_wbInv(explode_transposeTensor_4_ou__6, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_4_ou__6 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_4_ou__6 
		cache_wbInv(explode_transposeTensor_4_ou__2, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_4_ou__2 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_4_ou__2 
		cache_wbInv(explode_transposeTensor_4_ou__7, 32*sizeof(char));
		sendStart(1); // Core3 > Core1: explode_transposeTensor_4_ou__7 
		sendEnd(); // Core3 > Core1: explode_transposeTensor_4_ou__7 
		cache_wbInv(explode_transposeTensor_4_ou__5, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_4_ou__5 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_4_ou__5 
		receiveStart(); // Core6 > Core3: explode_transposeTensor_5_ou__7 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_5_ou__7 
		cache_inv(explode_transposeTensor_5_ou__7, 32*sizeof(char));
		receiveStart(); // Core6 > Core3: explode_transposeTensor_5_ou__1 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_5_ou__1 
		cache_inv(explode_transposeTensor_5_ou__1, 32*sizeof(char));
		receiveStart(); // Core6 > Core3: explode_transposeTensor_5_ou__0 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_5_ou__0 
		cache_inv(explode_transposeTensor_5_ou__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core3: explode_transposeTensor_5_ou__5 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_5_ou__5 
		cache_inv(explode_transposeTensor_5_ou__5, 32*sizeof(char));
		receiveStart(); // Core6 > Core3: explode_transposeTensor_5_ou__3 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_5_ou__3 
		cache_inv(explode_transposeTensor_5_ou__3, 32*sizeof(char));
		receiveStart(); // Core5 > Core3: explode_transposeTensor_6_ou__2 
		receiveEnd(5); // Core5 > Core3: explode_transposeTensor_6_ou__2 
		cache_inv(explode_transposeTensor_6_ou__2, 32*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__3,arrayB_80__arrayB__0,arrayC__input_128__31); // multiplyTensors_10
		cache_inv(output_16__arrayA__3, 8*sizeof(int));
		cache_inv(arrayB_80__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_8__arrayA__4,arrayB_840__arrayB__0,arrayC__input_64__24); // multiplyTensors_105
		cache_inv(output_8__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_840__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_105__implode__0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_105__implode__0 
		sendEnd(); // Core3 > Core2: multiplyTensors_105__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__25,arrayB_856__arrayB__0,arrayC__input_192__10); // multiplyTensors_107
		cache_inv(output_24__arrayA__25, 8*sizeof(int));
		cache_inv(arrayB_856__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_107__implode__0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_107__implode__0 
		sendEnd(); // Core3 > Core2: multiplyTensors_107__implode__0 
		receiveStart(); // Core6 > Core3: multiplyTensors_11__implode___0 
		receiveEnd(6); // Core6 > Core3: multiplyTensors_11__implode___0 
		cache_inv(multiplyTensors_11__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__2,arrayB_888__arrayB__0,arrayC__input_448__11); // multiplyTensors_111
		cache_inv(output_56__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_888__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_111__implode__0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_111__implode__0 
		sendEnd(); // Core3 > Core2: multiplyTensors_111__implode__0 
		receiveStart(); // Core1 > Core3: multiplyTensors_12__implode___0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_12__implode___0 
		cache_inv(multiplyTensors_12__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__30,arrayB_960__arrayB__0,arrayC__input_0__27); // multiplyTensors_120
		cache_inv(output_0__arrayA__30, 8*sizeof(int));
		cache_inv(arrayB_960__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_120__implode__0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_120__implode__0 
		sendEnd(); // Core3 > Core0: multiplyTensors_120__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__22,arrayB_1000__arrayB__0,arrayC__input_320__30); // multiplyTensors_125
		cache_inv(output_40__arrayA__22, 8*sizeof(int));
		cache_inv(arrayB_1000__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_125__implode__0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_125__implode__0 
		sendEnd(); // Core3 > Core0: multiplyTensors_125__implode__0 
		receiveStart(); // Core2 > Core3: multiplyTensors_13__implode___0 
		receiveEnd(2); // Core2 > Core3: multiplyTensors_13__implode___0 
		cache_inv(multiplyTensors_13__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__14,arrayB_1088__arrayB__0,arrayC__input_0__8); // multiplyTensors_136
		cache_inv(output_0__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_1088__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_136__implode__0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_136__implode__0 
		sendEnd(); // Core3 > Core0: multiplyTensors_136__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__18,arrayB_1104__arrayB__0,arrayC__input_128__2); // multiplyTensors_138
		cache_inv(output_16__arrayA__18, 8*sizeof(int));
		cache_inv(arrayB_1104__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_138__implode__0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_138__implode__0 
		sendEnd(); // Core3 > Core0: multiplyTensors_138__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__14,arrayB_1112__arrayB__0,arrayC__input_192__29); // multiplyTensors_139
		cache_inv(output_24__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_1112__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_139__implode__0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_139__implode__0 
		sendEnd(); // Core3 > Core0: multiplyTensors_139__implode__0 
		receiveStart(); // Core1 > Core3: multiplyTensors_14__implode___0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_14__implode___0 
		cache_inv(multiplyTensors_14__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__20,arrayB_1120__arrayB__0,arrayC__input_256__12); // multiplyTensors_140
		cache_inv(output_32__arrayA__20, 8*sizeof(int));
		cache_inv(arrayB_1120__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_140__implode__0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_140__implode__0 
		sendEnd(); // Core3 > Core0: multiplyTensors_140__implode__0 
		receiveStart(); // Core4 > Core3: multiplyTensors_144__implode__0 
		receiveEnd(4); // Core4 > Core3: multiplyTensors_144__implode__0 
		cache_inv(multiplyTensors_144__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_145__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_145__implode__0 
		cache_inv(multiplyTensors_145__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_146__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_146__implode__0 
		cache_inv(multiplyTensors_146__implode__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core3: multiplyTensors_147__implode__0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_147__implode__0 
		cache_inv(multiplyTensors_147__implode__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core3: multiplyTensors_148__implode__0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_148__implode__0 
		cache_inv(multiplyTensors_148__implode__0, 256*sizeof(char));
		receiveStart(); // Core4 > Core3: multiplyTensors_149__implode__0 
		receiveEnd(4); // Core4 > Core3: multiplyTensors_149__implode__0 
		cache_inv(multiplyTensors_149__implode__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core3: multiplyTensors_15__implode___0 
		receiveEnd(6); // Core6 > Core3: multiplyTensors_15__implode___0 
		cache_inv(multiplyTensors_15__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core3: multiplyTensors_150__implode__0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_150__implode__0 
		cache_inv(multiplyTensors_150__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_151__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_151__implode__0 
		cache_inv(multiplyTensors_151__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core3: multiplyTensors_184__implode__0 
		receiveEnd(7); // Core7 > Core3: multiplyTensors_184__implode__0 
		cache_inv(multiplyTensors_184__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_185__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_185__implode__0 
		cache_inv(multiplyTensors_185__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core3: multiplyTensors_186__implode__0 
		receiveEnd(7); // Core7 > Core3: multiplyTensors_186__implode__0 
		cache_inv(multiplyTensors_186__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_187__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_187__implode__0 
		cache_inv(multiplyTensors_187__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_188__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_188__implode__0 
		cache_inv(multiplyTensors_188__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_189__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_189__implode__0 
		cache_inv(multiplyTensors_189__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_190__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_190__implode__0 
		cache_inv(multiplyTensors_190__implode__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core3: multiplyTensors_191__implode__0 
		receiveEnd(6); // Core6 > Core3: multiplyTensors_191__implode__0 
		cache_inv(multiplyTensors_191__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__24,arrayB_1536__arrayB__0,arrayC__input_0__13); // multiplyTensors_192
		cache_inv(output_0__arrayA__24, 8*sizeof(int));
		cache_inv(arrayB_1536__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_192__implode__0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: multiplyTensors_192__implode__0 
		sendEnd(); // Core3 > Core7: multiplyTensors_192__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__15,arrayB_1592__arrayB__0,arrayC__input_448__13); // multiplyTensors_199
		cache_inv(output_56__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_1592__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_199__implode__0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: multiplyTensors_199__implode__0 
		sendEnd(); // Core3 > Core7: multiplyTensors_199__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__19,arrayB_16__arrayB__0,arrayC__input_128__30); // multiplyTensors_2
		cache_inv(output_16__arrayA__19, 8*sizeof(int));
		cache_inv(arrayB_16__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_2__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core3 > Core5: multiplyTensors_2__implode_s__0 
		sendEnd(); // Core3 > Core5: multiplyTensors_2__implode_s__0 
		receiveStart(); // Core1 > Core3: multiplyTensors_216__implode__0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_216__implode__0 
		cache_inv(multiplyTensors_216__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core3: multiplyTensors_217__implode__0 
		receiveEnd(7); // Core7 > Core3: multiplyTensors_217__implode__0 
		cache_inv(multiplyTensors_217__implode__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core3: multiplyTensors_218__implode__0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_218__implode__0 
		cache_inv(multiplyTensors_218__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core3: multiplyTensors_219__implode__0 
		receiveEnd(7); // Core7 > Core3: multiplyTensors_219__implode__0 
		cache_inv(multiplyTensors_219__implode__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core3: multiplyTensors_220__implode__0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_220__implode__0 
		cache_inv(multiplyTensors_220__implode__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core3: multiplyTensors_221__implode__0 
		receiveEnd(6); // Core6 > Core3: multiplyTensors_221__implode__0 
		cache_inv(multiplyTensors_221__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__15,arrayB_1776__arrayB__0,arrayC__input_384__19); // multiplyTensors_222
		cache_inv(output_48__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_1776__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core6 > Core3: multiplyTensors_223__implode__0 
		receiveEnd(6); // Core6 > Core3: multiplyTensors_223__implode__0 
		cache_inv(multiplyTensors_223__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_8__arrayA__24,arrayB_1800__arrayB__0,arrayC__input_64__29); // multiplyTensors_225
		cache_inv(output_8__arrayA__24, 8*sizeof(int));
		cache_inv(arrayB_1800__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_225__implode__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_225__implode__0 
		sendEnd(); // Core3 > Core4: multiplyTensors_225__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__8,arrayB_1816__arrayB__0,arrayC__input_192__17); // multiplyTensors_227
		cache_inv(output_24__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_1816__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_227__implode__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_227__implode__0 
		sendEnd(); // Core3 > Core4: multiplyTensors_227__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_32__arrayA__27,arrayB_1824__arrayB__0,arrayC__input_256__30); // multiplyTensors_228
		cache_inv(output_32__arrayA__27, 8*sizeof(int));
		cache_inv(arrayB_1824__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_228__implode__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_228__implode__0 
		sendEnd(); // Core3 > Core4: multiplyTensors_228__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__5,arrayB_1832__arrayB__0,arrayC__input_320__24); // multiplyTensors_229
		cache_inv(output_40__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_1832__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_229__implode__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_229__implode__0 
		sendEnd(); // Core3 > Core4: multiplyTensors_229__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__21,arrayB_1840__arrayB__0,arrayC__input_384__24); // multiplyTensors_230
		cache_inv(output_48__arrayA__21, 8*sizeof(int));
		cache_inv(arrayB_1840__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_230__implode__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_230__implode__0 
		sendEnd(); // Core3 > Core4: multiplyTensors_230__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_8__arrayA__10,arrayB_1928__arrayB__0,arrayC__input_64__10); // multiplyTensors_241
		cache_inv(output_8__arrayA__10, 8*sizeof(int));
		cache_inv(arrayB_1928__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_241__implode__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_241__implode__0 
		sendEnd(); // Core3 > Core4: multiplyTensors_241__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__7,arrayB_2000__arrayB__0,arrayC__input_128__0); // multiplyTensors_250
		cache_inv(output_16__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_2000__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_250__implode__0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_250__implode__0 
		sendEnd(); // Core3 > Core2: multiplyTensors_250__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__8,arrayB_2032__arrayB__0,arrayC__input_384__3); // multiplyTensors_254
		cache_inv(output_48__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_2032__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_254__implode__0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_254__implode__0 
		sendEnd(); // Core3 > Core2: multiplyTensors_254__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__16,arrayB_232__arrayB__0,arrayC__input_320__13); // multiplyTensors_29
		cache_inv(output_40__arrayA__16, 8*sizeof(int));
		cache_inv(arrayB_232__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_29__implode___0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: multiplyTensors_29__implode___0 
		sendEnd(); // Core3 > Core7: multiplyTensors_29__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__16,arrayB_280__arrayB__0,arrayC__input_192__6); // multiplyTensors_35
		cache_inv(output_24__arrayA__16, 8*sizeof(int));
		cache_inv(arrayB_280__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_35__implode___0, 256*sizeof(char));
		sendStart(5); // Core3 > Core5: multiplyTensors_35__implode___0 
		sendEnd(); // Core3 > Core5: multiplyTensors_35__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__12,arrayB_304__arrayB__0,arrayC__input_384__0); // multiplyTensors_38
		cache_inv(output_48__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_304__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_38__implode___0, 256*sizeof(char));
		sendStart(5); // Core3 > Core5: multiplyTensors_38__implode___0 
		sendEnd(); // Core3 > Core5: multiplyTensors_38__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_0__arrayA__16,arrayB_320__arrayB__0,arrayC__input_0__18); // multiplyTensors_40
		cache_inv(output_0__arrayA__16, 8*sizeof(int));
		cache_inv(arrayB_320__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_40__implode___0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_40__implode___0 
		sendEnd(); // Core3 > Core4: multiplyTensors_40__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_16__arrayA__11,arrayB_336__arrayB__0,arrayC__input_128__5); // multiplyTensors_42
		cache_inv(output_16__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_336__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_42__implode___0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_42__implode___0 
		sendEnd(); // Core3 > Core4: multiplyTensors_42__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_24__arrayA__5,arrayB_344__arrayB__0,arrayC__input_192__31); // multiplyTensors_43
		cache_inv(output_24__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_344__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_43__implode___0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_43__implode___0 
		sendEnd(); // Core3 > Core4: multiplyTensors_43__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__5,arrayB_368__arrayB__0,arrayC__input_384__31); // multiplyTensors_46
		cache_inv(output_48__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_368__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_46__implode___0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_46__implode___0 
		sendEnd(); // Core3 > Core4: multiplyTensors_46__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_56__arrayA__31,arrayB_376__arrayB__0,arrayC__input_448__19); // multiplyTensors_47
		cache_inv(output_56__arrayA__31, 8*sizeof(int));
		cache_inv(arrayB_376__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_47__implode___0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: multiplyTensors_47__implode___0 
		sendEnd(); // Core3 > Core4: multiplyTensors_47__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_40__arrayA__7,arrayB_424__arrayB__0,arrayC__input_320__0); // multiplyTensors_53
		cache_inv(output_40__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_424__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_53__implode___0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_53__implode___0 
		sendEnd(); // Core3 > Core0: multiplyTensors_53__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_48__arrayA__9,arrayB_48__arrayB__0,arrayC__input_384__1); // multiplyTensors_6
		cache_inv(output_48__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_48__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_6__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core3 > Core5: multiplyTensors_6__implode_s__0 
		sendEnd(); // Core3 > Core5: multiplyTensors_6__implode_s__0 
		receiveStart(); // Core2 > Core3: multiplyTensors_8__implode_s__0 
		receiveEnd(2); // Core2 > Core3: multiplyTensors_8__implode_s__0 
		cache_inv(multiplyTensors_8__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,output_8__arrayA__14,arrayB_72__arrayB__0,arrayC__input_64__19); // multiplyTensors_9
		cache_inv(output_8__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_72__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core5 > Core3: implode_sumResults_0_input____0 
		receiveEnd(5); // Core5 > Core3: implode_sumResults_0_input____0 
		cache_inv(implode_sumResults_0_input____0, 2048*sizeof(char));
		receiveStart(); // Core5 > Core3: implode_sumResults_14_input___0 
		receiveEnd(5); // Core5 > Core3: implode_sumResults_14_input___0 
		cache_inv(implode_sumResults_14_input___0, 2048*sizeof(char));
		receiveStart(); // Core0 > Core3: implode_sumResults_15_input___0 
		receiveEnd(0); // Core0 > Core3: implode_sumResults_15_input___0 
		cache_inv(implode_sumResults_15_input___0, 2048*sizeof(char));
		// Join implode_sumResults_18_input
		{
			cache_wb(arrayC__input_0__7, 64*sizeof(long));
			memcpy((void*)(arrayC__input__22+64),(void*)( arrayC__input_64__17+0), 64*sizeof(long));
			cache_wb(arrayC__input_128__17, 64*sizeof(long));
			memcpy((void*)(arrayC__input__22+192),(void*)( arrayC__input_192__26+0), 64*sizeof(long));
			cache_wb(arrayC__input_256__28, 64*sizeof(long));
			memcpy((void*)(arrayC__input__22+320),(void*)( arrayC__input_320__20+0), 64*sizeof(long));
			cache_wb(arrayC__input_384__4, 64*sizeof(long));
			memcpy((void*)(arrayC__input__22+448),(void*)( arrayC__input_448__2+0), 64*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__7) + 0, 256);
		cache_inv(arrayC__input_0__7, 64*sizeof(long));
		cache_inv(arrayC__input_64__17, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_128__17) + 0, 256);
		cache_inv(arrayC__input_128__17, 64*sizeof(long));
		cache_inv(arrayC__input_192__26, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_256__28) + 0, 256);
		cache_inv(arrayC__input_256__28, 64*sizeof(long));
		cache_inv(arrayC__input_320__20, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_384__4) + 0, 256);
		cache_inv(arrayC__input_384__4, 64*sizeof(long));
		cache_inv(arrayC__input_448__2, 64*sizeof(long));
		cache_wbInv(implode_sumResults_18_input___0, 2048*sizeof(char));
		sendStart(4); // Core3 > Core4: implode_sumResults_18_input___0 
		sendEnd(); // Core3 > Core4: implode_sumResults_18_input___0 
		// Join implode_sumResults_1_input
		{
			cache_wb(arrayC__input_0__22, 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+64),(void*)( arrayC__input_64__19+0), 64*sizeof(long));
			cache_wb(arrayC__input_128__31, 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+192),(void*)( arrayC__input_192__4+0), 64*sizeof(long));
			cache_wb(arrayC__input_256__7, 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+320),(void*)( arrayC__input_320__21+0), 64*sizeof(long));
			cache_wb(arrayC__input_384__25, 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+448),(void*)( arrayC__input_448__4+0), 64*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__22) + 0, 256);
		cache_inv(arrayC__input_0__22, 64*sizeof(long));
		cache_inv(arrayC__input_64__19, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_128__31) + 0, 256);
		cache_inv(arrayC__input_128__31, 64*sizeof(long));
		cache_inv(arrayC__input_192__4, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_256__7) + 0, 256);
		cache_inv(arrayC__input_256__7, 64*sizeof(long));
		cache_inv(arrayC__input_320__21, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_384__25) + 0, 256);
		cache_inv(arrayC__input_384__25, 64*sizeof(long));
		cache_inv(arrayC__input_448__4, 64*sizeof(long));
		// Join implode_sumResults_23_input
		{
			cache_wb(arrayC__input_0__14, 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+64),(void*)( arrayC__input_64__13+0), 64*sizeof(long));
			cache_wb(arrayC__input_128__3, 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+192),(void*)( arrayC__input_192__14+0), 64*sizeof(long));
			cache_wb(arrayC__input_256__2, 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+320),(void*)( arrayC__input_320__3+0), 64*sizeof(long));
			cache_wb(arrayC__input_384__8, 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+448),(void*)( arrayC__input_448__22+0), 64*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__14) + 0, 256);
		cache_inv(arrayC__input_0__14, 64*sizeof(long));
		cache_inv(arrayC__input_64__13, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_128__3) + 0, 256);
		cache_inv(arrayC__input_128__3, 64*sizeof(long));
		cache_inv(arrayC__input_192__14, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_256__2) + 0, 256);
		cache_inv(arrayC__input_256__2, 64*sizeof(long));
		cache_inv(arrayC__input_320__3, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_384__8) + 0, 256);
		cache_inv(arrayC__input_384__8, 64*sizeof(long));
		cache_inv(arrayC__input_448__22, 64*sizeof(long));
		cache_wbInv(implode_sumResults_23_input___0, 2048*sizeof(char));
		sendStart(2); // Core3 > Core2: implode_sumResults_23_input___0 
		sendEnd(); // Core3 > Core2: implode_sumResults_23_input___0 
		receiveStart(); // Core7 > Core3: implode_sumResults_24_input___0 
		receiveEnd(7); // Core7 > Core3: implode_sumResults_24_input___0 
		cache_inv(implode_sumResults_24_input___0, 2048*sizeof(char));
		// Join implode_sumResults_27_input
		{
			cache_wb(arrayC__input_0__24, 64*sizeof(long));
			memcpy((void*)(arrayC__input__13+64),(void*)( arrayC__input_64__7+0), 64*sizeof(long));
			cache_wb(arrayC__input_128__21, 64*sizeof(long));
			memcpy((void*)(arrayC__input__13+192),(void*)( arrayC__input_192__22+0), 64*sizeof(long));
			cache_wb(arrayC__input_256__27, 64*sizeof(long));
			memcpy((void*)(arrayC__input__13+320),(void*)( arrayC__input_320__28+0), 64*sizeof(long));
			cache_wb(arrayC__input_384__19, 64*sizeof(long));
			memcpy((void*)(arrayC__input__13+448),(void*)( arrayC__input_448__26+0), 64*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__24) + 0, 256);
		cache_inv(arrayC__input_0__24, 64*sizeof(long));
		cache_inv(arrayC__input_64__7, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_128__21) + 0, 256);
		cache_inv(arrayC__input_128__21, 64*sizeof(long));
		cache_inv(arrayC__input_192__22, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_256__27) + 0, 256);
		cache_inv(arrayC__input_256__27, 64*sizeof(long));
		cache_inv(arrayC__input_320__28, 64*sizeof(long));
		cache_wb(((char*)arrayC__input_384__19) + 0, 256);
		cache_inv(arrayC__input_384__19, 64*sizeof(long));
		cache_inv(arrayC__input_448__26, 64*sizeof(long));
		cache_wbInv(implode_sumResults_27_input___0, 2048*sizeof(char));
		sendStart(2); // Core3 > Core2: implode_sumResults_27_input___0 
		sendEnd(); // Core3 > Core2: implode_sumResults_27_input___0 
		receiveStart(); // Core4 > Core3: implode_sumResults_28_input___0 
		receiveEnd(4); // Core4 > Core3: implode_sumResults_28_input___0 
		cache_inv(implode_sumResults_28_input___0, 2048*sizeof(char));
		receiveStart(); // Core2 > Core3: implode_sumResults_2_input____0 
		receiveEnd(2); // Core2 > Core3: implode_sumResults_2_input____0 
		cache_inv(implode_sumResults_2_input____0, 2048*sizeof(char));
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__2,output__arrayC_0__0); // sumResults_0
		cache_inv(arrayC__input__2, 512*sizeof(long));
		cache_wbInv(sumResults_0__implode_displa__0, 256*sizeof(char));
		sendStart(1); // Core3 > Core1: sumResults_0__implode_displa__0 
		sendEnd(); // Core3 > Core1: sumResults_0__implode_displa__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__8,output__arrayC_64__0); // sumResults_1
		cache_inv(arrayC__input__8, 512*sizeof(long));
		cache_wbInv(sumResults_1__implode_displa__0, 256*sizeof(char));
		sendStart(1); // Core3 > Core1: sumResults_1__implode_displa__0 
		sendEnd(); // Core3 > Core1: sumResults_1__implode_displa__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__29,output__arrayC_896__0); // sumResults_14
		cache_inv(arrayC__input__29, 512*sizeof(long));
		cache_wbInv(sumResults_14__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core3 > Core1: sumResults_14__implode_displ__0 
		sendEnd(); // Core3 > Core1: sumResults_14__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__19,output__arrayC_960__0); // sumResults_15
		cache_inv(arrayC__input__19, 512*sizeof(long));
		cache_wbInv(sumResults_15__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core3 > Core1: sumResults_15__implode_displ__0 
		sendEnd(); // Core3 > Core1: sumResults_15__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__12,output__arrayC_128__0); // sumResults_2
		cache_inv(arrayC__input__12, 512*sizeof(long));
		cache_wbInv(sumResults_2__implode_displa__0, 256*sizeof(char));
		sendStart(1); // Core3 > Core1: sumResults_2__implode_displa__0 
		sendEnd(); // Core3 > Core1: sumResults_2__implode_displa__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__5,output__arrayC_1536__0); // sumResults_24
		cache_inv(arrayC__input__5, 512*sizeof(long));
		cache_wbInv(sumResults_24__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core3 > Core1: sumResults_24__implode_displ__0 
		sendEnd(); // Core3 > Core1: sumResults_24__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,32/*depthA*/,arrayC__input__16,output__arrayC_1792__0); // sumResults_28
		cache_inv(arrayC__input__16, 512*sizeof(long));
		cache_wbInv(sumResults_28__implode_displ__0, 256*sizeof(char));
		sendStart(1); // Core3 > Core1: sumResults_28__implode_displ__0 
		sendEnd(); // Core3 > Core1: sumResults_28__implode_displ__0 
	}
}
