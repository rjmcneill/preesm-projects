/** 
 * @file Core7.c
 * @generated by C6678CPrinter
 * @date Wed Apr 15 21:28:45 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const generateTensors__explode_gen__1;  // generateTensors > explode_generateTensors_arrayA size:= 8388608*char defined in Core0
extern int *const arrayA_0__input__0;  // explode_generateTensors_arrayA_arrayA_0 > transposeTensor_0_input size:= 262144*int defined in Core0
extern int *const arrayA_262144__input__0;  // explode_generateTensors_arrayA_arrayA_262144 > transposeTensor_1_input size:= 262144*int defined in Core0
extern int *const arrayA_524288__input__0;  // explode_generateTensors_arrayA_arrayA_524288 > transposeTensor_2_input size:= 262144*int defined in Core0
extern int *const arrayA_786432__input__0;  // explode_generateTensors_arrayA_arrayA_786432 > transposeTensor_3_input size:= 262144*int defined in Core0
extern int *const arrayA_1048576__input__0;  // explode_generateTensors_arrayA_arrayA_1048576 > transposeTensor_4_input size:= 262144*int defined in Core0
extern int *const arrayA_1310720__input__0;  // explode_generateTensors_arrayA_arrayA_1310720 > transposeTensor_5_input size:= 262144*int defined in Core0
extern int *const arrayA_1572864__input__0;  // explode_generateTensors_arrayA_arrayA_1572864 > transposeTensor_6_input size:= 262144*int defined in Core0
extern int *const arrayA_1835008__input__0;  // explode_generateTensors_arrayA_arrayA_1835008 > transposeTensor_7_input size:= 262144*int defined in Core0
extern int *const arrayA__input__0;  // generateTensors_arrayA > explode_generateTensors_arrayA_input size:= 2097152*int defined in Core0
extern char *const explode_generateTensors_arra__39;  // explode_generateTensors_arrayA > transposeTensor_7 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__55;  // explode_generateTensors_arrayA > transposeTensor_6 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__71;  // explode_generateTensors_arrayA > transposeTensor_5 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__46;  // explode_generateTensors_arrayA > transposeTensor_4 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__41;  // explode_generateTensors_arrayA > transposeTensor_3 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__61;  // explode_generateTensors_arrayA > transposeTensor_2 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__20;  // explode_generateTensors_arrayA > transposeTensor_1 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayB > multiplyTensors_2 size:= 131072*char defined in Core0
extern int *const output__arrayA__2;  // transposeTensor_0_output > explode_transposeTensor_0_output_arrayA size:= 262144*int defined in Core0
extern int *const output_0__arrayA__4;  // explode_transposeTensor_0_output_output_0 > multiplyTensors_0_arrayA size:= 32768*int defined in Core0
extern int *const output_32768__arrayA__1;  // explode_transposeTensor_0_output_output_32768 > multiplyTensors_1_arrayA size:= 32768*int defined in Core0
extern int *const output_65536__arrayA__4;  // explode_transposeTensor_0_output_output_65536 > multiplyTensors_2_arrayA size:= 32768*int defined in Core0
extern int *const output_98304__arrayA__2;  // explode_transposeTensor_0_output_output_98304 > multiplyTensors_3_arrayA size:= 32768*int defined in Core0
extern int *const output_131072__arrayA__3;  // explode_transposeTensor_0_output_output_131072 > multiplyTensors_4_arrayA size:= 32768*int defined in Core0
extern int *const output_163840__arrayA__1;  // explode_transposeTensor_0_output_output_163840 > multiplyTensors_5_arrayA size:= 32768*int defined in Core0
extern int *const output_196608__arrayA__4;  // explode_transposeTensor_0_output_output_196608 > multiplyTensors_6_arrayA size:= 32768*int defined in Core0
extern int *const output_229376__arrayA__6;  // explode_transposeTensor_0_output_output_229376 > multiplyTensors_7_arrayA size:= 32768*int defined in Core0
extern char *const explode_transposeTensor_0_ou__7;  // explode_transposeTensor_0_output > multiplyTensors_7 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_0_ou__6;  // explode_transposeTensor_0_output > multiplyTensors_6 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_0_ou__0;  // explode_transposeTensor_0_output > multiplyTensors_5 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_0_ou__2;  // explode_transposeTensor_0_output > multiplyTensors_4 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_0_ou__3;  // explode_transposeTensor_0_output > multiplyTensors_3 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_0_ou__1;  // explode_transposeTensor_0_output > multiplyTensors_1 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_0_ou__5;  // explode_transposeTensor_0_output > multiplyTensors_0 size:= 131072*char defined in Core0
extern char *const multiplyTensors_0__implode_s__0;  // multiplyTensors_0 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_1__implode_s__0;  // multiplyTensors_1 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern int *const arrayB_65536__arrayB__0;  // explode_generateTensors_arrayB_arrayB_65536 > multiplyTensors_2_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_524288__3;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_524288 size:= 262144*long defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_4__implode_s__0;  // multiplyTensors_4 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_5__implode_s__0;  // multiplyTensors_5 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_6__implode_s__0;  // multiplyTensors_6 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_7__implode_s__0;  // multiplyTensors_7 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern long *const arrayC__input_0__2;  // multiplyTensors_0_arrayC > implode_sumResults_0_input_input_0 size:= 262144*long defined in Core0
extern long *const arrayC__input_262144__3;  // multiplyTensors_1_arrayC > implode_sumResults_0_input_input_262144 size:= 262144*long defined in Core0
extern long *const arrayC__input_786432__7;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_786432 size:= 262144*long defined in Core0
extern long *const arrayC__input_1048576__3;  // multiplyTensors_4_arrayC > implode_sumResults_0_input_input_1048576 size:= 262144*long defined in Core0
extern long *const arrayC__input_1310720__6;  // multiplyTensors_5_arrayC > implode_sumResults_0_input_input_1310720 size:= 262144*long defined in Core0
extern long *const arrayC__input_1572864__3;  // multiplyTensors_6_arrayC > implode_sumResults_0_input_input_1572864 size:= 262144*long defined in Core0
extern long *const arrayC__input_1835008__7;  // multiplyTensors_7_arrayC > implode_sumResults_0_input_input_1835008 size:= 262144*long defined in Core0
extern long *const arrayC__input__5;  // implode_sumResults_0_input_arrayC > sumResults_0_input size:= 2097152*long defined in Core0
extern long *const output__arrayC_0__0;  // sumResults_0_output > implode_displayTensor_arrayC_arrayC_0 size:= 262144*long defined in Core0
extern char *const sumResults_0__implode_displa__0;  // sumResults_0 > implode_displayTensor_arrayC size:= 1048576*char defined in Core0

// Core Global Definitions

void core7(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core7: generateTensors__explode_gen__1 
		receiveEnd(0); // Core0 > Core7: generateTensors__explode_gen__1 
		cache_inv(generateTensors__explode_gen__1, 8388608*sizeof(char));
		// Fork explode_generateTensors_arrayA
		{
			cache_wb(arrayA__input__0, 2097152*sizeof(int));
		}
		cache_wb(((char*)arrayA__input__0) + 0, 8388608);
		cache_inv(arrayA__input__0, 2097152*sizeof(int));
		cache_wbInv(explode_generateTensors_arra__39, 1048576*sizeof(char));
		sendStart(2); // Core7 > Core2: explode_generateTensors_arra__39 
		sendEnd(); // Core7 > Core2: explode_generateTensors_arra__39 
		cache_wbInv(explode_generateTensors_arra__55, 1048576*sizeof(char));
		sendStart(3); // Core7 > Core3: explode_generateTensors_arra__55 
		sendEnd(); // Core7 > Core3: explode_generateTensors_arra__55 
		cache_wbInv(explode_generateTensors_arra__71, 1048576*sizeof(char));
		sendStart(4); // Core7 > Core4: explode_generateTensors_arra__71 
		sendEnd(); // Core7 > Core4: explode_generateTensors_arra__71 
		cache_wbInv(explode_generateTensors_arra__46, 1048576*sizeof(char));
		sendStart(1); // Core7 > Core1: explode_generateTensors_arra__46 
		sendEnd(); // Core7 > Core1: explode_generateTensors_arra__46 
		cache_wbInv(explode_generateTensors_arra__41, 1048576*sizeof(char));
		sendStart(1); // Core7 > Core1: explode_generateTensors_arra__41 
		sendEnd(); // Core7 > Core1: explode_generateTensors_arra__41 
		cache_wbInv(explode_generateTensors_arra__61, 1048576*sizeof(char));
		sendStart(2); // Core7 > Core2: explode_generateTensors_arra__61 
		sendEnd(); // Core7 > Core2: explode_generateTensors_arra__61 
		cache_wbInv(explode_generateTensors_arra__20, 1048576*sizeof(char));
		sendStart(1); // Core7 > Core1: explode_generateTensors_arra__20 
		sendEnd(); // Core7 > Core1: explode_generateTensors_arra__20 
		receiveStart(); // Core0 > Core7: explode_generateTensors_arra__13 
		receiveEnd(0); // Core0 > Core7: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 131072*sizeof(char));
		transpose(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,arrayA_0__input__0,output__arrayA__2); // transposeTensor_0
		cache_inv(arrayA_0__input__0, 262144*sizeof(int));
		// Fork explode_transposeTensor_0_output
		{
			cache_wb(output__arrayA__2, 262144*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__2) + 0, 1048576);
		cache_inv(output__arrayA__2, 262144*sizeof(int));
		cache_wbInv(explode_transposeTensor_0_ou__7, 131072*sizeof(char));
		sendStart(2); // Core7 > Core2: explode_transposeTensor_0_ou__7 
		sendEnd(); // Core7 > Core2: explode_transposeTensor_0_ou__7 
		cache_wbInv(explode_transposeTensor_0_ou__6, 131072*sizeof(char));
		sendStart(5); // Core7 > Core5: explode_transposeTensor_0_ou__6 
		sendEnd(); // Core7 > Core5: explode_transposeTensor_0_ou__6 
		cache_wbInv(explode_transposeTensor_0_ou__0, 131072*sizeof(char));
		sendStart(3); // Core7 > Core3: explode_transposeTensor_0_ou__0 
		sendEnd(); // Core7 > Core3: explode_transposeTensor_0_ou__0 
		cache_wbInv(explode_transposeTensor_0_ou__2, 131072*sizeof(char));
		sendStart(4); // Core7 > Core4: explode_transposeTensor_0_ou__2 
		sendEnd(); // Core7 > Core4: explode_transposeTensor_0_ou__2 
		cache_wbInv(explode_transposeTensor_0_ou__3, 131072*sizeof(char));
		sendStart(0); // Core7 > Core0: explode_transposeTensor_0_ou__3 
		sendEnd(); // Core7 > Core0: explode_transposeTensor_0_ou__3 
		cache_wbInv(explode_transposeTensor_0_ou__1, 131072*sizeof(char));
		sendStart(6); // Core7 > Core6: explode_transposeTensor_0_ou__1 
		sendEnd(); // Core7 > Core6: explode_transposeTensor_0_ou__1 
		cache_wbInv(explode_transposeTensor_0_ou__5, 131072*sizeof(char));
		sendStart(1); // Core7 > Core1: explode_transposeTensor_0_ou__5 
		sendEnd(); // Core7 > Core1: explode_transposeTensor_0_ou__5 
		receiveStart(); // Core1 > Core7: multiplyTensors_0__implode_s__0 
		receiveEnd(1); // Core1 > Core7: multiplyTensors_0__implode_s__0 
		cache_inv(multiplyTensors_0__implode_s__0, 1048576*sizeof(char));
		receiveStart(); // Core6 > Core7: multiplyTensors_1__implode_s__0 
		receiveEnd(6); // Core6 > Core7: multiplyTensors_1__implode_s__0 
		cache_inv(multiplyTensors_1__implode_s__0, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_65536__arrayA__4,arrayB_65536__arrayB__0,arrayC__input_524288__3); // multiplyTensors_2
		cache_inv(output_65536__arrayA__4, 32768*sizeof(int));
		cache_inv(arrayB_65536__arrayB__0, 32768*sizeof(int));
		receiveStart(); // Core0 > Core7: multiplyTensors_3__implode_s__0 
		receiveEnd(0); // Core0 > Core7: multiplyTensors_3__implode_s__0 
		cache_inv(multiplyTensors_3__implode_s__0, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core7: multiplyTensors_4__implode_s__0 
		receiveEnd(4); // Core4 > Core7: multiplyTensors_4__implode_s__0 
		cache_inv(multiplyTensors_4__implode_s__0, 1048576*sizeof(char));
		receiveStart(); // Core3 > Core7: multiplyTensors_5__implode_s__0 
		receiveEnd(3); // Core3 > Core7: multiplyTensors_5__implode_s__0 
		cache_inv(multiplyTensors_5__implode_s__0, 1048576*sizeof(char));
		receiveStart(); // Core5 > Core7: multiplyTensors_6__implode_s__0 
		receiveEnd(5); // Core5 > Core7: multiplyTensors_6__implode_s__0 
		cache_inv(multiplyTensors_6__implode_s__0, 1048576*sizeof(char));
		receiveStart(); // Core2 > Core7: multiplyTensors_7__implode_s__0 
		receiveEnd(2); // Core2 > Core7: multiplyTensors_7__implode_s__0 
		cache_inv(multiplyTensors_7__implode_s__0, 1048576*sizeof(char));
		// Join implode_sumResults_0_input
		{
			cache_wb(arrayC__input_0__2, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__5+262144),(void*)( arrayC__input_262144__3+0), 262144*sizeof(long));
			cache_wb(arrayC__input_524288__3, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__5+786432),(void*)( arrayC__input_786432__7+0), 262144*sizeof(long));
			cache_wb(arrayC__input_1048576__3, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__5+1310720),(void*)( arrayC__input_1310720__6+0), 262144*sizeof(long));
			cache_wb(arrayC__input_1572864__3, 262144*sizeof(long));
			memcpy((void*)(arrayC__input__5+1835008),(void*)( arrayC__input_1835008__7+0), 262144*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__2) + 0, 1048576);
		cache_inv(arrayC__input_0__2, 262144*sizeof(long));
		cache_inv(arrayC__input_262144__3, 262144*sizeof(long));
		cache_wb(((char*)arrayC__input_524288__3) + 0, 1048576);
		cache_inv(arrayC__input_524288__3, 262144*sizeof(long));
		cache_inv(arrayC__input_786432__7, 262144*sizeof(long));
		cache_wb(((char*)arrayC__input_1048576__3) + 0, 1048576);
		cache_inv(arrayC__input_1048576__3, 262144*sizeof(long));
		cache_inv(arrayC__input_1310720__6, 262144*sizeof(long));
		cache_wb(((char*)arrayC__input_1572864__3) + 0, 1048576);
		cache_inv(arrayC__input_1572864__3, 262144*sizeof(long));
		cache_inv(arrayC__input_1835008__7, 262144*sizeof(long));
		sum(512/*rowsA*/,512/*columnsB*/,8/*depthA*/,arrayC__input__5,output__arrayC_0__0); // sumResults_0
		cache_inv(arrayC__input__5, 2097152*sizeof(long));
		cache_wbInv(sumResults_0__implode_displa__0, 1048576*sizeof(char));
		sendStart(1); // Core7 > Core1: sumResults_0__implode_displa__0 
		sendEnd(); // Core7 > Core1: sumResults_0__implode_displa__0 
	}
}
