/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Thu Apr 02 23:19:58 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__8;  // explode_generateTensors_arrayA > transposeTensor_15 size:= 1024*char defined in Core0
extern char *const explode_generateTensors_arra__0;  // explode_generateTensors_arrayA > transposeTensor_1 size:= 1024*char defined in Core0
extern char *const explode_generateTensors_arra__104;  // explode_generateTensors_arrayB > multiplyTensors_127 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__24;  // explode_generateTensors_arrayB > multiplyTensors_126 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__72;  // explode_generateTensors_arrayB > multiplyTensors_125 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__10;  // explode_generateTensors_arrayB > multiplyTensors_124 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__93;  // explode_generateTensors_arrayB > multiplyTensors_123 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__4;  // explode_generateTensors_arrayB > multiplyTensors_122 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__3;  // explode_generateTensors_arrayB > multiplyTensors_121 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__120;  // explode_generateTensors_arrayB > multiplyTensors_120 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__111;  // explode_generateTensors_arrayB > multiplyTensors_113 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__108;  // explode_generateTensors_arrayB > multiplyTensors_93 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__58;  // explode_generateTensors_arrayB > multiplyTensors_88 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__112;  // explode_generateTensors_arrayB > multiplyTensors_87 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__131;  // explode_generateTensors_arrayB > multiplyTensors_84 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__102;  // explode_generateTensors_arrayB > multiplyTensors_82 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__141;  // explode_generateTensors_arrayB > multiplyTensors_81 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayB > multiplyTensors_80 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__56;  // explode_generateTensors_arrayB > multiplyTensors_24 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__117;  // explode_generateTensors_arrayB > multiplyTensors_14 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__53;  // explode_generateTensors_arrayB > multiplyTensors_11 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__48;  // explode_generateTensors_arrayB > multiplyTensors_5 size:= 128*char defined in Core0
extern int *const arrayA_256__input__0;  // explode_generateTensors_arrayA_arrayA_256 > transposeTensor_1_input size:= 256*int defined in Core0
extern int *const output__arrayA__9;  // transposeTensor_1_output > explode_transposeTensor_1_output_arrayA size:= 256*int defined in Core0
extern int *const arrayA_3840__input__0;  // explode_generateTensors_arrayA_arrayA_3840 > transposeTensor_15_input size:= 256*int defined in Core0
extern int *const output__arrayA__10;  // transposeTensor_15_output > explode_transposeTensor_15_output_arrayA size:= 256*int defined in Core0
extern char *const explode_transposeTensor_0_ou__0;  // explode_transposeTensor_0_output > multiplyTensors_5 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_10_o__5;  // explode_transposeTensor_10_output > multiplyTensors_87 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_10_o__1;  // explode_transposeTensor_10_output > multiplyTensors_84 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_10_o__7;  // explode_transposeTensor_10_output > multiplyTensors_82 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_10_o__2;  // explode_transposeTensor_10_output > multiplyTensors_81 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_10_o__0;  // explode_transposeTensor_10_output > multiplyTensors_80 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__4;  // explode_transposeTensor_11_output > multiplyTensors_93 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__3;  // explode_transposeTensor_11_output > multiplyTensors_88 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__5;  // explode_transposeTensor_14_output > multiplyTensors_113 size:= 128*char defined in Core0
extern int *const output_0__arrayA__2;  // explode_transposeTensor_15_output_output_0 > multiplyTensors_120_arrayA size:= 32*int defined in Core0
extern int *const output_32__arrayA__4;  // explode_transposeTensor_15_output_output_32 > multiplyTensors_121_arrayA size:= 32*int defined in Core0
extern int *const output_64__arrayA__2;  // explode_transposeTensor_15_output_output_64 > multiplyTensors_122_arrayA size:= 32*int defined in Core0
extern int *const output_96__arrayA__7;  // explode_transposeTensor_15_output_output_96 > multiplyTensors_123_arrayA size:= 32*int defined in Core0
extern int *const output_128__arrayA__10;  // explode_transposeTensor_15_output_output_128 > multiplyTensors_124_arrayA size:= 32*int defined in Core0
extern int *const output_160__arrayA__10;  // explode_transposeTensor_15_output_output_160 > multiplyTensors_125_arrayA size:= 32*int defined in Core0
extern int *const output_192__arrayA__12;  // explode_transposeTensor_15_output_output_192 > multiplyTensors_126_arrayA size:= 32*int defined in Core0
extern int *const output_224__arrayA__1;  // explode_transposeTensor_15_output_output_224 > multiplyTensors_127_arrayA size:= 32*int defined in Core0
extern int *const output_0__arrayA__14;  // explode_transposeTensor_1_output_output_0 > multiplyTensors_8_arrayA size:= 32*int defined in Core0
extern int *const output_32__arrayA__14;  // explode_transposeTensor_1_output_output_32 > multiplyTensors_9_arrayA size:= 32*int defined in Core0
extern int *const output_64__arrayA__1;  // explode_transposeTensor_1_output_output_64 > multiplyTensors_10_arrayA size:= 32*int defined in Core0
extern int *const output_96__arrayA__9;  // explode_transposeTensor_1_output_output_96 > multiplyTensors_11_arrayA size:= 32*int defined in Core0
extern int *const output_128__arrayA__5;  // explode_transposeTensor_1_output_output_128 > multiplyTensors_12_arrayA size:= 32*int defined in Core0
extern int *const output_160__arrayA__14;  // explode_transposeTensor_1_output_output_160 > multiplyTensors_13_arrayA size:= 32*int defined in Core0
extern int *const output_192__arrayA__8;  // explode_transposeTensor_1_output_output_192 > multiplyTensors_14_arrayA size:= 32*int defined in Core0
extern int *const output_224__arrayA__13;  // explode_transposeTensor_1_output_output_224 > multiplyTensors_15_arrayA size:= 32*int defined in Core0
extern char *const explode_transposeTensor_1_ou__6;  // explode_transposeTensor_1_output > multiplyTensors_15 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__5;  // explode_transposeTensor_1_output > multiplyTensors_13 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__1;  // explode_transposeTensor_1_output > multiplyTensors_12 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__0;  // explode_transposeTensor_1_output > multiplyTensors_10 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__4;  // explode_transposeTensor_1_output > multiplyTensors_9 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__7;  // explode_transposeTensor_1_output > multiplyTensors_8 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_3_ou__7;  // explode_transposeTensor_3_output > multiplyTensors_24 size:= 128*char defined in Core0
extern char *const multiplyTensors_10__implode___0;  // multiplyTensors_10 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const arrayB_352__arrayB__0;  // explode_generateTensors_arrayB_arrayB_352 > multiplyTensors_11_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__0;  // multiplyTensors_11_arrayC > implode_sumResults_1_input_input_768 size:= 256*long defined in Core0
extern int *const output_32__arrayA__12;  // explode_transposeTensor_14_output_output_32 > multiplyTensors_113_arrayA size:= 32*int defined in Core0
extern int *const arrayB_3616__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3616 > multiplyTensors_113_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__5;  // multiplyTensors_113_arrayC > implode_sumResults_14_input_input_256 size:= 256*long defined in Core0
extern char *const multiplyTensors_113__implode__0;  // multiplyTensors_113 > implode_sumResults_14_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_12__implode___0;  // multiplyTensors_12 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const arrayB_3840__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3840 > multiplyTensors_120_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_0__1;  // multiplyTensors_120_arrayC > implode_sumResults_15_input_input_0 size:= 256*long defined in Core0
extern int *const arrayB_3872__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3872 > multiplyTensors_121_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__4;  // multiplyTensors_121_arrayC > implode_sumResults_15_input_input_256 size:= 256*long defined in Core0
extern int *const arrayB_3904__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3904 > multiplyTensors_122_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__7;  // multiplyTensors_122_arrayC > implode_sumResults_15_input_input_512 size:= 256*long defined in Core0
extern int *const arrayB_3936__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3936 > multiplyTensors_123_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__14;  // multiplyTensors_123_arrayC > implode_sumResults_15_input_input_768 size:= 256*long defined in Core0
extern int *const arrayB_3968__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3968 > multiplyTensors_124_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__4;  // multiplyTensors_124_arrayC > implode_sumResults_15_input_input_1024 size:= 256*long defined in Core0
extern int *const arrayB_4000__arrayB__0;  // explode_generateTensors_arrayB_arrayB_4000 > multiplyTensors_125_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1280__3;  // multiplyTensors_125_arrayC > implode_sumResults_15_input_input_1280 size:= 256*long defined in Core0
extern int *const arrayB_4032__arrayB__0;  // explode_generateTensors_arrayB_arrayB_4032 > multiplyTensors_126_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1536__9;  // multiplyTensors_126_arrayC > implode_sumResults_15_input_input_1536 size:= 256*long defined in Core0
extern int *const arrayB_4064__arrayB__0;  // explode_generateTensors_arrayB_arrayB_4064 > multiplyTensors_127_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1792__7;  // multiplyTensors_127_arrayC > implode_sumResults_15_input_input_1792 size:= 256*long defined in Core0
extern char *const multiplyTensors_13__implode___0;  // multiplyTensors_13 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const arrayB_448__arrayB__0;  // explode_generateTensors_arrayB_arrayB_448 > multiplyTensors_14_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1536__13;  // multiplyTensors_14_arrayC > implode_sumResults_1_input_input_1536 size:= 256*long defined in Core0
extern char *const multiplyTensors_15__implode___0;  // multiplyTensors_15 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const output_0__arrayA__13;  // explode_transposeTensor_3_output_output_0 > multiplyTensors_24_arrayA size:= 32*int defined in Core0
extern int *const arrayB_768__arrayB__0;  // explode_generateTensors_arrayB_arrayB_768 > multiplyTensors_24_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_0__9;  // multiplyTensors_24_arrayC > implode_sumResults_3_input_input_0 size:= 256*long defined in Core0
extern char *const multiplyTensors_24__implode___0;  // multiplyTensors_24 > implode_sumResults_3_input size:= 1024*char defined in Core0
extern int *const output_160__arrayA__1;  // explode_transposeTensor_0_output_output_160 > multiplyTensors_5_arrayA size:= 32*int defined in Core0
extern int *const arrayB_160__arrayB__0;  // explode_generateTensors_arrayB_arrayB_160 > multiplyTensors_5_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1280__9;  // multiplyTensors_5_arrayC > implode_sumResults_0_input_input_1280 size:= 256*long defined in Core0
extern char *const multiplyTensors_5__implode_s__0;  // multiplyTensors_5 > implode_sumResults_0_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_8__implode_s__0;  // multiplyTensors_8 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const output_0__arrayA__1;  // explode_transposeTensor_10_output_output_0 > multiplyTensors_80_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2560__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2560 > multiplyTensors_80_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_0__7;  // multiplyTensors_80_arrayC > implode_sumResults_10_input_input_0 size:= 256*long defined in Core0
extern char *const multiplyTensors_80__implode___0;  // multiplyTensors_80 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern int *const output_32__arrayA__2;  // explode_transposeTensor_10_output_output_32 > multiplyTensors_81_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2592__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2592 > multiplyTensors_81_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__15;  // multiplyTensors_81_arrayC > implode_sumResults_10_input_input_256 size:= 256*long defined in Core0
extern char *const multiplyTensors_81__implode___0;  // multiplyTensors_81 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern int *const output_64__arrayA__11;  // explode_transposeTensor_10_output_output_64 > multiplyTensors_82_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2624__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2624 > multiplyTensors_82_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__8;  // multiplyTensors_82_arrayC > implode_sumResults_10_input_input_512 size:= 256*long defined in Core0
extern char *const multiplyTensors_82__implode___0;  // multiplyTensors_82 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern int *const output_128__arrayA__4;  // explode_transposeTensor_10_output_output_128 > multiplyTensors_84_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2688__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2688 > multiplyTensors_84_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__3;  // multiplyTensors_84_arrayC > implode_sumResults_10_input_input_1024 size:= 256*long defined in Core0
extern char *const multiplyTensors_84__implode___0;  // multiplyTensors_84 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern int *const output_224__arrayA__6;  // explode_transposeTensor_10_output_output_224 > multiplyTensors_87_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2784__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2784 > multiplyTensors_87_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1792__15;  // multiplyTensors_87_arrayC > implode_sumResults_10_input_input_1792 size:= 256*long defined in Core0
extern char *const multiplyTensors_87__implode___0;  // multiplyTensors_87 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern int *const output_0__arrayA__3;  // explode_transposeTensor_11_output_output_0 > multiplyTensors_88_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2816__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2816 > multiplyTensors_88_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_0__14;  // multiplyTensors_88_arrayC > implode_sumResults_11_input_input_0 size:= 256*long defined in Core0
extern char *const multiplyTensors_88__implode___0;  // multiplyTensors_88 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_9__implode_s__0;  // multiplyTensors_9 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const output_160__arrayA__4;  // explode_transposeTensor_11_output_output_160 > multiplyTensors_93_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2976__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2976 > multiplyTensors_93_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1280__4;  // multiplyTensors_93_arrayC > implode_sumResults_11_input_input_1280 size:= 256*long defined in Core0
extern char *const multiplyTensors_93__implode___0;  // multiplyTensors_93 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern long *const arrayC__input__7;  // implode_sumResults_15_input_arrayC > sumResults_15_input size:= 2048*long defined in Core0
extern char *const implode_sumResults_15_input___0;  // implode_sumResults_15_input > sumResults_15 size:= 8192*char defined in Core0
extern long *const arrayC__input_0__12;  // multiplyTensors_8_arrayC > implode_sumResults_1_input_input_0 size:= 256*long defined in Core0
extern long *const arrayC__input_256__11;  // multiplyTensors_9_arrayC > implode_sumResults_1_input_input_256 size:= 256*long defined in Core0
extern long *const arrayC__input_512__12;  // multiplyTensors_10_arrayC > implode_sumResults_1_input_input_512 size:= 256*long defined in Core0
extern long *const arrayC__input_1024__5;  // multiplyTensors_12_arrayC > implode_sumResults_1_input_input_1024 size:= 256*long defined in Core0
extern long *const arrayC__input_1280__7;  // multiplyTensors_13_arrayC > implode_sumResults_1_input_input_1280 size:= 256*long defined in Core0
extern long *const arrayC__input_1792__9;  // multiplyTensors_15_arrayC > implode_sumResults_1_input_input_1792 size:= 256*long defined in Core0
extern long *const arrayC__input__3;  // implode_sumResults_1_input_arrayC > sumResults_1_input size:= 2048*long defined in Core0
extern long *const output__arrayC_256__0;  // sumResults_1_output > implode_displayTensor_arrayC_arrayC_256 size:= 256*long defined in Core0
extern char *const sumResults_1__implode_displa__0;  // sumResults_1 > implode_displayTensor_arrayC size:= 1024*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__8 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__8 
		cache_inv(explode_generateTensors_arra__8, 1024*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__0 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__0 
		cache_inv(explode_generateTensors_arra__0, 1024*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__104 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__104 
		cache_inv(explode_generateTensors_arra__104, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__24 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__24 
		cache_inv(explode_generateTensors_arra__24, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__72 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__72 
		cache_inv(explode_generateTensors_arra__72, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__10 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__10 
		cache_inv(explode_generateTensors_arra__10, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__93 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__93 
		cache_inv(explode_generateTensors_arra__93, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__4 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__4 
		cache_inv(explode_generateTensors_arra__4, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__3 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__3 
		cache_inv(explode_generateTensors_arra__3, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__120 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__120 
		cache_inv(explode_generateTensors_arra__120, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__111 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__111 
		cache_inv(explode_generateTensors_arra__111, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__108 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__108 
		cache_inv(explode_generateTensors_arra__108, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__58 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__58 
		cache_inv(explode_generateTensors_arra__58, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__112 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__112 
		cache_inv(explode_generateTensors_arra__112, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__131 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__131 
		cache_inv(explode_generateTensors_arra__131, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__102 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__102 
		cache_inv(explode_generateTensors_arra__102, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__141 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__141 
		cache_inv(explode_generateTensors_arra__141, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__13 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__56 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__56 
		cache_inv(explode_generateTensors_arra__56, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__117 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__117 
		cache_inv(explode_generateTensors_arra__117, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__53 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__53 
		cache_inv(explode_generateTensors_arra__53, 128*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__48 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__48 
		cache_inv(explode_generateTensors_arra__48, 128*sizeof(char));
		transpose(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,arrayA_256__input__0,output__arrayA__9); // transposeTensor_1
		cache_inv(arrayA_256__input__0, 256*sizeof(int));
		transpose(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,arrayA_3840__input__0,output__arrayA__10); // transposeTensor_15
		cache_inv(arrayA_3840__input__0, 256*sizeof(int));
		receiveStart(); // Core3 > Core2: explode_transposeTensor_0_ou__0 
		receiveEnd(3); // Core3 > Core2: explode_transposeTensor_0_ou__0 
		cache_inv(explode_transposeTensor_0_ou__0, 128*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_10_o__5 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_10_o__5 
		cache_inv(explode_transposeTensor_10_o__5, 128*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_10_o__1 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_10_o__1 
		cache_inv(explode_transposeTensor_10_o__1, 128*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_10_o__7 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_10_o__7 
		cache_inv(explode_transposeTensor_10_o__7, 128*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_10_o__2 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_10_o__2 
		cache_inv(explode_transposeTensor_10_o__2, 128*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_10_o__0 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_10_o__0 
		cache_inv(explode_transposeTensor_10_o__0, 128*sizeof(char));
		receiveStart(); // Core5 > Core2: explode_transposeTensor_11_o__4 
		receiveEnd(5); // Core5 > Core2: explode_transposeTensor_11_o__4 
		cache_inv(explode_transposeTensor_11_o__4, 128*sizeof(char));
		receiveStart(); // Core5 > Core2: explode_transposeTensor_11_o__3 
		receiveEnd(5); // Core5 > Core2: explode_transposeTensor_11_o__3 
		cache_inv(explode_transposeTensor_11_o__3, 128*sizeof(char));
		receiveStart(); // Core1 > Core2: explode_transposeTensor_14_o__5 
		receiveEnd(1); // Core1 > Core2: explode_transposeTensor_14_o__5 
		cache_inv(explode_transposeTensor_14_o__5, 128*sizeof(char));
		// Fork explode_transposeTensor_15_output
		{
			cache_wb(output__arrayA__10, 256*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__10) + 0, 1024);
		cache_inv(output__arrayA__10, 256*sizeof(int));
		// Fork explode_transposeTensor_1_output
		{
			cache_wb(output__arrayA__9, 256*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__9) + 0, 1024);
		cache_inv(output__arrayA__9, 256*sizeof(int));
		cache_wbInv(explode_transposeTensor_1_ou__6, 128*sizeof(char));
		sendStart(0); // Core2 > Core0: explode_transposeTensor_1_ou__6 
		sendEnd(); // Core2 > Core0: explode_transposeTensor_1_ou__6 
		cache_wbInv(explode_transposeTensor_1_ou__5, 128*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_1_ou__5 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_1_ou__5 
		cache_wbInv(explode_transposeTensor_1_ou__1, 128*sizeof(char));
		sendStart(5); // Core2 > Core5: explode_transposeTensor_1_ou__1 
		sendEnd(); // Core2 > Core5: explode_transposeTensor_1_ou__1 
		cache_wbInv(explode_transposeTensor_1_ou__0, 128*sizeof(char));
		sendStart(5); // Core2 > Core5: explode_transposeTensor_1_ou__0 
		sendEnd(); // Core2 > Core5: explode_transposeTensor_1_ou__0 
		cache_wbInv(explode_transposeTensor_1_ou__4, 128*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_1_ou__4 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_1_ou__4 
		cache_wbInv(explode_transposeTensor_1_ou__7, 128*sizeof(char));
		sendStart(0); // Core2 > Core0: explode_transposeTensor_1_ou__7 
		sendEnd(); // Core2 > Core0: explode_transposeTensor_1_ou__7 
		receiveStart(); // Core0 > Core2: explode_transposeTensor_3_ou__7 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_3_ou__7 
		cache_inv(explode_transposeTensor_3_ou__7, 128*sizeof(char));
		receiveStart(); // Core5 > Core2: multiplyTensors_10__implode___0 
		receiveEnd(5); // Core5 > Core2: multiplyTensors_10__implode___0 
		cache_inv(multiplyTensors_10__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__9,arrayB_352__arrayB__0,arrayC__input_768__0); // multiplyTensors_11
		cache_inv(output_96__arrayA__9, 32*sizeof(int));
		cache_inv(arrayB_352__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__12,arrayB_3616__arrayB__0,arrayC__input_256__5); // multiplyTensors_113
		cache_inv(output_32__arrayA__12, 32*sizeof(int));
		cache_inv(arrayB_3616__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_113__implode__0, 1024*sizeof(char));
		sendStart(4); // Core2 > Core4: multiplyTensors_113__implode__0 
		sendEnd(); // Core2 > Core4: multiplyTensors_113__implode__0 
		receiveStart(); // Core5 > Core2: multiplyTensors_12__implode___0 
		receiveEnd(5); // Core5 > Core2: multiplyTensors_12__implode___0 
		cache_inv(multiplyTensors_12__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_0__arrayA__2,arrayB_3840__arrayB__0,arrayC__input_0__1); // multiplyTensors_120
		cache_inv(output_0__arrayA__2, 32*sizeof(int));
		cache_inv(arrayB_3840__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__4,arrayB_3872__arrayB__0,arrayC__input_256__4); // multiplyTensors_121
		cache_inv(output_32__arrayA__4, 32*sizeof(int));
		cache_inv(arrayB_3872__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__2,arrayB_3904__arrayB__0,arrayC__input_512__7); // multiplyTensors_122
		cache_inv(output_64__arrayA__2, 32*sizeof(int));
		cache_inv(arrayB_3904__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__7,arrayB_3936__arrayB__0,arrayC__input_768__14); // multiplyTensors_123
		cache_inv(output_96__arrayA__7, 32*sizeof(int));
		cache_inv(arrayB_3936__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__10,arrayB_3968__arrayB__0,arrayC__input_1024__4); // multiplyTensors_124
		cache_inv(output_128__arrayA__10, 32*sizeof(int));
		cache_inv(arrayB_3968__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_160__arrayA__10,arrayB_4000__arrayB__0,arrayC__input_1280__3); // multiplyTensors_125
		cache_inv(output_160__arrayA__10, 32*sizeof(int));
		cache_inv(arrayB_4000__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_192__arrayA__12,arrayB_4032__arrayB__0,arrayC__input_1536__9); // multiplyTensors_126
		cache_inv(output_192__arrayA__12, 32*sizeof(int));
		cache_inv(arrayB_4032__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_224__arrayA__1,arrayB_4064__arrayB__0,arrayC__input_1792__7); // multiplyTensors_127
		cache_inv(output_224__arrayA__1, 32*sizeof(int));
		cache_inv(arrayB_4064__arrayB__0, 32*sizeof(int));
		receiveStart(); // Core1 > Core2: multiplyTensors_13__implode___0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_13__implode___0 
		cache_inv(multiplyTensors_13__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_192__arrayA__8,arrayB_448__arrayB__0,arrayC__input_1536__13); // multiplyTensors_14
		cache_inv(output_192__arrayA__8, 32*sizeof(int));
		cache_inv(arrayB_448__arrayB__0, 32*sizeof(int));
		receiveStart(); // Core0 > Core2: multiplyTensors_15__implode___0 
		receiveEnd(0); // Core0 > Core2: multiplyTensors_15__implode___0 
		cache_inv(multiplyTensors_15__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_0__arrayA__13,arrayB_768__arrayB__0,arrayC__input_0__9); // multiplyTensors_24
		cache_inv(output_0__arrayA__13, 32*sizeof(int));
		cache_inv(arrayB_768__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_24__implode___0, 1024*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_24__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_24__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_160__arrayA__1,arrayB_160__arrayB__0,arrayC__input_1280__9); // multiplyTensors_5
		cache_inv(output_160__arrayA__1, 32*sizeof(int));
		cache_inv(arrayB_160__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_5__implode_s__0, 1024*sizeof(char));
		sendStart(3); // Core2 > Core3: multiplyTensors_5__implode_s__0 
		sendEnd(); // Core2 > Core3: multiplyTensors_5__implode_s__0 
		receiveStart(); // Core0 > Core2: multiplyTensors_8__implode_s__0 
		receiveEnd(0); // Core0 > Core2: multiplyTensors_8__implode_s__0 
		cache_inv(multiplyTensors_8__implode_s__0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_0__arrayA__1,arrayB_2560__arrayB__0,arrayC__input_0__7); // multiplyTensors_80
		cache_inv(output_0__arrayA__1, 32*sizeof(int));
		cache_inv(arrayB_2560__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_80__implode___0, 1024*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_80__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_80__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__2,arrayB_2592__arrayB__0,arrayC__input_256__15); // multiplyTensors_81
		cache_inv(output_32__arrayA__2, 32*sizeof(int));
		cache_inv(arrayB_2592__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_81__implode___0, 1024*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_81__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_81__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__11,arrayB_2624__arrayB__0,arrayC__input_512__8); // multiplyTensors_82
		cache_inv(output_64__arrayA__11, 32*sizeof(int));
		cache_inv(arrayB_2624__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_82__implode___0, 1024*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_82__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_82__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__4,arrayB_2688__arrayB__0,arrayC__input_1024__3); // multiplyTensors_84
		cache_inv(output_128__arrayA__4, 32*sizeof(int));
		cache_inv(arrayB_2688__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_84__implode___0, 1024*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_84__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_84__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_224__arrayA__6,arrayB_2784__arrayB__0,arrayC__input_1792__15); // multiplyTensors_87
		cache_inv(output_224__arrayA__6, 32*sizeof(int));
		cache_inv(arrayB_2784__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_87__implode___0, 1024*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_87__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_87__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_0__arrayA__3,arrayB_2816__arrayB__0,arrayC__input_0__14); // multiplyTensors_88
		cache_inv(output_0__arrayA__3, 32*sizeof(int));
		cache_inv(arrayB_2816__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_88__implode___0, 1024*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_88__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_88__implode___0 
		receiveStart(); // Core1 > Core2: multiplyTensors_9__implode_s__0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_9__implode_s__0 
		cache_inv(multiplyTensors_9__implode_s__0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_160__arrayA__4,arrayB_2976__arrayB__0,arrayC__input_1280__4); // multiplyTensors_93
		cache_inv(output_160__arrayA__4, 32*sizeof(int));
		cache_inv(arrayB_2976__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_93__implode___0, 1024*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_93__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_93__implode___0 
		// Join implode_sumResults_15_input
		{
			cache_wb(arrayC__input_0__1, 256*sizeof(long));
			memcpy((void*)(arrayC__input__7+256),(void*)( arrayC__input_256__4+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__7, 256*sizeof(long));
			memcpy((void*)(arrayC__input__7+768),(void*)( arrayC__input_768__14+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__4, 256*sizeof(long));
			memcpy((void*)(arrayC__input__7+1280),(void*)( arrayC__input_1280__3+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__9, 256*sizeof(long));
			memcpy((void*)(arrayC__input__7+1792),(void*)( arrayC__input_1792__7+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__1) + 0, 1024);
		cache_inv(arrayC__input_0__1, 256*sizeof(long));
		cache_inv(arrayC__input_256__4, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__7) + 0, 1024);
		cache_inv(arrayC__input_512__7, 256*sizeof(long));
		cache_inv(arrayC__input_768__14, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__4) + 0, 1024);
		cache_inv(arrayC__input_1024__4, 256*sizeof(long));
		cache_inv(arrayC__input_1280__3, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__9) + 0, 1024);
		cache_inv(arrayC__input_1536__9, 256*sizeof(long));
		cache_inv(arrayC__input_1792__7, 256*sizeof(long));
		cache_wbInv(implode_sumResults_15_input___0, 8192*sizeof(char));
		sendStart(3); // Core2 > Core3: implode_sumResults_15_input___0 
		sendEnd(); // Core2 > Core3: implode_sumResults_15_input___0 
		// Join implode_sumResults_1_input
		{
			cache_wb(arrayC__input_0__12, 256*sizeof(long));
			memcpy((void*)(arrayC__input__3+256),(void*)( arrayC__input_256__11+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__12, 256*sizeof(long));
			memcpy((void*)(arrayC__input__3+768),(void*)( arrayC__input_768__0+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__5, 256*sizeof(long));
			memcpy((void*)(arrayC__input__3+1280),(void*)( arrayC__input_1280__7+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__13, 256*sizeof(long));
			memcpy((void*)(arrayC__input__3+1792),(void*)( arrayC__input_1792__9+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__12) + 0, 1024);
		cache_inv(arrayC__input_0__12, 256*sizeof(long));
		cache_inv(arrayC__input_256__11, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__12) + 0, 1024);
		cache_inv(arrayC__input_512__12, 256*sizeof(long));
		cache_inv(arrayC__input_768__0, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__5) + 0, 1024);
		cache_inv(arrayC__input_1024__5, 256*sizeof(long));
		cache_inv(arrayC__input_1280__7, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__13) + 0, 1024);
		cache_inv(arrayC__input_1536__13, 256*sizeof(long));
		cache_inv(arrayC__input_1792__9, 256*sizeof(long));
		sum(16/*rowsA*/,16/*columnsB*/,16/*depthA*/,arrayC__input__3,output__arrayC_256__0); // sumResults_1
		cache_inv(arrayC__input__3, 2048*sizeof(long));
		cache_wbInv(sumResults_1__implode_displa__0, 1024*sizeof(char));
		sendStart(3); // Core2 > Core3: sumResults_1__implode_displa__0 
		sendEnd(); // Core2 > Core3: sumResults_1__implode_displa__0 
	}
}
