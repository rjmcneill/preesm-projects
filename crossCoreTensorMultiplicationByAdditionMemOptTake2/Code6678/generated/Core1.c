/** 
 * @file Core1.c
 * @generated by C6678CPrinter
 * @date Thu Apr 02 23:19:58 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__5;  // explode_generateTensors_arrayA > transposeTensor_14 size:= 1024*char defined in Core0
extern char *const explode_generateTensors_arra__73;  // explode_generateTensors_arrayA > transposeTensor_12 size:= 1024*char defined in Core0
extern char *const explode_generateTensors_arra__123;  // explode_generateTensors_arrayA > transposeTensor_7 size:= 1024*char defined in Core0
extern char *const explode_generateTensors_arra__14;  // explode_generateTensors_arrayB > multiplyTensors_116 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__128;  // explode_generateTensors_arrayB > multiplyTensors_114 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__83;  // explode_generateTensors_arrayB > multiplyTensors_103 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__110;  // explode_generateTensors_arrayB > multiplyTensors_102 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__54;  // explode_generateTensors_arrayB > multiplyTensors_101 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__55;  // explode_generateTensors_arrayB > multiplyTensors_100 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__107;  // explode_generateTensors_arrayB > multiplyTensors_99 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__103;  // explode_generateTensors_arrayB > multiplyTensors_98 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__121;  // explode_generateTensors_arrayB > multiplyTensors_97 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__50;  // explode_generateTensors_arrayB > multiplyTensors_96 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__22;  // explode_generateTensors_arrayB > multiplyTensors_91 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__43;  // explode_generateTensors_arrayB > multiplyTensors_60 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__116;  // explode_generateTensors_arrayB > multiplyTensors_46 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__32;  // explode_generateTensors_arrayB > multiplyTensors_45 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__138;  // explode_generateTensors_arrayB > multiplyTensors_43 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__90;  // explode_generateTensors_arrayB > multiplyTensors_42 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__142;  // explode_generateTensors_arrayB > multiplyTensors_41 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__84;  // explode_generateTensors_arrayB > multiplyTensors_28 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayB > multiplyTensors_13 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__115;  // explode_generateTensors_arrayB > multiplyTensors_9 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__122;  // explode_generateTensors_arrayB > multiplyTensors_2 size:= 128*char defined in Core0
extern int *const arrayA_3072__input__0;  // explode_generateTensors_arrayA_arrayA_3072 > transposeTensor_12_input size:= 256*int defined in Core0
extern int *const output__arrayA__0;  // transposeTensor_12_output > explode_transposeTensor_12_output_arrayA size:= 256*int defined in Core0
extern int *const arrayA_3584__input__0;  // explode_generateTensors_arrayA_arrayA_3584 > transposeTensor_14_input size:= 256*int defined in Core0
extern int *const output__arrayA__8;  // transposeTensor_14_output > explode_transposeTensor_14_output_arrayA size:= 256*int defined in Core0
extern int *const arrayA_1792__input__0;  // explode_generateTensors_arrayA_arrayA_1792 > transposeTensor_7_input size:= 256*int defined in Core0
extern int *const output__arrayA__2;  // transposeTensor_7_output > explode_transposeTensor_7_output_arrayA size:= 256*int defined in Core0
extern char *const explode_transposeTensor_0_ou__3;  // explode_transposeTensor_0_output > multiplyTensors_2 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__2;  // explode_transposeTensor_11_output > multiplyTensors_91 size:= 128*char defined in Core0
extern int *const output_0__arrayA__8;  // explode_transposeTensor_12_output_output_0 > multiplyTensors_96_arrayA size:= 32*int defined in Core0
extern int *const output_32__arrayA__1;  // explode_transposeTensor_12_output_output_32 > multiplyTensors_97_arrayA size:= 32*int defined in Core0
extern int *const output_64__arrayA__0;  // explode_transposeTensor_12_output_output_64 > multiplyTensors_98_arrayA size:= 32*int defined in Core0
extern int *const output_96__arrayA__4;  // explode_transposeTensor_12_output_output_96 > multiplyTensors_99_arrayA size:= 32*int defined in Core0
extern int *const output_128__arrayA__7;  // explode_transposeTensor_12_output_output_128 > multiplyTensors_100_arrayA size:= 32*int defined in Core0
extern int *const output_160__arrayA__6;  // explode_transposeTensor_12_output_output_160 > multiplyTensors_101_arrayA size:= 32*int defined in Core0
extern int *const output_192__arrayA__11;  // explode_transposeTensor_12_output_output_192 > multiplyTensors_102_arrayA size:= 32*int defined in Core0
extern int *const output_224__arrayA__7;  // explode_transposeTensor_12_output_output_224 > multiplyTensors_103_arrayA size:= 32*int defined in Core0
extern int *const output_0__arrayA__0;  // explode_transposeTensor_14_output_output_0 > multiplyTensors_112_arrayA size:= 32*int defined in Core0
extern int *const output_32__arrayA__12;  // explode_transposeTensor_14_output_output_32 > multiplyTensors_113_arrayA size:= 32*int defined in Core0
extern int *const output_64__arrayA__12;  // explode_transposeTensor_14_output_output_64 > multiplyTensors_114_arrayA size:= 32*int defined in Core0
extern int *const output_96__arrayA__3;  // explode_transposeTensor_14_output_output_96 > multiplyTensors_115_arrayA size:= 32*int defined in Core0
extern int *const output_128__arrayA__8;  // explode_transposeTensor_14_output_output_128 > multiplyTensors_116_arrayA size:= 32*int defined in Core0
extern int *const output_160__arrayA__7;  // explode_transposeTensor_14_output_output_160 > multiplyTensors_117_arrayA size:= 32*int defined in Core0
extern int *const output_192__arrayA__14;  // explode_transposeTensor_14_output_output_192 > multiplyTensors_118_arrayA size:= 32*int defined in Core0
extern int *const output_224__arrayA__0;  // explode_transposeTensor_14_output_output_224 > multiplyTensors_119_arrayA size:= 32*int defined in Core0
extern char *const explode_transposeTensor_14_o__0;  // explode_transposeTensor_14_output > multiplyTensors_119 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__7;  // explode_transposeTensor_14_output > multiplyTensors_118 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__4;  // explode_transposeTensor_14_output > multiplyTensors_117 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__2;  // explode_transposeTensor_14_output > multiplyTensors_115 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__5;  // explode_transposeTensor_14_output > multiplyTensors_113 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__1;  // explode_transposeTensor_14_output > multiplyTensors_112 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__5;  // explode_transposeTensor_1_output > multiplyTensors_13 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__4;  // explode_transposeTensor_1_output > multiplyTensors_9 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_3_ou__3;  // explode_transposeTensor_3_output > multiplyTensors_28 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__5;  // explode_transposeTensor_5_output > multiplyTensors_46 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__3;  // explode_transposeTensor_5_output > multiplyTensors_45 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__0;  // explode_transposeTensor_5_output > multiplyTensors_43 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__7;  // explode_transposeTensor_5_output > multiplyTensors_42 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__4;  // explode_transposeTensor_5_output > multiplyTensors_41 size:= 128*char defined in Core0
extern int *const output_0__arrayA__5;  // explode_transposeTensor_7_output_output_0 > multiplyTensors_56_arrayA size:= 32*int defined in Core0
extern int *const output_32__arrayA__5;  // explode_transposeTensor_7_output_output_32 > multiplyTensors_57_arrayA size:= 32*int defined in Core0
extern int *const output_64__arrayA__9;  // explode_transposeTensor_7_output_output_64 > multiplyTensors_58_arrayA size:= 32*int defined in Core0
extern int *const output_96__arrayA__14;  // explode_transposeTensor_7_output_output_96 > multiplyTensors_59_arrayA size:= 32*int defined in Core0
extern int *const output_128__arrayA__13;  // explode_transposeTensor_7_output_output_128 > multiplyTensors_60_arrayA size:= 32*int defined in Core0
extern int *const output_160__arrayA__9;  // explode_transposeTensor_7_output_output_160 > multiplyTensors_61_arrayA size:= 32*int defined in Core0
extern int *const output_192__arrayA__0;  // explode_transposeTensor_7_output_output_192 > multiplyTensors_62_arrayA size:= 32*int defined in Core0
extern int *const output_224__arrayA__9;  // explode_transposeTensor_7_output_output_224 > multiplyTensors_63_arrayA size:= 32*int defined in Core0
extern char *const explode_transposeTensor_7_ou__5;  // explode_transposeTensor_7_output > multiplyTensors_63 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__0;  // explode_transposeTensor_7_output > multiplyTensors_62 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__3;  // explode_transposeTensor_7_output > multiplyTensors_61 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__6;  // explode_transposeTensor_7_output > multiplyTensors_59 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__4;  // explode_transposeTensor_7_output > multiplyTensors_58 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__1;  // explode_transposeTensor_7_output > multiplyTensors_57 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__2;  // explode_transposeTensor_7_output > multiplyTensors_56 size:= 128*char defined in Core0
extern int *const arrayB_3200__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3200 > multiplyTensors_100_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__7;  // multiplyTensors_100_arrayC > implode_sumResults_12_input_input_1024 size:= 256*long defined in Core0
extern int *const arrayB_3232__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3232 > multiplyTensors_101_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1280__13;  // multiplyTensors_101_arrayC > implode_sumResults_12_input_input_1280 size:= 256*long defined in Core0
extern int *const arrayB_3264__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3264 > multiplyTensors_102_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1536__6;  // multiplyTensors_102_arrayC > implode_sumResults_12_input_input_1536 size:= 256*long defined in Core0
extern int *const arrayB_3296__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3296 > multiplyTensors_103_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1792__5;  // multiplyTensors_103_arrayC > implode_sumResults_12_input_input_1792 size:= 256*long defined in Core0
extern int *const arrayB_3648__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3648 > multiplyTensors_114_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__13;  // multiplyTensors_114_arrayC > implode_sumResults_14_input_input_512 size:= 256*long defined in Core0
extern char *const multiplyTensors_114__implode__0;  // multiplyTensors_114 > implode_sumResults_14_input size:= 1024*char defined in Core0
extern int *const arrayB_3712__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3712 > multiplyTensors_116_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__6;  // multiplyTensors_116_arrayC > implode_sumResults_14_input_input_1024 size:= 256*long defined in Core0
extern char *const multiplyTensors_116__implode__0;  // multiplyTensors_116 > implode_sumResults_14_input size:= 1024*char defined in Core0
extern int *const output_160__arrayA__14;  // explode_transposeTensor_1_output_output_160 > multiplyTensors_13_arrayA size:= 32*int defined in Core0
extern int *const arrayB_416__arrayB__0;  // explode_generateTensors_arrayB_arrayB_416 > multiplyTensors_13_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1280__7;  // multiplyTensors_13_arrayC > implode_sumResults_1_input_input_1280 size:= 256*long defined in Core0
extern char *const multiplyTensors_13__implode___0;  // multiplyTensors_13 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const output_64__arrayA__8;  // explode_transposeTensor_0_output_output_64 > multiplyTensors_2_arrayA size:= 32*int defined in Core0
extern int *const arrayB_64__arrayB__0;  // explode_generateTensors_arrayB_arrayB_64 > multiplyTensors_2_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__9;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_512 size:= 256*long defined in Core0
extern char *const multiplyTensors_2__implode_s__0;  // multiplyTensors_2 > implode_sumResults_0_input size:= 1024*char defined in Core0
extern int *const output_128__arrayA__2;  // explode_transposeTensor_3_output_output_128 > multiplyTensors_28_arrayA size:= 32*int defined in Core0
extern int *const arrayB_896__arrayB__0;  // explode_generateTensors_arrayB_arrayB_896 > multiplyTensors_28_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__15;  // multiplyTensors_28_arrayC > implode_sumResults_3_input_input_1024 size:= 256*long defined in Core0
extern char *const multiplyTensors_28__implode___0;  // multiplyTensors_28 > implode_sumResults_3_input size:= 1024*char defined in Core0
extern int *const output_32__arrayA__11;  // explode_transposeTensor_5_output_output_32 > multiplyTensors_41_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1312__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1312 > multiplyTensors_41_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__3;  // multiplyTensors_41_arrayC > implode_sumResults_5_input_input_256 size:= 256*long defined in Core0
extern char *const multiplyTensors_41__implode___0;  // multiplyTensors_41 > implode_sumResults_5_input size:= 1024*char defined in Core0
extern int *const output_64__arrayA__13;  // explode_transposeTensor_5_output_output_64 > multiplyTensors_42_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1344__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1344 > multiplyTensors_42_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__11;  // multiplyTensors_42_arrayC > implode_sumResults_5_input_input_512 size:= 256*long defined in Core0
extern char *const multiplyTensors_42__implode___0;  // multiplyTensors_42 > implode_sumResults_5_input size:= 1024*char defined in Core0
extern int *const output_96__arrayA__0;  // explode_transposeTensor_5_output_output_96 > multiplyTensors_43_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1376__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1376 > multiplyTensors_43_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__1;  // multiplyTensors_43_arrayC > implode_sumResults_5_input_input_768 size:= 256*long defined in Core0
extern char *const multiplyTensors_43__implode___0;  // multiplyTensors_43 > implode_sumResults_5_input size:= 1024*char defined in Core0
extern int *const output_160__arrayA__11;  // explode_transposeTensor_5_output_output_160 > multiplyTensors_45_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1440__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1440 > multiplyTensors_45_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1280__12;  // multiplyTensors_45_arrayC > implode_sumResults_5_input_input_1280 size:= 256*long defined in Core0
extern char *const multiplyTensors_45__implode___0;  // multiplyTensors_45 > implode_sumResults_5_input size:= 1024*char defined in Core0
extern int *const output_192__arrayA__13;  // explode_transposeTensor_5_output_output_192 > multiplyTensors_46_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1472__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1472 > multiplyTensors_46_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1536__15;  // multiplyTensors_46_arrayC > implode_sumResults_5_input_input_1536 size:= 256*long defined in Core0
extern char *const multiplyTensors_46__implode___0;  // multiplyTensors_46 > implode_sumResults_5_input size:= 1024*char defined in Core0
extern int *const arrayB_1920__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1920 > multiplyTensors_60_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__12;  // multiplyTensors_60_arrayC > implode_sumResults_7_input_input_1024 size:= 256*long defined in Core0
extern char *const multiplyTensors_60__implode___0;  // multiplyTensors_60 > implode_sumResults_7_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_64__implode___0;  // multiplyTensors_64 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_65__implode___0;  // multiplyTensors_65 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_66__implode___0;  // multiplyTensors_66 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_67__implode___0;  // multiplyTensors_67 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_68__implode___0;  // multiplyTensors_68 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_69__implode___0;  // multiplyTensors_69 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_70__implode___0;  // multiplyTensors_70 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_71__implode___0;  // multiplyTensors_71 > implode_sumResults_8_input size:= 1024*char defined in Core0
extern int *const output_32__arrayA__14;  // explode_transposeTensor_1_output_output_32 > multiplyTensors_9_arrayA size:= 32*int defined in Core0
extern int *const arrayB_288__arrayB__0;  // explode_generateTensors_arrayB_arrayB_288 > multiplyTensors_9_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__11;  // multiplyTensors_9_arrayC > implode_sumResults_1_input_input_256 size:= 256*long defined in Core0
extern char *const multiplyTensors_9__implode_s__0;  // multiplyTensors_9 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const output_96__arrayA__2;  // explode_transposeTensor_11_output_output_96 > multiplyTensors_91_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2912__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2912 > multiplyTensors_91_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__8;  // multiplyTensors_91_arrayC > implode_sumResults_11_input_input_768 size:= 256*long defined in Core0
extern char *const multiplyTensors_91__implode___0;  // multiplyTensors_91 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern int *const arrayB_3072__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3072 > multiplyTensors_96_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_0__3;  // multiplyTensors_96_arrayC > implode_sumResults_12_input_input_0 size:= 256*long defined in Core0
extern int *const arrayB_3104__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3104 > multiplyTensors_97_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__2;  // multiplyTensors_97_arrayC > implode_sumResults_12_input_input_256 size:= 256*long defined in Core0
extern int *const arrayB_3136__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3136 > multiplyTensors_98_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__1;  // multiplyTensors_98_arrayC > implode_sumResults_12_input_input_512 size:= 256*long defined in Core0
extern int *const arrayB_3168__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3168 > multiplyTensors_99_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__7;  // multiplyTensors_99_arrayC > implode_sumResults_12_input_input_768 size:= 256*long defined in Core0
extern long *const arrayC__input__8;  // implode_sumResults_12_input_arrayC > sumResults_12_input size:= 2048*long defined in Core0
extern long *const arrayC__input_0__13;  // multiplyTensors_64_arrayC > implode_sumResults_8_input_input_0 size:= 256*long defined in Core0
extern long *const arrayC__input_256__10;  // multiplyTensors_65_arrayC > implode_sumResults_8_input_input_256 size:= 256*long defined in Core0
extern long *const arrayC__input_512__3;  // multiplyTensors_66_arrayC > implode_sumResults_8_input_input_512 size:= 256*long defined in Core0
extern long *const arrayC__input_768__4;  // multiplyTensors_67_arrayC > implode_sumResults_8_input_input_768 size:= 256*long defined in Core0
extern long *const arrayC__input_1024__2;  // multiplyTensors_68_arrayC > implode_sumResults_8_input_input_1024 size:= 256*long defined in Core0
extern long *const arrayC__input_1280__5;  // multiplyTensors_69_arrayC > implode_sumResults_8_input_input_1280 size:= 256*long defined in Core0
extern long *const arrayC__input_1536__2;  // multiplyTensors_70_arrayC > implode_sumResults_8_input_input_1536 size:= 256*long defined in Core0
extern long *const arrayC__input_1792__12;  // multiplyTensors_71_arrayC > implode_sumResults_8_input_input_1792 size:= 256*long defined in Core0
extern long *const arrayC__input__14;  // implode_sumResults_8_input_arrayC > sumResults_8_input size:= 2048*long defined in Core0
extern char *const implode_sumResults_8_input____0;  // implode_sumResults_8_input > sumResults_8 size:= 8192*char defined in Core0
extern char *const implode_sumResults_9_input____0;  // implode_sumResults_9_input > sumResults_9 size:= 8192*char defined in Core0
extern long *const output__arrayC_3072__0;  // sumResults_12_output > implode_displayTensor_arrayC_arrayC_3072 size:= 256*long defined in Core0
extern char *const sumResults_12__implode_displ__0;  // sumResults_12 > implode_displayTensor_arrayC size:= 1024*char defined in Core0
extern long *const arrayC__input__6;  // implode_sumResults_9_input_arrayC > sumResults_9_input size:= 2048*long defined in Core0
extern long *const output__arrayC_2304__0;  // sumResults_9_output > implode_displayTensor_arrayC_arrayC_2304 size:= 256*long defined in Core0
extern char *const sumResults_9__implode_displa__0;  // sumResults_9 > implode_displayTensor_arrayC size:= 1024*char defined in Core0

// Core Global Definitions

void core1(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__5 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__5 
		cache_inv(explode_generateTensors_arra__5, 1024*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__73 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__73 
		cache_inv(explode_generateTensors_arra__73, 1024*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__123 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__123 
		cache_inv(explode_generateTensors_arra__123, 1024*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__14 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__14 
		cache_inv(explode_generateTensors_arra__14, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__128 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__128 
		cache_inv(explode_generateTensors_arra__128, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__83 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__83 
		cache_inv(explode_generateTensors_arra__83, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__110 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__110 
		cache_inv(explode_generateTensors_arra__110, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__54 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__54 
		cache_inv(explode_generateTensors_arra__54, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__55 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__55 
		cache_inv(explode_generateTensors_arra__55, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__107 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__107 
		cache_inv(explode_generateTensors_arra__107, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__103 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__103 
		cache_inv(explode_generateTensors_arra__103, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__121 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__121 
		cache_inv(explode_generateTensors_arra__121, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__50 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__50 
		cache_inv(explode_generateTensors_arra__50, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__22 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__22 
		cache_inv(explode_generateTensors_arra__22, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__43 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__43 
		cache_inv(explode_generateTensors_arra__43, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__116 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__116 
		cache_inv(explode_generateTensors_arra__116, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__32 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__32 
		cache_inv(explode_generateTensors_arra__32, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__138 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__138 
		cache_inv(explode_generateTensors_arra__138, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__90 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__90 
		cache_inv(explode_generateTensors_arra__90, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__142 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__142 
		cache_inv(explode_generateTensors_arra__142, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__84 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__84 
		cache_inv(explode_generateTensors_arra__84, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__12 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__115 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__115 
		cache_inv(explode_generateTensors_arra__115, 128*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__122 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__122 
		cache_inv(explode_generateTensors_arra__122, 128*sizeof(char));
		transpose(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,arrayA_3072__input__0,output__arrayA__0); // transposeTensor_12
		cache_inv(arrayA_3072__input__0, 256*sizeof(int));
		transpose(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,arrayA_3584__input__0,output__arrayA__8); // transposeTensor_14
		cache_inv(arrayA_3584__input__0, 256*sizeof(int));
		transpose(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,arrayA_1792__input__0,output__arrayA__2); // transposeTensor_7
		cache_inv(arrayA_1792__input__0, 256*sizeof(int));
		receiveStart(); // Core3 > Core1: explode_transposeTensor_0_ou__3 
		receiveEnd(3); // Core3 > Core1: explode_transposeTensor_0_ou__3 
		cache_inv(explode_transposeTensor_0_ou__3, 128*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_11_o__2 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_11_o__2 
		cache_inv(explode_transposeTensor_11_o__2, 128*sizeof(char));
		// Fork explode_transposeTensor_12_output
		{
			cache_wb(output__arrayA__0, 256*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__0) + 0, 1024);
		cache_inv(output__arrayA__0, 256*sizeof(int));
		// Fork explode_transposeTensor_14_output
		{
			cache_wb(output__arrayA__8, 256*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__8) + 0, 1024);
		cache_inv(output__arrayA__8, 256*sizeof(int));
		cache_wbInv(explode_transposeTensor_14_o__0, 128*sizeof(char));
		sendStart(4); // Core1 > Core4: explode_transposeTensor_14_o__0 
		sendEnd(); // Core1 > Core4: explode_transposeTensor_14_o__0 
		cache_wbInv(explode_transposeTensor_14_o__7, 128*sizeof(char));
		sendStart(3); // Core1 > Core3: explode_transposeTensor_14_o__7 
		sendEnd(); // Core1 > Core3: explode_transposeTensor_14_o__7 
		cache_wbInv(explode_transposeTensor_14_o__4, 128*sizeof(char));
		sendStart(0); // Core1 > Core0: explode_transposeTensor_14_o__4 
		sendEnd(); // Core1 > Core0: explode_transposeTensor_14_o__4 
		cache_wbInv(explode_transposeTensor_14_o__2, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_14_o__2 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_14_o__2 
		cache_wbInv(explode_transposeTensor_14_o__5, 128*sizeof(char));
		sendStart(2); // Core1 > Core2: explode_transposeTensor_14_o__5 
		sendEnd(); // Core1 > Core2: explode_transposeTensor_14_o__5 
		cache_wbInv(explode_transposeTensor_14_o__1, 128*sizeof(char));
		sendStart(6); // Core1 > Core6: explode_transposeTensor_14_o__1 
		sendEnd(); // Core1 > Core6: explode_transposeTensor_14_o__1 
		receiveStart(); // Core2 > Core1: explode_transposeTensor_1_ou__5 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_1_ou__5 
		cache_inv(explode_transposeTensor_1_ou__5, 128*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_1_ou__4 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_1_ou__4 
		cache_inv(explode_transposeTensor_1_ou__4, 128*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_transposeTensor_3_ou__3 
		receiveEnd(0); // Core0 > Core1: explode_transposeTensor_3_ou__3 
		cache_inv(explode_transposeTensor_3_ou__3, 128*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_5_ou__5 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_5_ou__5 
		cache_inv(explode_transposeTensor_5_ou__5, 128*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_5_ou__3 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_5_ou__3 
		cache_inv(explode_transposeTensor_5_ou__3, 128*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_5_ou__0 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_5_ou__0 
		cache_inv(explode_transposeTensor_5_ou__0, 128*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_5_ou__7 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_5_ou__7 
		cache_inv(explode_transposeTensor_5_ou__7, 128*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_5_ou__4 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_5_ou__4 
		cache_inv(explode_transposeTensor_5_ou__4, 128*sizeof(char));
		// Fork explode_transposeTensor_7_output
		{
			cache_wb(output__arrayA__2, 256*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__2) + 0, 1024);
		cache_inv(output__arrayA__2, 256*sizeof(int));
		cache_wbInv(explode_transposeTensor_7_ou__5, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_7_ou__5 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_7_ou__5 
		cache_wbInv(explode_transposeTensor_7_ou__0, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_7_ou__0 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_7_ou__0 
		cache_wbInv(explode_transposeTensor_7_ou__3, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_7_ou__3 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_7_ou__3 
		cache_wbInv(explode_transposeTensor_7_ou__6, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_7_ou__6 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_7_ou__6 
		cache_wbInv(explode_transposeTensor_7_ou__4, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_7_ou__4 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_7_ou__4 
		cache_wbInv(explode_transposeTensor_7_ou__1, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_7_ou__1 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_7_ou__1 
		cache_wbInv(explode_transposeTensor_7_ou__2, 128*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_7_ou__2 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_7_ou__2 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__7,arrayB_3200__arrayB__0,arrayC__input_1024__7); // multiplyTensors_100
		cache_inv(output_128__arrayA__7, 32*sizeof(int));
		cache_inv(arrayB_3200__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_160__arrayA__6,arrayB_3232__arrayB__0,arrayC__input_1280__13); // multiplyTensors_101
		cache_inv(output_160__arrayA__6, 32*sizeof(int));
		cache_inv(arrayB_3232__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_192__arrayA__11,arrayB_3264__arrayB__0,arrayC__input_1536__6); // multiplyTensors_102
		cache_inv(output_192__arrayA__11, 32*sizeof(int));
		cache_inv(arrayB_3264__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_224__arrayA__7,arrayB_3296__arrayB__0,arrayC__input_1792__5); // multiplyTensors_103
		cache_inv(output_224__arrayA__7, 32*sizeof(int));
		cache_inv(arrayB_3296__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__12,arrayB_3648__arrayB__0,arrayC__input_512__13); // multiplyTensors_114
		cache_inv(output_64__arrayA__12, 32*sizeof(int));
		cache_inv(arrayB_3648__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_114__implode__0, 1024*sizeof(char));
		sendStart(4); // Core1 > Core4: multiplyTensors_114__implode__0 
		sendEnd(); // Core1 > Core4: multiplyTensors_114__implode__0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__8,arrayB_3712__arrayB__0,arrayC__input_1024__6); // multiplyTensors_116
		cache_inv(output_128__arrayA__8, 32*sizeof(int));
		cache_inv(arrayB_3712__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_116__implode__0, 1024*sizeof(char));
		sendStart(4); // Core1 > Core4: multiplyTensors_116__implode__0 
		sendEnd(); // Core1 > Core4: multiplyTensors_116__implode__0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_160__arrayA__14,arrayB_416__arrayB__0,arrayC__input_1280__7); // multiplyTensors_13
		cache_inv(output_160__arrayA__14, 32*sizeof(int));
		cache_inv(arrayB_416__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_13__implode___0, 1024*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_13__implode___0 
		sendEnd(); // Core1 > Core2: multiplyTensors_13__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__8,arrayB_64__arrayB__0,arrayC__input_512__9); // multiplyTensors_2
		cache_inv(output_64__arrayA__8, 32*sizeof(int));
		cache_inv(arrayB_64__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_2__implode_s__0, 1024*sizeof(char));
		sendStart(3); // Core1 > Core3: multiplyTensors_2__implode_s__0 
		sendEnd(); // Core1 > Core3: multiplyTensors_2__implode_s__0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__2,arrayB_896__arrayB__0,arrayC__input_1024__15); // multiplyTensors_28
		cache_inv(output_128__arrayA__2, 32*sizeof(int));
		cache_inv(arrayB_896__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_28__implode___0, 1024*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_28__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_28__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__11,arrayB_1312__arrayB__0,arrayC__input_256__3); // multiplyTensors_41
		cache_inv(output_32__arrayA__11, 32*sizeof(int));
		cache_inv(arrayB_1312__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_41__implode___0, 1024*sizeof(char));
		sendStart(0); // Core1 > Core0: multiplyTensors_41__implode___0 
		sendEnd(); // Core1 > Core0: multiplyTensors_41__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__13,arrayB_1344__arrayB__0,arrayC__input_512__11); // multiplyTensors_42
		cache_inv(output_64__arrayA__13, 32*sizeof(int));
		cache_inv(arrayB_1344__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_42__implode___0, 1024*sizeof(char));
		sendStart(0); // Core1 > Core0: multiplyTensors_42__implode___0 
		sendEnd(); // Core1 > Core0: multiplyTensors_42__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__0,arrayB_1376__arrayB__0,arrayC__input_768__1); // multiplyTensors_43
		cache_inv(output_96__arrayA__0, 32*sizeof(int));
		cache_inv(arrayB_1376__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_43__implode___0, 1024*sizeof(char));
		sendStart(0); // Core1 > Core0: multiplyTensors_43__implode___0 
		sendEnd(); // Core1 > Core0: multiplyTensors_43__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_160__arrayA__11,arrayB_1440__arrayB__0,arrayC__input_1280__12); // multiplyTensors_45
		cache_inv(output_160__arrayA__11, 32*sizeof(int));
		cache_inv(arrayB_1440__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_45__implode___0, 1024*sizeof(char));
		sendStart(0); // Core1 > Core0: multiplyTensors_45__implode___0 
		sendEnd(); // Core1 > Core0: multiplyTensors_45__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_192__arrayA__13,arrayB_1472__arrayB__0,arrayC__input_1536__15); // multiplyTensors_46
		cache_inv(output_192__arrayA__13, 32*sizeof(int));
		cache_inv(arrayB_1472__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_46__implode___0, 1024*sizeof(char));
		sendStart(0); // Core1 > Core0: multiplyTensors_46__implode___0 
		sendEnd(); // Core1 > Core0: multiplyTensors_46__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__13,arrayB_1920__arrayB__0,arrayC__input_1024__12); // multiplyTensors_60
		cache_inv(output_128__arrayA__13, 32*sizeof(int));
		cache_inv(arrayB_1920__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_60__implode___0, 1024*sizeof(char));
		sendStart(5); // Core1 > Core5: multiplyTensors_60__implode___0 
		sendEnd(); // Core1 > Core5: multiplyTensors_60__implode___0 
		receiveStart(); // Core3 > Core1: multiplyTensors_64__implode___0 
		receiveEnd(3); // Core3 > Core1: multiplyTensors_64__implode___0 
		cache_inv(multiplyTensors_64__implode___0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core1: multiplyTensors_65__implode___0 
		receiveEnd(3); // Core3 > Core1: multiplyTensors_65__implode___0 
		cache_inv(multiplyTensors_65__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core1: multiplyTensors_66__implode___0 
		receiveEnd(0); // Core0 > Core1: multiplyTensors_66__implode___0 
		cache_inv(multiplyTensors_66__implode___0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core1: multiplyTensors_67__implode___0 
		receiveEnd(3); // Core3 > Core1: multiplyTensors_67__implode___0 
		cache_inv(multiplyTensors_67__implode___0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core1: multiplyTensors_68__implode___0 
		receiveEnd(3); // Core3 > Core1: multiplyTensors_68__implode___0 
		cache_inv(multiplyTensors_68__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core1: multiplyTensors_69__implode___0 
		receiveEnd(0); // Core0 > Core1: multiplyTensors_69__implode___0 
		cache_inv(multiplyTensors_69__implode___0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core1: multiplyTensors_70__implode___0 
		receiveEnd(3); // Core3 > Core1: multiplyTensors_70__implode___0 
		cache_inv(multiplyTensors_70__implode___0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core1: multiplyTensors_71__implode___0 
		receiveEnd(3); // Core3 > Core1: multiplyTensors_71__implode___0 
		cache_inv(multiplyTensors_71__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__14,arrayB_288__arrayB__0,arrayC__input_256__11); // multiplyTensors_9
		cache_inv(output_32__arrayA__14, 32*sizeof(int));
		cache_inv(arrayB_288__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_9__implode_s__0, 1024*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_9__implode_s__0 
		sendEnd(); // Core1 > Core2: multiplyTensors_9__implode_s__0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__2,arrayB_2912__arrayB__0,arrayC__input_768__8); // multiplyTensors_91
		cache_inv(output_96__arrayA__2, 32*sizeof(int));
		cache_inv(arrayB_2912__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_91__implode___0, 1024*sizeof(char));
		sendStart(6); // Core1 > Core6: multiplyTensors_91__implode___0 
		sendEnd(); // Core1 > Core6: multiplyTensors_91__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_0__arrayA__8,arrayB_3072__arrayB__0,arrayC__input_0__3); // multiplyTensors_96
		cache_inv(output_0__arrayA__8, 32*sizeof(int));
		cache_inv(arrayB_3072__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__1,arrayB_3104__arrayB__0,arrayC__input_256__2); // multiplyTensors_97
		cache_inv(output_32__arrayA__1, 32*sizeof(int));
		cache_inv(arrayB_3104__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__0,arrayB_3136__arrayB__0,arrayC__input_512__1); // multiplyTensors_98
		cache_inv(output_64__arrayA__0, 32*sizeof(int));
		cache_inv(arrayB_3136__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__4,arrayB_3168__arrayB__0,arrayC__input_768__7); // multiplyTensors_99
		cache_inv(output_96__arrayA__4, 32*sizeof(int));
		cache_inv(arrayB_3168__arrayB__0, 32*sizeof(int));
		// Join implode_sumResults_12_input
		{
			cache_wb(arrayC__input_0__3, 256*sizeof(long));
			memcpy((void*)(arrayC__input__8+256),(void*)( arrayC__input_256__2+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__1, 256*sizeof(long));
			memcpy((void*)(arrayC__input__8+768),(void*)( arrayC__input_768__7+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__7, 256*sizeof(long));
			memcpy((void*)(arrayC__input__8+1280),(void*)( arrayC__input_1280__13+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__6, 256*sizeof(long));
			memcpy((void*)(arrayC__input__8+1792),(void*)( arrayC__input_1792__5+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__3) + 0, 1024);
		cache_inv(arrayC__input_0__3, 256*sizeof(long));
		cache_inv(arrayC__input_256__2, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__1) + 0, 1024);
		cache_inv(arrayC__input_512__1, 256*sizeof(long));
		cache_inv(arrayC__input_768__7, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__7) + 0, 1024);
		cache_inv(arrayC__input_1024__7, 256*sizeof(long));
		cache_inv(arrayC__input_1280__13, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__6) + 0, 1024);
		cache_inv(arrayC__input_1536__6, 256*sizeof(long));
		cache_inv(arrayC__input_1792__5, 256*sizeof(long));
		// Join implode_sumResults_8_input
		{
			cache_wb(arrayC__input_0__13, 256*sizeof(long));
			memcpy((void*)(arrayC__input__14+256),(void*)( arrayC__input_256__10+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__3, 256*sizeof(long));
			memcpy((void*)(arrayC__input__14+768),(void*)( arrayC__input_768__4+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__2, 256*sizeof(long));
			memcpy((void*)(arrayC__input__14+1280),(void*)( arrayC__input_1280__5+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__2, 256*sizeof(long));
			memcpy((void*)(arrayC__input__14+1792),(void*)( arrayC__input_1792__12+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__13) + 0, 1024);
		cache_inv(arrayC__input_0__13, 256*sizeof(long));
		cache_inv(arrayC__input_256__10, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__3) + 0, 1024);
		cache_inv(arrayC__input_512__3, 256*sizeof(long));
		cache_inv(arrayC__input_768__4, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__2) + 0, 1024);
		cache_inv(arrayC__input_1024__2, 256*sizeof(long));
		cache_inv(arrayC__input_1280__5, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__2) + 0, 1024);
		cache_inv(arrayC__input_1536__2, 256*sizeof(long));
		cache_inv(arrayC__input_1792__12, 256*sizeof(long));
		cache_wbInv(implode_sumResults_8_input____0, 8192*sizeof(char));
		sendStart(7); // Core1 > Core7: implode_sumResults_8_input____0 
		sendEnd(); // Core1 > Core7: implode_sumResults_8_input____0 
		receiveStart(); // Core4 > Core1: implode_sumResults_9_input____0 
		receiveEnd(4); // Core4 > Core1: implode_sumResults_9_input____0 
		cache_inv(implode_sumResults_9_input____0, 8192*sizeof(char));
		sum(16/*rowsA*/,16/*columnsB*/,16/*depthA*/,arrayC__input__8,output__arrayC_3072__0); // sumResults_12
		cache_inv(arrayC__input__8, 2048*sizeof(long));
		cache_wbInv(sumResults_12__implode_displ__0, 1024*sizeof(char));
		sendStart(3); // Core1 > Core3: sumResults_12__implode_displ__0 
		sendEnd(); // Core1 > Core3: sumResults_12__implode_displ__0 
		sum(16/*rowsA*/,16/*columnsB*/,16/*depthA*/,arrayC__input__6,output__arrayC_2304__0); // sumResults_9
		cache_inv(arrayC__input__6, 2048*sizeof(long));
		cache_wbInv(sumResults_9__implode_displa__0, 1024*sizeof(char));
		sendStart(3); // Core1 > Core3: sumResults_9__implode_displa__0 
		sendEnd(); // Core1 > Core3: sumResults_9__implode_displa__0 
	}
}
