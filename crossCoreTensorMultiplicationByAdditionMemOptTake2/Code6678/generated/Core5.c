/** 
 * @file Core5.c
 * @generated by C6678CPrinter
 * @date Thu Apr 02 23:19:58 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__40;  // explode_generateTensors_arrayA > transposeTensor_11 size:= 1024*char defined in Core0
extern char *const explode_generateTensors_arra__74;  // explode_generateTensors_arrayB > multiplyTensors_115 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__30;  // explode_generateTensors_arrayB > multiplyTensors_95 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__109;  // explode_generateTensors_arrayB > multiplyTensors_92 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__52;  // explode_generateTensors_arrayB > multiplyTensors_63 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__71;  // explode_generateTensors_arrayB > multiplyTensors_62 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__81;  // explode_generateTensors_arrayB > multiplyTensors_61 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__44;  // explode_generateTensors_arrayB > multiplyTensors_59 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__132;  // explode_generateTensors_arrayB > multiplyTensors_58 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__29;  // explode_generateTensors_arrayB > multiplyTensors_57 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayB > multiplyTensors_56 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__64;  // explode_generateTensors_arrayB > multiplyTensors_27 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__16;  // explode_generateTensors_arrayB > multiplyTensors_12 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__80;  // explode_generateTensors_arrayB > multiplyTensors_10 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__99;  // explode_generateTensors_arrayB > multiplyTensors_3 size:= 128*char defined in Core0
extern int *const arrayA_2816__input__0;  // explode_generateTensors_arrayA_arrayA_2816 > transposeTensor_11_input size:= 256*int defined in Core0
extern int *const output__arrayA__6;  // transposeTensor_11_output > explode_transposeTensor_11_output_arrayA size:= 256*int defined in Core0
extern char *const transposeTensor_5__explode_t__0;  // transposeTensor_5 > explode_transposeTensor_5_output size:= 1024*char defined in Core0
extern char *const explode_transposeTensor_0_ou__7;  // explode_transposeTensor_0_output > multiplyTensors_3 size:= 128*char defined in Core0
extern int *const output_0__arrayA__3;  // explode_transposeTensor_11_output_output_0 > multiplyTensors_88_arrayA size:= 32*int defined in Core0
extern int *const output_32__arrayA__3;  // explode_transposeTensor_11_output_output_32 > multiplyTensors_89_arrayA size:= 32*int defined in Core0
extern int *const output_64__arrayA__10;  // explode_transposeTensor_11_output_output_64 > multiplyTensors_90_arrayA size:= 32*int defined in Core0
extern int *const output_96__arrayA__2;  // explode_transposeTensor_11_output_output_96 > multiplyTensors_91_arrayA size:= 32*int defined in Core0
extern int *const output_128__arrayA__9;  // explode_transposeTensor_11_output_output_128 > multiplyTensors_92_arrayA size:= 32*int defined in Core0
extern int *const output_160__arrayA__4;  // explode_transposeTensor_11_output_output_160 > multiplyTensors_93_arrayA size:= 32*int defined in Core0
extern int *const output_192__arrayA__2;  // explode_transposeTensor_11_output_output_192 > multiplyTensors_94_arrayA size:= 32*int defined in Core0
extern int *const output_224__arrayA__4;  // explode_transposeTensor_11_output_output_224 > multiplyTensors_95_arrayA size:= 32*int defined in Core0
extern char *const explode_transposeTensor_11_o__0;  // explode_transposeTensor_11_output > multiplyTensors_94 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__4;  // explode_transposeTensor_11_output > multiplyTensors_93 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__2;  // explode_transposeTensor_11_output > multiplyTensors_91 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__7;  // explode_transposeTensor_11_output > multiplyTensors_90 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__1;  // explode_transposeTensor_11_output > multiplyTensors_89 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__3;  // explode_transposeTensor_11_output > multiplyTensors_88 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__2;  // explode_transposeTensor_14_output > multiplyTensors_115 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__1;  // explode_transposeTensor_1_output > multiplyTensors_12 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_1_ou__0;  // explode_transposeTensor_1_output > multiplyTensors_10 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_3_ou__4;  // explode_transposeTensor_3_output > multiplyTensors_27 size:= 128*char defined in Core0
extern int *const output_0__arrayA__7;  // explode_transposeTensor_5_output_output_0 > multiplyTensors_40_arrayA size:= 32*int defined in Core0
extern int *const output_32__arrayA__11;  // explode_transposeTensor_5_output_output_32 > multiplyTensors_41_arrayA size:= 32*int defined in Core0
extern int *const output_64__arrayA__13;  // explode_transposeTensor_5_output_output_64 > multiplyTensors_42_arrayA size:= 32*int defined in Core0
extern int *const output_96__arrayA__0;  // explode_transposeTensor_5_output_output_96 > multiplyTensors_43_arrayA size:= 32*int defined in Core0
extern int *const output_128__arrayA__3;  // explode_transposeTensor_5_output_output_128 > multiplyTensors_44_arrayA size:= 32*int defined in Core0
extern int *const output_160__arrayA__11;  // explode_transposeTensor_5_output_output_160 > multiplyTensors_45_arrayA size:= 32*int defined in Core0
extern int *const output_192__arrayA__13;  // explode_transposeTensor_5_output_output_192 > multiplyTensors_46_arrayA size:= 32*int defined in Core0
extern int *const output_224__arrayA__10;  // explode_transposeTensor_5_output_output_224 > multiplyTensors_47_arrayA size:= 32*int defined in Core0
extern int *const output__arrayA__13;  // transposeTensor_5_output > explode_transposeTensor_5_output_arrayA size:= 256*int defined in Core0
extern char *const explode_transposeTensor_5_ou__6;  // explode_transposeTensor_5_output > multiplyTensors_47 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__5;  // explode_transposeTensor_5_output > multiplyTensors_46 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__3;  // explode_transposeTensor_5_output > multiplyTensors_45 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__1;  // explode_transposeTensor_5_output > multiplyTensors_44 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__0;  // explode_transposeTensor_5_output > multiplyTensors_43 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__7;  // explode_transposeTensor_5_output > multiplyTensors_42 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__4;  // explode_transposeTensor_5_output > multiplyTensors_41 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_5_ou__2;  // explode_transposeTensor_5_output > multiplyTensors_40 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__5;  // explode_transposeTensor_7_output > multiplyTensors_63 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__0;  // explode_transposeTensor_7_output > multiplyTensors_62 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__3;  // explode_transposeTensor_7_output > multiplyTensors_61 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__6;  // explode_transposeTensor_7_output > multiplyTensors_59 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__4;  // explode_transposeTensor_7_output > multiplyTensors_58 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__1;  // explode_transposeTensor_7_output > multiplyTensors_57 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_7_ou__2;  // explode_transposeTensor_7_output > multiplyTensors_56 size:= 128*char defined in Core0
extern int *const output_64__arrayA__1;  // explode_transposeTensor_1_output_output_64 > multiplyTensors_10_arrayA size:= 32*int defined in Core0
extern int *const arrayB_320__arrayB__0;  // explode_generateTensors_arrayB_arrayB_320 > multiplyTensors_10_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__12;  // multiplyTensors_10_arrayC > implode_sumResults_1_input_input_512 size:= 256*long defined in Core0
extern char *const multiplyTensors_10__implode___0;  // multiplyTensors_10 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const output_96__arrayA__3;  // explode_transposeTensor_14_output_output_96 > multiplyTensors_115_arrayA size:= 32*int defined in Core0
extern int *const arrayB_3680__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3680 > multiplyTensors_115_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__10;  // multiplyTensors_115_arrayC > implode_sumResults_14_input_input_768 size:= 256*long defined in Core0
extern char *const multiplyTensors_115__implode__0;  // multiplyTensors_115 > implode_sumResults_14_input size:= 1024*char defined in Core0
extern int *const output_128__arrayA__5;  // explode_transposeTensor_1_output_output_128 > multiplyTensors_12_arrayA size:= 32*int defined in Core0
extern int *const arrayB_384__arrayB__0;  // explode_generateTensors_arrayB_arrayB_384 > multiplyTensors_12_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__5;  // multiplyTensors_12_arrayC > implode_sumResults_1_input_input_1024 size:= 256*long defined in Core0
extern char *const multiplyTensors_12__implode___0;  // multiplyTensors_12 > implode_sumResults_1_input size:= 1024*char defined in Core0
extern int *const output_96__arrayA__1;  // explode_transposeTensor_3_output_output_96 > multiplyTensors_27_arrayA size:= 32*int defined in Core0
extern int *const arrayB_864__arrayB__0;  // explode_generateTensors_arrayB_arrayB_864 > multiplyTensors_27_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__15;  // multiplyTensors_27_arrayC > implode_sumResults_3_input_input_768 size:= 256*long defined in Core0
extern char *const multiplyTensors_27__implode___0;  // multiplyTensors_27 > implode_sumResults_3_input size:= 1024*char defined in Core0
extern int *const output_96__arrayA__15;  // explode_transposeTensor_0_output_output_96 > multiplyTensors_3_arrayA size:= 32*int defined in Core0
extern int *const arrayB_96__arrayB__0;  // explode_generateTensors_arrayB_arrayB_96 > multiplyTensors_3_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__2;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_768 size:= 256*long defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_32__implode___0;  // multiplyTensors_32 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_33__implode___0;  // multiplyTensors_33 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_34__implode___0;  // multiplyTensors_34 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_35__implode___0;  // multiplyTensors_35 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_36__implode___0;  // multiplyTensors_36 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_37__implode___0;  // multiplyTensors_37 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_38__implode___0;  // multiplyTensors_38 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_39__implode___0;  // multiplyTensors_39 > implode_sumResults_4_input size:= 1024*char defined in Core0
extern int *const output_0__arrayA__5;  // explode_transposeTensor_7_output_output_0 > multiplyTensors_56_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1792__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1792 > multiplyTensors_56_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_0__8;  // multiplyTensors_56_arrayC > implode_sumResults_7_input_input_0 size:= 256*long defined in Core0
extern int *const output_32__arrayA__5;  // explode_transposeTensor_7_output_output_32 > multiplyTensors_57_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1824__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1824 > multiplyTensors_57_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__8;  // multiplyTensors_57_arrayC > implode_sumResults_7_input_input_256 size:= 256*long defined in Core0
extern int *const output_64__arrayA__9;  // explode_transposeTensor_7_output_output_64 > multiplyTensors_58_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1856__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1856 > multiplyTensors_58_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__0;  // multiplyTensors_58_arrayC > implode_sumResults_7_input_input_512 size:= 256*long defined in Core0
extern int *const output_96__arrayA__14;  // explode_transposeTensor_7_output_output_96 > multiplyTensors_59_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1888__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1888 > multiplyTensors_59_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_768__13;  // multiplyTensors_59_arrayC > implode_sumResults_7_input_input_768 size:= 256*long defined in Core0
extern char *const multiplyTensors_60__implode___0;  // multiplyTensors_60 > implode_sumResults_7_input size:= 1024*char defined in Core0
extern int *const output_160__arrayA__9;  // explode_transposeTensor_7_output_output_160 > multiplyTensors_61_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1952__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1952 > multiplyTensors_61_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1280__10;  // multiplyTensors_61_arrayC > implode_sumResults_7_input_input_1280 size:= 256*long defined in Core0
extern int *const output_192__arrayA__0;  // explode_transposeTensor_7_output_output_192 > multiplyTensors_62_arrayA size:= 32*int defined in Core0
extern int *const arrayB_1984__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1984 > multiplyTensors_62_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1536__7;  // multiplyTensors_62_arrayC > implode_sumResults_7_input_input_1536 size:= 256*long defined in Core0
extern int *const output_224__arrayA__9;  // explode_transposeTensor_7_output_output_224 > multiplyTensors_63_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2016__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2016 > multiplyTensors_63_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1792__3;  // multiplyTensors_63_arrayC > implode_sumResults_7_input_input_1792 size:= 256*long defined in Core0
extern int *const arrayB_2944__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2944 > multiplyTensors_92_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1024__9;  // multiplyTensors_92_arrayC > implode_sumResults_11_input_input_1024 size:= 256*long defined in Core0
extern char *const multiplyTensors_92__implode___0;  // multiplyTensors_92 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern int *const arrayB_3040__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3040 > multiplyTensors_95_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1792__8;  // multiplyTensors_95_arrayC > implode_sumResults_11_input_input_1792 size:= 256*long defined in Core0
extern char *const multiplyTensors_95__implode___0;  // multiplyTensors_95 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern long *const arrayC__input_0__11;  // multiplyTensors_32_arrayC > implode_sumResults_4_input_input_0 size:= 256*long defined in Core0
extern long *const arrayC__input_256__7;  // multiplyTensors_33_arrayC > implode_sumResults_4_input_input_256 size:= 256*long defined in Core0
extern long *const arrayC__input_512__6;  // multiplyTensors_34_arrayC > implode_sumResults_4_input_input_512 size:= 256*long defined in Core0
extern long *const arrayC__input_768__11;  // multiplyTensors_35_arrayC > implode_sumResults_4_input_input_768 size:= 256*long defined in Core0
extern long *const arrayC__input_1024__11;  // multiplyTensors_36_arrayC > implode_sumResults_4_input_input_1024 size:= 256*long defined in Core0
extern long *const arrayC__input_1280__2;  // multiplyTensors_37_arrayC > implode_sumResults_4_input_input_1280 size:= 256*long defined in Core0
extern long *const arrayC__input_1536__10;  // multiplyTensors_38_arrayC > implode_sumResults_4_input_input_1536 size:= 256*long defined in Core0
extern long *const arrayC__input_1792__6;  // multiplyTensors_39_arrayC > implode_sumResults_4_input_input_1792 size:= 256*long defined in Core0
extern long *const arrayC__input__9;  // implode_sumResults_4_input_arrayC > sumResults_4_input size:= 2048*long defined in Core0
extern char *const implode_sumResults_4_input____0;  // implode_sumResults_4_input > sumResults_4 size:= 8192*char defined in Core0
extern long *const arrayC__input_1024__12;  // multiplyTensors_60_arrayC > implode_sumResults_7_input_input_1024 size:= 256*long defined in Core0
extern long *const arrayC__input__13;  // implode_sumResults_7_input_arrayC > sumResults_7_input size:= 2048*long defined in Core0
extern long *const output__arrayC_1792__0;  // sumResults_7_output > implode_displayTensor_arrayC_arrayC_1792 size:= 256*long defined in Core0
extern char *const sumResults_7__implode_displa__0;  // sumResults_7 > implode_displayTensor_arrayC size:= 1024*char defined in Core0

// Core Global Definitions

void core5(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__40 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__40 
		cache_inv(explode_generateTensors_arra__40, 1024*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__74 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__74 
		cache_inv(explode_generateTensors_arra__74, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__30 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__30 
		cache_inv(explode_generateTensors_arra__30, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__109 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__109 
		cache_inv(explode_generateTensors_arra__109, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__52 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__52 
		cache_inv(explode_generateTensors_arra__52, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__71 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__71 
		cache_inv(explode_generateTensors_arra__71, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__81 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__81 
		cache_inv(explode_generateTensors_arra__81, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__44 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__44 
		cache_inv(explode_generateTensors_arra__44, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__132 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__132 
		cache_inv(explode_generateTensors_arra__132, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__29 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__29 
		cache_inv(explode_generateTensors_arra__29, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__6 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__64 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__64 
		cache_inv(explode_generateTensors_arra__64, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__16 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__16 
		cache_inv(explode_generateTensors_arra__16, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__80 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__80 
		cache_inv(explode_generateTensors_arra__80, 128*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__99 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__99 
		cache_inv(explode_generateTensors_arra__99, 128*sizeof(char));
		transpose(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,arrayA_2816__input__0,output__arrayA__6); // transposeTensor_11
		cache_inv(arrayA_2816__input__0, 256*sizeof(int));
		receiveStart(); // Core0 > Core5: transposeTensor_5__explode_t__0 
		receiveEnd(0); // Core0 > Core5: transposeTensor_5__explode_t__0 
		cache_inv(transposeTensor_5__explode_t__0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_0_ou__7 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_0_ou__7 
		cache_inv(explode_transposeTensor_0_ou__7, 128*sizeof(char));
		// Fork explode_transposeTensor_11_output
		{
			cache_wb(output__arrayA__6, 256*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__6) + 0, 1024);
		cache_inv(output__arrayA__6, 256*sizeof(int));
		cache_wbInv(explode_transposeTensor_11_o__0, 128*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_11_o__0 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_11_o__0 
		cache_wbInv(explode_transposeTensor_11_o__4, 128*sizeof(char));
		sendStart(2); // Core5 > Core2: explode_transposeTensor_11_o__4 
		sendEnd(); // Core5 > Core2: explode_transposeTensor_11_o__4 
		cache_wbInv(explode_transposeTensor_11_o__2, 128*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_11_o__2 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_11_o__2 
		cache_wbInv(explode_transposeTensor_11_o__7, 128*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_11_o__7 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_11_o__7 
		cache_wbInv(explode_transposeTensor_11_o__1, 128*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_11_o__1 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_11_o__1 
		cache_wbInv(explode_transposeTensor_11_o__3, 128*sizeof(char));
		sendStart(2); // Core5 > Core2: explode_transposeTensor_11_o__3 
		sendEnd(); // Core5 > Core2: explode_transposeTensor_11_o__3 
		receiveStart(); // Core1 > Core5: explode_transposeTensor_14_o__2 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_14_o__2 
		cache_inv(explode_transposeTensor_14_o__2, 128*sizeof(char));
		receiveStart(); // Core2 > Core5: explode_transposeTensor_1_ou__1 
		receiveEnd(2); // Core2 > Core5: explode_transposeTensor_1_ou__1 
		cache_inv(explode_transposeTensor_1_ou__1, 128*sizeof(char));
		receiveStart(); // Core2 > Core5: explode_transposeTensor_1_ou__0 
		receiveEnd(2); // Core2 > Core5: explode_transposeTensor_1_ou__0 
		cache_inv(explode_transposeTensor_1_ou__0, 128*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_transposeTensor_3_ou__4 
		receiveEnd(0); // Core0 > Core5: explode_transposeTensor_3_ou__4 
		cache_inv(explode_transposeTensor_3_ou__4, 128*sizeof(char));
		// Fork explode_transposeTensor_5_output
		{
			cache_wb(output__arrayA__13, 256*sizeof(int));
		}
		cache_wb(((char*)output__arrayA__13) + 0, 1024);
		cache_inv(output__arrayA__13, 256*sizeof(int));
		cache_wbInv(explode_transposeTensor_5_ou__6, 128*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_5_ou__6 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_5_ou__6 
		cache_wbInv(explode_transposeTensor_5_ou__5, 128*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_5_ou__5 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_5_ou__5 
		cache_wbInv(explode_transposeTensor_5_ou__3, 128*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_5_ou__3 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_5_ou__3 
		cache_wbInv(explode_transposeTensor_5_ou__1, 128*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_5_ou__1 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_5_ou__1 
		cache_wbInv(explode_transposeTensor_5_ou__0, 128*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_5_ou__0 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_5_ou__0 
		cache_wbInv(explode_transposeTensor_5_ou__7, 128*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_5_ou__7 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_5_ou__7 
		cache_wbInv(explode_transposeTensor_5_ou__4, 128*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_5_ou__4 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_5_ou__4 
		cache_wbInv(explode_transposeTensor_5_ou__2, 128*sizeof(char));
		sendStart(0); // Core5 > Core0: explode_transposeTensor_5_ou__2 
		sendEnd(); // Core5 > Core0: explode_transposeTensor_5_ou__2 
		receiveStart(); // Core1 > Core5: explode_transposeTensor_7_ou__5 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_7_ou__5 
		cache_inv(explode_transposeTensor_7_ou__5, 128*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_7_ou__0 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_7_ou__0 
		cache_inv(explode_transposeTensor_7_ou__0, 128*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_7_ou__3 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_7_ou__3 
		cache_inv(explode_transposeTensor_7_ou__3, 128*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_7_ou__6 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_7_ou__6 
		cache_inv(explode_transposeTensor_7_ou__6, 128*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_7_ou__4 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_7_ou__4 
		cache_inv(explode_transposeTensor_7_ou__4, 128*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_7_ou__1 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_7_ou__1 
		cache_inv(explode_transposeTensor_7_ou__1, 128*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_7_ou__2 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_7_ou__2 
		cache_inv(explode_transposeTensor_7_ou__2, 128*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__1,arrayB_320__arrayB__0,arrayC__input_512__12); // multiplyTensors_10
		cache_inv(output_64__arrayA__1, 32*sizeof(int));
		cache_inv(arrayB_320__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_10__implode___0, 1024*sizeof(char));
		sendStart(2); // Core5 > Core2: multiplyTensors_10__implode___0 
		sendEnd(); // Core5 > Core2: multiplyTensors_10__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__3,arrayB_3680__arrayB__0,arrayC__input_768__10); // multiplyTensors_115
		cache_inv(output_96__arrayA__3, 32*sizeof(int));
		cache_inv(arrayB_3680__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_115__implode__0, 1024*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_115__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_115__implode__0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__5,arrayB_384__arrayB__0,arrayC__input_1024__5); // multiplyTensors_12
		cache_inv(output_128__arrayA__5, 32*sizeof(int));
		cache_inv(arrayB_384__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_12__implode___0, 1024*sizeof(char));
		sendStart(2); // Core5 > Core2: multiplyTensors_12__implode___0 
		sendEnd(); // Core5 > Core2: multiplyTensors_12__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__1,arrayB_864__arrayB__0,arrayC__input_768__15); // multiplyTensors_27
		cache_inv(output_96__arrayA__1, 32*sizeof(int));
		cache_inv(arrayB_864__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_27__implode___0, 1024*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_27__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_27__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__15,arrayB_96__arrayB__0,arrayC__input_768__2); // multiplyTensors_3
		cache_inv(output_96__arrayA__15, 32*sizeof(int));
		cache_inv(arrayB_96__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_3__implode_s__0, 1024*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_3__implode_s__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_3__implode_s__0 
		receiveStart(); // Core0 > Core5: multiplyTensors_32__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_32__implode___0 
		cache_inv(multiplyTensors_32__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_33__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_33__implode___0 
		cache_inv(multiplyTensors_33__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_34__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_34__implode___0 
		cache_inv(multiplyTensors_34__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_35__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_35__implode___0 
		cache_inv(multiplyTensors_35__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_36__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_36__implode___0 
		cache_inv(multiplyTensors_36__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_37__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_37__implode___0 
		cache_inv(multiplyTensors_37__implode___0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core5: multiplyTensors_38__implode___0 
		receiveEnd(3); // Core3 > Core5: multiplyTensors_38__implode___0 
		cache_inv(multiplyTensors_38__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_39__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_39__implode___0 
		cache_inv(multiplyTensors_39__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_0__arrayA__5,arrayB_1792__arrayB__0,arrayC__input_0__8); // multiplyTensors_56
		cache_inv(output_0__arrayA__5, 32*sizeof(int));
		cache_inv(arrayB_1792__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__5,arrayB_1824__arrayB__0,arrayC__input_256__8); // multiplyTensors_57
		cache_inv(output_32__arrayA__5, 32*sizeof(int));
		cache_inv(arrayB_1824__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__9,arrayB_1856__arrayB__0,arrayC__input_512__0); // multiplyTensors_58
		cache_inv(output_64__arrayA__9, 32*sizeof(int));
		cache_inv(arrayB_1856__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_96__arrayA__14,arrayB_1888__arrayB__0,arrayC__input_768__13); // multiplyTensors_59
		cache_inv(output_96__arrayA__14, 32*sizeof(int));
		cache_inv(arrayB_1888__arrayB__0, 32*sizeof(int));
		receiveStart(); // Core1 > Core5: multiplyTensors_60__implode___0 
		receiveEnd(1); // Core1 > Core5: multiplyTensors_60__implode___0 
		cache_inv(multiplyTensors_60__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_160__arrayA__9,arrayB_1952__arrayB__0,arrayC__input_1280__10); // multiplyTensors_61
		cache_inv(output_160__arrayA__9, 32*sizeof(int));
		cache_inv(arrayB_1952__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_192__arrayA__0,arrayB_1984__arrayB__0,arrayC__input_1536__7); // multiplyTensors_62
		cache_inv(output_192__arrayA__0, 32*sizeof(int));
		cache_inv(arrayB_1984__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_224__arrayA__9,arrayB_2016__arrayB__0,arrayC__input_1792__3); // multiplyTensors_63
		cache_inv(output_224__arrayA__9, 32*sizeof(int));
		cache_inv(arrayB_2016__arrayB__0, 32*sizeof(int));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_128__arrayA__9,arrayB_2944__arrayB__0,arrayC__input_1024__9); // multiplyTensors_92
		cache_inv(output_128__arrayA__9, 32*sizeof(int));
		cache_inv(arrayB_2944__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_92__implode___0, 1024*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_92__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_92__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_224__arrayA__4,arrayB_3040__arrayB__0,arrayC__input_1792__8); // multiplyTensors_95
		cache_inv(output_224__arrayA__4, 32*sizeof(int));
		cache_inv(arrayB_3040__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_95__implode___0, 1024*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_95__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_95__implode___0 
		// Join implode_sumResults_4_input
		{
			cache_wb(arrayC__input_0__11, 256*sizeof(long));
			memcpy((void*)(arrayC__input__9+256),(void*)( arrayC__input_256__7+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__6, 256*sizeof(long));
			memcpy((void*)(arrayC__input__9+768),(void*)( arrayC__input_768__11+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__11, 256*sizeof(long));
			memcpy((void*)(arrayC__input__9+1280),(void*)( arrayC__input_1280__2+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__10, 256*sizeof(long));
			memcpy((void*)(arrayC__input__9+1792),(void*)( arrayC__input_1792__6+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__11) + 0, 1024);
		cache_inv(arrayC__input_0__11, 256*sizeof(long));
		cache_inv(arrayC__input_256__7, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__6) + 0, 1024);
		cache_inv(arrayC__input_512__6, 256*sizeof(long));
		cache_inv(arrayC__input_768__11, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__11) + 0, 1024);
		cache_inv(arrayC__input_1024__11, 256*sizeof(long));
		cache_inv(arrayC__input_1280__2, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__10) + 0, 1024);
		cache_inv(arrayC__input_1536__10, 256*sizeof(long));
		cache_inv(arrayC__input_1792__6, 256*sizeof(long));
		cache_wbInv(implode_sumResults_4_input____0, 8192*sizeof(char));
		sendStart(3); // Core5 > Core3: implode_sumResults_4_input____0 
		sendEnd(); // Core5 > Core3: implode_sumResults_4_input____0 
		// Join implode_sumResults_7_input
		{
			cache_wb(arrayC__input_0__8, 256*sizeof(long));
			memcpy((void*)(arrayC__input__13+256),(void*)( arrayC__input_256__8+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__0, 256*sizeof(long));
			memcpy((void*)(arrayC__input__13+768),(void*)( arrayC__input_768__13+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__12, 256*sizeof(long));
			memcpy((void*)(arrayC__input__13+1280),(void*)( arrayC__input_1280__10+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__7, 256*sizeof(long));
			memcpy((void*)(arrayC__input__13+1792),(void*)( arrayC__input_1792__3+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__8) + 0, 1024);
		cache_inv(arrayC__input_0__8, 256*sizeof(long));
		cache_inv(arrayC__input_256__8, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__0) + 0, 1024);
		cache_inv(arrayC__input_512__0, 256*sizeof(long));
		cache_inv(arrayC__input_768__13, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__12) + 0, 1024);
		cache_inv(arrayC__input_1024__12, 256*sizeof(long));
		cache_inv(arrayC__input_1280__10, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__7) + 0, 1024);
		cache_inv(arrayC__input_1536__7, 256*sizeof(long));
		cache_inv(arrayC__input_1792__3, 256*sizeof(long));
		sum(16/*rowsA*/,16/*columnsB*/,16/*depthA*/,arrayC__input__13,output__arrayC_1792__0); // sumResults_7
		cache_inv(arrayC__input__13, 2048*sizeof(long));
		cache_wbInv(sumResults_7__implode_displa__0, 1024*sizeof(char));
		sendStart(3); // Core5 > Core3: sumResults_7__implode_displa__0 
		sendEnd(); // Core5 > Core3: sumResults_7__implode_displa__0 
	}
}
