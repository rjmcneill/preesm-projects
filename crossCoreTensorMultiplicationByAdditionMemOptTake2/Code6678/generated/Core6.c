/** 
 * @file Core6.c
 * @generated by C6678CPrinter
 * @date Thu Apr 02 23:19:58 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__77;  // explode_generateTensors_arrayB > multiplyTensors_112 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__2;  // explode_generateTensors_arrayB > multiplyTensors_90 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__105;  // explode_generateTensors_arrayB > multiplyTensors_26 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__27;  // explode_generateTensors_arrayB > multiplyTensors_6 size:= 128*char defined in Core0
extern char *const explode_generateTensors_arra__21;  // explode_generateTensors_arrayB > multiplyTensors_1 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_0_ou__4;  // explode_transposeTensor_0_output > multiplyTensors_6 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_0_ou__1;  // explode_transposeTensor_0_output > multiplyTensors_1 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_11_o__7;  // explode_transposeTensor_11_output > multiplyTensors_90 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_14_o__1;  // explode_transposeTensor_14_output > multiplyTensors_112 size:= 128*char defined in Core0
extern char *const explode_transposeTensor_3_ou__5;  // explode_transposeTensor_3_output > multiplyTensors_26 size:= 128*char defined in Core0
extern int *const output_32__arrayA__6;  // explode_transposeTensor_0_output_output_32 > multiplyTensors_1_arrayA size:= 32*int defined in Core0
extern int *const arrayB_32__arrayB__0;  // explode_generateTensors_arrayB_arrayB_32 > multiplyTensors_1_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_256__14;  // multiplyTensors_1_arrayC > implode_sumResults_0_input_input_256 size:= 256*long defined in Core0
extern char *const multiplyTensors_1__implode_s__0;  // multiplyTensors_1 > implode_sumResults_0_input size:= 1024*char defined in Core0
extern int *const output_0__arrayA__0;  // explode_transposeTensor_14_output_output_0 > multiplyTensors_112_arrayA size:= 32*int defined in Core0
extern int *const arrayB_3584__arrayB__0;  // explode_generateTensors_arrayB_arrayB_3584 > multiplyTensors_112_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_0__4;  // multiplyTensors_112_arrayC > implode_sumResults_14_input_input_0 size:= 256*long defined in Core0
extern char *const multiplyTensors_112__implode__0;  // multiplyTensors_112 > implode_sumResults_14_input size:= 1024*char defined in Core0
extern int *const output_64__arrayA__5;  // explode_transposeTensor_3_output_output_64 > multiplyTensors_26_arrayA size:= 32*int defined in Core0
extern int *const arrayB_832__arrayB__0;  // explode_generateTensors_arrayB_arrayB_832 > multiplyTensors_26_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__15;  // multiplyTensors_26_arrayC > implode_sumResults_3_input_input_512 size:= 256*long defined in Core0
extern char *const multiplyTensors_26__implode___0;  // multiplyTensors_26 > implode_sumResults_3_input size:= 1024*char defined in Core0
extern int *const output_192__arrayA__7;  // explode_transposeTensor_0_output_output_192 > multiplyTensors_6_arrayA size:= 32*int defined in Core0
extern int *const arrayB_192__arrayB__0;  // explode_generateTensors_arrayB_arrayB_192 > multiplyTensors_6_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_1536__5;  // multiplyTensors_6_arrayC > implode_sumResults_0_input_input_1536 size:= 256*long defined in Core0
extern char *const multiplyTensors_6__implode_s__0;  // multiplyTensors_6 > implode_sumResults_0_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_80__implode___0;  // multiplyTensors_80 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_81__implode___0;  // multiplyTensors_81 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_82__implode___0;  // multiplyTensors_82 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_83__implode___0;  // multiplyTensors_83 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_84__implode___0;  // multiplyTensors_84 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_85__implode___0;  // multiplyTensors_85 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_86__implode___0;  // multiplyTensors_86 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_87__implode___0;  // multiplyTensors_87 > implode_sumResults_10_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_88__implode___0;  // multiplyTensors_88 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_89__implode___0;  // multiplyTensors_89 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern int *const output_64__arrayA__10;  // explode_transposeTensor_11_output_output_64 > multiplyTensors_90_arrayA size:= 32*int defined in Core0
extern int *const arrayB_2880__arrayB__0;  // explode_generateTensors_arrayB_arrayB_2880 > multiplyTensors_90_arrayB size:= 32*int defined in Core0
extern long *const arrayC__input_512__5;  // multiplyTensors_90_arrayC > implode_sumResults_11_input_input_512 size:= 256*long defined in Core0
extern char *const multiplyTensors_91__implode___0;  // multiplyTensors_91 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_92__implode___0;  // multiplyTensors_92 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_93__implode___0;  // multiplyTensors_93 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_94__implode___0;  // multiplyTensors_94 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern char *const multiplyTensors_95__implode___0;  // multiplyTensors_95 > implode_sumResults_11_input size:= 1024*char defined in Core0
extern long *const arrayC__input_0__7;  // multiplyTensors_80_arrayC > implode_sumResults_10_input_input_0 size:= 256*long defined in Core0
extern long *const arrayC__input_256__15;  // multiplyTensors_81_arrayC > implode_sumResults_10_input_input_256 size:= 256*long defined in Core0
extern long *const arrayC__input_512__8;  // multiplyTensors_82_arrayC > implode_sumResults_10_input_input_512 size:= 256*long defined in Core0
extern long *const arrayC__input_768__12;  // multiplyTensors_83_arrayC > implode_sumResults_10_input_input_768 size:= 256*long defined in Core0
extern long *const arrayC__input_1024__3;  // multiplyTensors_84_arrayC > implode_sumResults_10_input_input_1024 size:= 256*long defined in Core0
extern long *const arrayC__input_1280__14;  // multiplyTensors_85_arrayC > implode_sumResults_10_input_input_1280 size:= 256*long defined in Core0
extern long *const arrayC__input_1536__14;  // multiplyTensors_86_arrayC > implode_sumResults_10_input_input_1536 size:= 256*long defined in Core0
extern long *const arrayC__input_1792__15;  // multiplyTensors_87_arrayC > implode_sumResults_10_input_input_1792 size:= 256*long defined in Core0
extern long *const arrayC__input__0;  // implode_sumResults_10_input_arrayC > sumResults_10_input size:= 2048*long defined in Core0
extern char *const implode_sumResults_10_input___0;  // implode_sumResults_10_input > sumResults_10 size:= 8192*char defined in Core0
extern long *const arrayC__input_0__14;  // multiplyTensors_88_arrayC > implode_sumResults_11_input_input_0 size:= 256*long defined in Core0
extern long *const arrayC__input_256__0;  // multiplyTensors_89_arrayC > implode_sumResults_11_input_input_256 size:= 256*long defined in Core0
extern long *const arrayC__input_768__8;  // multiplyTensors_91_arrayC > implode_sumResults_11_input_input_768 size:= 256*long defined in Core0
extern long *const arrayC__input_1024__9;  // multiplyTensors_92_arrayC > implode_sumResults_11_input_input_1024 size:= 256*long defined in Core0
extern long *const arrayC__input_1280__4;  // multiplyTensors_93_arrayC > implode_sumResults_11_input_input_1280 size:= 256*long defined in Core0
extern long *const arrayC__input_1536__3;  // multiplyTensors_94_arrayC > implode_sumResults_11_input_input_1536 size:= 256*long defined in Core0
extern long *const arrayC__input_1792__8;  // multiplyTensors_95_arrayC > implode_sumResults_11_input_input_1792 size:= 256*long defined in Core0
extern long *const arrayC__input__12;  // implode_sumResults_11_input_arrayC > sumResults_11_input size:= 2048*long defined in Core0
extern long *const output__arrayC_2816__0;  // sumResults_11_output > implode_displayTensor_arrayC_arrayC_2816 size:= 256*long defined in Core0
extern char *const sumResults_11__implode_displ__0;  // sumResults_11 > implode_displayTensor_arrayC size:= 1024*char defined in Core0

// Core Global Definitions

void core6(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__77 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__77 
		cache_inv(explode_generateTensors_arra__77, 128*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__2 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__2 
		cache_inv(explode_generateTensors_arra__2, 128*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__105 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__105 
		cache_inv(explode_generateTensors_arra__105, 128*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__27 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__27 
		cache_inv(explode_generateTensors_arra__27, 128*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__21 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__21 
		cache_inv(explode_generateTensors_arra__21, 128*sizeof(char));
		receiveStart(); // Core3 > Core6: explode_transposeTensor_0_ou__4 
		receiveEnd(3); // Core3 > Core6: explode_transposeTensor_0_ou__4 
		cache_inv(explode_transposeTensor_0_ou__4, 128*sizeof(char));
		receiveStart(); // Core3 > Core6: explode_transposeTensor_0_ou__1 
		receiveEnd(3); // Core3 > Core6: explode_transposeTensor_0_ou__1 
		cache_inv(explode_transposeTensor_0_ou__1, 128*sizeof(char));
		receiveStart(); // Core5 > Core6: explode_transposeTensor_11_o__7 
		receiveEnd(5); // Core5 > Core6: explode_transposeTensor_11_o__7 
		cache_inv(explode_transposeTensor_11_o__7, 128*sizeof(char));
		receiveStart(); // Core1 > Core6: explode_transposeTensor_14_o__1 
		receiveEnd(1); // Core1 > Core6: explode_transposeTensor_14_o__1 
		cache_inv(explode_transposeTensor_14_o__1, 128*sizeof(char));
		receiveStart(); // Core0 > Core6: explode_transposeTensor_3_ou__5 
		receiveEnd(0); // Core0 > Core6: explode_transposeTensor_3_ou__5 
		cache_inv(explode_transposeTensor_3_ou__5, 128*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_32__arrayA__6,arrayB_32__arrayB__0,arrayC__input_256__14); // multiplyTensors_1
		cache_inv(output_32__arrayA__6, 32*sizeof(int));
		cache_inv(arrayB_32__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_1__implode_s__0, 1024*sizeof(char));
		sendStart(3); // Core6 > Core3: multiplyTensors_1__implode_s__0 
		sendEnd(); // Core6 > Core3: multiplyTensors_1__implode_s__0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_0__arrayA__0,arrayB_3584__arrayB__0,arrayC__input_0__4); // multiplyTensors_112
		cache_inv(output_0__arrayA__0, 32*sizeof(int));
		cache_inv(arrayB_3584__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_112__implode__0, 1024*sizeof(char));
		sendStart(4); // Core6 > Core4: multiplyTensors_112__implode__0 
		sendEnd(); // Core6 > Core4: multiplyTensors_112__implode__0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__5,arrayB_832__arrayB__0,arrayC__input_512__15); // multiplyTensors_26
		cache_inv(output_64__arrayA__5, 32*sizeof(int));
		cache_inv(arrayB_832__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_26__implode___0, 1024*sizeof(char));
		sendStart(7); // Core6 > Core7: multiplyTensors_26__implode___0 
		sendEnd(); // Core6 > Core7: multiplyTensors_26__implode___0 
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_192__arrayA__7,arrayB_192__arrayB__0,arrayC__input_1536__5); // multiplyTensors_6
		cache_inv(output_192__arrayA__7, 32*sizeof(int));
		cache_inv(arrayB_192__arrayB__0, 32*sizeof(int));
		cache_wbInv(multiplyTensors_6__implode_s__0, 1024*sizeof(char));
		sendStart(3); // Core6 > Core3: multiplyTensors_6__implode_s__0 
		sendEnd(); // Core6 > Core3: multiplyTensors_6__implode_s__0 
		receiveStart(); // Core2 > Core6: multiplyTensors_80__implode___0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_80__implode___0 
		cache_inv(multiplyTensors_80__implode___0, 1024*sizeof(char));
		receiveStart(); // Core2 > Core6: multiplyTensors_81__implode___0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_81__implode___0 
		cache_inv(multiplyTensors_81__implode___0, 1024*sizeof(char));
		receiveStart(); // Core2 > Core6: multiplyTensors_82__implode___0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_82__implode___0 
		cache_inv(multiplyTensors_82__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core6: multiplyTensors_83__implode___0 
		receiveEnd(0); // Core0 > Core6: multiplyTensors_83__implode___0 
		cache_inv(multiplyTensors_83__implode___0, 1024*sizeof(char));
		receiveStart(); // Core2 > Core6: multiplyTensors_84__implode___0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_84__implode___0 
		cache_inv(multiplyTensors_84__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core6: multiplyTensors_85__implode___0 
		receiveEnd(0); // Core0 > Core6: multiplyTensors_85__implode___0 
		cache_inv(multiplyTensors_85__implode___0, 1024*sizeof(char));
		receiveStart(); // Core3 > Core6: multiplyTensors_86__implode___0 
		receiveEnd(3); // Core3 > Core6: multiplyTensors_86__implode___0 
		cache_inv(multiplyTensors_86__implode___0, 1024*sizeof(char));
		receiveStart(); // Core2 > Core6: multiplyTensors_87__implode___0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_87__implode___0 
		cache_inv(multiplyTensors_87__implode___0, 1024*sizeof(char));
		receiveStart(); // Core2 > Core6: multiplyTensors_88__implode___0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_88__implode___0 
		cache_inv(multiplyTensors_88__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core6: multiplyTensors_89__implode___0 
		receiveEnd(0); // Core0 > Core6: multiplyTensors_89__implode___0 
		cache_inv(multiplyTensors_89__implode___0, 1024*sizeof(char));
		multiply(16/*rowsA*/,16/*columnsA*/,16/*depthA*/,16/*rowsB*/,16/*columnsB*/,16/*depthB*/,output_64__arrayA__10,arrayB_2880__arrayB__0,arrayC__input_512__5); // multiplyTensors_90
		cache_inv(output_64__arrayA__10, 32*sizeof(int));
		cache_inv(arrayB_2880__arrayB__0, 32*sizeof(int));
		receiveStart(); // Core1 > Core6: multiplyTensors_91__implode___0 
		receiveEnd(1); // Core1 > Core6: multiplyTensors_91__implode___0 
		cache_inv(multiplyTensors_91__implode___0, 1024*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_92__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_92__implode___0 
		cache_inv(multiplyTensors_92__implode___0, 1024*sizeof(char));
		receiveStart(); // Core2 > Core6: multiplyTensors_93__implode___0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_93__implode___0 
		cache_inv(multiplyTensors_93__implode___0, 1024*sizeof(char));
		receiveStart(); // Core0 > Core6: multiplyTensors_94__implode___0 
		receiveEnd(0); // Core0 > Core6: multiplyTensors_94__implode___0 
		cache_inv(multiplyTensors_94__implode___0, 1024*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_95__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_95__implode___0 
		cache_inv(multiplyTensors_95__implode___0, 1024*sizeof(char));
		// Join implode_sumResults_10_input
		{
			cache_wb(arrayC__input_0__7, 256*sizeof(long));
			memcpy((void*)(arrayC__input__0+256),(void*)( arrayC__input_256__15+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__8, 256*sizeof(long));
			memcpy((void*)(arrayC__input__0+768),(void*)( arrayC__input_768__12+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__3, 256*sizeof(long));
			memcpy((void*)(arrayC__input__0+1280),(void*)( arrayC__input_1280__14+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__14, 256*sizeof(long));
			memcpy((void*)(arrayC__input__0+1792),(void*)( arrayC__input_1792__15+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__7) + 0, 1024);
		cache_inv(arrayC__input_0__7, 256*sizeof(long));
		cache_inv(arrayC__input_256__15, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__8) + 0, 1024);
		cache_inv(arrayC__input_512__8, 256*sizeof(long));
		cache_inv(arrayC__input_768__12, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__3) + 0, 1024);
		cache_inv(arrayC__input_1024__3, 256*sizeof(long));
		cache_inv(arrayC__input_1280__14, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__14) + 0, 1024);
		cache_inv(arrayC__input_1536__14, 256*sizeof(long));
		cache_inv(arrayC__input_1792__15, 256*sizeof(long));
		cache_wbInv(implode_sumResults_10_input___0, 8192*sizeof(char));
		sendStart(0); // Core6 > Core0: implode_sumResults_10_input___0 
		sendEnd(); // Core6 > Core0: implode_sumResults_10_input___0 
		// Join implode_sumResults_11_input
		{
			cache_wb(arrayC__input_0__14, 256*sizeof(long));
			memcpy((void*)(arrayC__input__12+256),(void*)( arrayC__input_256__0+0), 256*sizeof(long));
			cache_wb(arrayC__input_512__5, 256*sizeof(long));
			memcpy((void*)(arrayC__input__12+768),(void*)( arrayC__input_768__8+0), 256*sizeof(long));
			cache_wb(arrayC__input_1024__9, 256*sizeof(long));
			memcpy((void*)(arrayC__input__12+1280),(void*)( arrayC__input_1280__4+0), 256*sizeof(long));
			cache_wb(arrayC__input_1536__3, 256*sizeof(long));
			memcpy((void*)(arrayC__input__12+1792),(void*)( arrayC__input_1792__8+0), 256*sizeof(long));
		}
		cache_wb(((char*)arrayC__input_0__14) + 0, 1024);
		cache_inv(arrayC__input_0__14, 256*sizeof(long));
		cache_inv(arrayC__input_256__0, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_512__5) + 0, 1024);
		cache_inv(arrayC__input_512__5, 256*sizeof(long));
		cache_inv(arrayC__input_768__8, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1024__9) + 0, 1024);
		cache_inv(arrayC__input_1024__9, 256*sizeof(long));
		cache_inv(arrayC__input_1280__4, 256*sizeof(long));
		cache_wb(((char*)arrayC__input_1536__3) + 0, 1024);
		cache_inv(arrayC__input_1536__3, 256*sizeof(long));
		cache_inv(arrayC__input_1792__8, 256*sizeof(long));
		sum(16/*rowsA*/,16/*columnsB*/,16/*depthA*/,arrayC__input__12,output__arrayC_2816__0); // sumResults_11
		cache_inv(arrayC__input__12, 2048*sizeof(long));
		cache_wbInv(sumResults_11__implode_displ__0, 1024*sizeof(char));
		sendStart(3); // Core6 > Core3: sumResults_11__implode_displ__0 
		sendEnd(); // Core6 > Core3: sumResults_11__implode_displ__0 
	}
}
