/** 
 * @file Core1.c
 * @generated by C6678CPrinter
 * @date Mon Apr 20 00:05:10 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayA > splitTensorA_27 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__52;  // explode_generateTensors_arrayA > splitTensorA_26 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__34;  // explode_generateTensors_arrayA > splitTensorA_22 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayA > splitTensorA_0 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__47;  // explode_generateTensors_arrayB > transpose_4 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__19;  // explode_generateTensors_arrayB > transpose_0 size:= 256*char defined in Core0
extern int *const arrayA_0__input__0;  // explode_generateTensors_arrayA_arrayA_0 > splitTensorA_0_input size:= 64*int defined in Core0
extern int *const output0__inputA__19;  // splitTensorA_0_output0 > multiply0_0_inputA size:= 8*int defined in Core0
extern int *const output1__inputA__19;  // splitTensorA_0_output1 > multiply1_0_inputA size:= 8*int defined in Core0
extern int *const output2__inputA__3;  // splitTensorA_0_output2 > multiply2_0_inputA size:= 8*int defined in Core0
extern int *const output3__inputA__21;  // splitTensorA_0_output3 > multiply3_0_inputA size:= 8*int defined in Core0
extern int *const output4__inputA__25;  // splitTensorA_0_output4 > multiply4_0_inputA size:= 8*int defined in Core0
extern int *const output5__inputA__27;  // splitTensorA_0_output5 > multiply5_0_inputA size:= 8*int defined in Core0
extern int *const output6__inputA__19;  // splitTensorA_0_output6 > multiply6_0_inputA size:= 8*int defined in Core0
extern int *const output7__inputA__5;  // splitTensorA_0_output7 > multiply7_0_inputA size:= 8*int defined in Core0
extern char *const splitTensorA_0__multiply7_0__0;  // splitTensorA_0 > multiply7_0 size:= 32*char defined in Core0
extern char *const splitTensorA_0__multiply6_0__0;  // splitTensorA_0 > multiply6_0 size:= 32*char defined in Core0
extern char *const splitTensorA_0__multiply5_0__0;  // splitTensorA_0 > multiply5_0 size:= 32*char defined in Core0
extern char *const splitTensorA_0__multiply4_0__0;  // splitTensorA_0 > multiply4_0 size:= 32*char defined in Core0
extern char *const splitTensorA_0__multiply3_0__0;  // splitTensorA_0 > multiply3_0 size:= 32*char defined in Core0
extern char *const splitTensorA_0__multiply2_0__0;  // splitTensorA_0 > multiply2_0 size:= 32*char defined in Core0
extern char *const splitTensorA_0__multiply0_0__0;  // splitTensorA_0 > multiply0_0 size:= 32*char defined in Core0
extern char *const splitTensorA_1__multiply1_1__0;  // splitTensorA_1 > multiply1_1 size:= 32*char defined in Core0
extern char *const splitTensorA_10__multiply1_1__0;  // splitTensorA_10 > multiply1_10 size:= 32*char defined in Core0
extern char *const splitTensorA_11__multiply1_1__0;  // splitTensorA_11 > multiply1_11 size:= 32*char defined in Core0
extern char *const splitTensorA_12__multiply1_1__0;  // splitTensorA_12 > multiply1_12 size:= 32*char defined in Core0
extern char *const splitTensorA_13__multiply1_1__0;  // splitTensorA_13 > multiply1_13 size:= 32*char defined in Core0
extern char *const splitTensorA_14__multiply1_1__0;  // splitTensorA_14 > multiply1_14 size:= 32*char defined in Core0
extern char *const splitTensorA_15__multiply1_1__0;  // splitTensorA_15 > multiply1_15 size:= 32*char defined in Core0
extern char *const splitTensorA_16__multiply1_1__0;  // splitTensorA_16 > multiply1_16 size:= 32*char defined in Core0
extern char *const splitTensorA_17__multiply1_1__0;  // splitTensorA_17 > multiply1_17 size:= 32*char defined in Core0
extern char *const splitTensorA_18__multiply1_1__0;  // splitTensorA_18 > multiply1_18 size:= 32*char defined in Core0
extern char *const splitTensorA_19__multiply1_1__0;  // splitTensorA_19 > multiply1_19 size:= 32*char defined in Core0
extern char *const splitTensorA_2__multiply1_2__0;  // splitTensorA_2 > multiply1_2 size:= 32*char defined in Core0
extern char *const splitTensorA_20__multiply1_2__0;  // splitTensorA_20 > multiply1_20 size:= 32*char defined in Core0
extern char *const splitTensorA_21__multiply1_2__0;  // splitTensorA_21 > multiply1_21 size:= 32*char defined in Core0
extern int *const arrayA_1408__input__0;  // explode_generateTensors_arrayA_arrayA_1408 > splitTensorA_22_input size:= 64*int defined in Core0
extern int *const output0__inputA__25;  // splitTensorA_22_output0 > multiply0_22_inputA size:= 8*int defined in Core0
extern int *const output1__inputA__17;  // splitTensorA_22_output1 > multiply1_22_inputA size:= 8*int defined in Core0
extern int *const output2__inputA__1;  // splitTensorA_22_output2 > multiply2_22_inputA size:= 8*int defined in Core0
extern int *const output3__inputA__19;  // splitTensorA_22_output3 > multiply3_22_inputA size:= 8*int defined in Core0
extern int *const output4__inputA__27;  // splitTensorA_22_output4 > multiply4_22_inputA size:= 8*int defined in Core0
extern int *const output5__inputA__19;  // splitTensorA_22_output5 > multiply5_22_inputA size:= 8*int defined in Core0
extern int *const output6__inputA__17;  // splitTensorA_22_output6 > multiply6_22_inputA size:= 8*int defined in Core0
extern int *const output7__inputA__30;  // splitTensorA_22_output7 > multiply7_22_inputA size:= 8*int defined in Core0
extern char *const splitTensorA_22__multiply7_2__0;  // splitTensorA_22 > multiply7_22 size:= 32*char defined in Core0
extern char *const splitTensorA_22__multiply6_2__0;  // splitTensorA_22 > multiply6_22 size:= 32*char defined in Core0
extern char *const splitTensorA_22__multiply5_2__0;  // splitTensorA_22 > multiply5_22 size:= 32*char defined in Core0
extern char *const splitTensorA_22__multiply4_2__0;  // splitTensorA_22 > multiply4_22 size:= 32*char defined in Core0
extern char *const splitTensorA_22__multiply3_2__0;  // splitTensorA_22 > multiply3_22 size:= 32*char defined in Core0
extern char *const splitTensorA_22__multiply2_2__0;  // splitTensorA_22 > multiply2_22 size:= 32*char defined in Core0
extern char *const splitTensorA_22__multiply0_2__0;  // splitTensorA_22 > multiply0_22 size:= 32*char defined in Core0
extern char *const splitTensorA_23__multiply1_2__0;  // splitTensorA_23 > multiply1_23 size:= 32*char defined in Core0
extern char *const splitTensorA_24__multiply1_2__0;  // splitTensorA_24 > multiply1_24 size:= 32*char defined in Core0
extern char *const splitTensorA_25__multiply1_2__0;  // splitTensorA_25 > multiply1_25 size:= 32*char defined in Core0
extern int *const arrayA_1664__input__0;  // explode_generateTensors_arrayA_arrayA_1664 > splitTensorA_26_input size:= 64*int defined in Core0
extern int *const output0__inputA__8;  // splitTensorA_26_output0 > multiply0_26_inputA size:= 8*int defined in Core0
extern int *const output1__inputA__18;  // splitTensorA_26_output1 > multiply1_26_inputA size:= 8*int defined in Core0
extern int *const output2__inputA__0;  // splitTensorA_26_output2 > multiply2_26_inputA size:= 8*int defined in Core0
extern int *const output3__inputA__4;  // splitTensorA_26_output3 > multiply3_26_inputA size:= 8*int defined in Core0
extern int *const output4__inputA__17;  // splitTensorA_26_output4 > multiply4_26_inputA size:= 8*int defined in Core0
extern int *const output5__inputA__15;  // splitTensorA_26_output5 > multiply5_26_inputA size:= 8*int defined in Core0
extern int *const output6__inputA__30;  // splitTensorA_26_output6 > multiply6_26_inputA size:= 8*int defined in Core0
extern int *const output7__inputA__6;  // splitTensorA_26_output7 > multiply7_26_inputA size:= 8*int defined in Core0
extern char *const splitTensorA_26__multiply7_2__0;  // splitTensorA_26 > multiply7_26 size:= 32*char defined in Core0
extern char *const splitTensorA_26__multiply6_2__0;  // splitTensorA_26 > multiply6_26 size:= 32*char defined in Core0
extern char *const splitTensorA_26__multiply5_2__0;  // splitTensorA_26 > multiply5_26 size:= 32*char defined in Core0
extern char *const splitTensorA_26__multiply4_2__0;  // splitTensorA_26 > multiply4_26 size:= 32*char defined in Core0
extern char *const splitTensorA_26__multiply3_2__0;  // splitTensorA_26 > multiply3_26 size:= 32*char defined in Core0
extern char *const splitTensorA_26__multiply2_2__0;  // splitTensorA_26 > multiply2_26 size:= 32*char defined in Core0
extern char *const splitTensorA_26__multiply0_2__0;  // splitTensorA_26 > multiply0_26 size:= 32*char defined in Core0
extern int *const arrayA_1728__input__0;  // explode_generateTensors_arrayA_arrayA_1728 > splitTensorA_27_input size:= 64*int defined in Core0
extern int *const output0__inputA__7;  // splitTensorA_27_output0 > multiply0_27_inputA size:= 8*int defined in Core0
extern int *const output1__inputA__3;  // splitTensorA_27_output1 > multiply1_27_inputA size:= 8*int defined in Core0
extern int *const output2__inputA__5;  // splitTensorA_27_output2 > multiply2_27_inputA size:= 8*int defined in Core0
extern int *const output3__inputA__7;  // splitTensorA_27_output3 > multiply3_27_inputA size:= 8*int defined in Core0
extern int *const output4__inputA__1;  // splitTensorA_27_output4 > multiply4_27_inputA size:= 8*int defined in Core0
extern int *const output5__inputA__11;  // splitTensorA_27_output5 > multiply5_27_inputA size:= 8*int defined in Core0
extern int *const output6__inputA__2;  // splitTensorA_27_output6 > multiply6_27_inputA size:= 8*int defined in Core0
extern int *const output7__inputA__28;  // splitTensorA_27_output7 > multiply7_27_inputA size:= 8*int defined in Core0
extern char *const splitTensorA_27__multiply7_2__0;  // splitTensorA_27 > multiply7_27 size:= 32*char defined in Core0
extern char *const splitTensorA_27__multiply6_2__0;  // splitTensorA_27 > multiply6_27 size:= 32*char defined in Core0
extern char *const splitTensorA_27__multiply5_2__0;  // splitTensorA_27 > multiply5_27 size:= 32*char defined in Core0
extern char *const splitTensorA_27__multiply4_2__0;  // splitTensorA_27 > multiply4_27 size:= 32*char defined in Core0
extern char *const splitTensorA_27__multiply3_2__0;  // splitTensorA_27 > multiply3_27 size:= 32*char defined in Core0
extern char *const splitTensorA_27__multiply2_2__0;  // splitTensorA_27 > multiply2_27 size:= 32*char defined in Core0
extern char *const splitTensorA_27__multiply0_2__0;  // splitTensorA_27 > multiply0_27 size:= 32*char defined in Core0
extern char *const splitTensorA_28__multiply1_2__0;  // splitTensorA_28 > multiply1_28 size:= 32*char defined in Core0
extern char *const splitTensorA_29__multiply1_2__0;  // splitTensorA_29 > multiply1_29 size:= 32*char defined in Core0
extern char *const splitTensorA_3__multiply1_3__0;  // splitTensorA_3 > multiply1_3 size:= 32*char defined in Core0
extern char *const splitTensorA_30__multiply1_3__0;  // splitTensorA_30 > multiply1_30 size:= 32*char defined in Core0
extern char *const splitTensorA_31__multiply1_3__0;  // splitTensorA_31 > multiply1_31 size:= 32*char defined in Core0
extern char *const splitTensorA_4__multiply1_4__0;  // splitTensorA_4 > multiply1_4 size:= 32*char defined in Core0
extern char *const splitTensorA_5__multiply1_5__0;  // splitTensorA_5 > multiply1_5 size:= 32*char defined in Core0
extern char *const splitTensorA_6__multiply1_6__0;  // splitTensorA_6 > multiply1_6 size:= 32*char defined in Core0
extern char *const splitTensorA_7__multiply1_7__0;  // splitTensorA_7 > multiply1_7 size:= 32*char defined in Core0
extern char *const splitTensorA_8__multiply1_8__0;  // splitTensorA_8 > multiply1_8 size:= 32*char defined in Core0
extern char *const splitTensorA_9__multiply1_9__0;  // splitTensorA_9 > multiply1_9 size:= 32*char defined in Core0
extern int *const arrayB_0__input__0;  // explode_generateTensors_arrayB_arrayB_0 > transpose_0_input size:= 64*int defined in Core0
extern int *const output__input__13;  // transpose_0_output > splitTensorB_0_input size:= 64*int defined in Core0
extern char *const transpose_10__splitTensorB_1__0;  // transpose_10 > splitTensorB_10 size:= 256*char defined in Core0
extern char *const transpose_13__splitTensorB_1__0;  // transpose_13 > splitTensorB_13 size:= 256*char defined in Core0
extern char *const transpose_19__splitTensorB_1__0;  // transpose_19 > splitTensorB_19 size:= 256*char defined in Core0
extern char *const transpose_25__splitTensorB_2__0;  // transpose_25 > splitTensorB_25 size:= 256*char defined in Core0
extern char *const transpose_26__splitTensorB_2__0;  // transpose_26 > splitTensorB_26 size:= 256*char defined in Core0
extern char *const transpose_27__splitTensorB_2__0;  // transpose_27 > splitTensorB_27 size:= 256*char defined in Core0
extern char *const transpose_3__splitTensorB_3__0;  // transpose_3 > splitTensorB_3 size:= 256*char defined in Core0
extern char *const transpose_31__splitTensorB_3__0;  // transpose_31 > splitTensorB_31 size:= 256*char defined in Core0
extern int *const arrayB_256__input__0;  // explode_generateTensors_arrayB_arrayB_256 > transpose_4_input size:= 64*int defined in Core0
extern int *const output__input__18;  // transpose_4_output > splitTensorB_4_input size:= 64*int defined in Core0
extern char *const transpose_4__splitTensorB_4__0;  // transpose_4 > splitTensorB_4 size:= 256*char defined in Core0
extern int *const output0__inputB__22;  // splitTensorB_0_output0 > multiply0_0_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__26;  // splitTensorB_0_output1 > multiply1_0_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__24;  // splitTensorB_0_output2 > multiply2_0_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__23;  // splitTensorB_0_output3 > multiply3_0_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__30;  // splitTensorB_0_output4 > multiply4_0_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__0;  // splitTensorB_0_output5 > multiply5_0_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__2;  // splitTensorB_0_output6 > multiply6_0_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__11;  // splitTensorB_0_output7 > multiply7_0_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_0__multiply7_0__0;  // splitTensorB_0 > multiply7_0 size:= 32*char defined in Core0
extern char *const splitTensorB_0__multiply6_0__0;  // splitTensorB_0 > multiply6_0 size:= 32*char defined in Core0
extern char *const splitTensorB_0__multiply5_0__0;  // splitTensorB_0 > multiply5_0 size:= 32*char defined in Core0
extern char *const splitTensorB_0__multiply4_0__0;  // splitTensorB_0 > multiply4_0 size:= 32*char defined in Core0
extern char *const splitTensorB_0__multiply3_0__0;  // splitTensorB_0 > multiply3_0 size:= 32*char defined in Core0
extern char *const splitTensorB_0__multiply2_0__0;  // splitTensorB_0 > multiply2_0 size:= 32*char defined in Core0
extern char *const splitTensorB_0__multiply0_0__0;  // splitTensorB_0 > multiply0_0 size:= 32*char defined in Core0
extern char *const splitTensorB_1__multiply1_1__0;  // splitTensorB_1 > multiply1_1 size:= 32*char defined in Core0
extern int *const output__input__23;  // transpose_10_output > splitTensorB_10_input size:= 64*int defined in Core0
extern int *const output0__inputB__0;  // splitTensorB_10_output0 > multiply0_10_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__16;  // splitTensorB_10_output1 > multiply1_10_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__12;  // splitTensorB_10_output2 > multiply2_10_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__30;  // splitTensorB_10_output3 > multiply3_10_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__1;  // splitTensorB_10_output4 > multiply4_10_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__6;  // splitTensorB_10_output5 > multiply5_10_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__13;  // splitTensorB_10_output6 > multiply6_10_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__13;  // splitTensorB_10_output7 > multiply7_10_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_10__multiply7_1__0;  // splitTensorB_10 > multiply7_10 size:= 32*char defined in Core0
extern char *const splitTensorB_10__multiply6_1__0;  // splitTensorB_10 > multiply6_10 size:= 32*char defined in Core0
extern char *const splitTensorB_10__multiply5_1__0;  // splitTensorB_10 > multiply5_10 size:= 32*char defined in Core0
extern char *const splitTensorB_10__multiply4_1__0;  // splitTensorB_10 > multiply4_10 size:= 32*char defined in Core0
extern char *const splitTensorB_10__multiply3_1__0;  // splitTensorB_10 > multiply3_10 size:= 32*char defined in Core0
extern char *const splitTensorB_10__multiply2_1__0;  // splitTensorB_10 > multiply2_10 size:= 32*char defined in Core0
extern char *const splitTensorB_10__multiply0_1__0;  // splitTensorB_10 > multiply0_10 size:= 32*char defined in Core0
extern char *const splitTensorB_11__multiply1_1__0;  // splitTensorB_11 > multiply1_11 size:= 32*char defined in Core0
extern char *const splitTensorB_12__multiply1_1__0;  // splitTensorB_12 > multiply1_12 size:= 32*char defined in Core0
extern int *const output__input__19;  // transpose_13_output > splitTensorB_13_input size:= 64*int defined in Core0
extern int *const output0__inputB__26;  // splitTensorB_13_output0 > multiply0_13_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__4;  // splitTensorB_13_output1 > multiply1_13_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__3;  // splitTensorB_13_output2 > multiply2_13_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__27;  // splitTensorB_13_output3 > multiply3_13_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__4;  // splitTensorB_13_output4 > multiply4_13_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__30;  // splitTensorB_13_output5 > multiply5_13_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__31;  // splitTensorB_13_output6 > multiply6_13_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__28;  // splitTensorB_13_output7 > multiply7_13_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_13__multiply7_1__0;  // splitTensorB_13 > multiply7_13 size:= 32*char defined in Core0
extern char *const splitTensorB_13__multiply6_1__0;  // splitTensorB_13 > multiply6_13 size:= 32*char defined in Core0
extern char *const splitTensorB_13__multiply5_1__0;  // splitTensorB_13 > multiply5_13 size:= 32*char defined in Core0
extern char *const splitTensorB_13__multiply4_1__0;  // splitTensorB_13 > multiply4_13 size:= 32*char defined in Core0
extern char *const splitTensorB_13__multiply3_1__0;  // splitTensorB_13 > multiply3_13 size:= 32*char defined in Core0
extern char *const splitTensorB_13__multiply2_1__0;  // splitTensorB_13 > multiply2_13 size:= 32*char defined in Core0
extern char *const splitTensorB_13__multiply0_1__0;  // splitTensorB_13 > multiply0_13 size:= 32*char defined in Core0
extern char *const splitTensorB_14__multiply1_1__0;  // splitTensorB_14 > multiply1_14 size:= 32*char defined in Core0
extern char *const splitTensorB_15__multiply1_1__0;  // splitTensorB_15 > multiply1_15 size:= 32*char defined in Core0
extern char *const splitTensorB_16__multiply1_1__0;  // splitTensorB_16 > multiply1_16 size:= 32*char defined in Core0
extern char *const splitTensorB_17__multiply1_1__0;  // splitTensorB_17 > multiply1_17 size:= 32*char defined in Core0
extern char *const splitTensorB_18__multiply1_1__0;  // splitTensorB_18 > multiply1_18 size:= 32*char defined in Core0
extern int *const output__input__16;  // transpose_19_output > splitTensorB_19_input size:= 64*int defined in Core0
extern int *const output0__inputB__31;  // splitTensorB_19_output0 > multiply0_19_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__20;  // splitTensorB_19_output1 > multiply1_19_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__15;  // splitTensorB_19_output2 > multiply2_19_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__25;  // splitTensorB_19_output3 > multiply3_19_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__26;  // splitTensorB_19_output4 > multiply4_19_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__29;  // splitTensorB_19_output5 > multiply5_19_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__1;  // splitTensorB_19_output6 > multiply6_19_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__22;  // splitTensorB_19_output7 > multiply7_19_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_19__multiply7_1__0;  // splitTensorB_19 > multiply7_19 size:= 32*char defined in Core0
extern char *const splitTensorB_19__multiply6_1__0;  // splitTensorB_19 > multiply6_19 size:= 32*char defined in Core0
extern char *const splitTensorB_19__multiply5_1__0;  // splitTensorB_19 > multiply5_19 size:= 32*char defined in Core0
extern char *const splitTensorB_19__multiply4_1__0;  // splitTensorB_19 > multiply4_19 size:= 32*char defined in Core0
extern char *const splitTensorB_19__multiply3_1__0;  // splitTensorB_19 > multiply3_19 size:= 32*char defined in Core0
extern char *const splitTensorB_19__multiply2_1__0;  // splitTensorB_19 > multiply2_19 size:= 32*char defined in Core0
extern char *const splitTensorB_19__multiply0_1__0;  // splitTensorB_19 > multiply0_19 size:= 32*char defined in Core0
extern char *const splitTensorB_2__multiply1_2__0;  // splitTensorB_2 > multiply1_2 size:= 32*char defined in Core0
extern char *const splitTensorB_20__multiply1_2__0;  // splitTensorB_20 > multiply1_20 size:= 32*char defined in Core0
extern char *const splitTensorB_21__multiply1_2__0;  // splitTensorB_21 > multiply1_21 size:= 32*char defined in Core0
extern char *const splitTensorB_22__multiply1_2__0;  // splitTensorB_22 > multiply1_22 size:= 32*char defined in Core0
extern char *const splitTensorB_23__multiply1_2__0;  // splitTensorB_23 > multiply1_23 size:= 32*char defined in Core0
extern char *const splitTensorB_24__multiply1_2__0;  // splitTensorB_24 > multiply1_24 size:= 32*char defined in Core0
extern int *const output__input__22;  // transpose_25_output > splitTensorB_25_input size:= 64*int defined in Core0
extern int *const output0__inputB__3;  // splitTensorB_25_output0 > multiply0_25_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__23;  // splitTensorB_25_output1 > multiply1_25_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__30;  // splitTensorB_25_output2 > multiply2_25_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__10;  // splitTensorB_25_output3 > multiply3_25_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__16;  // splitTensorB_25_output4 > multiply4_25_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__9;  // splitTensorB_25_output5 > multiply5_25_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__24;  // splitTensorB_25_output6 > multiply6_25_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__18;  // splitTensorB_25_output7 > multiply7_25_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_25__multiply7_2__0;  // splitTensorB_25 > multiply7_25 size:= 32*char defined in Core0
extern char *const splitTensorB_25__multiply6_2__0;  // splitTensorB_25 > multiply6_25 size:= 32*char defined in Core0
extern char *const splitTensorB_25__multiply5_2__0;  // splitTensorB_25 > multiply5_25 size:= 32*char defined in Core0
extern char *const splitTensorB_25__multiply4_2__0;  // splitTensorB_25 > multiply4_25 size:= 32*char defined in Core0
extern char *const splitTensorB_25__multiply3_2__0;  // splitTensorB_25 > multiply3_25 size:= 32*char defined in Core0
extern char *const splitTensorB_25__multiply2_2__0;  // splitTensorB_25 > multiply2_25 size:= 32*char defined in Core0
extern char *const splitTensorB_25__multiply0_2__0;  // splitTensorB_25 > multiply0_25 size:= 32*char defined in Core0
extern int *const output__input__5;  // transpose_26_output > splitTensorB_26_input size:= 64*int defined in Core0
extern int *const output0__inputB__25;  // splitTensorB_26_output0 > multiply0_26_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__25;  // splitTensorB_26_output1 > multiply1_26_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__11;  // splitTensorB_26_output2 > multiply2_26_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__22;  // splitTensorB_26_output3 > multiply3_26_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__23;  // splitTensorB_26_output4 > multiply4_26_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__26;  // splitTensorB_26_output5 > multiply5_26_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__0;  // splitTensorB_26_output6 > multiply6_26_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__29;  // splitTensorB_26_output7 > multiply7_26_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_26__multiply7_2__0;  // splitTensorB_26 > multiply7_26 size:= 32*char defined in Core0
extern char *const splitTensorB_26__multiply6_2__0;  // splitTensorB_26 > multiply6_26 size:= 32*char defined in Core0
extern char *const splitTensorB_26__multiply5_2__0;  // splitTensorB_26 > multiply5_26 size:= 32*char defined in Core0
extern char *const splitTensorB_26__multiply4_2__0;  // splitTensorB_26 > multiply4_26 size:= 32*char defined in Core0
extern char *const splitTensorB_26__multiply3_2__0;  // splitTensorB_26 > multiply3_26 size:= 32*char defined in Core0
extern char *const splitTensorB_26__multiply2_2__0;  // splitTensorB_26 > multiply2_26 size:= 32*char defined in Core0
extern char *const splitTensorB_26__multiply0_2__0;  // splitTensorB_26 > multiply0_26 size:= 32*char defined in Core0
extern int *const output__input__3;  // transpose_27_output > splitTensorB_27_input size:= 64*int defined in Core0
extern int *const output0__inputB__14;  // splitTensorB_27_output0 > multiply0_27_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__11;  // splitTensorB_27_output1 > multiply1_27_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__27;  // splitTensorB_27_output2 > multiply2_27_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__13;  // splitTensorB_27_output3 > multiply3_27_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__2;  // splitTensorB_27_output4 > multiply4_27_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__17;  // splitTensorB_27_output5 > multiply5_27_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__11;  // splitTensorB_27_output6 > multiply6_27_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__14;  // splitTensorB_27_output7 > multiply7_27_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_27__multiply7_2__0;  // splitTensorB_27 > multiply7_27 size:= 32*char defined in Core0
extern char *const splitTensorB_27__multiply6_2__0;  // splitTensorB_27 > multiply6_27 size:= 32*char defined in Core0
extern char *const splitTensorB_27__multiply5_2__0;  // splitTensorB_27 > multiply5_27 size:= 32*char defined in Core0
extern char *const splitTensorB_27__multiply4_2__0;  // splitTensorB_27 > multiply4_27 size:= 32*char defined in Core0
extern char *const splitTensorB_27__multiply3_2__0;  // splitTensorB_27 > multiply3_27 size:= 32*char defined in Core0
extern char *const splitTensorB_27__multiply2_2__0;  // splitTensorB_27 > multiply2_27 size:= 32*char defined in Core0
extern char *const splitTensorB_27__multiply0_2__0;  // splitTensorB_27 > multiply0_27 size:= 32*char defined in Core0
extern char *const splitTensorB_28__multiply1_2__0;  // splitTensorB_28 > multiply1_28 size:= 32*char defined in Core0
extern char *const splitTensorB_29__multiply1_2__0;  // splitTensorB_29 > multiply1_29 size:= 32*char defined in Core0
extern int *const output__input__0;  // transpose_3_output > splitTensorB_3_input size:= 64*int defined in Core0
extern int *const output0__inputB__16;  // splitTensorB_3_output0 > multiply0_3_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__18;  // splitTensorB_3_output1 > multiply1_3_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__9;  // splitTensorB_3_output2 > multiply2_3_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__4;  // splitTensorB_3_output3 > multiply3_3_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__5;  // splitTensorB_3_output4 > multiply4_3_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__31;  // splitTensorB_3_output5 > multiply5_3_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__25;  // splitTensorB_3_output6 > multiply6_3_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__23;  // splitTensorB_3_output7 > multiply7_3_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_3__multiply7_3__0;  // splitTensorB_3 > multiply7_3 size:= 32*char defined in Core0
extern char *const splitTensorB_3__multiply6_3__0;  // splitTensorB_3 > multiply6_3 size:= 32*char defined in Core0
extern char *const splitTensorB_3__multiply5_3__0;  // splitTensorB_3 > multiply5_3 size:= 32*char defined in Core0
extern char *const splitTensorB_3__multiply4_3__0;  // splitTensorB_3 > multiply4_3 size:= 32*char defined in Core0
extern char *const splitTensorB_3__multiply3_3__0;  // splitTensorB_3 > multiply3_3 size:= 32*char defined in Core0
extern char *const splitTensorB_3__multiply2_3__0;  // splitTensorB_3 > multiply2_3 size:= 32*char defined in Core0
extern char *const splitTensorB_3__multiply0_3__0;  // splitTensorB_3 > multiply0_3 size:= 32*char defined in Core0
extern char *const splitTensorB_30__multiply1_3__0;  // splitTensorB_30 > multiply1_30 size:= 32*char defined in Core0
extern int *const output__input__15;  // transpose_31_output > splitTensorB_31_input size:= 64*int defined in Core0
extern int *const output0__inputB__23;  // splitTensorB_31_output0 > multiply0_31_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__5;  // splitTensorB_31_output1 > multiply1_31_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__26;  // splitTensorB_31_output2 > multiply2_31_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__1;  // splitTensorB_31_output3 > multiply3_31_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__20;  // splitTensorB_31_output4 > multiply4_31_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__13;  // splitTensorB_31_output5 > multiply5_31_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__27;  // splitTensorB_31_output6 > multiply6_31_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__2;  // splitTensorB_31_output7 > multiply7_31_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_31__multiply7_3__0;  // splitTensorB_31 > multiply7_31 size:= 32*char defined in Core0
extern char *const splitTensorB_31__multiply6_3__0;  // splitTensorB_31 > multiply6_31 size:= 32*char defined in Core0
extern char *const splitTensorB_31__multiply5_3__0;  // splitTensorB_31 > multiply5_31 size:= 32*char defined in Core0
extern char *const splitTensorB_31__multiply4_3__0;  // splitTensorB_31 > multiply4_31 size:= 32*char defined in Core0
extern char *const splitTensorB_31__multiply3_3__0;  // splitTensorB_31 > multiply3_31 size:= 32*char defined in Core0
extern char *const splitTensorB_31__multiply2_3__0;  // splitTensorB_31 > multiply2_31 size:= 32*char defined in Core0
extern char *const splitTensorB_31__multiply0_3__0;  // splitTensorB_31 > multiply0_31 size:= 32*char defined in Core0
extern char *const splitTensorB_4__multiply1_4__0;  // splitTensorB_4 > multiply1_4 size:= 32*char defined in Core0
extern char *const splitTensorB_5__multiply1_5__0;  // splitTensorB_5 > multiply1_5 size:= 32*char defined in Core0
extern char *const splitTensorB_6__multiply1_6__0;  // splitTensorB_6 > multiply1_6 size:= 32*char defined in Core0
extern char *const splitTensorB_7__multiply1_7__0;  // splitTensorB_7 > multiply1_7 size:= 32*char defined in Core0
extern char *const splitTensorB_8__multiply1_8__0;  // splitTensorB_8 > multiply1_8 size:= 32*char defined in Core0
extern char *const splitTensorB_9__multiply1_9__0;  // splitTensorB_9 > multiply1_9 size:= 32*char defined in Core0
extern char *const multiply0_0__sum_0__0;  // multiply0_0 > sum_0 size:= 256*char defined in Core0
extern long *const output__input1__18;  // multiply1_0_output > sum_0_input1 size:= 64*long defined in Core0
extern int *const output1__inputA__0;  // splitTensorA_1_output1 > multiply1_1_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__31;  // splitTensorB_1_output1 > multiply1_1_inputB size:= 8*int defined in Core0
extern long *const output__input1__16;  // multiply1_1_output > sum_1_input1 size:= 64*long defined in Core0
extern char *const multiply1_1__sum_1__0;  // multiply1_1 > sum_1 size:= 256*char defined in Core0
extern int *const output1__inputA__31;  // splitTensorA_10_output1 > multiply1_10_inputA size:= 8*int defined in Core0
extern long *const output__input1__27;  // multiply1_10_output > sum_10_input1 size:= 64*long defined in Core0
extern char *const multiply1_10__sum_10__0;  // multiply1_10 > sum_10 size:= 256*char defined in Core0
extern int *const output1__inputA__24;  // splitTensorA_11_output1 > multiply1_11_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__17;  // splitTensorB_11_output1 > multiply1_11_inputB size:= 8*int defined in Core0
extern long *const output__input1__12;  // multiply1_11_output > sum_11_input1 size:= 64*long defined in Core0
extern char *const multiply1_11__sum_11__0;  // multiply1_11 > sum_11 size:= 256*char defined in Core0
extern int *const output1__inputA__14;  // splitTensorA_12_output1 > multiply1_12_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__21;  // splitTensorB_12_output1 > multiply1_12_inputB size:= 8*int defined in Core0
extern long *const output__input1__28;  // multiply1_12_output > sum_12_input1 size:= 64*long defined in Core0
extern char *const multiply1_12__sum_12__0;  // multiply1_12 > sum_12 size:= 256*char defined in Core0
extern int *const output1__inputA__9;  // splitTensorA_13_output1 > multiply1_13_inputA size:= 8*int defined in Core0
extern long *const output__input1__6;  // multiply1_13_output > sum_13_input1 size:= 64*long defined in Core0
extern char *const multiply1_13__sum_13__0;  // multiply1_13 > sum_13 size:= 256*char defined in Core0
extern int *const output1__inputA__7;  // splitTensorA_14_output1 > multiply1_14_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__3;  // splitTensorB_14_output1 > multiply1_14_inputB size:= 8*int defined in Core0
extern long *const output__input1__4;  // multiply1_14_output > sum_14_input1 size:= 64*long defined in Core0
extern char *const multiply1_14__sum_14__0;  // multiply1_14 > sum_14 size:= 256*char defined in Core0
extern int *const output1__inputA__13;  // splitTensorA_15_output1 > multiply1_15_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__30;  // splitTensorB_15_output1 > multiply1_15_inputB size:= 8*int defined in Core0
extern long *const output__input1__17;  // multiply1_15_output > sum_15_input1 size:= 64*long defined in Core0
extern char *const multiply1_15__sum_15__0;  // multiply1_15 > sum_15 size:= 256*char defined in Core0
extern int *const output1__inputA__26;  // splitTensorA_16_output1 > multiply1_16_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__1;  // splitTensorB_16_output1 > multiply1_16_inputB size:= 8*int defined in Core0
extern long *const output__input1__8;  // multiply1_16_output > sum_16_input1 size:= 64*long defined in Core0
extern char *const multiply1_16__sum_16__0;  // multiply1_16 > sum_16 size:= 256*char defined in Core0
extern int *const output1__inputA__16;  // splitTensorA_17_output1 > multiply1_17_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__8;  // splitTensorB_17_output1 > multiply1_17_inputB size:= 8*int defined in Core0
extern long *const output__input1__21;  // multiply1_17_output > sum_17_input1 size:= 64*long defined in Core0
extern char *const multiply1_17__sum_17__0;  // multiply1_17 > sum_17 size:= 256*char defined in Core0
extern int *const output1__inputA__23;  // splitTensorA_18_output1 > multiply1_18_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__13;  // splitTensorB_18_output1 > multiply1_18_inputB size:= 8*int defined in Core0
extern long *const output__input1__31;  // multiply1_18_output > sum_18_input1 size:= 64*long defined in Core0
extern char *const multiply1_18__sum_18__0;  // multiply1_18 > sum_18 size:= 256*char defined in Core0
extern int *const output1__inputA__2;  // splitTensorA_19_output1 > multiply1_19_inputA size:= 8*int defined in Core0
extern long *const output__input1__26;  // multiply1_19_output > sum_19_input1 size:= 64*long defined in Core0
extern char *const multiply1_19__sum_19__0;  // multiply1_19 > sum_19 size:= 256*char defined in Core0
extern int *const output1__inputA__6;  // splitTensorA_2_output1 > multiply1_2_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__29;  // splitTensorB_2_output1 > multiply1_2_inputB size:= 8*int defined in Core0
extern long *const output__input1__3;  // multiply1_2_output > sum_2_input1 size:= 64*long defined in Core0
extern char *const multiply1_2__sum_2__0;  // multiply1_2 > sum_2 size:= 256*char defined in Core0
extern int *const output1__inputA__12;  // splitTensorA_20_output1 > multiply1_20_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__0;  // splitTensorB_20_output1 > multiply1_20_inputB size:= 8*int defined in Core0
extern long *const output__input1__22;  // multiply1_20_output > sum_20_input1 size:= 64*long defined in Core0
extern char *const multiply1_20__sum_20__0;  // multiply1_20 > sum_20 size:= 256*char defined in Core0
extern int *const output1__inputA__21;  // splitTensorA_21_output1 > multiply1_21_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__12;  // splitTensorB_21_output1 > multiply1_21_inputB size:= 8*int defined in Core0
extern long *const output__input1__11;  // multiply1_21_output > sum_21_input1 size:= 64*long defined in Core0
extern char *const multiply1_21__sum_21__0;  // multiply1_21 > sum_21 size:= 256*char defined in Core0
extern int *const output1__inputB__27;  // splitTensorB_22_output1 > multiply1_22_inputB size:= 8*int defined in Core0
extern long *const output__input1__23;  // multiply1_22_output > sum_22_input1 size:= 64*long defined in Core0
extern char *const multiply1_22__sum_22__0;  // multiply1_22 > sum_22 size:= 256*char defined in Core0
extern int *const output1__inputA__4;  // splitTensorA_23_output1 > multiply1_23_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__2;  // splitTensorB_23_output1 > multiply1_23_inputB size:= 8*int defined in Core0
extern long *const output__input1__0;  // multiply1_23_output > sum_23_input1 size:= 64*long defined in Core0
extern char *const multiply1_23__sum_23__0;  // multiply1_23 > sum_23 size:= 256*char defined in Core0
extern int *const output1__inputA__15;  // splitTensorA_24_output1 > multiply1_24_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__15;  // splitTensorB_24_output1 > multiply1_24_inputB size:= 8*int defined in Core0
extern long *const output__input1__30;  // multiply1_24_output > sum_24_input1 size:= 64*long defined in Core0
extern char *const multiply1_24__sum_24__0;  // multiply1_24 > sum_24 size:= 256*char defined in Core0
extern int *const output1__inputA__29;  // splitTensorA_25_output1 > multiply1_25_inputA size:= 8*int defined in Core0
extern long *const output__input1__19;  // multiply1_25_output > sum_25_input1 size:= 64*long defined in Core0
extern char *const multiply1_25__sum_25__0;  // multiply1_25 > sum_25 size:= 256*char defined in Core0
extern long *const output__input1__25;  // multiply1_26_output > sum_26_input1 size:= 64*long defined in Core0
extern char *const multiply1_26__sum_26__0;  // multiply1_26 > sum_26 size:= 256*char defined in Core0
extern long *const output__input1__14;  // multiply1_27_output > sum_27_input1 size:= 64*long defined in Core0
extern char *const multiply1_27__sum_27__0;  // multiply1_27 > sum_27 size:= 256*char defined in Core0
extern int *const output1__inputA__27;  // splitTensorA_28_output1 > multiply1_28_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__24;  // splitTensorB_28_output1 > multiply1_28_inputB size:= 8*int defined in Core0
extern long *const output__input1__7;  // multiply1_28_output > sum_28_input1 size:= 64*long defined in Core0
extern char *const multiply1_28__sum_28__0;  // multiply1_28 > sum_28 size:= 256*char defined in Core0
extern int *const output1__inputA__28;  // splitTensorA_29_output1 > multiply1_29_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__19;  // splitTensorB_29_output1 > multiply1_29_inputB size:= 8*int defined in Core0
extern long *const output__input1__9;  // multiply1_29_output > sum_29_input1 size:= 64*long defined in Core0
extern char *const multiply1_29__sum_29__0;  // multiply1_29 > sum_29 size:= 256*char defined in Core0
extern int *const output1__inputA__11;  // splitTensorA_3_output1 > multiply1_3_inputA size:= 8*int defined in Core0
extern long *const output__input1__24;  // multiply1_3_output > sum_3_input1 size:= 64*long defined in Core0
extern char *const multiply1_3__sum_3__0;  // multiply1_3 > sum_3 size:= 256*char defined in Core0
extern int *const output1__inputA__20;  // splitTensorA_30_output1 > multiply1_30_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__9;  // splitTensorB_30_output1 > multiply1_30_inputB size:= 8*int defined in Core0
extern long *const output__input1__10;  // multiply1_30_output > sum_30_input1 size:= 64*long defined in Core0
extern char *const multiply1_30__sum_30__0;  // multiply1_30 > sum_30 size:= 256*char defined in Core0
extern int *const output1__inputA__25;  // splitTensorA_31_output1 > multiply1_31_inputA size:= 8*int defined in Core0
extern long *const output__input1__20;  // multiply1_31_output > sum_31_input1 size:= 64*long defined in Core0
extern char *const multiply1_31__sum_31__0;  // multiply1_31 > sum_31 size:= 256*char defined in Core0
extern int *const output1__inputA__5;  // splitTensorA_4_output1 > multiply1_4_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__22;  // splitTensorB_4_output1 > multiply1_4_inputB size:= 8*int defined in Core0
extern long *const output__input1__29;  // multiply1_4_output > sum_4_input1 size:= 64*long defined in Core0
extern char *const multiply1_4__sum_4__0;  // multiply1_4 > sum_4 size:= 256*char defined in Core0
extern int *const output1__inputA__8;  // splitTensorA_5_output1 > multiply1_5_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__6;  // splitTensorB_5_output1 > multiply1_5_inputB size:= 8*int defined in Core0
extern long *const output__input1__2;  // multiply1_5_output > sum_5_input1 size:= 64*long defined in Core0
extern char *const multiply1_5__sum_5__0;  // multiply1_5 > sum_5 size:= 256*char defined in Core0
extern int *const output1__inputA__10;  // splitTensorA_6_output1 > multiply1_6_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__10;  // splitTensorB_6_output1 > multiply1_6_inputB size:= 8*int defined in Core0
extern long *const output__input1__15;  // multiply1_6_output > sum_6_input1 size:= 64*long defined in Core0
extern char *const multiply1_6__sum_6__0;  // multiply1_6 > sum_6 size:= 256*char defined in Core0
extern int *const output1__inputA__30;  // splitTensorA_7_output1 > multiply1_7_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__7;  // splitTensorB_7_output1 > multiply1_7_inputB size:= 8*int defined in Core0
extern long *const output__input1__1;  // multiply1_7_output > sum_7_input1 size:= 64*long defined in Core0
extern char *const multiply1_7__sum_7__0;  // multiply1_7 > sum_7 size:= 256*char defined in Core0
extern int *const output1__inputA__22;  // splitTensorA_8_output1 > multiply1_8_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__14;  // splitTensorB_8_output1 > multiply1_8_inputB size:= 8*int defined in Core0
extern long *const output__input1__5;  // multiply1_8_output > sum_8_input1 size:= 64*long defined in Core0
extern char *const multiply1_8__sum_8__0;  // multiply1_8 > sum_8 size:= 256*char defined in Core0
extern int *const output1__inputA__1;  // splitTensorA_9_output1 > multiply1_9_inputA size:= 8*int defined in Core0
extern int *const output1__inputB__28;  // splitTensorB_9_output1 > multiply1_9_inputB size:= 8*int defined in Core0
extern long *const output__input1__13;  // multiply1_9_output > sum_9_input1 size:= 64*long defined in Core0
extern char *const multiply1_9__sum_9__0;  // multiply1_9 > sum_9 size:= 256*char defined in Core0
extern char *const multiply2_0__sum_0__0;  // multiply2_0 > sum_0 size:= 256*char defined in Core0
extern char *const multiply3_0__sum_0__0;  // multiply3_0 > sum_0 size:= 256*char defined in Core0
extern char *const multiply4_0__sum_0__0;  // multiply4_0 > sum_0 size:= 256*char defined in Core0
extern char *const multiply5_0__sum_0__0;  // multiply5_0 > sum_0 size:= 256*char defined in Core0
extern char *const multiply6_0__sum_0__0;  // multiply6_0 > sum_0 size:= 256*char defined in Core0
extern char *const multiply7_0__sum_0__0;  // multiply7_0 > sum_0 size:= 256*char defined in Core0
extern long *const output__input0__4;  // multiply0_0_output > sum_0_input0 size:= 64*long defined in Core0
extern long *const output__input2__25;  // multiply2_0_output > sum_0_input2 size:= 64*long defined in Core0
extern long *const output__input3__29;  // multiply3_0_output > sum_0_input3 size:= 64*long defined in Core0
extern long *const output__input4__0;  // multiply4_0_output > sum_0_input4 size:= 64*long defined in Core0
extern long *const output__input5__2;  // multiply5_0_output > sum_0_input5 size:= 64*long defined in Core0
extern long *const output__input6__1;  // multiply6_0_output > sum_0_input6 size:= 64*long defined in Core0
extern long *const output__input7__7;  // multiply7_0_output > sum_0_input7 size:= 64*long defined in Core0
extern long *const output__arrayC_0__0;  // sum_0_output > implode_displayResult_arrayC_arrayC_0 size:= 64*long defined in Core0
extern char *const sum_0__implode_displayResult__0;  // sum_0 > implode_displayResult_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core1(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__12 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__52 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__52 
		cache_inv(explode_generateTensors_arra__52, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__34 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__34 
		cache_inv(explode_generateTensors_arra__34, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__6 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__47 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__47 
		cache_inv(explode_generateTensors_arra__47, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__19 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__19 
		cache_inv(explode_generateTensors_arra__19, 256*sizeof(char));
		splitA(8/*rowsA*/,8/*columnsA*/,arrayA_0__input__0,output0__inputA__19,output1__inputA__19,output2__inputA__3,output3__inputA__21,output4__inputA__25,output5__inputA__27,output6__inputA__19,output7__inputA__5); // splitTensorA_0
		cache_inv(arrayA_0__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorA_0__multiply7_0__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorA_0__multiply7_0__0 
		sendEnd(); // Core1 > Core7: splitTensorA_0__multiply7_0__0 
		cache_wbInv(splitTensorA_0__multiply6_0__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorA_0__multiply6_0__0 
		sendEnd(); // Core1 > Core6: splitTensorA_0__multiply6_0__0 
		cache_wbInv(splitTensorA_0__multiply5_0__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorA_0__multiply5_0__0 
		sendEnd(); // Core1 > Core5: splitTensorA_0__multiply5_0__0 
		cache_wbInv(splitTensorA_0__multiply4_0__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorA_0__multiply4_0__0 
		sendEnd(); // Core1 > Core4: splitTensorA_0__multiply4_0__0 
		cache_wbInv(splitTensorA_0__multiply3_0__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorA_0__multiply3_0__0 
		sendEnd(); // Core1 > Core3: splitTensorA_0__multiply3_0__0 
		cache_wbInv(splitTensorA_0__multiply2_0__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorA_0__multiply2_0__0 
		sendEnd(); // Core1 > Core2: splitTensorA_0__multiply2_0__0 
		cache_wbInv(splitTensorA_0__multiply0_0__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorA_0__multiply0_0__0 
		sendEnd(); // Core1 > Core0: splitTensorA_0__multiply0_0__0 
		receiveStart(); // Core6 > Core1: splitTensorA_1__multiply1_1__0 
		receiveEnd(6); // Core6 > Core1: splitTensorA_1__multiply1_1__0 
		cache_inv(splitTensorA_1__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_10__multiply1_1__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_10__multiply1_1__0 
		cache_inv(splitTensorA_10__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core1: splitTensorA_11__multiply1_1__0 
		receiveEnd(4); // Core4 > Core1: splitTensorA_11__multiply1_1__0 
		cache_inv(splitTensorA_11__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: splitTensorA_12__multiply1_1__0 
		receiveEnd(0); // Core0 > Core1: splitTensorA_12__multiply1_1__0 
		cache_inv(splitTensorA_12__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: splitTensorA_13__multiply1_1__0 
		receiveEnd(2); // Core2 > Core1: splitTensorA_13__multiply1_1__0 
		cache_inv(splitTensorA_13__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: splitTensorA_14__multiply1_1__0 
		receiveEnd(0); // Core0 > Core1: splitTensorA_14__multiply1_1__0 
		cache_inv(splitTensorA_14__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: splitTensorA_15__multiply1_1__0 
		receiveEnd(0); // Core0 > Core1: splitTensorA_15__multiply1_1__0 
		cache_inv(splitTensorA_15__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core3 > Core1: splitTensorA_16__multiply1_1__0 
		receiveEnd(3); // Core3 > Core1: splitTensorA_16__multiply1_1__0 
		cache_inv(splitTensorA_16__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: splitTensorA_17__multiply1_1__0 
		receiveEnd(2); // Core2 > Core1: splitTensorA_17__multiply1_1__0 
		cache_inv(splitTensorA_17__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_18__multiply1_1__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_18__multiply1_1__0 
		cache_inv(splitTensorA_18__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: splitTensorA_19__multiply1_1__0 
		receiveEnd(7); // Core7 > Core1: splitTensorA_19__multiply1_1__0 
		cache_inv(splitTensorA_19__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core1: splitTensorA_2__multiply1_2__0 
		receiveEnd(4); // Core4 > Core1: splitTensorA_2__multiply1_2__0 
		cache_inv(splitTensorA_2__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_20__multiply1_2__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_20__multiply1_2__0 
		cache_inv(splitTensorA_20__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: splitTensorA_21__multiply1_2__0 
		receiveEnd(0); // Core0 > Core1: splitTensorA_21__multiply1_2__0 
		cache_inv(splitTensorA_21__multiply1_2__0, 32*sizeof(char));
		splitA(8/*rowsA*/,8/*columnsA*/,arrayA_1408__input__0,output0__inputA__25,output1__inputA__17,output2__inputA__1,output3__inputA__19,output4__inputA__27,output5__inputA__19,output6__inputA__17,output7__inputA__30); // splitTensorA_22
		cache_inv(arrayA_1408__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorA_22__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorA_22__multiply7_2__0 
		sendEnd(); // Core1 > Core7: splitTensorA_22__multiply7_2__0 
		cache_wbInv(splitTensorA_22__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorA_22__multiply6_2__0 
		sendEnd(); // Core1 > Core6: splitTensorA_22__multiply6_2__0 
		cache_wbInv(splitTensorA_22__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorA_22__multiply5_2__0 
		sendEnd(); // Core1 > Core5: splitTensorA_22__multiply5_2__0 
		cache_wbInv(splitTensorA_22__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorA_22__multiply4_2__0 
		sendEnd(); // Core1 > Core4: splitTensorA_22__multiply4_2__0 
		cache_wbInv(splitTensorA_22__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorA_22__multiply3_2__0 
		sendEnd(); // Core1 > Core3: splitTensorA_22__multiply3_2__0 
		cache_wbInv(splitTensorA_22__multiply2_2__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorA_22__multiply2_2__0 
		sendEnd(); // Core1 > Core2: splitTensorA_22__multiply2_2__0 
		cache_wbInv(splitTensorA_22__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorA_22__multiply0_2__0 
		sendEnd(); // Core1 > Core0: splitTensorA_22__multiply0_2__0 
		receiveStart(); // Core0 > Core1: splitTensorA_23__multiply1_2__0 
		receiveEnd(0); // Core0 > Core1: splitTensorA_23__multiply1_2__0 
		cache_inv(splitTensorA_23__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core1: splitTensorA_24__multiply1_2__0 
		receiveEnd(6); // Core6 > Core1: splitTensorA_24__multiply1_2__0 
		cache_inv(splitTensorA_24__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: splitTensorA_25__multiply1_2__0 
		receiveEnd(0); // Core0 > Core1: splitTensorA_25__multiply1_2__0 
		cache_inv(splitTensorA_25__multiply1_2__0, 32*sizeof(char));
		splitA(8/*rowsA*/,8/*columnsA*/,arrayA_1664__input__0,output0__inputA__8,output1__inputA__18,output2__inputA__0,output3__inputA__4,output4__inputA__17,output5__inputA__15,output6__inputA__30,output7__inputA__6); // splitTensorA_26
		cache_inv(arrayA_1664__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorA_26__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorA_26__multiply7_2__0 
		sendEnd(); // Core1 > Core7: splitTensorA_26__multiply7_2__0 
		cache_wbInv(splitTensorA_26__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorA_26__multiply6_2__0 
		sendEnd(); // Core1 > Core6: splitTensorA_26__multiply6_2__0 
		cache_wbInv(splitTensorA_26__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorA_26__multiply5_2__0 
		sendEnd(); // Core1 > Core5: splitTensorA_26__multiply5_2__0 
		cache_wbInv(splitTensorA_26__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorA_26__multiply4_2__0 
		sendEnd(); // Core1 > Core4: splitTensorA_26__multiply4_2__0 
		cache_wbInv(splitTensorA_26__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorA_26__multiply3_2__0 
		sendEnd(); // Core1 > Core3: splitTensorA_26__multiply3_2__0 
		cache_wbInv(splitTensorA_26__multiply2_2__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorA_26__multiply2_2__0 
		sendEnd(); // Core1 > Core2: splitTensorA_26__multiply2_2__0 
		cache_wbInv(splitTensorA_26__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorA_26__multiply0_2__0 
		sendEnd(); // Core1 > Core0: splitTensorA_26__multiply0_2__0 
		splitA(8/*rowsA*/,8/*columnsA*/,arrayA_1728__input__0,output0__inputA__7,output1__inputA__3,output2__inputA__5,output3__inputA__7,output4__inputA__1,output5__inputA__11,output6__inputA__2,output7__inputA__28); // splitTensorA_27
		cache_inv(arrayA_1728__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorA_27__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorA_27__multiply7_2__0 
		sendEnd(); // Core1 > Core7: splitTensorA_27__multiply7_2__0 
		cache_wbInv(splitTensorA_27__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorA_27__multiply6_2__0 
		sendEnd(); // Core1 > Core6: splitTensorA_27__multiply6_2__0 
		cache_wbInv(splitTensorA_27__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorA_27__multiply5_2__0 
		sendEnd(); // Core1 > Core5: splitTensorA_27__multiply5_2__0 
		cache_wbInv(splitTensorA_27__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorA_27__multiply4_2__0 
		sendEnd(); // Core1 > Core4: splitTensorA_27__multiply4_2__0 
		cache_wbInv(splitTensorA_27__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorA_27__multiply3_2__0 
		sendEnd(); // Core1 > Core3: splitTensorA_27__multiply3_2__0 
		cache_wbInv(splitTensorA_27__multiply2_2__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorA_27__multiply2_2__0 
		sendEnd(); // Core1 > Core2: splitTensorA_27__multiply2_2__0 
		cache_wbInv(splitTensorA_27__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorA_27__multiply0_2__0 
		sendEnd(); // Core1 > Core0: splitTensorA_27__multiply0_2__0 
		receiveStart(); // Core5 > Core1: splitTensorA_28__multiply1_2__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_28__multiply1_2__0 
		cache_inv(splitTensorA_28__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_29__multiply1_2__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_29__multiply1_2__0 
		cache_inv(splitTensorA_29__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core1: splitTensorA_3__multiply1_3__0 
		receiveEnd(6); // Core6 > Core1: splitTensorA_3__multiply1_3__0 
		cache_inv(splitTensorA_3__multiply1_3__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_30__multiply1_3__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_30__multiply1_3__0 
		cache_inv(splitTensorA_30__multiply1_3__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: splitTensorA_31__multiply1_3__0 
		receiveEnd(0); // Core0 > Core1: splitTensorA_31__multiply1_3__0 
		cache_inv(splitTensorA_31__multiply1_3__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: splitTensorA_4__multiply1_4__0 
		receiveEnd(2); // Core2 > Core1: splitTensorA_4__multiply1_4__0 
		cache_inv(splitTensorA_4__multiply1_4__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_5__multiply1_5__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_5__multiply1_5__0 
		cache_inv(splitTensorA_5__multiply1_5__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core1: splitTensorA_6__multiply1_6__0 
		receiveEnd(4); // Core4 > Core1: splitTensorA_6__multiply1_6__0 
		cache_inv(splitTensorA_6__multiply1_6__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_7__multiply1_7__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_7__multiply1_7__0 
		cache_inv(splitTensorA_7__multiply1_7__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorA_8__multiply1_8__0 
		receiveEnd(5); // Core5 > Core1: splitTensorA_8__multiply1_8__0 
		cache_inv(splitTensorA_8__multiply1_8__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core1: splitTensorA_9__multiply1_9__0 
		receiveEnd(6); // Core6 > Core1: splitTensorA_9__multiply1_9__0 
		cache_inv(splitTensorA_9__multiply1_9__0, 32*sizeof(char));
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_0__input__0,output__input__13); // transpose_0
		cache_inv(arrayB_0__input__0, 64*sizeof(int));
		receiveStart(); // Core7 > Core1: transpose_10__splitTensorB_1__0 
		receiveEnd(7); // Core7 > Core1: transpose_10__splitTensorB_1__0 
		cache_inv(transpose_10__splitTensorB_1__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: transpose_13__splitTensorB_1__0 
		receiveEnd(7); // Core7 > Core1: transpose_13__splitTensorB_1__0 
		cache_inv(transpose_13__splitTensorB_1__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: transpose_19__splitTensorB_1__0 
		receiveEnd(3); // Core3 > Core1: transpose_19__splitTensorB_1__0 
		cache_inv(transpose_19__splitTensorB_1__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: transpose_25__splitTensorB_2__0 
		receiveEnd(3); // Core3 > Core1: transpose_25__splitTensorB_2__0 
		cache_inv(transpose_25__splitTensorB_2__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: transpose_26__splitTensorB_2__0 
		receiveEnd(3); // Core3 > Core1: transpose_26__splitTensorB_2__0 
		cache_inv(transpose_26__splitTensorB_2__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: transpose_27__splitTensorB_2__0 
		receiveEnd(3); // Core3 > Core1: transpose_27__splitTensorB_2__0 
		cache_inv(transpose_27__splitTensorB_2__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: transpose_3__splitTensorB_3__0 
		receiveEnd(3); // Core3 > Core1: transpose_3__splitTensorB_3__0 
		cache_inv(transpose_3__splitTensorB_3__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: transpose_31__splitTensorB_3__0 
		receiveEnd(3); // Core3 > Core1: transpose_31__splitTensorB_3__0 
		cache_inv(transpose_31__splitTensorB_3__0, 256*sizeof(char));
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_256__input__0,output__input__18); // transpose_4
		cache_inv(arrayB_256__input__0, 64*sizeof(int));
		cache_wbInv(transpose_4__splitTensorB_4__0, 256*sizeof(char));
		sendStart(7); // Core1 > Core7: transpose_4__splitTensorB_4__0 
		sendEnd(); // Core1 > Core7: transpose_4__splitTensorB_4__0 
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__13,output0__inputB__22,output1__inputB__26,output2__inputB__24,output3__inputB__23,output4__inputB__30,output5__inputB__0,output6__inputB__2,output7__inputB__11); // splitTensorB_0
		cache_inv(output__input__13, 64*sizeof(int));
		cache_wbInv(splitTensorB_0__multiply7_0__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_0__multiply7_0__0 
		sendEnd(); // Core1 > Core7: splitTensorB_0__multiply7_0__0 
		cache_wbInv(splitTensorB_0__multiply6_0__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_0__multiply6_0__0 
		sendEnd(); // Core1 > Core6: splitTensorB_0__multiply6_0__0 
		cache_wbInv(splitTensorB_0__multiply5_0__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_0__multiply5_0__0 
		sendEnd(); // Core1 > Core5: splitTensorB_0__multiply5_0__0 
		cache_wbInv(splitTensorB_0__multiply4_0__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_0__multiply4_0__0 
		sendEnd(); // Core1 > Core4: splitTensorB_0__multiply4_0__0 
		cache_wbInv(splitTensorB_0__multiply3_0__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_0__multiply3_0__0 
		sendEnd(); // Core1 > Core3: splitTensorB_0__multiply3_0__0 
		cache_wbInv(splitTensorB_0__multiply2_0__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_0__multiply2_0__0 
		sendEnd(); // Core1 > Core2: splitTensorB_0__multiply2_0__0 
		cache_wbInv(splitTensorB_0__multiply0_0__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_0__multiply0_0__0 
		sendEnd(); // Core1 > Core0: splitTensorB_0__multiply0_0__0 
		receiveStart(); // Core4 > Core1: splitTensorB_1__multiply1_1__0 
		receiveEnd(4); // Core4 > Core1: splitTensorB_1__multiply1_1__0 
		cache_inv(splitTensorB_1__multiply1_1__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__23,output0__inputB__0,output1__inputB__16,output2__inputB__12,output3__inputB__30,output4__inputB__1,output5__inputB__6,output6__inputB__13,output7__inputB__13); // splitTensorB_10
		cache_inv(output__input__23, 64*sizeof(int));
		cache_wbInv(splitTensorB_10__multiply7_1__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_10__multiply7_1__0 
		sendEnd(); // Core1 > Core7: splitTensorB_10__multiply7_1__0 
		cache_wbInv(splitTensorB_10__multiply6_1__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_10__multiply6_1__0 
		sendEnd(); // Core1 > Core6: splitTensorB_10__multiply6_1__0 
		cache_wbInv(splitTensorB_10__multiply5_1__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_10__multiply5_1__0 
		sendEnd(); // Core1 > Core5: splitTensorB_10__multiply5_1__0 
		cache_wbInv(splitTensorB_10__multiply4_1__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_10__multiply4_1__0 
		sendEnd(); // Core1 > Core4: splitTensorB_10__multiply4_1__0 
		cache_wbInv(splitTensorB_10__multiply3_1__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_10__multiply3_1__0 
		sendEnd(); // Core1 > Core3: splitTensorB_10__multiply3_1__0 
		cache_wbInv(splitTensorB_10__multiply2_1__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_10__multiply2_1__0 
		sendEnd(); // Core1 > Core2: splitTensorB_10__multiply2_1__0 
		cache_wbInv(splitTensorB_10__multiply0_1__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_10__multiply0_1__0 
		sendEnd(); // Core1 > Core0: splitTensorB_10__multiply0_1__0 
		receiveStart(); // Core7 > Core1: splitTensorB_11__multiply1_1__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_11__multiply1_1__0 
		cache_inv(splitTensorB_11__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: splitTensorB_12__multiply1_1__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_12__multiply1_1__0 
		cache_inv(splitTensorB_12__multiply1_1__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__19,output0__inputB__26,output1__inputB__4,output2__inputB__3,output3__inputB__27,output4__inputB__4,output5__inputB__30,output6__inputB__31,output7__inputB__28); // splitTensorB_13
		cache_inv(output__input__19, 64*sizeof(int));
		cache_wbInv(splitTensorB_13__multiply7_1__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_13__multiply7_1__0 
		sendEnd(); // Core1 > Core7: splitTensorB_13__multiply7_1__0 
		cache_wbInv(splitTensorB_13__multiply6_1__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_13__multiply6_1__0 
		sendEnd(); // Core1 > Core6: splitTensorB_13__multiply6_1__0 
		cache_wbInv(splitTensorB_13__multiply5_1__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_13__multiply5_1__0 
		sendEnd(); // Core1 > Core5: splitTensorB_13__multiply5_1__0 
		cache_wbInv(splitTensorB_13__multiply4_1__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_13__multiply4_1__0 
		sendEnd(); // Core1 > Core4: splitTensorB_13__multiply4_1__0 
		cache_wbInv(splitTensorB_13__multiply3_1__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_13__multiply3_1__0 
		sendEnd(); // Core1 > Core3: splitTensorB_13__multiply3_1__0 
		cache_wbInv(splitTensorB_13__multiply2_1__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_13__multiply2_1__0 
		sendEnd(); // Core1 > Core2: splitTensorB_13__multiply2_1__0 
		cache_wbInv(splitTensorB_13__multiply0_1__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_13__multiply0_1__0 
		sendEnd(); // Core1 > Core0: splitTensorB_13__multiply0_1__0 
		receiveStart(); // Core4 > Core1: splitTensorB_14__multiply1_1__0 
		receiveEnd(4); // Core4 > Core1: splitTensorB_14__multiply1_1__0 
		cache_inv(splitTensorB_14__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core1: splitTensorB_15__multiply1_1__0 
		receiveEnd(4); // Core4 > Core1: splitTensorB_15__multiply1_1__0 
		cache_inv(splitTensorB_15__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core3 > Core1: splitTensorB_16__multiply1_1__0 
		receiveEnd(3); // Core3 > Core1: splitTensorB_16__multiply1_1__0 
		cache_inv(splitTensorB_16__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: splitTensorB_17__multiply1_1__0 
		receiveEnd(2); // Core2 > Core1: splitTensorB_17__multiply1_1__0 
		cache_inv(splitTensorB_17__multiply1_1__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: splitTensorB_18__multiply1_1__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_18__multiply1_1__0 
		cache_inv(splitTensorB_18__multiply1_1__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__16,output0__inputB__31,output1__inputB__20,output2__inputB__15,output3__inputB__25,output4__inputB__26,output5__inputB__29,output6__inputB__1,output7__inputB__22); // splitTensorB_19
		cache_inv(output__input__16, 64*sizeof(int));
		cache_wbInv(splitTensorB_19__multiply7_1__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_19__multiply7_1__0 
		sendEnd(); // Core1 > Core7: splitTensorB_19__multiply7_1__0 
		cache_wbInv(splitTensorB_19__multiply6_1__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_19__multiply6_1__0 
		sendEnd(); // Core1 > Core6: splitTensorB_19__multiply6_1__0 
		cache_wbInv(splitTensorB_19__multiply5_1__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_19__multiply5_1__0 
		sendEnd(); // Core1 > Core5: splitTensorB_19__multiply5_1__0 
		cache_wbInv(splitTensorB_19__multiply4_1__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_19__multiply4_1__0 
		sendEnd(); // Core1 > Core4: splitTensorB_19__multiply4_1__0 
		cache_wbInv(splitTensorB_19__multiply3_1__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_19__multiply3_1__0 
		sendEnd(); // Core1 > Core3: splitTensorB_19__multiply3_1__0 
		cache_wbInv(splitTensorB_19__multiply2_1__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_19__multiply2_1__0 
		sendEnd(); // Core1 > Core2: splitTensorB_19__multiply2_1__0 
		cache_wbInv(splitTensorB_19__multiply0_1__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_19__multiply0_1__0 
		sendEnd(); // Core1 > Core0: splitTensorB_19__multiply0_1__0 
		receiveStart(); // Core4 > Core1: splitTensorB_2__multiply1_2__0 
		receiveEnd(4); // Core4 > Core1: splitTensorB_2__multiply1_2__0 
		cache_inv(splitTensorB_2__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: splitTensorB_20__multiply1_2__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_20__multiply1_2__0 
		cache_inv(splitTensorB_20__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: splitTensorB_21__multiply1_2__0 
		receiveEnd(2); // Core2 > Core1: splitTensorB_21__multiply1_2__0 
		cache_inv(splitTensorB_21__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: splitTensorB_22__multiply1_2__0 
		receiveEnd(2); // Core2 > Core1: splitTensorB_22__multiply1_2__0 
		cache_inv(splitTensorB_22__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: splitTensorB_23__multiply1_2__0 
		receiveEnd(0); // Core0 > Core1: splitTensorB_23__multiply1_2__0 
		cache_inv(splitTensorB_23__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: splitTensorB_24__multiply1_2__0 
		receiveEnd(2); // Core2 > Core1: splitTensorB_24__multiply1_2__0 
		cache_inv(splitTensorB_24__multiply1_2__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__22,output0__inputB__3,output1__inputB__23,output2__inputB__30,output3__inputB__10,output4__inputB__16,output5__inputB__9,output6__inputB__24,output7__inputB__18); // splitTensorB_25
		cache_inv(output__input__22, 64*sizeof(int));
		cache_wbInv(splitTensorB_25__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_25__multiply7_2__0 
		sendEnd(); // Core1 > Core7: splitTensorB_25__multiply7_2__0 
		cache_wbInv(splitTensorB_25__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_25__multiply6_2__0 
		sendEnd(); // Core1 > Core6: splitTensorB_25__multiply6_2__0 
		cache_wbInv(splitTensorB_25__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_25__multiply5_2__0 
		sendEnd(); // Core1 > Core5: splitTensorB_25__multiply5_2__0 
		cache_wbInv(splitTensorB_25__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_25__multiply4_2__0 
		sendEnd(); // Core1 > Core4: splitTensorB_25__multiply4_2__0 
		cache_wbInv(splitTensorB_25__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_25__multiply3_2__0 
		sendEnd(); // Core1 > Core3: splitTensorB_25__multiply3_2__0 
		cache_wbInv(splitTensorB_25__multiply2_2__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_25__multiply2_2__0 
		sendEnd(); // Core1 > Core2: splitTensorB_25__multiply2_2__0 
		cache_wbInv(splitTensorB_25__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_25__multiply0_2__0 
		sendEnd(); // Core1 > Core0: splitTensorB_25__multiply0_2__0 
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__5,output0__inputB__25,output1__inputB__25,output2__inputB__11,output3__inputB__22,output4__inputB__23,output5__inputB__26,output6__inputB__0,output7__inputB__29); // splitTensorB_26
		cache_inv(output__input__5, 64*sizeof(int));
		cache_wbInv(splitTensorB_26__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_26__multiply7_2__0 
		sendEnd(); // Core1 > Core7: splitTensorB_26__multiply7_2__0 
		cache_wbInv(splitTensorB_26__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_26__multiply6_2__0 
		sendEnd(); // Core1 > Core6: splitTensorB_26__multiply6_2__0 
		cache_wbInv(splitTensorB_26__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_26__multiply5_2__0 
		sendEnd(); // Core1 > Core5: splitTensorB_26__multiply5_2__0 
		cache_wbInv(splitTensorB_26__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_26__multiply4_2__0 
		sendEnd(); // Core1 > Core4: splitTensorB_26__multiply4_2__0 
		cache_wbInv(splitTensorB_26__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_26__multiply3_2__0 
		sendEnd(); // Core1 > Core3: splitTensorB_26__multiply3_2__0 
		cache_wbInv(splitTensorB_26__multiply2_2__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_26__multiply2_2__0 
		sendEnd(); // Core1 > Core2: splitTensorB_26__multiply2_2__0 
		cache_wbInv(splitTensorB_26__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_26__multiply0_2__0 
		sendEnd(); // Core1 > Core0: splitTensorB_26__multiply0_2__0 
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__3,output0__inputB__14,output1__inputB__11,output2__inputB__27,output3__inputB__13,output4__inputB__2,output5__inputB__17,output6__inputB__11,output7__inputB__14); // splitTensorB_27
		cache_inv(output__input__3, 64*sizeof(int));
		cache_wbInv(splitTensorB_27__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_27__multiply7_2__0 
		sendEnd(); // Core1 > Core7: splitTensorB_27__multiply7_2__0 
		cache_wbInv(splitTensorB_27__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_27__multiply6_2__0 
		sendEnd(); // Core1 > Core6: splitTensorB_27__multiply6_2__0 
		cache_wbInv(splitTensorB_27__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_27__multiply5_2__0 
		sendEnd(); // Core1 > Core5: splitTensorB_27__multiply5_2__0 
		cache_wbInv(splitTensorB_27__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_27__multiply4_2__0 
		sendEnd(); // Core1 > Core4: splitTensorB_27__multiply4_2__0 
		cache_wbInv(splitTensorB_27__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_27__multiply3_2__0 
		sendEnd(); // Core1 > Core3: splitTensorB_27__multiply3_2__0 
		cache_wbInv(splitTensorB_27__multiply2_2__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_27__multiply2_2__0 
		sendEnd(); // Core1 > Core2: splitTensorB_27__multiply2_2__0 
		cache_wbInv(splitTensorB_27__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_27__multiply0_2__0 
		sendEnd(); // Core1 > Core0: splitTensorB_27__multiply0_2__0 
		receiveStart(); // Core6 > Core1: splitTensorB_28__multiply1_2__0 
		receiveEnd(6); // Core6 > Core1: splitTensorB_28__multiply1_2__0 
		cache_inv(splitTensorB_28__multiply1_2__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: splitTensorB_29__multiply1_2__0 
		receiveEnd(5); // Core5 > Core1: splitTensorB_29__multiply1_2__0 
		cache_inv(splitTensorB_29__multiply1_2__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__0,output0__inputB__16,output1__inputB__18,output2__inputB__9,output3__inputB__4,output4__inputB__5,output5__inputB__31,output6__inputB__25,output7__inputB__23); // splitTensorB_3
		cache_inv(output__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorB_3__multiply7_3__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_3__multiply7_3__0 
		sendEnd(); // Core1 > Core7: splitTensorB_3__multiply7_3__0 
		cache_wbInv(splitTensorB_3__multiply6_3__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_3__multiply6_3__0 
		sendEnd(); // Core1 > Core6: splitTensorB_3__multiply6_3__0 
		cache_wbInv(splitTensorB_3__multiply5_3__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_3__multiply5_3__0 
		sendEnd(); // Core1 > Core5: splitTensorB_3__multiply5_3__0 
		cache_wbInv(splitTensorB_3__multiply4_3__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_3__multiply4_3__0 
		sendEnd(); // Core1 > Core4: splitTensorB_3__multiply4_3__0 
		cache_wbInv(splitTensorB_3__multiply3_3__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_3__multiply3_3__0 
		sendEnd(); // Core1 > Core3: splitTensorB_3__multiply3_3__0 
		cache_wbInv(splitTensorB_3__multiply2_3__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_3__multiply2_3__0 
		sendEnd(); // Core1 > Core2: splitTensorB_3__multiply2_3__0 
		cache_wbInv(splitTensorB_3__multiply0_3__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_3__multiply0_3__0 
		sendEnd(); // Core1 > Core0: splitTensorB_3__multiply0_3__0 
		receiveStart(); // Core6 > Core1: splitTensorB_30__multiply1_3__0 
		receiveEnd(6); // Core6 > Core1: splitTensorB_30__multiply1_3__0 
		cache_inv(splitTensorB_30__multiply1_3__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__15,output0__inputB__23,output1__inputB__5,output2__inputB__26,output3__inputB__1,output4__inputB__20,output5__inputB__13,output6__inputB__27,output7__inputB__2); // splitTensorB_31
		cache_inv(output__input__15, 64*sizeof(int));
		cache_wbInv(splitTensorB_31__multiply7_3__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: splitTensorB_31__multiply7_3__0 
		sendEnd(); // Core1 > Core7: splitTensorB_31__multiply7_3__0 
		cache_wbInv(splitTensorB_31__multiply6_3__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: splitTensorB_31__multiply6_3__0 
		sendEnd(); // Core1 > Core6: splitTensorB_31__multiply6_3__0 
		cache_wbInv(splitTensorB_31__multiply5_3__0, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: splitTensorB_31__multiply5_3__0 
		sendEnd(); // Core1 > Core5: splitTensorB_31__multiply5_3__0 
		cache_wbInv(splitTensorB_31__multiply4_3__0, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: splitTensorB_31__multiply4_3__0 
		sendEnd(); // Core1 > Core4: splitTensorB_31__multiply4_3__0 
		cache_wbInv(splitTensorB_31__multiply3_3__0, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: splitTensorB_31__multiply3_3__0 
		sendEnd(); // Core1 > Core3: splitTensorB_31__multiply3_3__0 
		cache_wbInv(splitTensorB_31__multiply2_3__0, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: splitTensorB_31__multiply2_3__0 
		sendEnd(); // Core1 > Core2: splitTensorB_31__multiply2_3__0 
		cache_wbInv(splitTensorB_31__multiply0_3__0, 32*sizeof(char));
		sendStart(0); // Core1 > Core0: splitTensorB_31__multiply0_3__0 
		sendEnd(); // Core1 > Core0: splitTensorB_31__multiply0_3__0 
		receiveStart(); // Core7 > Core1: splitTensorB_4__multiply1_4__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_4__multiply1_4__0 
		cache_inv(splitTensorB_4__multiply1_4__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core1: splitTensorB_5__multiply1_5__0 
		receiveEnd(6); // Core6 > Core1: splitTensorB_5__multiply1_5__0 
		cache_inv(splitTensorB_5__multiply1_5__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: splitTensorB_6__multiply1_6__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_6__multiply1_6__0 
		cache_inv(splitTensorB_6__multiply1_6__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: splitTensorB_7__multiply1_7__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_7__multiply1_7__0 
		cache_inv(splitTensorB_7__multiply1_7__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: splitTensorB_8__multiply1_8__0 
		receiveEnd(7); // Core7 > Core1: splitTensorB_8__multiply1_8__0 
		cache_inv(splitTensorB_8__multiply1_8__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core1: splitTensorB_9__multiply1_9__0 
		receiveEnd(6); // Core6 > Core1: splitTensorB_9__multiply1_9__0 
		cache_inv(splitTensorB_9__multiply1_9__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: multiply0_0__sum_0__0 
		receiveEnd(0); // Core0 > Core1: multiply0_0__sum_0__0 
		cache_inv(multiply0_0__sum_0__0, 256*sizeof(char));
		multiply(8/*rows*/,8/*columns*/,output1__inputA__19,output1__inputB__26,output__input1__18); // multiply1_0
		cache_inv(output1__inputA__19, 8*sizeof(int));
		cache_inv(output1__inputB__26, 8*sizeof(int));
		multiply(8/*rows*/,8/*columns*/,output1__inputA__0,output1__inputB__31,output__input1__16); // multiply1_1
		cache_inv(output1__inputA__0, 8*sizeof(int));
		cache_inv(output1__inputB__31, 8*sizeof(int));
		cache_wbInv(multiply1_1__sum_1__0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: multiply1_1__sum_1__0 
		sendEnd(); // Core1 > Core2: multiply1_1__sum_1__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__31,output1__inputB__16,output__input1__27); // multiply1_10
		cache_inv(output1__inputA__31, 8*sizeof(int));
		cache_inv(output1__inputB__16, 8*sizeof(int));
		cache_wbInv(multiply1_10__sum_10__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiply1_10__sum_10__0 
		sendEnd(); // Core1 > Core0: multiply1_10__sum_10__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__24,output1__inputB__17,output__input1__12); // multiply1_11
		cache_inv(output1__inputA__24, 8*sizeof(int));
		cache_inv(output1__inputB__17, 8*sizeof(int));
		cache_wbInv(multiply1_11__sum_11__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiply1_11__sum_11__0 
		sendEnd(); // Core1 > Core6: multiply1_11__sum_11__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__14,output1__inputB__21,output__input1__28); // multiply1_12
		cache_inv(output1__inputA__14, 8*sizeof(int));
		cache_inv(output1__inputB__21, 8*sizeof(int));
		cache_wbInv(multiply1_12__sum_12__0, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: multiply1_12__sum_12__0 
		sendEnd(); // Core1 > Core3: multiply1_12__sum_12__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__9,output1__inputB__4,output__input1__6); // multiply1_13
		cache_inv(output1__inputA__9, 8*sizeof(int));
		cache_inv(output1__inputB__4, 8*sizeof(int));
		cache_wbInv(multiply1_13__sum_13__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiply1_13__sum_13__0 
		sendEnd(); // Core1 > Core0: multiply1_13__sum_13__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__7,output1__inputB__3,output__input1__4); // multiply1_14
		cache_inv(output1__inputA__7, 8*sizeof(int));
		cache_inv(output1__inputB__3, 8*sizeof(int));
		cache_wbInv(multiply1_14__sum_14__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiply1_14__sum_14__0 
		sendEnd(); // Core1 > Core5: multiply1_14__sum_14__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__13,output1__inputB__30,output__input1__17); // multiply1_15
		cache_inv(output1__inputA__13, 8*sizeof(int));
		cache_inv(output1__inputB__30, 8*sizeof(int));
		cache_wbInv(multiply1_15__sum_15__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiply1_15__sum_15__0 
		sendEnd(); // Core1 > Core5: multiply1_15__sum_15__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__26,output1__inputB__1,output__input1__8); // multiply1_16
		cache_inv(output1__inputA__26, 8*sizeof(int));
		cache_inv(output1__inputB__1, 8*sizeof(int));
		cache_wbInv(multiply1_16__sum_16__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiply1_16__sum_16__0 
		sendEnd(); // Core1 > Core0: multiply1_16__sum_16__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__16,output1__inputB__8,output__input1__21); // multiply1_17
		cache_inv(output1__inputA__16, 8*sizeof(int));
		cache_inv(output1__inputB__8, 8*sizeof(int));
		cache_wbInv(multiply1_17__sum_17__0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: multiply1_17__sum_17__0 
		sendEnd(); // Core1 > Core2: multiply1_17__sum_17__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__23,output1__inputB__13,output__input1__31); // multiply1_18
		cache_inv(output1__inputA__23, 8*sizeof(int));
		cache_inv(output1__inputB__13, 8*sizeof(int));
		cache_wbInv(multiply1_18__sum_18__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiply1_18__sum_18__0 
		sendEnd(); // Core1 > Core6: multiply1_18__sum_18__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__2,output1__inputB__20,output__input1__26); // multiply1_19
		cache_inv(output1__inputA__2, 8*sizeof(int));
		cache_inv(output1__inputB__20, 8*sizeof(int));
		cache_wbInv(multiply1_19__sum_19__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_19__sum_19__0 
		sendEnd(); // Core1 > Core4: multiply1_19__sum_19__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__6,output1__inputB__29,output__input1__3); // multiply1_2
		cache_inv(output1__inputA__6, 8*sizeof(int));
		cache_inv(output1__inputB__29, 8*sizeof(int));
		cache_wbInv(multiply1_2__sum_2__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_2__sum_2__0 
		sendEnd(); // Core1 > Core4: multiply1_2__sum_2__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__12,output1__inputB__0,output__input1__22); // multiply1_20
		cache_inv(output1__inputA__12, 8*sizeof(int));
		cache_inv(output1__inputB__0, 8*sizeof(int));
		cache_wbInv(multiply1_20__sum_20__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiply1_20__sum_20__0 
		sendEnd(); // Core1 > Core6: multiply1_20__sum_20__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__21,output1__inputB__12,output__input1__11); // multiply1_21
		cache_inv(output1__inputA__21, 8*sizeof(int));
		cache_inv(output1__inputB__12, 8*sizeof(int));
		cache_wbInv(multiply1_21__sum_21__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_21__sum_21__0 
		sendEnd(); // Core1 > Core4: multiply1_21__sum_21__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__17,output1__inputB__27,output__input1__23); // multiply1_22
		cache_inv(output1__inputA__17, 8*sizeof(int));
		cache_inv(output1__inputB__27, 8*sizeof(int));
		cache_wbInv(multiply1_22__sum_22__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_22__sum_22__0 
		sendEnd(); // Core1 > Core4: multiply1_22__sum_22__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__4,output1__inputB__2,output__input1__0); // multiply1_23
		cache_inv(output1__inputA__4, 8*sizeof(int));
		cache_inv(output1__inputB__2, 8*sizeof(int));
		cache_wbInv(multiply1_23__sum_23__0, 256*sizeof(char));
		sendStart(7); // Core1 > Core7: multiply1_23__sum_23__0 
		sendEnd(); // Core1 > Core7: multiply1_23__sum_23__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__15,output1__inputB__15,output__input1__30); // multiply1_24
		cache_inv(output1__inputA__15, 8*sizeof(int));
		cache_inv(output1__inputB__15, 8*sizeof(int));
		cache_wbInv(multiply1_24__sum_24__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_24__sum_24__0 
		sendEnd(); // Core1 > Core4: multiply1_24__sum_24__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__29,output1__inputB__23,output__input1__19); // multiply1_25
		cache_inv(output1__inputA__29, 8*sizeof(int));
		cache_inv(output1__inputB__23, 8*sizeof(int));
		cache_wbInv(multiply1_25__sum_25__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiply1_25__sum_25__0 
		sendEnd(); // Core1 > Core5: multiply1_25__sum_25__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__18,output1__inputB__25,output__input1__25); // multiply1_26
		cache_inv(output1__inputA__18, 8*sizeof(int));
		cache_inv(output1__inputB__25, 8*sizeof(int));
		cache_wbInv(multiply1_26__sum_26__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_26__sum_26__0 
		sendEnd(); // Core1 > Core4: multiply1_26__sum_26__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__3,output1__inputB__11,output__input1__14); // multiply1_27
		cache_inv(output1__inputA__3, 8*sizeof(int));
		cache_inv(output1__inputB__11, 8*sizeof(int));
		cache_wbInv(multiply1_27__sum_27__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiply1_27__sum_27__0 
		sendEnd(); // Core1 > Core5: multiply1_27__sum_27__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__27,output1__inputB__24,output__input1__7); // multiply1_28
		cache_inv(output1__inputA__27, 8*sizeof(int));
		cache_inv(output1__inputB__24, 8*sizeof(int));
		cache_wbInv(multiply1_28__sum_28__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiply1_28__sum_28__0 
		sendEnd(); // Core1 > Core0: multiply1_28__sum_28__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__28,output1__inputB__19,output__input1__9); // multiply1_29
		cache_inv(output1__inputA__28, 8*sizeof(int));
		cache_inv(output1__inputB__19, 8*sizeof(int));
		cache_wbInv(multiply1_29__sum_29__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiply1_29__sum_29__0 
		sendEnd(); // Core1 > Core5: multiply1_29__sum_29__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__11,output1__inputB__18,output__input1__24); // multiply1_3
		cache_inv(output1__inputA__11, 8*sizeof(int));
		cache_inv(output1__inputB__18, 8*sizeof(int));
		cache_wbInv(multiply1_3__sum_3__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_3__sum_3__0 
		sendEnd(); // Core1 > Core4: multiply1_3__sum_3__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__20,output1__inputB__9,output__input1__10); // multiply1_30
		cache_inv(output1__inputA__20, 8*sizeof(int));
		cache_inv(output1__inputB__9, 8*sizeof(int));
		cache_wbInv(multiply1_30__sum_30__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiply1_30__sum_30__0 
		sendEnd(); // Core1 > Core0: multiply1_30__sum_30__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__25,output1__inputB__5,output__input1__20); // multiply1_31
		cache_inv(output1__inputA__25, 8*sizeof(int));
		cache_inv(output1__inputB__5, 8*sizeof(int));
		cache_wbInv(multiply1_31__sum_31__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiply1_31__sum_31__0 
		sendEnd(); // Core1 > Core4: multiply1_31__sum_31__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__5,output1__inputB__22,output__input1__29); // multiply1_4
		cache_inv(output1__inputA__5, 8*sizeof(int));
		cache_inv(output1__inputB__22, 8*sizeof(int));
		cache_wbInv(multiply1_4__sum_4__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiply1_4__sum_4__0 
		sendEnd(); // Core1 > Core0: multiply1_4__sum_4__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__8,output1__inputB__6,output__input1__2); // multiply1_5
		cache_inv(output1__inputA__8, 8*sizeof(int));
		cache_inv(output1__inputB__6, 8*sizeof(int));
		cache_wbInv(multiply1_5__sum_5__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiply1_5__sum_5__0 
		sendEnd(); // Core1 > Core0: multiply1_5__sum_5__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__10,output1__inputB__10,output__input1__15); // multiply1_6
		cache_inv(output1__inputA__10, 8*sizeof(int));
		cache_inv(output1__inputB__10, 8*sizeof(int));
		cache_wbInv(multiply1_6__sum_6__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiply1_6__sum_6__0 
		sendEnd(); // Core1 > Core6: multiply1_6__sum_6__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__30,output1__inputB__7,output__input1__1); // multiply1_7
		cache_inv(output1__inputA__30, 8*sizeof(int));
		cache_inv(output1__inputB__7, 8*sizeof(int));
		cache_wbInv(multiply1_7__sum_7__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiply1_7__sum_7__0 
		sendEnd(); // Core1 > Core6: multiply1_7__sum_7__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__22,output1__inputB__14,output__input1__5); // multiply1_8
		cache_inv(output1__inputA__22, 8*sizeof(int));
		cache_inv(output1__inputB__14, 8*sizeof(int));
		cache_wbInv(multiply1_8__sum_8__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiply1_8__sum_8__0 
		sendEnd(); // Core1 > Core6: multiply1_8__sum_8__0 
		multiply(8/*rows*/,8/*columns*/,output1__inputA__1,output1__inputB__28,output__input1__13); // multiply1_9
		cache_inv(output1__inputA__1, 8*sizeof(int));
		cache_inv(output1__inputB__28, 8*sizeof(int));
		cache_wbInv(multiply1_9__sum_9__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiply1_9__sum_9__0 
		sendEnd(); // Core1 > Core6: multiply1_9__sum_9__0 
		receiveStart(); // Core2 > Core1: multiply2_0__sum_0__0 
		receiveEnd(2); // Core2 > Core1: multiply2_0__sum_0__0 
		cache_inv(multiply2_0__sum_0__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: multiply3_0__sum_0__0 
		receiveEnd(3); // Core3 > Core1: multiply3_0__sum_0__0 
		cache_inv(multiply3_0__sum_0__0, 256*sizeof(char));
		receiveStart(); // Core4 > Core1: multiply4_0__sum_0__0 
		receiveEnd(4); // Core4 > Core1: multiply4_0__sum_0__0 
		cache_inv(multiply4_0__sum_0__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: multiply5_0__sum_0__0 
		receiveEnd(5); // Core5 > Core1: multiply5_0__sum_0__0 
		cache_inv(multiply5_0__sum_0__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core1: multiply6_0__sum_0__0 
		receiveEnd(6); // Core6 > Core1: multiply6_0__sum_0__0 
		cache_inv(multiply6_0__sum_0__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiply7_0__sum_0__0 
		receiveEnd(7); // Core7 > Core1: multiply7_0__sum_0__0 
		cache_inv(multiply7_0__sum_0__0, 256*sizeof(char));
		sum(8/*rows*/,8/*columns*/,output__input0__4,output__input1__18,output__input2__25,output__input3__29,output__input4__0,output__input5__2,output__input6__1,output__input7__7,output__arrayC_0__0); // sum_0
		cache_inv(output__input0__4, 64*sizeof(long));
		cache_inv(output__input1__18, 64*sizeof(long));
		cache_inv(output__input2__25, 64*sizeof(long));
		cache_inv(output__input3__29, 64*sizeof(long));
		cache_inv(output__input4__0, 64*sizeof(long));
		cache_inv(output__input5__2, 64*sizeof(long));
		cache_inv(output__input6__1, 64*sizeof(long));
		cache_inv(output__input7__7, 64*sizeof(long));
		cache_wbInv(sum_0__implode_displayResult__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: sum_0__implode_displayResult__0 
		sendEnd(); // Core1 > Core6: sum_0__implode_displayResult__0 
	}
}
