/** 
 * @file Core5.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 17:17:02 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__4;  // explode_generateTensors_arrayA > splitTensorA_3 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayB > transpose_3 size:= 1048576*char defined in Core0
extern char *const splitTensorA_0__multiply5_0__0;  // splitTensorA_0 > multiply5_0 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply5_1__0;  // splitTensorA_1 > multiply5_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply5_2__0;  // splitTensorA_2 > multiply5_2 size:= 131072*char defined in Core0
extern int *const arrayA_786432__input__0;  // explode_generateTensors_arrayA_arrayA_786432 > splitTensorA_3_input size:= 262144*int defined in Core0
extern int *const output0__inputA__6;  // splitTensorA_3_output0 > multiply0_3_inputA size:= 32768*int defined in Core0
extern int *const output1__inputA__0;  // splitTensorA_3_output1 > multiply1_3_inputA size:= 32768*int defined in Core0
extern int *const output2__inputA__5;  // splitTensorA_3_output2 > multiply2_3_inputA size:= 32768*int defined in Core0
extern int *const output3__inputA__5;  // splitTensorA_3_output3 > multiply3_3_inputA size:= 32768*int defined in Core0
extern int *const output4__inputA__7;  // splitTensorA_3_output4 > multiply4_3_inputA size:= 32768*int defined in Core0
extern int *const output5__inputA__0;  // splitTensorA_3_output5 > multiply5_3_inputA size:= 32768*int defined in Core0
extern int *const output6__inputA__3;  // splitTensorA_3_output6 > multiply6_3_inputA size:= 32768*int defined in Core0
extern int *const output7__inputA__3;  // splitTensorA_3_output7 > multiply7_3_inputA size:= 32768*int defined in Core0
extern char *const splitTensorA_3__multiply7_3__0;  // splitTensorA_3 > multiply7_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply6_3__0;  // splitTensorA_3 > multiply6_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply4_3__0;  // splitTensorA_3 > multiply4_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply3_3__0;  // splitTensorA_3 > multiply3_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply2_3__0;  // splitTensorA_3 > multiply2_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply1_3__0;  // splitTensorA_3 > multiply1_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply0_3__0;  // splitTensorA_3 > multiply0_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_4__multiply5_4__0;  // splitTensorA_4 > multiply5_4 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply5_5__0;  // splitTensorA_5 > multiply5_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_6__multiply5_6__0;  // splitTensorA_6 > multiply5_6 size:= 131072*char defined in Core0
extern char *const splitTensorA_7__multiply5_7__0;  // splitTensorA_7 > multiply5_7 size:= 131072*char defined in Core0
extern int *const arrayB_786432__input__0;  // explode_generateTensors_arrayB_arrayB_786432 > transpose_3_input size:= 262144*int defined in Core0
extern int *const output__input__7;  // transpose_3_output > splitTensorB_3_input size:= 262144*int defined in Core0
extern char *const splitTensorB_0__multiply5_0__0;  // splitTensorB_0 > multiply5_0 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply5_1__0;  // splitTensorB_1 > multiply5_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply5_2__0;  // splitTensorB_2 > multiply5_2 size:= 131072*char defined in Core0
extern int *const output0__inputB__2;  // splitTensorB_3_output0 > multiply0_3_inputB size:= 32768*int defined in Core0
extern int *const output1__inputB__1;  // splitTensorB_3_output1 > multiply1_3_inputB size:= 32768*int defined in Core0
extern int *const output2__inputB__4;  // splitTensorB_3_output2 > multiply2_3_inputB size:= 32768*int defined in Core0
extern int *const output3__inputB__6;  // splitTensorB_3_output3 > multiply3_3_inputB size:= 32768*int defined in Core0
extern int *const output4__inputB__3;  // splitTensorB_3_output4 > multiply4_3_inputB size:= 32768*int defined in Core0
extern int *const output5__inputB__4;  // splitTensorB_3_output5 > multiply5_3_inputB size:= 32768*int defined in Core0
extern int *const output6__inputB__7;  // splitTensorB_3_output6 > multiply6_3_inputB size:= 32768*int defined in Core0
extern int *const output7__inputB__2;  // splitTensorB_3_output7 > multiply7_3_inputB size:= 32768*int defined in Core0
extern char *const splitTensorB_3__multiply7_3__0;  // splitTensorB_3 > multiply7_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply6_3__0;  // splitTensorB_3 > multiply6_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply4_3__0;  // splitTensorB_3 > multiply4_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply3_3__0;  // splitTensorB_3 > multiply3_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply2_3__0;  // splitTensorB_3 > multiply2_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply1_3__0;  // splitTensorB_3 > multiply1_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply0_3__0;  // splitTensorB_3 > multiply0_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_4__multiply5_4__0;  // splitTensorB_4 > multiply5_4 size:= 131072*char defined in Core0
extern char *const splitTensorB_5__multiply5_5__0;  // splitTensorB_5 > multiply5_5 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply5_6__0;  // splitTensorB_6 > multiply5_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_7__multiply5_7__0;  // splitTensorB_7 > multiply5_7 size:= 131072*char defined in Core0
extern char *const multiply0_3__sum_3__0;  // multiply0_3 > sum_3 size:= 1048576*char defined in Core0
extern char *const multiply1_3__sum_3__0;  // multiply1_3 > sum_3 size:= 1048576*char defined in Core0
extern char *const multiply2_3__sum_3__0;  // multiply2_3 > sum_3 size:= 1048576*char defined in Core0
extern char *const multiply3_3__sum_3__0;  // multiply3_3 > sum_3 size:= 1048576*char defined in Core0
extern char *const multiply4_3__sum_3__0;  // multiply4_3 > sum_3 size:= 1048576*char defined in Core0
extern int *const output5__inputA__6;  // splitTensorA_0_output5 > multiply5_0_inputA size:= 32768*int defined in Core0
extern int *const output5__inputB__3;  // splitTensorB_0_output5 > multiply5_0_inputB size:= 32768*int defined in Core0
extern long *const output__input5__6;  // multiply5_0_output > sum_0_input5 size:= 262144*long defined in Core0
extern char *const multiply5_0__sum_0__0;  // multiply5_0 > sum_0 size:= 1048576*char defined in Core0
extern int *const output5__inputA__7;  // splitTensorA_1_output5 > multiply5_1_inputA size:= 32768*int defined in Core0
extern int *const output5__inputB__0;  // splitTensorB_1_output5 > multiply5_1_inputB size:= 32768*int defined in Core0
extern long *const output__input5__7;  // multiply5_1_output > sum_1_input5 size:= 262144*long defined in Core0
extern char *const multiply5_1__sum_1__0;  // multiply5_1 > sum_1 size:= 1048576*char defined in Core0
extern int *const output5__inputA__5;  // splitTensorA_2_output5 > multiply5_2_inputA size:= 32768*int defined in Core0
extern int *const output5__inputB__5;  // splitTensorB_2_output5 > multiply5_2_inputB size:= 32768*int defined in Core0
extern long *const output__input5__0;  // multiply5_2_output > sum_2_input5 size:= 262144*long defined in Core0
extern char *const multiply5_2__sum_2__0;  // multiply5_2 > sum_2 size:= 1048576*char defined in Core0
extern long *const output__input5__5;  // multiply5_3_output > sum_3_input5 size:= 262144*long defined in Core0
extern int *const output5__inputA__4;  // splitTensorA_4_output5 > multiply5_4_inputA size:= 32768*int defined in Core0
extern int *const output5__inputB__1;  // splitTensorB_4_output5 > multiply5_4_inputB size:= 32768*int defined in Core0
extern long *const output__input5__2;  // multiply5_4_output > sum_4_input5 size:= 262144*long defined in Core0
extern char *const multiply5_4__sum_4__0;  // multiply5_4 > sum_4 size:= 1048576*char defined in Core0
extern int *const output5__inputA__1;  // splitTensorA_5_output5 > multiply5_5_inputA size:= 32768*int defined in Core0
extern int *const output5__inputB__7;  // splitTensorB_5_output5 > multiply5_5_inputB size:= 32768*int defined in Core0
extern long *const output__input5__4;  // multiply5_5_output > sum_5_input5 size:= 262144*long defined in Core0
extern char *const multiply5_5__sum_5__0;  // multiply5_5 > sum_5 size:= 1048576*char defined in Core0
extern int *const output5__inputA__2;  // splitTensorA_6_output5 > multiply5_6_inputA size:= 32768*int defined in Core0
extern int *const output5__inputB__6;  // splitTensorB_6_output5 > multiply5_6_inputB size:= 32768*int defined in Core0
extern long *const output__input5__1;  // multiply5_6_output > sum_6_input5 size:= 262144*long defined in Core0
extern char *const multiply5_6__sum_6__0;  // multiply5_6 > sum_6 size:= 1048576*char defined in Core0
extern int *const output5__inputA__3;  // splitTensorA_7_output5 > multiply5_7_inputA size:= 32768*int defined in Core0
extern int *const output5__inputB__2;  // splitTensorB_7_output5 > multiply5_7_inputB size:= 32768*int defined in Core0
extern long *const output__input5__3;  // multiply5_7_output > sum_7_input5 size:= 262144*long defined in Core0
extern char *const multiply5_7__sum_7__0;  // multiply5_7 > sum_7 size:= 1048576*char defined in Core0
extern char *const multiply6_3__sum_3__0;  // multiply6_3 > sum_3 size:= 1048576*char defined in Core0
extern char *const multiply7_3__sum_3__0;  // multiply7_3 > sum_3 size:= 1048576*char defined in Core0
extern long *const output__input0__3;  // multiply0_3_output > sum_3_input0 size:= 262144*long defined in Core0
extern long *const output__input1__4;  // multiply1_3_output > sum_3_input1 size:= 262144*long defined in Core0
extern long *const output__input2__1;  // multiply2_3_output > sum_3_input2 size:= 262144*long defined in Core0
extern long *const output__input3__2;  // multiply3_3_output > sum_3_input3 size:= 262144*long defined in Core0
extern long *const output__input4__4;  // multiply4_3_output > sum_3_input4 size:= 262144*long defined in Core0
extern long *const output__input6__2;  // multiply6_3_output > sum_3_input6 size:= 262144*long defined in Core0
extern long *const output__input7__1;  // multiply7_3_output > sum_3_input7 size:= 262144*long defined in Core0
extern long *const output__arrayC_786432__0;  // sum_3_output > implode_displayResult_arrayC_arrayC_786432 size:= 262144*long defined in Core0
extern char *const sum_3__implode_displayResult__0;  // sum_3 > implode_displayResult_arrayC size:= 1048576*char defined in Core0

// Core Global Definitions

void core5(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__4 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__4 
		cache_inv(explode_generateTensors_arra__4, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__12 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core5: splitTensorA_0__multiply5_0__0 
		receiveEnd(4); // Core4 > Core5: splitTensorA_0__multiply5_0__0 
		cache_inv(splitTensorA_0__multiply5_0__0, 131072*sizeof(char));
		receiveStart(); // Core2 > Core5: splitTensorA_1__multiply5_1__0 
		receiveEnd(2); // Core2 > Core5: splitTensorA_1__multiply5_1__0 
		cache_inv(splitTensorA_1__multiply5_1__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core5: splitTensorA_2__multiply5_2__0 
		receiveEnd(6); // Core6 > Core5: splitTensorA_2__multiply5_2__0 
		cache_inv(splitTensorA_2__multiply5_2__0, 131072*sizeof(char));
		splitA(512/*rowsA*/,512/*columnsA*/,arrayA_786432__input__0,output0__inputA__6,output1__inputA__0,output2__inputA__5,output3__inputA__5,output4__inputA__7,output5__inputA__0,output6__inputA__3,output7__inputA__3); // splitTensorA_3
		cache_inv(arrayA_786432__input__0, 262144*sizeof(int));
		cache_wbInv(splitTensorA_3__multiply7_3__0, 131072*sizeof(char));
		sendStart(7); // Core5 > Core7: splitTensorA_3__multiply7_3__0 
		sendEnd(); // Core5 > Core7: splitTensorA_3__multiply7_3__0 
		cache_wbInv(splitTensorA_3__multiply6_3__0, 131072*sizeof(char));
		sendStart(6); // Core5 > Core6: splitTensorA_3__multiply6_3__0 
		sendEnd(); // Core5 > Core6: splitTensorA_3__multiply6_3__0 
		cache_wbInv(splitTensorA_3__multiply4_3__0, 131072*sizeof(char));
		sendStart(4); // Core5 > Core4: splitTensorA_3__multiply4_3__0 
		sendEnd(); // Core5 > Core4: splitTensorA_3__multiply4_3__0 
		cache_wbInv(splitTensorA_3__multiply3_3__0, 131072*sizeof(char));
		sendStart(3); // Core5 > Core3: splitTensorA_3__multiply3_3__0 
		sendEnd(); // Core5 > Core3: splitTensorA_3__multiply3_3__0 
		cache_wbInv(splitTensorA_3__multiply2_3__0, 131072*sizeof(char));
		sendStart(2); // Core5 > Core2: splitTensorA_3__multiply2_3__0 
		sendEnd(); // Core5 > Core2: splitTensorA_3__multiply2_3__0 
		cache_wbInv(splitTensorA_3__multiply1_3__0, 131072*sizeof(char));
		sendStart(1); // Core5 > Core1: splitTensorA_3__multiply1_3__0 
		sendEnd(); // Core5 > Core1: splitTensorA_3__multiply1_3__0 
		cache_wbInv(splitTensorA_3__multiply0_3__0, 131072*sizeof(char));
		sendStart(0); // Core5 > Core0: splitTensorA_3__multiply0_3__0 
		sendEnd(); // Core5 > Core0: splitTensorA_3__multiply0_3__0 
		receiveStart(); // Core0 > Core5: splitTensorA_4__multiply5_4__0 
		receiveEnd(0); // Core0 > Core5: splitTensorA_4__multiply5_4__0 
		cache_inv(splitTensorA_4__multiply5_4__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core5: splitTensorA_5__multiply5_5__0 
		receiveEnd(6); // Core6 > Core5: splitTensorA_5__multiply5_5__0 
		cache_inv(splitTensorA_5__multiply5_5__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core5: splitTensorA_6__multiply5_6__0 
		receiveEnd(1); // Core1 > Core5: splitTensorA_6__multiply5_6__0 
		cache_inv(splitTensorA_6__multiply5_6__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core5: splitTensorA_7__multiply5_7__0 
		receiveEnd(7); // Core7 > Core5: splitTensorA_7__multiply5_7__0 
		cache_inv(splitTensorA_7__multiply5_7__0, 131072*sizeof(char));
		transpose(512/*rowsB*/,512/*columnsB*/,arrayB_786432__input__0,output__input__7); // transpose_3
		cache_inv(arrayB_786432__input__0, 262144*sizeof(int));
		receiveStart(); // Core4 > Core5: splitTensorB_0__multiply5_0__0 
		receiveEnd(4); // Core4 > Core5: splitTensorB_0__multiply5_0__0 
		cache_inv(splitTensorB_0__multiply5_0__0, 131072*sizeof(char));
		receiveStart(); // Core3 > Core5: splitTensorB_1__multiply5_1__0 
		receiveEnd(3); // Core3 > Core5: splitTensorB_1__multiply5_1__0 
		cache_inv(splitTensorB_1__multiply5_1__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core5: splitTensorB_2__multiply5_2__0 
		receiveEnd(6); // Core6 > Core5: splitTensorB_2__multiply5_2__0 
		cache_inv(splitTensorB_2__multiply5_2__0, 131072*sizeof(char));
		splitB(512/*rowsB*/,512/*columnsB*/,output__input__7,output0__inputB__2,output1__inputB__1,output2__inputB__4,output3__inputB__6,output4__inputB__3,output5__inputB__4,output6__inputB__7,output7__inputB__2); // splitTensorB_3
		cache_inv(output__input__7, 262144*sizeof(int));
		cache_wbInv(splitTensorB_3__multiply7_3__0, 131072*sizeof(char));
		sendStart(7); // Core5 > Core7: splitTensorB_3__multiply7_3__0 
		sendEnd(); // Core5 > Core7: splitTensorB_3__multiply7_3__0 
		cache_wbInv(splitTensorB_3__multiply6_3__0, 131072*sizeof(char));
		sendStart(6); // Core5 > Core6: splitTensorB_3__multiply6_3__0 
		sendEnd(); // Core5 > Core6: splitTensorB_3__multiply6_3__0 
		cache_wbInv(splitTensorB_3__multiply4_3__0, 131072*sizeof(char));
		sendStart(4); // Core5 > Core4: splitTensorB_3__multiply4_3__0 
		sendEnd(); // Core5 > Core4: splitTensorB_3__multiply4_3__0 
		cache_wbInv(splitTensorB_3__multiply3_3__0, 131072*sizeof(char));
		sendStart(3); // Core5 > Core3: splitTensorB_3__multiply3_3__0 
		sendEnd(); // Core5 > Core3: splitTensorB_3__multiply3_3__0 
		cache_wbInv(splitTensorB_3__multiply2_3__0, 131072*sizeof(char));
		sendStart(2); // Core5 > Core2: splitTensorB_3__multiply2_3__0 
		sendEnd(); // Core5 > Core2: splitTensorB_3__multiply2_3__0 
		cache_wbInv(splitTensorB_3__multiply1_3__0, 131072*sizeof(char));
		sendStart(1); // Core5 > Core1: splitTensorB_3__multiply1_3__0 
		sendEnd(); // Core5 > Core1: splitTensorB_3__multiply1_3__0 
		cache_wbInv(splitTensorB_3__multiply0_3__0, 131072*sizeof(char));
		sendStart(0); // Core5 > Core0: splitTensorB_3__multiply0_3__0 
		sendEnd(); // Core5 > Core0: splitTensorB_3__multiply0_3__0 
		receiveStart(); // Core7 > Core5: splitTensorB_4__multiply5_4__0 
		receiveEnd(7); // Core7 > Core5: splitTensorB_4__multiply5_4__0 
		cache_inv(splitTensorB_4__multiply5_4__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core5: splitTensorB_5__multiply5_5__0 
		receiveEnd(0); // Core0 > Core5: splitTensorB_5__multiply5_5__0 
		cache_inv(splitTensorB_5__multiply5_5__0, 131072*sizeof(char));
		receiveStart(); // Core2 > Core5: splitTensorB_6__multiply5_6__0 
		receiveEnd(2); // Core2 > Core5: splitTensorB_6__multiply5_6__0 
		cache_inv(splitTensorB_6__multiply5_6__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core5: splitTensorB_7__multiply5_7__0 
		receiveEnd(1); // Core1 > Core5: splitTensorB_7__multiply5_7__0 
		cache_inv(splitTensorB_7__multiply5_7__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core5: multiply0_3__sum_3__0 
		receiveEnd(0); // Core0 > Core5: multiply0_3__sum_3__0 
		cache_inv(multiply0_3__sum_3__0, 1048576*sizeof(char));
		receiveStart(); // Core1 > Core5: multiply1_3__sum_3__0 
		receiveEnd(1); // Core1 > Core5: multiply1_3__sum_3__0 
		cache_inv(multiply1_3__sum_3__0, 1048576*sizeof(char));
		receiveStart(); // Core2 > Core5: multiply2_3__sum_3__0 
		receiveEnd(2); // Core2 > Core5: multiply2_3__sum_3__0 
		cache_inv(multiply2_3__sum_3__0, 1048576*sizeof(char));
		receiveStart(); // Core3 > Core5: multiply3_3__sum_3__0 
		receiveEnd(3); // Core3 > Core5: multiply3_3__sum_3__0 
		cache_inv(multiply3_3__sum_3__0, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core5: multiply4_3__sum_3__0 
		receiveEnd(4); // Core4 > Core5: multiply4_3__sum_3__0 
		cache_inv(multiply4_3__sum_3__0, 1048576*sizeof(char));
		multiply(512/*rows*/,512/*columns*/,output5__inputA__6,output5__inputB__3,output__input5__6); // multiply5_0
		cache_inv(output5__inputA__6, 32768*sizeof(int));
		cache_inv(output5__inputB__3, 32768*sizeof(int));
		cache_wbInv(multiply5_0__sum_0__0, 1048576*sizeof(char));
		sendStart(4); // Core5 > Core4: multiply5_0__sum_0__0 
		sendEnd(); // Core5 > Core4: multiply5_0__sum_0__0 
		multiply(512/*rows*/,512/*columns*/,output5__inputA__7,output5__inputB__0,output__input5__7); // multiply5_1
		cache_inv(output5__inputA__7, 32768*sizeof(int));
		cache_inv(output5__inputB__0, 32768*sizeof(int));
		cache_wbInv(multiply5_1__sum_1__0, 1048576*sizeof(char));
		sendStart(3); // Core5 > Core3: multiply5_1__sum_1__0 
		sendEnd(); // Core5 > Core3: multiply5_1__sum_1__0 
		multiply(512/*rows*/,512/*columns*/,output5__inputA__5,output5__inputB__5,output__input5__0); // multiply5_2
		cache_inv(output5__inputA__5, 32768*sizeof(int));
		cache_inv(output5__inputB__5, 32768*sizeof(int));
		cache_wbInv(multiply5_2__sum_2__0, 1048576*sizeof(char));
		sendStart(2); // Core5 > Core2: multiply5_2__sum_2__0 
		sendEnd(); // Core5 > Core2: multiply5_2__sum_2__0 
		multiply(512/*rows*/,512/*columns*/,output5__inputA__0,output5__inputB__4,output__input5__5); // multiply5_3
		cache_inv(output5__inputA__0, 32768*sizeof(int));
		cache_inv(output5__inputB__4, 32768*sizeof(int));
		multiply(512/*rows*/,512/*columns*/,output5__inputA__4,output5__inputB__1,output__input5__2); // multiply5_4
		cache_inv(output5__inputA__4, 32768*sizeof(int));
		cache_inv(output5__inputB__1, 32768*sizeof(int));
		cache_wbInv(multiply5_4__sum_4__0, 1048576*sizeof(char));
		sendStart(0); // Core5 > Core0: multiply5_4__sum_4__0 
		sendEnd(); // Core5 > Core0: multiply5_4__sum_4__0 
		multiply(512/*rows*/,512/*columns*/,output5__inputA__1,output5__inputB__7,output__input5__4); // multiply5_5
		cache_inv(output5__inputA__1, 32768*sizeof(int));
		cache_inv(output5__inputB__7, 32768*sizeof(int));
		cache_wbInv(multiply5_5__sum_5__0, 1048576*sizeof(char));
		sendStart(4); // Core5 > Core4: multiply5_5__sum_5__0 
		sendEnd(); // Core5 > Core4: multiply5_5__sum_5__0 
		multiply(512/*rows*/,512/*columns*/,output5__inputA__2,output5__inputB__6,output__input5__1); // multiply5_6
		cache_inv(output5__inputA__2, 32768*sizeof(int));
		cache_inv(output5__inputB__6, 32768*sizeof(int));
		cache_wbInv(multiply5_6__sum_6__0, 1048576*sizeof(char));
		sendStart(1); // Core5 > Core1: multiply5_6__sum_6__0 
		sendEnd(); // Core5 > Core1: multiply5_6__sum_6__0 
		multiply(512/*rows*/,512/*columns*/,output5__inputA__3,output5__inputB__2,output__input5__3); // multiply5_7
		cache_inv(output5__inputA__3, 32768*sizeof(int));
		cache_inv(output5__inputB__2, 32768*sizeof(int));
		cache_wbInv(multiply5_7__sum_7__0, 1048576*sizeof(char));
		sendStart(7); // Core5 > Core7: multiply5_7__sum_7__0 
		sendEnd(); // Core5 > Core7: multiply5_7__sum_7__0 
		receiveStart(); // Core6 > Core5: multiply6_3__sum_3__0 
		receiveEnd(6); // Core6 > Core5: multiply6_3__sum_3__0 
		cache_inv(multiply6_3__sum_3__0, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core5: multiply7_3__sum_3__0 
		receiveEnd(7); // Core7 > Core5: multiply7_3__sum_3__0 
		cache_inv(multiply7_3__sum_3__0, 1048576*sizeof(char));
		sum(512/*rows*/,512/*columns*/,output__input0__3,output__input1__4,output__input2__1,output__input3__2,output__input4__4,output__input5__5,output__input6__2,output__input7__1,output__arrayC_786432__0); // sum_3
		cache_inv(output__input0__3, 262144*sizeof(long));
		cache_inv(output__input1__4, 262144*sizeof(long));
		cache_inv(output__input2__1, 262144*sizeof(long));
		cache_inv(output__input3__2, 262144*sizeof(long));
		cache_inv(output__input4__4, 262144*sizeof(long));
		cache_inv(output__input5__5, 262144*sizeof(long));
		cache_inv(output__input6__2, 262144*sizeof(long));
		cache_inv(output__input7__1, 262144*sizeof(long));
		cache_wbInv(sum_3__implode_displayResult__0, 1048576*sizeof(char));
		sendStart(7); // Core5 > Core7: sum_3__implode_displayResult__0 
		sendEnd(); // Core5 > Core7: sum_3__implode_displayResult__0 
	}
}
