/** 
 * @file Core3.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 17:17:02 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__11;  // explode_generateTensors_arrayB > transpose_1 size:= 1048576*char defined in Core0
extern char *const splitTensorA_0__multiply3_0__0;  // splitTensorA_0 > multiply3_0 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply3_1__0;  // splitTensorA_1 > multiply3_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply3_2__0;  // splitTensorA_2 > multiply3_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply3_3__0;  // splitTensorA_3 > multiply3_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_4__multiply3_4__0;  // splitTensorA_4 > multiply3_4 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply3_5__0;  // splitTensorA_5 > multiply3_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_6__multiply3_6__0;  // splitTensorA_6 > multiply3_6 size:= 131072*char defined in Core0
extern char *const splitTensorA_7__multiply3_7__0;  // splitTensorA_7 > multiply3_7 size:= 131072*char defined in Core0
extern int *const arrayB_262144__input__0;  // explode_generateTensors_arrayB_arrayB_262144 > transpose_1_input size:= 262144*int defined in Core0
extern int *const output__input__3;  // transpose_1_output > splitTensorB_1_input size:= 262144*int defined in Core0
extern char *const splitTensorB_0__multiply3_0__0;  // splitTensorB_0 > multiply3_0 size:= 131072*char defined in Core0
extern int *const output0__inputB__3;  // splitTensorB_1_output0 > multiply0_1_inputB size:= 32768*int defined in Core0
extern int *const output1__inputB__6;  // splitTensorB_1_output1 > multiply1_1_inputB size:= 32768*int defined in Core0
extern int *const output2__inputB__6;  // splitTensorB_1_output2 > multiply2_1_inputB size:= 32768*int defined in Core0
extern int *const output3__inputB__0;  // splitTensorB_1_output3 > multiply3_1_inputB size:= 32768*int defined in Core0
extern int *const output4__inputB__2;  // splitTensorB_1_output4 > multiply4_1_inputB size:= 32768*int defined in Core0
extern int *const output5__inputB__0;  // splitTensorB_1_output5 > multiply5_1_inputB size:= 32768*int defined in Core0
extern int *const output6__inputB__5;  // splitTensorB_1_output6 > multiply6_1_inputB size:= 32768*int defined in Core0
extern int *const output7__inputB__1;  // splitTensorB_1_output7 > multiply7_1_inputB size:= 32768*int defined in Core0
extern char *const splitTensorB_1__multiply7_1__0;  // splitTensorB_1 > multiply7_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply6_1__0;  // splitTensorB_1 > multiply6_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply5_1__0;  // splitTensorB_1 > multiply5_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply4_1__0;  // splitTensorB_1 > multiply4_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply2_1__0;  // splitTensorB_1 > multiply2_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply1_1__0;  // splitTensorB_1 > multiply1_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply0_1__0;  // splitTensorB_1 > multiply0_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply3_2__0;  // splitTensorB_2 > multiply3_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply3_3__0;  // splitTensorB_3 > multiply3_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_4__multiply3_4__0;  // splitTensorB_4 > multiply3_4 size:= 131072*char defined in Core0
extern char *const splitTensorB_5__multiply3_5__0;  // splitTensorB_5 > multiply3_5 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply3_6__0;  // splitTensorB_6 > multiply3_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_7__multiply3_7__0;  // splitTensorB_7 > multiply3_7 size:= 131072*char defined in Core0
extern char *const multiply0_1__sum_1__0;  // multiply0_1 > sum_1 size:= 1048576*char defined in Core0
extern char *const multiply1_1__sum_1__0;  // multiply1_1 > sum_1 size:= 1048576*char defined in Core0
extern char *const multiply2_1__sum_1__0;  // multiply2_1 > sum_1 size:= 1048576*char defined in Core0
extern int *const output3__inputA__0;  // splitTensorA_0_output3 > multiply3_0_inputA size:= 32768*int defined in Core0
extern int *const output3__inputB__4;  // splitTensorB_0_output3 > multiply3_0_inputB size:= 32768*int defined in Core0
extern long *const output__input3__0;  // multiply3_0_output > sum_0_input3 size:= 262144*long defined in Core0
extern char *const multiply3_0__sum_0__0;  // multiply3_0 > sum_0 size:= 1048576*char defined in Core0
extern int *const output3__inputA__1;  // splitTensorA_1_output3 > multiply3_1_inputA size:= 32768*int defined in Core0
extern long *const output__input3__5;  // multiply3_1_output > sum_1_input3 size:= 262144*long defined in Core0
extern int *const output3__inputA__6;  // splitTensorA_2_output3 > multiply3_2_inputA size:= 32768*int defined in Core0
extern int *const output3__inputB__5;  // splitTensorB_2_output3 > multiply3_2_inputB size:= 32768*int defined in Core0
extern long *const output__input3__7;  // multiply3_2_output > sum_2_input3 size:= 262144*long defined in Core0
extern char *const multiply3_2__sum_2__0;  // multiply3_2 > sum_2 size:= 1048576*char defined in Core0
extern int *const output3__inputA__5;  // splitTensorA_3_output3 > multiply3_3_inputA size:= 32768*int defined in Core0
extern int *const output3__inputB__6;  // splitTensorB_3_output3 > multiply3_3_inputB size:= 32768*int defined in Core0
extern long *const output__input3__2;  // multiply3_3_output > sum_3_input3 size:= 262144*long defined in Core0
extern char *const multiply3_3__sum_3__0;  // multiply3_3 > sum_3 size:= 1048576*char defined in Core0
extern int *const output3__inputA__4;  // splitTensorA_4_output3 > multiply3_4_inputA size:= 32768*int defined in Core0
extern int *const output3__inputB__2;  // splitTensorB_4_output3 > multiply3_4_inputB size:= 32768*int defined in Core0
extern long *const output__input3__6;  // multiply3_4_output > sum_4_input3 size:= 262144*long defined in Core0
extern char *const multiply3_4__sum_4__0;  // multiply3_4 > sum_4 size:= 1048576*char defined in Core0
extern int *const output3__inputA__7;  // splitTensorA_5_output3 > multiply3_5_inputA size:= 32768*int defined in Core0
extern int *const output3__inputB__1;  // splitTensorB_5_output3 > multiply3_5_inputB size:= 32768*int defined in Core0
extern long *const output__input3__3;  // multiply3_5_output > sum_5_input3 size:= 262144*long defined in Core0
extern char *const multiply3_5__sum_5__0;  // multiply3_5 > sum_5 size:= 1048576*char defined in Core0
extern int *const output3__inputA__2;  // splitTensorA_6_output3 > multiply3_6_inputA size:= 32768*int defined in Core0
extern int *const output3__inputB__7;  // splitTensorB_6_output3 > multiply3_6_inputB size:= 32768*int defined in Core0
extern long *const output__input3__4;  // multiply3_6_output > sum_6_input3 size:= 262144*long defined in Core0
extern char *const multiply3_6__sum_6__0;  // multiply3_6 > sum_6 size:= 1048576*char defined in Core0
extern int *const output3__inputA__3;  // splitTensorA_7_output3 > multiply3_7_inputA size:= 32768*int defined in Core0
extern int *const output3__inputB__3;  // splitTensorB_7_output3 > multiply3_7_inputB size:= 32768*int defined in Core0
extern long *const output__input3__1;  // multiply3_7_output > sum_7_input3 size:= 262144*long defined in Core0
extern char *const multiply3_7__sum_7__0;  // multiply3_7 > sum_7 size:= 1048576*char defined in Core0
extern char *const multiply4_1__sum_1__0;  // multiply4_1 > sum_1 size:= 1048576*char defined in Core0
extern char *const multiply5_1__sum_1__0;  // multiply5_1 > sum_1 size:= 1048576*char defined in Core0
extern char *const multiply6_1__sum_1__0;  // multiply6_1 > sum_1 size:= 1048576*char defined in Core0
extern char *const multiply7_1__sum_1__0;  // multiply7_1 > sum_1 size:= 1048576*char defined in Core0
extern long *const output__input0__7;  // multiply0_1_output > sum_1_input0 size:= 262144*long defined in Core0
extern long *const output__input1__1;  // multiply1_1_output > sum_1_input1 size:= 262144*long defined in Core0
extern long *const output__input2__6;  // multiply2_1_output > sum_1_input2 size:= 262144*long defined in Core0
extern long *const output__input4__6;  // multiply4_1_output > sum_1_input4 size:= 262144*long defined in Core0
extern long *const output__input5__7;  // multiply5_1_output > sum_1_input5 size:= 262144*long defined in Core0
extern long *const output__input6__3;  // multiply6_1_output > sum_1_input6 size:= 262144*long defined in Core0
extern long *const output__input7__3;  // multiply7_1_output > sum_1_input7 size:= 262144*long defined in Core0
extern long *const output__arrayC_262144__0;  // sum_1_output > implode_displayResult_arrayC_arrayC_262144 size:= 262144*long defined in Core0
extern char *const sum_1__implode_displayResult__0;  // sum_1 > implode_displayResult_arrayC size:= 1048576*char defined in Core0

// Core Global Definitions

void core3(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__11 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__11 
		cache_inv(explode_generateTensors_arra__11, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core3: splitTensorA_0__multiply3_0__0 
		receiveEnd(4); // Core4 > Core3: splitTensorA_0__multiply3_0__0 
		cache_inv(splitTensorA_0__multiply3_0__0, 131072*sizeof(char));
		receiveStart(); // Core2 > Core3: splitTensorA_1__multiply3_1__0 
		receiveEnd(2); // Core2 > Core3: splitTensorA_1__multiply3_1__0 
		cache_inv(splitTensorA_1__multiply3_1__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core3: splitTensorA_2__multiply3_2__0 
		receiveEnd(6); // Core6 > Core3: splitTensorA_2__multiply3_2__0 
		cache_inv(splitTensorA_2__multiply3_2__0, 131072*sizeof(char));
		receiveStart(); // Core5 > Core3: splitTensorA_3__multiply3_3__0 
		receiveEnd(5); // Core5 > Core3: splitTensorA_3__multiply3_3__0 
		cache_inv(splitTensorA_3__multiply3_3__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core3: splitTensorA_4__multiply3_4__0 
		receiveEnd(0); // Core0 > Core3: splitTensorA_4__multiply3_4__0 
		cache_inv(splitTensorA_4__multiply3_4__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core3: splitTensorA_5__multiply3_5__0 
		receiveEnd(6); // Core6 > Core3: splitTensorA_5__multiply3_5__0 
		cache_inv(splitTensorA_5__multiply3_5__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core3: splitTensorA_6__multiply3_6__0 
		receiveEnd(1); // Core1 > Core3: splitTensorA_6__multiply3_6__0 
		cache_inv(splitTensorA_6__multiply3_6__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core3: splitTensorA_7__multiply3_7__0 
		receiveEnd(7); // Core7 > Core3: splitTensorA_7__multiply3_7__0 
		cache_inv(splitTensorA_7__multiply3_7__0, 131072*sizeof(char));
		transpose(512/*rowsB*/,512/*columnsB*/,arrayB_262144__input__0,output__input__3); // transpose_1
		cache_inv(arrayB_262144__input__0, 262144*sizeof(int));
		receiveStart(); // Core4 > Core3: splitTensorB_0__multiply3_0__0 
		receiveEnd(4); // Core4 > Core3: splitTensorB_0__multiply3_0__0 
		cache_inv(splitTensorB_0__multiply3_0__0, 131072*sizeof(char));
		splitB(512/*rowsB*/,512/*columnsB*/,output__input__3,output0__inputB__3,output1__inputB__6,output2__inputB__6,output3__inputB__0,output4__inputB__2,output5__inputB__0,output6__inputB__5,output7__inputB__1); // splitTensorB_1
		cache_inv(output__input__3, 262144*sizeof(int));
		cache_wbInv(splitTensorB_1__multiply7_1__0, 131072*sizeof(char));
		sendStart(7); // Core3 > Core7: splitTensorB_1__multiply7_1__0 
		sendEnd(); // Core3 > Core7: splitTensorB_1__multiply7_1__0 
		cache_wbInv(splitTensorB_1__multiply6_1__0, 131072*sizeof(char));
		sendStart(6); // Core3 > Core6: splitTensorB_1__multiply6_1__0 
		sendEnd(); // Core3 > Core6: splitTensorB_1__multiply6_1__0 
		cache_wbInv(splitTensorB_1__multiply5_1__0, 131072*sizeof(char));
		sendStart(5); // Core3 > Core5: splitTensorB_1__multiply5_1__0 
		sendEnd(); // Core3 > Core5: splitTensorB_1__multiply5_1__0 
		cache_wbInv(splitTensorB_1__multiply4_1__0, 131072*sizeof(char));
		sendStart(4); // Core3 > Core4: splitTensorB_1__multiply4_1__0 
		sendEnd(); // Core3 > Core4: splitTensorB_1__multiply4_1__0 
		cache_wbInv(splitTensorB_1__multiply2_1__0, 131072*sizeof(char));
		sendStart(2); // Core3 > Core2: splitTensorB_1__multiply2_1__0 
		sendEnd(); // Core3 > Core2: splitTensorB_1__multiply2_1__0 
		cache_wbInv(splitTensorB_1__multiply1_1__0, 131072*sizeof(char));
		sendStart(1); // Core3 > Core1: splitTensorB_1__multiply1_1__0 
		sendEnd(); // Core3 > Core1: splitTensorB_1__multiply1_1__0 
		cache_wbInv(splitTensorB_1__multiply0_1__0, 131072*sizeof(char));
		sendStart(0); // Core3 > Core0: splitTensorB_1__multiply0_1__0 
		sendEnd(); // Core3 > Core0: splitTensorB_1__multiply0_1__0 
		receiveStart(); // Core6 > Core3: splitTensorB_2__multiply3_2__0 
		receiveEnd(6); // Core6 > Core3: splitTensorB_2__multiply3_2__0 
		cache_inv(splitTensorB_2__multiply3_2__0, 131072*sizeof(char));
		receiveStart(); // Core5 > Core3: splitTensorB_3__multiply3_3__0 
		receiveEnd(5); // Core5 > Core3: splitTensorB_3__multiply3_3__0 
		cache_inv(splitTensorB_3__multiply3_3__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core3: splitTensorB_4__multiply3_4__0 
		receiveEnd(7); // Core7 > Core3: splitTensorB_4__multiply3_4__0 
		cache_inv(splitTensorB_4__multiply3_4__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core3: splitTensorB_5__multiply3_5__0 
		receiveEnd(0); // Core0 > Core3: splitTensorB_5__multiply3_5__0 
		cache_inv(splitTensorB_5__multiply3_5__0, 131072*sizeof(char));
		receiveStart(); // Core2 > Core3: splitTensorB_6__multiply3_6__0 
		receiveEnd(2); // Core2 > Core3: splitTensorB_6__multiply3_6__0 
		cache_inv(splitTensorB_6__multiply3_6__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core3: splitTensorB_7__multiply3_7__0 
		receiveEnd(1); // Core1 > Core3: splitTensorB_7__multiply3_7__0 
		cache_inv(splitTensorB_7__multiply3_7__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core3: multiply0_1__sum_1__0 
		receiveEnd(0); // Core0 > Core3: multiply0_1__sum_1__0 
		cache_inv(multiply0_1__sum_1__0, 1048576*sizeof(char));
		receiveStart(); // Core1 > Core3: multiply1_1__sum_1__0 
		receiveEnd(1); // Core1 > Core3: multiply1_1__sum_1__0 
		cache_inv(multiply1_1__sum_1__0, 1048576*sizeof(char));
		receiveStart(); // Core2 > Core3: multiply2_1__sum_1__0 
		receiveEnd(2); // Core2 > Core3: multiply2_1__sum_1__0 
		cache_inv(multiply2_1__sum_1__0, 1048576*sizeof(char));
		multiply(512/*rows*/,512/*columns*/,output3__inputA__0,output3__inputB__4,output__input3__0); // multiply3_0
		cache_inv(output3__inputA__0, 32768*sizeof(int));
		cache_inv(output3__inputB__4, 32768*sizeof(int));
		cache_wbInv(multiply3_0__sum_0__0, 1048576*sizeof(char));
		sendStart(4); // Core3 > Core4: multiply3_0__sum_0__0 
		sendEnd(); // Core3 > Core4: multiply3_0__sum_0__0 
		multiply(512/*rows*/,512/*columns*/,output3__inputA__1,output3__inputB__0,output__input3__5); // multiply3_1
		cache_inv(output3__inputA__1, 32768*sizeof(int));
		cache_inv(output3__inputB__0, 32768*sizeof(int));
		multiply(512/*rows*/,512/*columns*/,output3__inputA__6,output3__inputB__5,output__input3__7); // multiply3_2
		cache_inv(output3__inputA__6, 32768*sizeof(int));
		cache_inv(output3__inputB__5, 32768*sizeof(int));
		cache_wbInv(multiply3_2__sum_2__0, 1048576*sizeof(char));
		sendStart(2); // Core3 > Core2: multiply3_2__sum_2__0 
		sendEnd(); // Core3 > Core2: multiply3_2__sum_2__0 
		multiply(512/*rows*/,512/*columns*/,output3__inputA__5,output3__inputB__6,output__input3__2); // multiply3_3
		cache_inv(output3__inputA__5, 32768*sizeof(int));
		cache_inv(output3__inputB__6, 32768*sizeof(int));
		cache_wbInv(multiply3_3__sum_3__0, 1048576*sizeof(char));
		sendStart(5); // Core3 > Core5: multiply3_3__sum_3__0 
		sendEnd(); // Core3 > Core5: multiply3_3__sum_3__0 
		multiply(512/*rows*/,512/*columns*/,output3__inputA__4,output3__inputB__2,output__input3__6); // multiply3_4
		cache_inv(output3__inputA__4, 32768*sizeof(int));
		cache_inv(output3__inputB__2, 32768*sizeof(int));
		cache_wbInv(multiply3_4__sum_4__0, 1048576*sizeof(char));
		sendStart(0); // Core3 > Core0: multiply3_4__sum_4__0 
		sendEnd(); // Core3 > Core0: multiply3_4__sum_4__0 
		multiply(512/*rows*/,512/*columns*/,output3__inputA__7,output3__inputB__1,output__input3__3); // multiply3_5
		cache_inv(output3__inputA__7, 32768*sizeof(int));
		cache_inv(output3__inputB__1, 32768*sizeof(int));
		cache_wbInv(multiply3_5__sum_5__0, 1048576*sizeof(char));
		sendStart(4); // Core3 > Core4: multiply3_5__sum_5__0 
		sendEnd(); // Core3 > Core4: multiply3_5__sum_5__0 
		multiply(512/*rows*/,512/*columns*/,output3__inputA__2,output3__inputB__7,output__input3__4); // multiply3_6
		cache_inv(output3__inputA__2, 32768*sizeof(int));
		cache_inv(output3__inputB__7, 32768*sizeof(int));
		cache_wbInv(multiply3_6__sum_6__0, 1048576*sizeof(char));
		sendStart(1); // Core3 > Core1: multiply3_6__sum_6__0 
		sendEnd(); // Core3 > Core1: multiply3_6__sum_6__0 
		multiply(512/*rows*/,512/*columns*/,output3__inputA__3,output3__inputB__3,output__input3__1); // multiply3_7
		cache_inv(output3__inputA__3, 32768*sizeof(int));
		cache_inv(output3__inputB__3, 32768*sizeof(int));
		cache_wbInv(multiply3_7__sum_7__0, 1048576*sizeof(char));
		sendStart(7); // Core3 > Core7: multiply3_7__sum_7__0 
		sendEnd(); // Core3 > Core7: multiply3_7__sum_7__0 
		receiveStart(); // Core4 > Core3: multiply4_1__sum_1__0 
		receiveEnd(4); // Core4 > Core3: multiply4_1__sum_1__0 
		cache_inv(multiply4_1__sum_1__0, 1048576*sizeof(char));
		receiveStart(); // Core5 > Core3: multiply5_1__sum_1__0 
		receiveEnd(5); // Core5 > Core3: multiply5_1__sum_1__0 
		cache_inv(multiply5_1__sum_1__0, 1048576*sizeof(char));
		receiveStart(); // Core6 > Core3: multiply6_1__sum_1__0 
		receiveEnd(6); // Core6 > Core3: multiply6_1__sum_1__0 
		cache_inv(multiply6_1__sum_1__0, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core3: multiply7_1__sum_1__0 
		receiveEnd(7); // Core7 > Core3: multiply7_1__sum_1__0 
		cache_inv(multiply7_1__sum_1__0, 1048576*sizeof(char));
		sum(512/*rows*/,512/*columns*/,output__input0__7,output__input1__1,output__input2__6,output__input3__5,output__input4__6,output__input5__7,output__input6__3,output__input7__3,output__arrayC_262144__0); // sum_1
		cache_inv(output__input0__7, 262144*sizeof(long));
		cache_inv(output__input1__1, 262144*sizeof(long));
		cache_inv(output__input2__6, 262144*sizeof(long));
		cache_inv(output__input3__5, 262144*sizeof(long));
		cache_inv(output__input4__6, 262144*sizeof(long));
		cache_inv(output__input5__7, 262144*sizeof(long));
		cache_inv(output__input6__3, 262144*sizeof(long));
		cache_inv(output__input7__3, 262144*sizeof(long));
		cache_wbInv(sum_1__implode_displayResult__0, 1048576*sizeof(char));
		sendStart(7); // Core3 > Core7: sum_1__implode_displayResult__0 
		sendEnd(); // Core3 > Core7: sum_1__implode_displayResult__0 
	}
}
