/** 
 * @file Core6.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 17:17:02 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayA > splitTensorA_5 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayA > splitTensorA_2 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__15;  // explode_generateTensors_arrayB > transpose_2 size:= 1048576*char defined in Core0
extern char *const splitTensorA_0__multiply6_0__0;  // splitTensorA_0 > multiply6_0 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply6_1__0;  // splitTensorA_1 > multiply6_1 size:= 131072*char defined in Core0
extern int *const arrayA_524288__input__0;  // explode_generateTensors_arrayA_arrayA_524288 > splitTensorA_2_input size:= 262144*int defined in Core0
extern int *const output0__inputA__5;  // splitTensorA_2_output0 > multiply0_2_inputA size:= 32768*int defined in Core0
extern int *const output1__inputA__5;  // splitTensorA_2_output1 > multiply1_2_inputA size:= 32768*int defined in Core0
extern int *const output2__inputA__4;  // splitTensorA_2_output2 > multiply2_2_inputA size:= 32768*int defined in Core0
extern int *const output3__inputA__6;  // splitTensorA_2_output3 > multiply3_2_inputA size:= 32768*int defined in Core0
extern int *const output4__inputA__1;  // splitTensorA_2_output4 > multiply4_2_inputA size:= 32768*int defined in Core0
extern int *const output5__inputA__5;  // splitTensorA_2_output5 > multiply5_2_inputA size:= 32768*int defined in Core0
extern int *const output6__inputA__4;  // splitTensorA_2_output6 > multiply6_2_inputA size:= 32768*int defined in Core0
extern int *const output7__inputA__1;  // splitTensorA_2_output7 > multiply7_2_inputA size:= 32768*int defined in Core0
extern char *const splitTensorA_2__multiply7_2__0;  // splitTensorA_2 > multiply7_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply5_2__0;  // splitTensorA_2 > multiply5_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply4_2__0;  // splitTensorA_2 > multiply4_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply3_2__0;  // splitTensorA_2 > multiply3_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply2_2__0;  // splitTensorA_2 > multiply2_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply1_2__0;  // splitTensorA_2 > multiply1_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply0_2__0;  // splitTensorA_2 > multiply0_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply6_3__0;  // splitTensorA_3 > multiply6_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_4__multiply6_4__0;  // splitTensorA_4 > multiply6_4 size:= 131072*char defined in Core0
extern int *const arrayA_1310720__input__0;  // explode_generateTensors_arrayA_arrayA_1310720 > splitTensorA_5_input size:= 262144*int defined in Core0
extern int *const output0__inputA__4;  // splitTensorA_5_output0 > multiply0_5_inputA size:= 32768*int defined in Core0
extern int *const output1__inputA__1;  // splitTensorA_5_output1 > multiply1_5_inputA size:= 32768*int defined in Core0
extern int *const output2__inputA__0;  // splitTensorA_5_output2 > multiply2_5_inputA size:= 32768*int defined in Core0
extern int *const output3__inputA__7;  // splitTensorA_5_output3 > multiply3_5_inputA size:= 32768*int defined in Core0
extern int *const output4__inputA__0;  // splitTensorA_5_output4 > multiply4_5_inputA size:= 32768*int defined in Core0
extern int *const output5__inputA__1;  // splitTensorA_5_output5 > multiply5_5_inputA size:= 32768*int defined in Core0
extern int *const output6__inputA__1;  // splitTensorA_5_output6 > multiply6_5_inputA size:= 32768*int defined in Core0
extern int *const output7__inputA__4;  // splitTensorA_5_output7 > multiply7_5_inputA size:= 32768*int defined in Core0
extern char *const splitTensorA_5__multiply7_5__0;  // splitTensorA_5 > multiply7_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply5_5__0;  // splitTensorA_5 > multiply5_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply4_5__0;  // splitTensorA_5 > multiply4_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply3_5__0;  // splitTensorA_5 > multiply3_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply2_5__0;  // splitTensorA_5 > multiply2_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply1_5__0;  // splitTensorA_5 > multiply1_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply0_5__0;  // splitTensorA_5 > multiply0_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_6__multiply6_6__0;  // splitTensorA_6 > multiply6_6 size:= 131072*char defined in Core0
extern char *const splitTensorA_7__multiply6_7__0;  // splitTensorA_7 > multiply6_7 size:= 131072*char defined in Core0
extern int *const arrayB_524288__input__0;  // explode_generateTensors_arrayB_arrayB_524288 > transpose_2_input size:= 262144*int defined in Core0
extern int *const output__input__1;  // transpose_2_output > splitTensorB_2_input size:= 262144*int defined in Core0
extern char *const splitTensorB_0__multiply6_0__0;  // splitTensorB_0 > multiply6_0 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply6_1__0;  // splitTensorB_1 > multiply6_1 size:= 131072*char defined in Core0
extern int *const output0__inputB__0;  // splitTensorB_2_output0 > multiply0_2_inputB size:= 32768*int defined in Core0
extern int *const output1__inputB__5;  // splitTensorB_2_output1 > multiply1_2_inputB size:= 32768*int defined in Core0
extern int *const output2__inputB__0;  // splitTensorB_2_output2 > multiply2_2_inputB size:= 32768*int defined in Core0
extern int *const output3__inputB__5;  // splitTensorB_2_output3 > multiply3_2_inputB size:= 32768*int defined in Core0
extern int *const output4__inputB__4;  // splitTensorB_2_output4 > multiply4_2_inputB size:= 32768*int defined in Core0
extern int *const output5__inputB__5;  // splitTensorB_2_output5 > multiply5_2_inputB size:= 32768*int defined in Core0
extern int *const output6__inputB__0;  // splitTensorB_2_output6 > multiply6_2_inputB size:= 32768*int defined in Core0
extern int *const output7__inputB__3;  // splitTensorB_2_output7 > multiply7_2_inputB size:= 32768*int defined in Core0
extern char *const splitTensorB_2__multiply7_2__0;  // splitTensorB_2 > multiply7_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply5_2__0;  // splitTensorB_2 > multiply5_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply4_2__0;  // splitTensorB_2 > multiply4_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply3_2__0;  // splitTensorB_2 > multiply3_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply2_2__0;  // splitTensorB_2 > multiply2_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply1_2__0;  // splitTensorB_2 > multiply1_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply0_2__0;  // splitTensorB_2 > multiply0_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply6_3__0;  // splitTensorB_3 > multiply6_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_4__multiply6_4__0;  // splitTensorB_4 > multiply6_4 size:= 131072*char defined in Core0
extern char *const splitTensorB_5__multiply6_5__0;  // splitTensorB_5 > multiply6_5 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply6_6__0;  // splitTensorB_6 > multiply6_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_7__multiply6_7__0;  // splitTensorB_7 > multiply6_7 size:= 131072*char defined in Core0
extern int *const output6__inputA__2;  // splitTensorA_0_output6 > multiply6_0_inputA size:= 32768*int defined in Core0
extern int *const output6__inputB__1;  // splitTensorB_0_output6 > multiply6_0_inputB size:= 32768*int defined in Core0
extern long *const output__input6__7;  // multiply6_0_output > sum_0_input6 size:= 262144*long defined in Core0
extern char *const multiply6_0__sum_0__0;  // multiply6_0 > sum_0 size:= 1048576*char defined in Core0
extern int *const output6__inputA__6;  // splitTensorA_1_output6 > multiply6_1_inputA size:= 32768*int defined in Core0
extern int *const output6__inputB__5;  // splitTensorB_1_output6 > multiply6_1_inputB size:= 32768*int defined in Core0
extern long *const output__input6__3;  // multiply6_1_output > sum_1_input6 size:= 262144*long defined in Core0
extern char *const multiply6_1__sum_1__0;  // multiply6_1 > sum_1 size:= 1048576*char defined in Core0
extern long *const output__input6__5;  // multiply6_2_output > sum_2_input6 size:= 262144*long defined in Core0
extern char *const multiply6_2__sum_2__0;  // multiply6_2 > sum_2 size:= 1048576*char defined in Core0
extern int *const output6__inputA__3;  // splitTensorA_3_output6 > multiply6_3_inputA size:= 32768*int defined in Core0
extern int *const output6__inputB__7;  // splitTensorB_3_output6 > multiply6_3_inputB size:= 32768*int defined in Core0
extern long *const output__input6__2;  // multiply6_3_output > sum_3_input6 size:= 262144*long defined in Core0
extern char *const multiply6_3__sum_3__0;  // multiply6_3 > sum_3 size:= 1048576*char defined in Core0
extern int *const output6__inputA__0;  // splitTensorA_4_output6 > multiply6_4_inputA size:= 32768*int defined in Core0
extern int *const output6__inputB__2;  // splitTensorB_4_output6 > multiply6_4_inputB size:= 32768*int defined in Core0
extern long *const output__input6__6;  // multiply6_4_output > sum_4_input6 size:= 262144*long defined in Core0
extern char *const multiply6_4__sum_4__0;  // multiply6_4 > sum_4 size:= 1048576*char defined in Core0
extern int *const output6__inputB__3;  // splitTensorB_5_output6 > multiply6_5_inputB size:= 32768*int defined in Core0
extern long *const output__input6__0;  // multiply6_5_output > sum_5_input6 size:= 262144*long defined in Core0
extern char *const multiply6_5__sum_5__0;  // multiply6_5 > sum_5 size:= 1048576*char defined in Core0
extern int *const output6__inputA__5;  // splitTensorA_6_output6 > multiply6_6_inputA size:= 32768*int defined in Core0
extern int *const output6__inputB__6;  // splitTensorB_6_output6 > multiply6_6_inputB size:= 32768*int defined in Core0
extern long *const output__input6__4;  // multiply6_6_output > sum_6_input6 size:= 262144*long defined in Core0
extern char *const multiply6_6__sum_6__0;  // multiply6_6 > sum_6 size:= 1048576*char defined in Core0
extern int *const output6__inputA__7;  // splitTensorA_7_output6 > multiply6_7_inputA size:= 32768*int defined in Core0
extern int *const output6__inputB__4;  // splitTensorB_7_output6 > multiply6_7_inputB size:= 32768*int defined in Core0
extern long *const output__input6__1;  // multiply6_7_output > sum_7_input6 size:= 262144*long defined in Core0
extern char *const multiply6_7__sum_7__0;  // multiply6_7 > sum_7 size:= 1048576*char defined in Core0

// Core Global Definitions

void core6(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core6: explode_generateTensors_arra__6 
		receiveEnd(0); // Core0 > Core6: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 1048576*sizeof(char));
		receiveStart(); // Core0 > Core6: explode_generateTensors_arra__13 
		receiveEnd(0); // Core0 > Core6: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__15 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__15 
		cache_inv(explode_generateTensors_arra__15, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core6: splitTensorA_0__multiply6_0__0 
		receiveEnd(4); // Core4 > Core6: splitTensorA_0__multiply6_0__0 
		cache_inv(splitTensorA_0__multiply6_0__0, 131072*sizeof(char));
		receiveStart(); // Core2 > Core6: splitTensorA_1__multiply6_1__0 
		receiveEnd(2); // Core2 > Core6: splitTensorA_1__multiply6_1__0 
		cache_inv(splitTensorA_1__multiply6_1__0, 131072*sizeof(char));
		splitA(512/*rowsA*/,512/*columnsA*/,arrayA_524288__input__0,output0__inputA__5,output1__inputA__5,output2__inputA__4,output3__inputA__6,output4__inputA__1,output5__inputA__5,output6__inputA__4,output7__inputA__1); // splitTensorA_2
		cache_inv(arrayA_524288__input__0, 262144*sizeof(int));
		cache_wbInv(splitTensorA_2__multiply7_2__0, 131072*sizeof(char));
		sendStart(7); // Core6 > Core7: splitTensorA_2__multiply7_2__0 
		sendEnd(); // Core6 > Core7: splitTensorA_2__multiply7_2__0 
		cache_wbInv(splitTensorA_2__multiply5_2__0, 131072*sizeof(char));
		sendStart(5); // Core6 > Core5: splitTensorA_2__multiply5_2__0 
		sendEnd(); // Core6 > Core5: splitTensorA_2__multiply5_2__0 
		cache_wbInv(splitTensorA_2__multiply4_2__0, 131072*sizeof(char));
		sendStart(4); // Core6 > Core4: splitTensorA_2__multiply4_2__0 
		sendEnd(); // Core6 > Core4: splitTensorA_2__multiply4_2__0 
		cache_wbInv(splitTensorA_2__multiply3_2__0, 131072*sizeof(char));
		sendStart(3); // Core6 > Core3: splitTensorA_2__multiply3_2__0 
		sendEnd(); // Core6 > Core3: splitTensorA_2__multiply3_2__0 
		cache_wbInv(splitTensorA_2__multiply2_2__0, 131072*sizeof(char));
		sendStart(2); // Core6 > Core2: splitTensorA_2__multiply2_2__0 
		sendEnd(); // Core6 > Core2: splitTensorA_2__multiply2_2__0 
		cache_wbInv(splitTensorA_2__multiply1_2__0, 131072*sizeof(char));
		sendStart(1); // Core6 > Core1: splitTensorA_2__multiply1_2__0 
		sendEnd(); // Core6 > Core1: splitTensorA_2__multiply1_2__0 
		cache_wbInv(splitTensorA_2__multiply0_2__0, 131072*sizeof(char));
		sendStart(0); // Core6 > Core0: splitTensorA_2__multiply0_2__0 
		sendEnd(); // Core6 > Core0: splitTensorA_2__multiply0_2__0 
		receiveStart(); // Core5 > Core6: splitTensorA_3__multiply6_3__0 
		receiveEnd(5); // Core5 > Core6: splitTensorA_3__multiply6_3__0 
		cache_inv(splitTensorA_3__multiply6_3__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core6: splitTensorA_4__multiply6_4__0 
		receiveEnd(0); // Core0 > Core6: splitTensorA_4__multiply6_4__0 
		cache_inv(splitTensorA_4__multiply6_4__0, 131072*sizeof(char));
		splitA(512/*rowsA*/,512/*columnsA*/,arrayA_1310720__input__0,output0__inputA__4,output1__inputA__1,output2__inputA__0,output3__inputA__7,output4__inputA__0,output5__inputA__1,output6__inputA__1,output7__inputA__4); // splitTensorA_5
		cache_inv(arrayA_1310720__input__0, 262144*sizeof(int));
		cache_wbInv(splitTensorA_5__multiply7_5__0, 131072*sizeof(char));
		sendStart(7); // Core6 > Core7: splitTensorA_5__multiply7_5__0 
		sendEnd(); // Core6 > Core7: splitTensorA_5__multiply7_5__0 
		cache_wbInv(splitTensorA_5__multiply5_5__0, 131072*sizeof(char));
		sendStart(5); // Core6 > Core5: splitTensorA_5__multiply5_5__0 
		sendEnd(); // Core6 > Core5: splitTensorA_5__multiply5_5__0 
		cache_wbInv(splitTensorA_5__multiply4_5__0, 131072*sizeof(char));
		sendStart(4); // Core6 > Core4: splitTensorA_5__multiply4_5__0 
		sendEnd(); // Core6 > Core4: splitTensorA_5__multiply4_5__0 
		cache_wbInv(splitTensorA_5__multiply3_5__0, 131072*sizeof(char));
		sendStart(3); // Core6 > Core3: splitTensorA_5__multiply3_5__0 
		sendEnd(); // Core6 > Core3: splitTensorA_5__multiply3_5__0 
		cache_wbInv(splitTensorA_5__multiply2_5__0, 131072*sizeof(char));
		sendStart(2); // Core6 > Core2: splitTensorA_5__multiply2_5__0 
		sendEnd(); // Core6 > Core2: splitTensorA_5__multiply2_5__0 
		cache_wbInv(splitTensorA_5__multiply1_5__0, 131072*sizeof(char));
		sendStart(1); // Core6 > Core1: splitTensorA_5__multiply1_5__0 
		sendEnd(); // Core6 > Core1: splitTensorA_5__multiply1_5__0 
		cache_wbInv(splitTensorA_5__multiply0_5__0, 131072*sizeof(char));
		sendStart(0); // Core6 > Core0: splitTensorA_5__multiply0_5__0 
		sendEnd(); // Core6 > Core0: splitTensorA_5__multiply0_5__0 
		receiveStart(); // Core1 > Core6: splitTensorA_6__multiply6_6__0 
		receiveEnd(1); // Core1 > Core6: splitTensorA_6__multiply6_6__0 
		cache_inv(splitTensorA_6__multiply6_6__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core6: splitTensorA_7__multiply6_7__0 
		receiveEnd(7); // Core7 > Core6: splitTensorA_7__multiply6_7__0 
		cache_inv(splitTensorA_7__multiply6_7__0, 131072*sizeof(char));
		transpose(512/*rowsB*/,512/*columnsB*/,arrayB_524288__input__0,output__input__1); // transpose_2
		cache_inv(arrayB_524288__input__0, 262144*sizeof(int));
		receiveStart(); // Core4 > Core6: splitTensorB_0__multiply6_0__0 
		receiveEnd(4); // Core4 > Core6: splitTensorB_0__multiply6_0__0 
		cache_inv(splitTensorB_0__multiply6_0__0, 131072*sizeof(char));
		receiveStart(); // Core3 > Core6: splitTensorB_1__multiply6_1__0 
		receiveEnd(3); // Core3 > Core6: splitTensorB_1__multiply6_1__0 
		cache_inv(splitTensorB_1__multiply6_1__0, 131072*sizeof(char));
		splitB(512/*rowsB*/,512/*columnsB*/,output__input__1,output0__inputB__0,output1__inputB__5,output2__inputB__0,output3__inputB__5,output4__inputB__4,output5__inputB__5,output6__inputB__0,output7__inputB__3); // splitTensorB_2
		cache_inv(output__input__1, 262144*sizeof(int));
		cache_wbInv(splitTensorB_2__multiply7_2__0, 131072*sizeof(char));
		sendStart(7); // Core6 > Core7: splitTensorB_2__multiply7_2__0 
		sendEnd(); // Core6 > Core7: splitTensorB_2__multiply7_2__0 
		cache_wbInv(splitTensorB_2__multiply5_2__0, 131072*sizeof(char));
		sendStart(5); // Core6 > Core5: splitTensorB_2__multiply5_2__0 
		sendEnd(); // Core6 > Core5: splitTensorB_2__multiply5_2__0 
		cache_wbInv(splitTensorB_2__multiply4_2__0, 131072*sizeof(char));
		sendStart(4); // Core6 > Core4: splitTensorB_2__multiply4_2__0 
		sendEnd(); // Core6 > Core4: splitTensorB_2__multiply4_2__0 
		cache_wbInv(splitTensorB_2__multiply3_2__0, 131072*sizeof(char));
		sendStart(3); // Core6 > Core3: splitTensorB_2__multiply3_2__0 
		sendEnd(); // Core6 > Core3: splitTensorB_2__multiply3_2__0 
		cache_wbInv(splitTensorB_2__multiply2_2__0, 131072*sizeof(char));
		sendStart(2); // Core6 > Core2: splitTensorB_2__multiply2_2__0 
		sendEnd(); // Core6 > Core2: splitTensorB_2__multiply2_2__0 
		cache_wbInv(splitTensorB_2__multiply1_2__0, 131072*sizeof(char));
		sendStart(1); // Core6 > Core1: splitTensorB_2__multiply1_2__0 
		sendEnd(); // Core6 > Core1: splitTensorB_2__multiply1_2__0 
		cache_wbInv(splitTensorB_2__multiply0_2__0, 131072*sizeof(char));
		sendStart(0); // Core6 > Core0: splitTensorB_2__multiply0_2__0 
		sendEnd(); // Core6 > Core0: splitTensorB_2__multiply0_2__0 
		receiveStart(); // Core5 > Core6: splitTensorB_3__multiply6_3__0 
		receiveEnd(5); // Core5 > Core6: splitTensorB_3__multiply6_3__0 
		cache_inv(splitTensorB_3__multiply6_3__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core6: splitTensorB_4__multiply6_4__0 
		receiveEnd(7); // Core7 > Core6: splitTensorB_4__multiply6_4__0 
		cache_inv(splitTensorB_4__multiply6_4__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core6: splitTensorB_5__multiply6_5__0 
		receiveEnd(0); // Core0 > Core6: splitTensorB_5__multiply6_5__0 
		cache_inv(splitTensorB_5__multiply6_5__0, 131072*sizeof(char));
		receiveStart(); // Core2 > Core6: splitTensorB_6__multiply6_6__0 
		receiveEnd(2); // Core2 > Core6: splitTensorB_6__multiply6_6__0 
		cache_inv(splitTensorB_6__multiply6_6__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core6: splitTensorB_7__multiply6_7__0 
		receiveEnd(1); // Core1 > Core6: splitTensorB_7__multiply6_7__0 
		cache_inv(splitTensorB_7__multiply6_7__0, 131072*sizeof(char));
		multiply(512/*rows*/,512/*columns*/,output6__inputA__2,output6__inputB__1,output__input6__7); // multiply6_0
		cache_inv(output6__inputA__2, 32768*sizeof(int));
		cache_inv(output6__inputB__1, 32768*sizeof(int));
		cache_wbInv(multiply6_0__sum_0__0, 1048576*sizeof(char));
		sendStart(4); // Core6 > Core4: multiply6_0__sum_0__0 
		sendEnd(); // Core6 > Core4: multiply6_0__sum_0__0 
		multiply(512/*rows*/,512/*columns*/,output6__inputA__6,output6__inputB__5,output__input6__3); // multiply6_1
		cache_inv(output6__inputA__6, 32768*sizeof(int));
		cache_inv(output6__inputB__5, 32768*sizeof(int));
		cache_wbInv(multiply6_1__sum_1__0, 1048576*sizeof(char));
		sendStart(3); // Core6 > Core3: multiply6_1__sum_1__0 
		sendEnd(); // Core6 > Core3: multiply6_1__sum_1__0 
		multiply(512/*rows*/,512/*columns*/,output6__inputA__4,output6__inputB__0,output__input6__5); // multiply6_2
		cache_inv(output6__inputA__4, 32768*sizeof(int));
		cache_inv(output6__inputB__0, 32768*sizeof(int));
		cache_wbInv(multiply6_2__sum_2__0, 1048576*sizeof(char));
		sendStart(2); // Core6 > Core2: multiply6_2__sum_2__0 
		sendEnd(); // Core6 > Core2: multiply6_2__sum_2__0 
		multiply(512/*rows*/,512/*columns*/,output6__inputA__3,output6__inputB__7,output__input6__2); // multiply6_3
		cache_inv(output6__inputA__3, 32768*sizeof(int));
		cache_inv(output6__inputB__7, 32768*sizeof(int));
		cache_wbInv(multiply6_3__sum_3__0, 1048576*sizeof(char));
		sendStart(5); // Core6 > Core5: multiply6_3__sum_3__0 
		sendEnd(); // Core6 > Core5: multiply6_3__sum_3__0 
		multiply(512/*rows*/,512/*columns*/,output6__inputA__0,output6__inputB__2,output__input6__6); // multiply6_4
		cache_inv(output6__inputA__0, 32768*sizeof(int));
		cache_inv(output6__inputB__2, 32768*sizeof(int));
		cache_wbInv(multiply6_4__sum_4__0, 1048576*sizeof(char));
		sendStart(0); // Core6 > Core0: multiply6_4__sum_4__0 
		sendEnd(); // Core6 > Core0: multiply6_4__sum_4__0 
		multiply(512/*rows*/,512/*columns*/,output6__inputA__1,output6__inputB__3,output__input6__0); // multiply6_5
		cache_inv(output6__inputA__1, 32768*sizeof(int));
		cache_inv(output6__inputB__3, 32768*sizeof(int));
		cache_wbInv(multiply6_5__sum_5__0, 1048576*sizeof(char));
		sendStart(4); // Core6 > Core4: multiply6_5__sum_5__0 
		sendEnd(); // Core6 > Core4: multiply6_5__sum_5__0 
		multiply(512/*rows*/,512/*columns*/,output6__inputA__5,output6__inputB__6,output__input6__4); // multiply6_6
		cache_inv(output6__inputA__5, 32768*sizeof(int));
		cache_inv(output6__inputB__6, 32768*sizeof(int));
		cache_wbInv(multiply6_6__sum_6__0, 1048576*sizeof(char));
		sendStart(1); // Core6 > Core1: multiply6_6__sum_6__0 
		sendEnd(); // Core6 > Core1: multiply6_6__sum_6__0 
		multiply(512/*rows*/,512/*columns*/,output6__inputA__7,output6__inputB__4,output__input6__1); // multiply6_7
		cache_inv(output6__inputA__7, 32768*sizeof(int));
		cache_inv(output6__inputB__4, 32768*sizeof(int));
		cache_wbInv(multiply6_7__sum_7__0, 1048576*sizeof(char));
		sendStart(7); // Core6 > Core7: multiply6_7__sum_7__0 
		sendEnd(); // Core6 > Core7: multiply6_7__sum_7__0 
	}
}
