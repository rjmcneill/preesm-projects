/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 17:17:02 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__0;  // explode_generateTensors_arrayA > splitTensorA_1 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__2;  // explode_generateTensors_arrayB > transpose_6 size:= 1048576*char defined in Core0
extern char *const splitTensorA_0__multiply2_0__0;  // splitTensorA_0 > multiply2_0 size:= 131072*char defined in Core0
extern int *const arrayA_262144__input__0;  // explode_generateTensors_arrayA_arrayA_262144 > splitTensorA_1_input size:= 262144*int defined in Core0
extern int *const output0__inputA__3;  // splitTensorA_1_output0 > multiply0_1_inputA size:= 32768*int defined in Core0
extern int *const output1__inputA__7;  // splitTensorA_1_output1 > multiply1_1_inputA size:= 32768*int defined in Core0
extern int *const output2__inputA__1;  // splitTensorA_1_output2 > multiply2_1_inputA size:= 32768*int defined in Core0
extern int *const output3__inputA__1;  // splitTensorA_1_output3 > multiply3_1_inputA size:= 32768*int defined in Core0
extern int *const output4__inputA__5;  // splitTensorA_1_output4 > multiply4_1_inputA size:= 32768*int defined in Core0
extern int *const output5__inputA__7;  // splitTensorA_1_output5 > multiply5_1_inputA size:= 32768*int defined in Core0
extern int *const output6__inputA__6;  // splitTensorA_1_output6 > multiply6_1_inputA size:= 32768*int defined in Core0
extern int *const output7__inputA__2;  // splitTensorA_1_output7 > multiply7_1_inputA size:= 32768*int defined in Core0
extern char *const splitTensorA_1__multiply7_1__0;  // splitTensorA_1 > multiply7_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply6_1__0;  // splitTensorA_1 > multiply6_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply5_1__0;  // splitTensorA_1 > multiply5_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply4_1__0;  // splitTensorA_1 > multiply4_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply3_1__0;  // splitTensorA_1 > multiply3_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply1_1__0;  // splitTensorA_1 > multiply1_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_1__multiply0_1__0;  // splitTensorA_1 > multiply0_1 size:= 131072*char defined in Core0
extern char *const splitTensorA_2__multiply2_2__0;  // splitTensorA_2 > multiply2_2 size:= 131072*char defined in Core0
extern char *const splitTensorA_3__multiply2_3__0;  // splitTensorA_3 > multiply2_3 size:= 131072*char defined in Core0
extern char *const splitTensorA_4__multiply2_4__0;  // splitTensorA_4 > multiply2_4 size:= 131072*char defined in Core0
extern char *const splitTensorA_5__multiply2_5__0;  // splitTensorA_5 > multiply2_5 size:= 131072*char defined in Core0
extern char *const splitTensorA_6__multiply2_6__0;  // splitTensorA_6 > multiply2_6 size:= 131072*char defined in Core0
extern char *const splitTensorA_7__multiply2_7__0;  // splitTensorA_7 > multiply2_7 size:= 131072*char defined in Core0
extern int *const arrayB_1572864__input__0;  // explode_generateTensors_arrayB_arrayB_1572864 > transpose_6_input size:= 262144*int defined in Core0
extern int *const output__input__6;  // transpose_6_output > splitTensorB_6_input size:= 262144*int defined in Core0
extern char *const splitTensorB_0__multiply2_0__0;  // splitTensorB_0 > multiply2_0 size:= 131072*char defined in Core0
extern char *const splitTensorB_1__multiply2_1__0;  // splitTensorB_1 > multiply2_1 size:= 131072*char defined in Core0
extern char *const splitTensorB_2__multiply2_2__0;  // splitTensorB_2 > multiply2_2 size:= 131072*char defined in Core0
extern char *const splitTensorB_3__multiply2_3__0;  // splitTensorB_3 > multiply2_3 size:= 131072*char defined in Core0
extern char *const splitTensorB_4__multiply2_4__0;  // splitTensorB_4 > multiply2_4 size:= 131072*char defined in Core0
extern char *const splitTensorB_5__multiply2_5__0;  // splitTensorB_5 > multiply2_5 size:= 131072*char defined in Core0
extern int *const output0__inputB__7;  // splitTensorB_6_output0 > multiply0_6_inputB size:= 32768*int defined in Core0
extern int *const output1__inputB__7;  // splitTensorB_6_output1 > multiply1_6_inputB size:= 32768*int defined in Core0
extern int *const output2__inputB__5;  // splitTensorB_6_output2 > multiply2_6_inputB size:= 32768*int defined in Core0
extern int *const output3__inputB__7;  // splitTensorB_6_output3 > multiply3_6_inputB size:= 32768*int defined in Core0
extern int *const output4__inputB__0;  // splitTensorB_6_output4 > multiply4_6_inputB size:= 32768*int defined in Core0
extern int *const output5__inputB__6;  // splitTensorB_6_output5 > multiply5_6_inputB size:= 32768*int defined in Core0
extern int *const output6__inputB__6;  // splitTensorB_6_output6 > multiply6_6_inputB size:= 32768*int defined in Core0
extern int *const output7__inputB__7;  // splitTensorB_6_output7 > multiply7_6_inputB size:= 32768*int defined in Core0
extern char *const splitTensorB_6__multiply7_6__0;  // splitTensorB_6 > multiply7_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply6_6__0;  // splitTensorB_6 > multiply6_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply5_6__0;  // splitTensorB_6 > multiply5_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply4_6__0;  // splitTensorB_6 > multiply4_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply3_6__0;  // splitTensorB_6 > multiply3_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply1_6__0;  // splitTensorB_6 > multiply1_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_6__multiply0_6__0;  // splitTensorB_6 > multiply0_6 size:= 131072*char defined in Core0
extern char *const splitTensorB_7__multiply2_7__0;  // splitTensorB_7 > multiply2_7 size:= 131072*char defined in Core0
extern char *const multiply0_2__sum_2__0;  // multiply0_2 > sum_2 size:= 1048576*char defined in Core0
extern char *const multiply1_2__sum_2__0;  // multiply1_2 > sum_2 size:= 1048576*char defined in Core0
extern int *const output2__inputA__3;  // splitTensorA_0_output2 > multiply2_0_inputA size:= 32768*int defined in Core0
extern int *const output2__inputB__3;  // splitTensorB_0_output2 > multiply2_0_inputB size:= 32768*int defined in Core0
extern long *const output__input2__0;  // multiply2_0_output > sum_0_input2 size:= 262144*long defined in Core0
extern char *const multiply2_0__sum_0__0;  // multiply2_0 > sum_0 size:= 1048576*char defined in Core0
extern int *const output2__inputB__6;  // splitTensorB_1_output2 > multiply2_1_inputB size:= 32768*int defined in Core0
extern long *const output__input2__6;  // multiply2_1_output > sum_1_input2 size:= 262144*long defined in Core0
extern char *const multiply2_1__sum_1__0;  // multiply2_1 > sum_1 size:= 1048576*char defined in Core0
extern int *const output2__inputA__4;  // splitTensorA_2_output2 > multiply2_2_inputA size:= 32768*int defined in Core0
extern int *const output2__inputB__0;  // splitTensorB_2_output2 > multiply2_2_inputB size:= 32768*int defined in Core0
extern long *const output__input2__2;  // multiply2_2_output > sum_2_input2 size:= 262144*long defined in Core0
extern int *const output2__inputA__5;  // splitTensorA_3_output2 > multiply2_3_inputA size:= 32768*int defined in Core0
extern int *const output2__inputB__4;  // splitTensorB_3_output2 > multiply2_3_inputB size:= 32768*int defined in Core0
extern long *const output__input2__1;  // multiply2_3_output > sum_3_input2 size:= 262144*long defined in Core0
extern char *const multiply2_3__sum_3__0;  // multiply2_3 > sum_3 size:= 1048576*char defined in Core0
extern int *const output2__inputA__2;  // splitTensorA_4_output2 > multiply2_4_inputA size:= 32768*int defined in Core0
extern int *const output2__inputB__2;  // splitTensorB_4_output2 > multiply2_4_inputB size:= 32768*int defined in Core0
extern long *const output__input2__7;  // multiply2_4_output > sum_4_input2 size:= 262144*long defined in Core0
extern char *const multiply2_4__sum_4__0;  // multiply2_4 > sum_4 size:= 1048576*char defined in Core0
extern int *const output2__inputA__0;  // splitTensorA_5_output2 > multiply2_5_inputA size:= 32768*int defined in Core0
extern int *const output2__inputB__1;  // splitTensorB_5_output2 > multiply2_5_inputB size:= 32768*int defined in Core0
extern long *const output__input2__4;  // multiply2_5_output > sum_5_input2 size:= 262144*long defined in Core0
extern char *const multiply2_5__sum_5__0;  // multiply2_5 > sum_5 size:= 1048576*char defined in Core0
extern int *const output2__inputA__7;  // splitTensorA_6_output2 > multiply2_6_inputA size:= 32768*int defined in Core0
extern long *const output__input2__3;  // multiply2_6_output > sum_6_input2 size:= 262144*long defined in Core0
extern char *const multiply2_6__sum_6__0;  // multiply2_6 > sum_6 size:= 1048576*char defined in Core0
extern int *const output2__inputA__6;  // splitTensorA_7_output2 > multiply2_7_inputA size:= 32768*int defined in Core0
extern int *const output2__inputB__7;  // splitTensorB_7_output2 > multiply2_7_inputB size:= 32768*int defined in Core0
extern long *const output__input2__5;  // multiply2_7_output > sum_7_input2 size:= 262144*long defined in Core0
extern char *const multiply2_7__sum_7__0;  // multiply2_7 > sum_7 size:= 1048576*char defined in Core0
extern char *const multiply3_2__sum_2__0;  // multiply3_2 > sum_2 size:= 1048576*char defined in Core0
extern char *const multiply4_2__sum_2__0;  // multiply4_2 > sum_2 size:= 1048576*char defined in Core0
extern char *const multiply5_2__sum_2__0;  // multiply5_2 > sum_2 size:= 1048576*char defined in Core0
extern char *const multiply6_2__sum_2__0;  // multiply6_2 > sum_2 size:= 1048576*char defined in Core0
extern char *const multiply7_2__sum_2__0;  // multiply7_2 > sum_2 size:= 1048576*char defined in Core0
extern long *const output__input0__6;  // multiply0_2_output > sum_2_input0 size:= 262144*long defined in Core0
extern long *const output__input1__7;  // multiply1_2_output > sum_2_input1 size:= 262144*long defined in Core0
extern long *const output__input3__7;  // multiply3_2_output > sum_2_input3 size:= 262144*long defined in Core0
extern long *const output__input4__1;  // multiply4_2_output > sum_2_input4 size:= 262144*long defined in Core0
extern long *const output__input5__0;  // multiply5_2_output > sum_2_input5 size:= 262144*long defined in Core0
extern long *const output__input6__5;  // multiply6_2_output > sum_2_input6 size:= 262144*long defined in Core0
extern long *const output__input7__0;  // multiply7_2_output > sum_2_input7 size:= 262144*long defined in Core0
extern long *const output__arrayC_524288__0;  // sum_2_output > implode_displayResult_arrayC_arrayC_524288 size:= 262144*long defined in Core0
extern char *const sum_2__implode_displayResult__0;  // sum_2 > implode_displayResult_arrayC size:= 1048576*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__0 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__0 
		cache_inv(explode_generateTensors_arra__0, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__2 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__2 
		cache_inv(explode_generateTensors_arra__2, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorA_0__multiply2_0__0 
		receiveEnd(4); // Core4 > Core2: splitTensorA_0__multiply2_0__0 
		cache_inv(splitTensorA_0__multiply2_0__0, 131072*sizeof(char));
		splitA(512/*rowsA*/,512/*columnsA*/,arrayA_262144__input__0,output0__inputA__3,output1__inputA__7,output2__inputA__1,output3__inputA__1,output4__inputA__5,output5__inputA__7,output6__inputA__6,output7__inputA__2); // splitTensorA_1
		cache_inv(arrayA_262144__input__0, 262144*sizeof(int));
		cache_wbInv(splitTensorA_1__multiply7_1__0, 131072*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorA_1__multiply7_1__0 
		sendEnd(); // Core2 > Core7: splitTensorA_1__multiply7_1__0 
		cache_wbInv(splitTensorA_1__multiply6_1__0, 131072*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorA_1__multiply6_1__0 
		sendEnd(); // Core2 > Core6: splitTensorA_1__multiply6_1__0 
		cache_wbInv(splitTensorA_1__multiply5_1__0, 131072*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorA_1__multiply5_1__0 
		sendEnd(); // Core2 > Core5: splitTensorA_1__multiply5_1__0 
		cache_wbInv(splitTensorA_1__multiply4_1__0, 131072*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorA_1__multiply4_1__0 
		sendEnd(); // Core2 > Core4: splitTensorA_1__multiply4_1__0 
		cache_wbInv(splitTensorA_1__multiply3_1__0, 131072*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorA_1__multiply3_1__0 
		sendEnd(); // Core2 > Core3: splitTensorA_1__multiply3_1__0 
		cache_wbInv(splitTensorA_1__multiply1_1__0, 131072*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorA_1__multiply1_1__0 
		sendEnd(); // Core2 > Core1: splitTensorA_1__multiply1_1__0 
		cache_wbInv(splitTensorA_1__multiply0_1__0, 131072*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorA_1__multiply0_1__0 
		sendEnd(); // Core2 > Core0: splitTensorA_1__multiply0_1__0 
		receiveStart(); // Core6 > Core2: splitTensorA_2__multiply2_2__0 
		receiveEnd(6); // Core6 > Core2: splitTensorA_2__multiply2_2__0 
		cache_inv(splitTensorA_2__multiply2_2__0, 131072*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_3__multiply2_3__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_3__multiply2_3__0 
		cache_inv(splitTensorA_3__multiply2_3__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorA_4__multiply2_4__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_4__multiply2_4__0 
		cache_inv(splitTensorA_4__multiply2_4__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorA_5__multiply2_5__0 
		receiveEnd(6); // Core6 > Core2: splitTensorA_5__multiply2_5__0 
		cache_inv(splitTensorA_5__multiply2_5__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorA_6__multiply2_6__0 
		receiveEnd(1); // Core1 > Core2: splitTensorA_6__multiply2_6__0 
		cache_inv(splitTensorA_6__multiply2_6__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorA_7__multiply2_7__0 
		receiveEnd(7); // Core7 > Core2: splitTensorA_7__multiply2_7__0 
		cache_inv(splitTensorA_7__multiply2_7__0, 131072*sizeof(char));
		transpose(512/*rowsB*/,512/*columnsB*/,arrayB_1572864__input__0,output__input__6); // transpose_6
		cache_inv(arrayB_1572864__input__0, 262144*sizeof(int));
		receiveStart(); // Core4 > Core2: splitTensorB_0__multiply2_0__0 
		receiveEnd(4); // Core4 > Core2: splitTensorB_0__multiply2_0__0 
		cache_inv(splitTensorB_0__multiply2_0__0, 131072*sizeof(char));
		receiveStart(); // Core3 > Core2: splitTensorB_1__multiply2_1__0 
		receiveEnd(3); // Core3 > Core2: splitTensorB_1__multiply2_1__0 
		cache_inv(splitTensorB_1__multiply2_1__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorB_2__multiply2_2__0 
		receiveEnd(6); // Core6 > Core2: splitTensorB_2__multiply2_2__0 
		cache_inv(splitTensorB_2__multiply2_2__0, 131072*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorB_3__multiply2_3__0 
		receiveEnd(5); // Core5 > Core2: splitTensorB_3__multiply2_3__0 
		cache_inv(splitTensorB_3__multiply2_3__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_4__multiply2_4__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_4__multiply2_4__0 
		cache_inv(splitTensorB_4__multiply2_4__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorB_5__multiply2_5__0 
		receiveEnd(0); // Core0 > Core2: splitTensorB_5__multiply2_5__0 
		cache_inv(splitTensorB_5__multiply2_5__0, 131072*sizeof(char));
		splitB(512/*rowsB*/,512/*columnsB*/,output__input__6,output0__inputB__7,output1__inputB__7,output2__inputB__5,output3__inputB__7,output4__inputB__0,output5__inputB__6,output6__inputB__6,output7__inputB__7); // splitTensorB_6
		cache_inv(output__input__6, 262144*sizeof(int));
		cache_wbInv(splitTensorB_6__multiply7_6__0, 131072*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorB_6__multiply7_6__0 
		sendEnd(); // Core2 > Core7: splitTensorB_6__multiply7_6__0 
		cache_wbInv(splitTensorB_6__multiply6_6__0, 131072*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorB_6__multiply6_6__0 
		sendEnd(); // Core2 > Core6: splitTensorB_6__multiply6_6__0 
		cache_wbInv(splitTensorB_6__multiply5_6__0, 131072*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorB_6__multiply5_6__0 
		sendEnd(); // Core2 > Core5: splitTensorB_6__multiply5_6__0 
		cache_wbInv(splitTensorB_6__multiply4_6__0, 131072*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorB_6__multiply4_6__0 
		sendEnd(); // Core2 > Core4: splitTensorB_6__multiply4_6__0 
		cache_wbInv(splitTensorB_6__multiply3_6__0, 131072*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorB_6__multiply3_6__0 
		sendEnd(); // Core2 > Core3: splitTensorB_6__multiply3_6__0 
		cache_wbInv(splitTensorB_6__multiply1_6__0, 131072*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorB_6__multiply1_6__0 
		sendEnd(); // Core2 > Core1: splitTensorB_6__multiply1_6__0 
		cache_wbInv(splitTensorB_6__multiply0_6__0, 131072*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorB_6__multiply0_6__0 
		sendEnd(); // Core2 > Core0: splitTensorB_6__multiply0_6__0 
		receiveStart(); // Core1 > Core2: splitTensorB_7__multiply2_7__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_7__multiply2_7__0 
		cache_inv(splitTensorB_7__multiply2_7__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: multiply0_2__sum_2__0 
		receiveEnd(0); // Core0 > Core2: multiply0_2__sum_2__0 
		cache_inv(multiply0_2__sum_2__0, 1048576*sizeof(char));
		receiveStart(); // Core1 > Core2: multiply1_2__sum_2__0 
		receiveEnd(1); // Core1 > Core2: multiply1_2__sum_2__0 
		cache_inv(multiply1_2__sum_2__0, 1048576*sizeof(char));
		multiply(512/*rows*/,512/*columns*/,output2__inputA__3,output2__inputB__3,output__input2__0); // multiply2_0
		cache_inv(output2__inputA__3, 32768*sizeof(int));
		cache_inv(output2__inputB__3, 32768*sizeof(int));
		cache_wbInv(multiply2_0__sum_0__0, 1048576*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_0__sum_0__0 
		sendEnd(); // Core2 > Core4: multiply2_0__sum_0__0 
		multiply(512/*rows*/,512/*columns*/,output2__inputA__1,output2__inputB__6,output__input2__6); // multiply2_1
		cache_inv(output2__inputA__1, 32768*sizeof(int));
		cache_inv(output2__inputB__6, 32768*sizeof(int));
		cache_wbInv(multiply2_1__sum_1__0, 1048576*sizeof(char));
		sendStart(3); // Core2 > Core3: multiply2_1__sum_1__0 
		sendEnd(); // Core2 > Core3: multiply2_1__sum_1__0 
		multiply(512/*rows*/,512/*columns*/,output2__inputA__4,output2__inputB__0,output__input2__2); // multiply2_2
		cache_inv(output2__inputA__4, 32768*sizeof(int));
		cache_inv(output2__inputB__0, 32768*sizeof(int));
		multiply(512/*rows*/,512/*columns*/,output2__inputA__5,output2__inputB__4,output__input2__1); // multiply2_3
		cache_inv(output2__inputA__5, 32768*sizeof(int));
		cache_inv(output2__inputB__4, 32768*sizeof(int));
		cache_wbInv(multiply2_3__sum_3__0, 1048576*sizeof(char));
		sendStart(5); // Core2 > Core5: multiply2_3__sum_3__0 
		sendEnd(); // Core2 > Core5: multiply2_3__sum_3__0 
		multiply(512/*rows*/,512/*columns*/,output2__inputA__2,output2__inputB__2,output__input2__7); // multiply2_4
		cache_inv(output2__inputA__2, 32768*sizeof(int));
		cache_inv(output2__inputB__2, 32768*sizeof(int));
		cache_wbInv(multiply2_4__sum_4__0, 1048576*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_4__sum_4__0 
		sendEnd(); // Core2 > Core0: multiply2_4__sum_4__0 
		multiply(512/*rows*/,512/*columns*/,output2__inputA__0,output2__inputB__1,output__input2__4); // multiply2_5
		cache_inv(output2__inputA__0, 32768*sizeof(int));
		cache_inv(output2__inputB__1, 32768*sizeof(int));
		cache_wbInv(multiply2_5__sum_5__0, 1048576*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_5__sum_5__0 
		sendEnd(); // Core2 > Core4: multiply2_5__sum_5__0 
		multiply(512/*rows*/,512/*columns*/,output2__inputA__7,output2__inputB__5,output__input2__3); // multiply2_6
		cache_inv(output2__inputA__7, 32768*sizeof(int));
		cache_inv(output2__inputB__5, 32768*sizeof(int));
		cache_wbInv(multiply2_6__sum_6__0, 1048576*sizeof(char));
		sendStart(1); // Core2 > Core1: multiply2_6__sum_6__0 
		sendEnd(); // Core2 > Core1: multiply2_6__sum_6__0 
		multiply(512/*rows*/,512/*columns*/,output2__inputA__6,output2__inputB__7,output__input2__5); // multiply2_7
		cache_inv(output2__inputA__6, 32768*sizeof(int));
		cache_inv(output2__inputB__7, 32768*sizeof(int));
		cache_wbInv(multiply2_7__sum_7__0, 1048576*sizeof(char));
		sendStart(7); // Core2 > Core7: multiply2_7__sum_7__0 
		sendEnd(); // Core2 > Core7: multiply2_7__sum_7__0 
		receiveStart(); // Core3 > Core2: multiply3_2__sum_2__0 
		receiveEnd(3); // Core3 > Core2: multiply3_2__sum_2__0 
		cache_inv(multiply3_2__sum_2__0, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core2: multiply4_2__sum_2__0 
		receiveEnd(4); // Core4 > Core2: multiply4_2__sum_2__0 
		cache_inv(multiply4_2__sum_2__0, 1048576*sizeof(char));
		receiveStart(); // Core5 > Core2: multiply5_2__sum_2__0 
		receiveEnd(5); // Core5 > Core2: multiply5_2__sum_2__0 
		cache_inv(multiply5_2__sum_2__0, 1048576*sizeof(char));
		receiveStart(); // Core6 > Core2: multiply6_2__sum_2__0 
		receiveEnd(6); // Core6 > Core2: multiply6_2__sum_2__0 
		cache_inv(multiply6_2__sum_2__0, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core2: multiply7_2__sum_2__0 
		receiveEnd(7); // Core7 > Core2: multiply7_2__sum_2__0 
		cache_inv(multiply7_2__sum_2__0, 1048576*sizeof(char));
		sum(512/*rows*/,512/*columns*/,output__input0__6,output__input1__7,output__input2__2,output__input3__7,output__input4__1,output__input5__0,output__input6__5,output__input7__0,output__arrayC_524288__0); // sum_2
		cache_inv(output__input0__6, 262144*sizeof(long));
		cache_inv(output__input1__7, 262144*sizeof(long));
		cache_inv(output__input2__2, 262144*sizeof(long));
		cache_inv(output__input3__7, 262144*sizeof(long));
		cache_inv(output__input4__1, 262144*sizeof(long));
		cache_inv(output__input5__0, 262144*sizeof(long));
		cache_inv(output__input6__5, 262144*sizeof(long));
		cache_inv(output__input7__0, 262144*sizeof(long));
		cache_wbInv(sum_2__implode_displayResult__0, 1048576*sizeof(char));
		sendStart(7); // Core2 > Core7: sum_2__implode_displayResult__0 
		sendEnd(); // Core2 > Core7: sum_2__implode_displayResult__0 
	}
}
