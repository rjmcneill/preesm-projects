/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Mon Apr 20 00:05:10 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__25;  // explode_generateTensors_arrayA > splitTensorA_17 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__41;  // explode_generateTensors_arrayA > splitTensorA_13 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__44;  // explode_generateTensors_arrayA > splitTensorA_4 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__33;  // explode_generateTensors_arrayB > transpose_20 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__10;  // explode_generateTensors_arrayB > transpose_18 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__53;  // explode_generateTensors_arrayB > transpose_17 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__27;  // explode_generateTensors_arrayB > transpose_11 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__58;  // explode_generateTensors_arrayB > transpose_8 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__23;  // explode_generateTensors_arrayB > transpose_7 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__51;  // explode_generateTensors_arrayB > transpose_6 size:= 256*char defined in Core0
extern char *const splitTensorA_0__multiply2_0__0;  // splitTensorA_0 > multiply2_0 size:= 32*char defined in Core0
extern char *const splitTensorA_1__multiply2_1__0;  // splitTensorA_1 > multiply2_1 size:= 32*char defined in Core0
extern char *const splitTensorA_10__multiply2_1__0;  // splitTensorA_10 > multiply2_10 size:= 32*char defined in Core0
extern char *const splitTensorA_11__multiply2_1__0;  // splitTensorA_11 > multiply2_11 size:= 32*char defined in Core0
extern char *const splitTensorA_12__multiply2_1__0;  // splitTensorA_12 > multiply2_12 size:= 32*char defined in Core0
extern int *const arrayA_832__input__0;  // explode_generateTensors_arrayA_arrayA_832 > splitTensorA_13_input size:= 64*int defined in Core0
extern int *const output0__inputA__23;  // splitTensorA_13_output0 > multiply0_13_inputA size:= 8*int defined in Core0
extern int *const output1__inputA__9;  // splitTensorA_13_output1 > multiply1_13_inputA size:= 8*int defined in Core0
extern int *const output2__inputA__29;  // splitTensorA_13_output2 > multiply2_13_inputA size:= 8*int defined in Core0
extern int *const output3__inputA__3;  // splitTensorA_13_output3 > multiply3_13_inputA size:= 8*int defined in Core0
extern int *const output4__inputA__31;  // splitTensorA_13_output4 > multiply4_13_inputA size:= 8*int defined in Core0
extern int *const output5__inputA__22;  // splitTensorA_13_output5 > multiply5_13_inputA size:= 8*int defined in Core0
extern int *const output6__inputA__26;  // splitTensorA_13_output6 > multiply6_13_inputA size:= 8*int defined in Core0
extern int *const output7__inputA__9;  // splitTensorA_13_output7 > multiply7_13_inputA size:= 8*int defined in Core0
extern char *const splitTensorA_13__multiply7_1__0;  // splitTensorA_13 > multiply7_13 size:= 32*char defined in Core0
extern char *const splitTensorA_13__multiply6_1__0;  // splitTensorA_13 > multiply6_13 size:= 32*char defined in Core0
extern char *const splitTensorA_13__multiply5_1__0;  // splitTensorA_13 > multiply5_13 size:= 32*char defined in Core0
extern char *const splitTensorA_13__multiply4_1__0;  // splitTensorA_13 > multiply4_13 size:= 32*char defined in Core0
extern char *const splitTensorA_13__multiply3_1__0;  // splitTensorA_13 > multiply3_13 size:= 32*char defined in Core0
extern char *const splitTensorA_13__multiply1_1__0;  // splitTensorA_13 > multiply1_13 size:= 32*char defined in Core0
extern char *const splitTensorA_13__multiply0_1__0;  // splitTensorA_13 > multiply0_13 size:= 32*char defined in Core0
extern char *const splitTensorA_14__multiply2_1__0;  // splitTensorA_14 > multiply2_14 size:= 32*char defined in Core0
extern char *const splitTensorA_15__multiply2_1__0;  // splitTensorA_15 > multiply2_15 size:= 32*char defined in Core0
extern char *const splitTensorA_16__multiply2_1__0;  // splitTensorA_16 > multiply2_16 size:= 32*char defined in Core0
extern int *const arrayA_1088__input__0;  // explode_generateTensors_arrayA_arrayA_1088 > splitTensorA_17_input size:= 64*int defined in Core0
extern int *const output0__inputA__28;  // splitTensorA_17_output0 > multiply0_17_inputA size:= 8*int defined in Core0
extern int *const output1__inputA__16;  // splitTensorA_17_output1 > multiply1_17_inputA size:= 8*int defined in Core0
extern int *const output2__inputA__2;  // splitTensorA_17_output2 > multiply2_17_inputA size:= 8*int defined in Core0
extern int *const output3__inputA__11;  // splitTensorA_17_output3 > multiply3_17_inputA size:= 8*int defined in Core0
extern int *const output4__inputA__7;  // splitTensorA_17_output4 > multiply4_17_inputA size:= 8*int defined in Core0
extern int *const output5__inputA__20;  // splitTensorA_17_output5 > multiply5_17_inputA size:= 8*int defined in Core0
extern int *const output6__inputA__11;  // splitTensorA_17_output6 > multiply6_17_inputA size:= 8*int defined in Core0
extern int *const output7__inputA__1;  // splitTensorA_17_output7 > multiply7_17_inputA size:= 8*int defined in Core0
extern char *const splitTensorA_17__multiply7_1__0;  // splitTensorA_17 > multiply7_17 size:= 32*char defined in Core0
extern char *const splitTensorA_17__multiply6_1__0;  // splitTensorA_17 > multiply6_17 size:= 32*char defined in Core0
extern char *const splitTensorA_17__multiply5_1__0;  // splitTensorA_17 > multiply5_17 size:= 32*char defined in Core0
extern char *const splitTensorA_17__multiply4_1__0;  // splitTensorA_17 > multiply4_17 size:= 32*char defined in Core0
extern char *const splitTensorA_17__multiply3_1__0;  // splitTensorA_17 > multiply3_17 size:= 32*char defined in Core0
extern char *const splitTensorA_17__multiply1_1__0;  // splitTensorA_17 > multiply1_17 size:= 32*char defined in Core0
extern char *const splitTensorA_17__multiply0_1__0;  // splitTensorA_17 > multiply0_17 size:= 32*char defined in Core0
extern char *const splitTensorA_18__multiply2_1__0;  // splitTensorA_18 > multiply2_18 size:= 32*char defined in Core0
extern char *const splitTensorA_19__multiply2_1__0;  // splitTensorA_19 > multiply2_19 size:= 32*char defined in Core0
extern char *const splitTensorA_2__multiply2_2__0;  // splitTensorA_2 > multiply2_2 size:= 32*char defined in Core0
extern char *const splitTensorA_20__multiply2_2__0;  // splitTensorA_20 > multiply2_20 size:= 32*char defined in Core0
extern char *const splitTensorA_21__multiply2_2__0;  // splitTensorA_21 > multiply2_21 size:= 32*char defined in Core0
extern char *const splitTensorA_22__multiply2_2__0;  // splitTensorA_22 > multiply2_22 size:= 32*char defined in Core0
extern char *const splitTensorA_23__multiply2_2__0;  // splitTensorA_23 > multiply2_23 size:= 32*char defined in Core0
extern char *const splitTensorA_24__multiply2_2__0;  // splitTensorA_24 > multiply2_24 size:= 32*char defined in Core0
extern char *const splitTensorA_25__multiply2_2__0;  // splitTensorA_25 > multiply2_25 size:= 32*char defined in Core0
extern char *const splitTensorA_26__multiply2_2__0;  // splitTensorA_26 > multiply2_26 size:= 32*char defined in Core0
extern char *const splitTensorA_27__multiply2_2__0;  // splitTensorA_27 > multiply2_27 size:= 32*char defined in Core0
extern char *const splitTensorA_28__multiply2_2__0;  // splitTensorA_28 > multiply2_28 size:= 32*char defined in Core0
extern char *const splitTensorA_29__multiply2_2__0;  // splitTensorA_29 > multiply2_29 size:= 32*char defined in Core0
extern char *const splitTensorA_3__multiply2_3__0;  // splitTensorA_3 > multiply2_3 size:= 32*char defined in Core0
extern char *const splitTensorA_30__multiply2_3__0;  // splitTensorA_30 > multiply2_30 size:= 32*char defined in Core0
extern char *const splitTensorA_31__multiply2_3__0;  // splitTensorA_31 > multiply2_31 size:= 32*char defined in Core0
extern int *const arrayA_256__input__0;  // explode_generateTensors_arrayA_arrayA_256 > splitTensorA_4_input size:= 64*int defined in Core0
extern int *const output0__inputA__13;  // splitTensorA_4_output0 > multiply0_4_inputA size:= 8*int defined in Core0
extern int *const output1__inputA__5;  // splitTensorA_4_output1 > multiply1_4_inputA size:= 8*int defined in Core0
extern int *const output2__inputA__9;  // splitTensorA_4_output2 > multiply2_4_inputA size:= 8*int defined in Core0
extern int *const output3__inputA__28;  // splitTensorA_4_output3 > multiply3_4_inputA size:= 8*int defined in Core0
extern int *const output4__inputA__11;  // splitTensorA_4_output4 > multiply4_4_inputA size:= 8*int defined in Core0
extern int *const output5__inputA__13;  // splitTensorA_4_output5 > multiply5_4_inputA size:= 8*int defined in Core0
extern int *const output6__inputA__23;  // splitTensorA_4_output6 > multiply6_4_inputA size:= 8*int defined in Core0
extern int *const output7__inputA__15;  // splitTensorA_4_output7 > multiply7_4_inputA size:= 8*int defined in Core0
extern char *const splitTensorA_4__multiply7_4__0;  // splitTensorA_4 > multiply7_4 size:= 32*char defined in Core0
extern char *const splitTensorA_4__multiply6_4__0;  // splitTensorA_4 > multiply6_4 size:= 32*char defined in Core0
extern char *const splitTensorA_4__multiply5_4__0;  // splitTensorA_4 > multiply5_4 size:= 32*char defined in Core0
extern char *const splitTensorA_4__multiply4_4__0;  // splitTensorA_4 > multiply4_4 size:= 32*char defined in Core0
extern char *const splitTensorA_4__multiply3_4__0;  // splitTensorA_4 > multiply3_4 size:= 32*char defined in Core0
extern char *const splitTensorA_4__multiply1_4__0;  // splitTensorA_4 > multiply1_4 size:= 32*char defined in Core0
extern char *const splitTensorA_4__multiply0_4__0;  // splitTensorA_4 > multiply0_4 size:= 32*char defined in Core0
extern char *const splitTensorA_5__multiply2_5__0;  // splitTensorA_5 > multiply2_5 size:= 32*char defined in Core0
extern char *const splitTensorA_6__multiply2_6__0;  // splitTensorA_6 > multiply2_6 size:= 32*char defined in Core0
extern char *const splitTensorA_7__multiply2_7__0;  // splitTensorA_7 > multiply2_7 size:= 32*char defined in Core0
extern char *const splitTensorA_8__multiply2_8__0;  // splitTensorA_8 > multiply2_8 size:= 32*char defined in Core0
extern char *const splitTensorA_9__multiply2_9__0;  // splitTensorA_9 > multiply2_9 size:= 32*char defined in Core0
extern int *const arrayB_704__input__0;  // explode_generateTensors_arrayB_arrayB_704 > transpose_11_input size:= 64*int defined in Core0
extern int *const output__input__21;  // transpose_11_output > splitTensorB_11_input size:= 64*int defined in Core0
extern char *const transpose_11__splitTensorB_1__0;  // transpose_11 > splitTensorB_11 size:= 256*char defined in Core0
extern int *const arrayB_1088__input__0;  // explode_generateTensors_arrayB_arrayB_1088 > transpose_17_input size:= 64*int defined in Core0
extern int *const output__input__10;  // transpose_17_output > splitTensorB_17_input size:= 64*int defined in Core0
extern int *const arrayB_1152__input__0;  // explode_generateTensors_arrayB_arrayB_1152 > transpose_18_input size:= 64*int defined in Core0
extern int *const output__input__9;  // transpose_18_output > splitTensorB_18_input size:= 64*int defined in Core0
extern char *const transpose_18__splitTensorB_1__0;  // transpose_18 > splitTensorB_18 size:= 256*char defined in Core0
extern int *const arrayB_1280__input__0;  // explode_generateTensors_arrayB_arrayB_1280 > transpose_20_input size:= 64*int defined in Core0
extern int *const output__input__8;  // transpose_20_output > splitTensorB_20_input size:= 64*int defined in Core0
extern char *const transpose_20__splitTensorB_2__0;  // transpose_20 > splitTensorB_20 size:= 256*char defined in Core0
extern char *const transpose_21__splitTensorB_2__0;  // transpose_21 > splitTensorB_21 size:= 256*char defined in Core0
extern char *const transpose_22__splitTensorB_2__0;  // transpose_22 > splitTensorB_22 size:= 256*char defined in Core0
extern char *const transpose_24__splitTensorB_2__0;  // transpose_24 > splitTensorB_24 size:= 256*char defined in Core0
extern int *const arrayB_384__input__0;  // explode_generateTensors_arrayB_arrayB_384 > transpose_6_input size:= 64*int defined in Core0
extern int *const output__input__27;  // transpose_6_output > splitTensorB_6_input size:= 64*int defined in Core0
extern char *const transpose_6__splitTensorB_6__0;  // transpose_6 > splitTensorB_6 size:= 256*char defined in Core0
extern int *const arrayB_448__input__0;  // explode_generateTensors_arrayB_arrayB_448 > transpose_7_input size:= 64*int defined in Core0
extern int *const output__input__12;  // transpose_7_output > splitTensorB_7_input size:= 64*int defined in Core0
extern char *const transpose_7__splitTensorB_7__0;  // transpose_7 > splitTensorB_7 size:= 256*char defined in Core0
extern int *const arrayB_512__input__0;  // explode_generateTensors_arrayB_arrayB_512 > transpose_8_input size:= 64*int defined in Core0
extern int *const output__input__11;  // transpose_8_output > splitTensorB_8_input size:= 64*int defined in Core0
extern char *const transpose_8__splitTensorB_8__0;  // transpose_8 > splitTensorB_8 size:= 256*char defined in Core0
extern char *const splitTensorB_0__multiply2_0__0;  // splitTensorB_0 > multiply2_0 size:= 32*char defined in Core0
extern char *const splitTensorB_1__multiply2_1__0;  // splitTensorB_1 > multiply2_1 size:= 32*char defined in Core0
extern char *const splitTensorB_10__multiply2_1__0;  // splitTensorB_10 > multiply2_10 size:= 32*char defined in Core0
extern char *const splitTensorB_11__multiply2_1__0;  // splitTensorB_11 > multiply2_11 size:= 32*char defined in Core0
extern char *const splitTensorB_12__multiply2_1__0;  // splitTensorB_12 > multiply2_12 size:= 32*char defined in Core0
extern char *const splitTensorB_13__multiply2_1__0;  // splitTensorB_13 > multiply2_13 size:= 32*char defined in Core0
extern char *const splitTensorB_14__multiply2_1__0;  // splitTensorB_14 > multiply2_14 size:= 32*char defined in Core0
extern char *const splitTensorB_15__multiply2_1__0;  // splitTensorB_15 > multiply2_15 size:= 32*char defined in Core0
extern char *const splitTensorB_16__multiply2_1__0;  // splitTensorB_16 > multiply2_16 size:= 32*char defined in Core0
extern int *const output0__inputB__4;  // splitTensorB_17_output0 > multiply0_17_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__8;  // splitTensorB_17_output1 > multiply1_17_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__28;  // splitTensorB_17_output2 > multiply2_17_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__16;  // splitTensorB_17_output3 > multiply3_17_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__12;  // splitTensorB_17_output4 > multiply4_17_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__28;  // splitTensorB_17_output5 > multiply5_17_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__20;  // splitTensorB_17_output6 > multiply6_17_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__8;  // splitTensorB_17_output7 > multiply7_17_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_17__multiply7_1__0;  // splitTensorB_17 > multiply7_17 size:= 32*char defined in Core0
extern char *const splitTensorB_17__multiply6_1__0;  // splitTensorB_17 > multiply6_17 size:= 32*char defined in Core0
extern char *const splitTensorB_17__multiply5_1__0;  // splitTensorB_17 > multiply5_17 size:= 32*char defined in Core0
extern char *const splitTensorB_17__multiply4_1__0;  // splitTensorB_17 > multiply4_17 size:= 32*char defined in Core0
extern char *const splitTensorB_17__multiply3_1__0;  // splitTensorB_17 > multiply3_17 size:= 32*char defined in Core0
extern char *const splitTensorB_17__multiply1_1__0;  // splitTensorB_17 > multiply1_17 size:= 32*char defined in Core0
extern char *const splitTensorB_17__multiply0_1__0;  // splitTensorB_17 > multiply0_17 size:= 32*char defined in Core0
extern char *const splitTensorB_18__multiply2_1__0;  // splitTensorB_18 > multiply2_18 size:= 32*char defined in Core0
extern char *const splitTensorB_19__multiply2_1__0;  // splitTensorB_19 > multiply2_19 size:= 32*char defined in Core0
extern char *const splitTensorB_2__multiply2_2__0;  // splitTensorB_2 > multiply2_2 size:= 32*char defined in Core0
extern char *const splitTensorB_20__multiply2_2__0;  // splitTensorB_20 > multiply2_20 size:= 32*char defined in Core0
extern int *const output__input__30;  // transpose_21_output > splitTensorB_21_input size:= 64*int defined in Core0
extern int *const output0__inputB__10;  // splitTensorB_21_output0 > multiply0_21_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__12;  // splitTensorB_21_output1 > multiply1_21_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__16;  // splitTensorB_21_output2 > multiply2_21_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__7;  // splitTensorB_21_output3 > multiply3_21_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__19;  // splitTensorB_21_output4 > multiply4_21_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__19;  // splitTensorB_21_output5 > multiply5_21_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__3;  // splitTensorB_21_output6 > multiply6_21_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__0;  // splitTensorB_21_output7 > multiply7_21_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_21__multiply7_2__0;  // splitTensorB_21 > multiply7_21 size:= 32*char defined in Core0
extern char *const splitTensorB_21__multiply6_2__0;  // splitTensorB_21 > multiply6_21 size:= 32*char defined in Core0
extern char *const splitTensorB_21__multiply5_2__0;  // splitTensorB_21 > multiply5_21 size:= 32*char defined in Core0
extern char *const splitTensorB_21__multiply4_2__0;  // splitTensorB_21 > multiply4_21 size:= 32*char defined in Core0
extern char *const splitTensorB_21__multiply3_2__0;  // splitTensorB_21 > multiply3_21 size:= 32*char defined in Core0
extern char *const splitTensorB_21__multiply1_2__0;  // splitTensorB_21 > multiply1_21 size:= 32*char defined in Core0
extern char *const splitTensorB_21__multiply0_2__0;  // splitTensorB_21 > multiply0_21 size:= 32*char defined in Core0
extern int *const output__input__20;  // transpose_22_output > splitTensorB_22_input size:= 64*int defined in Core0
extern int *const output0__inputB__1;  // splitTensorB_22_output0 > multiply0_22_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__27;  // splitTensorB_22_output1 > multiply1_22_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__4;  // splitTensorB_22_output2 > multiply2_22_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__18;  // splitTensorB_22_output3 > multiply3_22_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__31;  // splitTensorB_22_output4 > multiply4_22_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__24;  // splitTensorB_22_output5 > multiply5_22_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__9;  // splitTensorB_22_output6 > multiply6_22_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__9;  // splitTensorB_22_output7 > multiply7_22_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_22__multiply7_2__0;  // splitTensorB_22 > multiply7_22 size:= 32*char defined in Core0
extern char *const splitTensorB_22__multiply6_2__0;  // splitTensorB_22 > multiply6_22 size:= 32*char defined in Core0
extern char *const splitTensorB_22__multiply5_2__0;  // splitTensorB_22 > multiply5_22 size:= 32*char defined in Core0
extern char *const splitTensorB_22__multiply4_2__0;  // splitTensorB_22 > multiply4_22 size:= 32*char defined in Core0
extern char *const splitTensorB_22__multiply3_2__0;  // splitTensorB_22 > multiply3_22 size:= 32*char defined in Core0
extern char *const splitTensorB_22__multiply1_2__0;  // splitTensorB_22 > multiply1_22 size:= 32*char defined in Core0
extern char *const splitTensorB_22__multiply0_2__0;  // splitTensorB_22 > multiply0_22 size:= 32*char defined in Core0
extern char *const splitTensorB_23__multiply2_2__0;  // splitTensorB_23 > multiply2_23 size:= 32*char defined in Core0
extern int *const output__input__24;  // transpose_24_output > splitTensorB_24_input size:= 64*int defined in Core0
extern int *const output0__inputB__7;  // splitTensorB_24_output0 > multiply0_24_inputB size:= 8*int defined in Core0
extern int *const output1__inputB__15;  // splitTensorB_24_output1 > multiply1_24_inputB size:= 8*int defined in Core0
extern int *const output2__inputB__7;  // splitTensorB_24_output2 > multiply2_24_inputB size:= 8*int defined in Core0
extern int *const output3__inputB__15;  // splitTensorB_24_output3 > multiply3_24_inputB size:= 8*int defined in Core0
extern int *const output4__inputB__6;  // splitTensorB_24_output4 > multiply4_24_inputB size:= 8*int defined in Core0
extern int *const output5__inputB__7;  // splitTensorB_24_output5 > multiply5_24_inputB size:= 8*int defined in Core0
extern int *const output6__inputB__30;  // splitTensorB_24_output6 > multiply6_24_inputB size:= 8*int defined in Core0
extern int *const output7__inputB__10;  // splitTensorB_24_output7 > multiply7_24_inputB size:= 8*int defined in Core0
extern char *const splitTensorB_24__multiply7_2__0;  // splitTensorB_24 > multiply7_24 size:= 32*char defined in Core0
extern char *const splitTensorB_24__multiply6_2__0;  // splitTensorB_24 > multiply6_24 size:= 32*char defined in Core0
extern char *const splitTensorB_24__multiply5_2__0;  // splitTensorB_24 > multiply5_24 size:= 32*char defined in Core0
extern char *const splitTensorB_24__multiply4_2__0;  // splitTensorB_24 > multiply4_24 size:= 32*char defined in Core0
extern char *const splitTensorB_24__multiply3_2__0;  // splitTensorB_24 > multiply3_24 size:= 32*char defined in Core0
extern char *const splitTensorB_24__multiply1_2__0;  // splitTensorB_24 > multiply1_24 size:= 32*char defined in Core0
extern char *const splitTensorB_24__multiply0_2__0;  // splitTensorB_24 > multiply0_24 size:= 32*char defined in Core0
extern char *const splitTensorB_25__multiply2_2__0;  // splitTensorB_25 > multiply2_25 size:= 32*char defined in Core0
extern char *const splitTensorB_26__multiply2_2__0;  // splitTensorB_26 > multiply2_26 size:= 32*char defined in Core0
extern char *const splitTensorB_27__multiply2_2__0;  // splitTensorB_27 > multiply2_27 size:= 32*char defined in Core0
extern char *const splitTensorB_28__multiply2_2__0;  // splitTensorB_28 > multiply2_28 size:= 32*char defined in Core0
extern char *const splitTensorB_29__multiply2_2__0;  // splitTensorB_29 > multiply2_29 size:= 32*char defined in Core0
extern char *const splitTensorB_3__multiply2_3__0;  // splitTensorB_3 > multiply2_3 size:= 32*char defined in Core0
extern char *const splitTensorB_30__multiply2_3__0;  // splitTensorB_30 > multiply2_30 size:= 32*char defined in Core0
extern char *const splitTensorB_31__multiply2_3__0;  // splitTensorB_31 > multiply2_31 size:= 32*char defined in Core0
extern char *const splitTensorB_4__multiply2_4__0;  // splitTensorB_4 > multiply2_4 size:= 32*char defined in Core0
extern char *const splitTensorB_5__multiply2_5__0;  // splitTensorB_5 > multiply2_5 size:= 32*char defined in Core0
extern char *const splitTensorB_6__multiply2_6__0;  // splitTensorB_6 > multiply2_6 size:= 32*char defined in Core0
extern char *const splitTensorB_7__multiply2_7__0;  // splitTensorB_7 > multiply2_7 size:= 32*char defined in Core0
extern char *const splitTensorB_8__multiply2_8__0;  // splitTensorB_8 > multiply2_8 size:= 32*char defined in Core0
extern char *const splitTensorB_9__multiply2_9__0;  // splitTensorB_9 > multiply2_9 size:= 32*char defined in Core0
extern char *const multiply0_1__sum_1__0;  // multiply0_1 > sum_1 size:= 256*char defined in Core0
extern char *const multiply0_17__sum_17__0;  // multiply0_17 > sum_17 size:= 256*char defined in Core0
extern char *const multiply1_1__sum_1__0;  // multiply1_1 > sum_1 size:= 256*char defined in Core0
extern char *const multiply1_17__sum_17__0;  // multiply1_17 > sum_17 size:= 256*char defined in Core0
extern int *const output2__inputA__3;  // splitTensorA_0_output2 > multiply2_0_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__24;  // splitTensorB_0_output2 > multiply2_0_inputB size:= 8*int defined in Core0
extern long *const output__input2__25;  // multiply2_0_output > sum_0_input2 size:= 64*long defined in Core0
extern char *const multiply2_0__sum_0__0;  // multiply2_0 > sum_0 size:= 256*char defined in Core0
extern int *const output2__inputA__21;  // splitTensorA_1_output2 > multiply2_1_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__18;  // splitTensorB_1_output2 > multiply2_1_inputB size:= 8*int defined in Core0
extern long *const output__input2__26;  // multiply2_1_output > sum_1_input2 size:= 64*long defined in Core0
extern int *const output2__inputA__17;  // splitTensorA_10_output2 > multiply2_10_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__12;  // splitTensorB_10_output2 > multiply2_10_inputB size:= 8*int defined in Core0
extern long *const output__input2__11;  // multiply2_10_output > sum_10_input2 size:= 64*long defined in Core0
extern char *const multiply2_10__sum_10__0;  // multiply2_10 > sum_10 size:= 256*char defined in Core0
extern int *const output2__inputA__11;  // splitTensorA_11_output2 > multiply2_11_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__21;  // splitTensorB_11_output2 > multiply2_11_inputB size:= 8*int defined in Core0
extern long *const output__input2__20;  // multiply2_11_output > sum_11_input2 size:= 64*long defined in Core0
extern char *const multiply2_11__sum_11__0;  // multiply2_11 > sum_11 size:= 256*char defined in Core0
extern int *const output2__inputA__14;  // splitTensorA_12_output2 > multiply2_12_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__25;  // splitTensorB_12_output2 > multiply2_12_inputB size:= 8*int defined in Core0
extern long *const output__input2__13;  // multiply2_12_output > sum_12_input2 size:= 64*long defined in Core0
extern char *const multiply2_12__sum_12__0;  // multiply2_12 > sum_12 size:= 256*char defined in Core0
extern int *const output2__inputB__3;  // splitTensorB_13_output2 > multiply2_13_inputB size:= 8*int defined in Core0
extern long *const output__input2__29;  // multiply2_13_output > sum_13_input2 size:= 64*long defined in Core0
extern char *const multiply2_13__sum_13__0;  // multiply2_13 > sum_13 size:= 256*char defined in Core0
extern int *const output2__inputA__10;  // splitTensorA_14_output2 > multiply2_14_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__5;  // splitTensorB_14_output2 > multiply2_14_inputB size:= 8*int defined in Core0
extern long *const output__input2__6;  // multiply2_14_output > sum_14_input2 size:= 64*long defined in Core0
extern char *const multiply2_14__sum_14__0;  // multiply2_14 > sum_14 size:= 256*char defined in Core0
extern int *const output2__inputA__20;  // splitTensorA_15_output2 > multiply2_15_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__14;  // splitTensorB_15_output2 > multiply2_15_inputB size:= 8*int defined in Core0
extern long *const output__input2__14;  // multiply2_15_output > sum_15_input2 size:= 64*long defined in Core0
extern char *const multiply2_15__sum_15__0;  // multiply2_15 > sum_15 size:= 256*char defined in Core0
extern int *const output2__inputA__31;  // splitTensorA_16_output2 > multiply2_16_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__2;  // splitTensorB_16_output2 > multiply2_16_inputB size:= 8*int defined in Core0
extern long *const output__input2__10;  // multiply2_16_output > sum_16_input2 size:= 64*long defined in Core0
extern char *const multiply2_16__sum_16__0;  // multiply2_16 > sum_16 size:= 256*char defined in Core0
extern long *const output__input2__15;  // multiply2_17_output > sum_17_input2 size:= 64*long defined in Core0
extern int *const output2__inputA__4;  // splitTensorA_18_output2 > multiply2_18_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__19;  // splitTensorB_18_output2 > multiply2_18_inputB size:= 8*int defined in Core0
extern long *const output__input2__30;  // multiply2_18_output > sum_18_input2 size:= 64*long defined in Core0
extern char *const multiply2_18__sum_18__0;  // multiply2_18 > sum_18 size:= 256*char defined in Core0
extern int *const output2__inputA__18;  // splitTensorA_19_output2 > multiply2_19_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__15;  // splitTensorB_19_output2 > multiply2_19_inputB size:= 8*int defined in Core0
extern long *const output__input2__3;  // multiply2_19_output > sum_19_input2 size:= 64*long defined in Core0
extern char *const multiply2_19__sum_19__0;  // multiply2_19 > sum_19 size:= 256*char defined in Core0
extern int *const output2__inputA__8;  // splitTensorA_2_output2 > multiply2_2_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__23;  // splitTensorB_2_output2 > multiply2_2_inputB size:= 8*int defined in Core0
extern long *const output__input2__9;  // multiply2_2_output > sum_2_input2 size:= 64*long defined in Core0
extern char *const multiply2_2__sum_2__0;  // multiply2_2 > sum_2 size:= 256*char defined in Core0
extern int *const output2__inputA__7;  // splitTensorA_20_output2 > multiply2_20_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__22;  // splitTensorB_20_output2 > multiply2_20_inputB size:= 8*int defined in Core0
extern long *const output__input2__19;  // multiply2_20_output > sum_20_input2 size:= 64*long defined in Core0
extern char *const multiply2_20__sum_20__0;  // multiply2_20 > sum_20 size:= 256*char defined in Core0
extern int *const output2__inputA__26;  // splitTensorA_21_output2 > multiply2_21_inputA size:= 8*int defined in Core0
extern long *const output__input2__31;  // multiply2_21_output > sum_21_input2 size:= 64*long defined in Core0
extern char *const multiply2_21__sum_21__0;  // multiply2_21 > sum_21 size:= 256*char defined in Core0
extern int *const output2__inputA__1;  // splitTensorA_22_output2 > multiply2_22_inputA size:= 8*int defined in Core0
extern long *const output__input2__28;  // multiply2_22_output > sum_22_input2 size:= 64*long defined in Core0
extern char *const multiply2_22__sum_22__0;  // multiply2_22 > sum_22 size:= 256*char defined in Core0
extern int *const output2__inputA__16;  // splitTensorA_23_output2 > multiply2_23_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__17;  // splitTensorB_23_output2 > multiply2_23_inputB size:= 8*int defined in Core0
extern long *const output__input2__1;  // multiply2_23_output > sum_23_input2 size:= 64*long defined in Core0
extern char *const multiply2_23__sum_23__0;  // multiply2_23 > sum_23 size:= 256*char defined in Core0
extern int *const output2__inputA__23;  // splitTensorA_24_output2 > multiply2_24_inputA size:= 8*int defined in Core0
extern long *const output__input2__5;  // multiply2_24_output > sum_24_input2 size:= 64*long defined in Core0
extern char *const multiply2_24__sum_24__0;  // multiply2_24 > sum_24 size:= 256*char defined in Core0
extern int *const output2__inputA__6;  // splitTensorA_25_output2 > multiply2_25_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__30;  // splitTensorB_25_output2 > multiply2_25_inputB size:= 8*int defined in Core0
extern long *const output__input2__24;  // multiply2_25_output > sum_25_input2 size:= 64*long defined in Core0
extern char *const multiply2_25__sum_25__0;  // multiply2_25 > sum_25 size:= 256*char defined in Core0
extern int *const output2__inputA__0;  // splitTensorA_26_output2 > multiply2_26_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__11;  // splitTensorB_26_output2 > multiply2_26_inputB size:= 8*int defined in Core0
extern long *const output__input2__18;  // multiply2_26_output > sum_26_input2 size:= 64*long defined in Core0
extern char *const multiply2_26__sum_26__0;  // multiply2_26 > sum_26 size:= 256*char defined in Core0
extern int *const output2__inputA__5;  // splitTensorA_27_output2 > multiply2_27_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__27;  // splitTensorB_27_output2 > multiply2_27_inputB size:= 8*int defined in Core0
extern long *const output__input2__21;  // multiply2_27_output > sum_27_input2 size:= 64*long defined in Core0
extern char *const multiply2_27__sum_27__0;  // multiply2_27 > sum_27 size:= 256*char defined in Core0
extern int *const output2__inputA__19;  // splitTensorA_28_output2 > multiply2_28_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__13;  // splitTensorB_28_output2 > multiply2_28_inputB size:= 8*int defined in Core0
extern long *const output__input2__17;  // multiply2_28_output > sum_28_input2 size:= 64*long defined in Core0
extern char *const multiply2_28__sum_28__0;  // multiply2_28 > sum_28 size:= 256*char defined in Core0
extern int *const output2__inputA__30;  // splitTensorA_29_output2 > multiply2_29_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__20;  // splitTensorB_29_output2 > multiply2_29_inputB size:= 8*int defined in Core0
extern long *const output__input2__4;  // multiply2_29_output > sum_29_input2 size:= 64*long defined in Core0
extern char *const multiply2_29__sum_29__0;  // multiply2_29 > sum_29 size:= 256*char defined in Core0
extern int *const output2__inputA__27;  // splitTensorA_3_output2 > multiply2_3_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__9;  // splitTensorB_3_output2 > multiply2_3_inputB size:= 8*int defined in Core0
extern long *const output__input2__7;  // multiply2_3_output > sum_3_input2 size:= 64*long defined in Core0
extern char *const multiply2_3__sum_3__0;  // multiply2_3 > sum_3 size:= 256*char defined in Core0
extern int *const output2__inputA__25;  // splitTensorA_30_output2 > multiply2_30_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__29;  // splitTensorB_30_output2 > multiply2_30_inputB size:= 8*int defined in Core0
extern long *const output__input2__16;  // multiply2_30_output > sum_30_input2 size:= 64*long defined in Core0
extern char *const multiply2_30__sum_30__0;  // multiply2_30 > sum_30 size:= 256*char defined in Core0
extern int *const output2__inputA__24;  // splitTensorA_31_output2 > multiply2_31_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__26;  // splitTensorB_31_output2 > multiply2_31_inputB size:= 8*int defined in Core0
extern long *const output__input2__12;  // multiply2_31_output > sum_31_input2 size:= 64*long defined in Core0
extern char *const multiply2_31__sum_31__0;  // multiply2_31 > sum_31 size:= 256*char defined in Core0
extern int *const output2__inputB__1;  // splitTensorB_4_output2 > multiply2_4_inputB size:= 8*int defined in Core0
extern long *const output__input2__23;  // multiply2_4_output > sum_4_input2 size:= 64*long defined in Core0
extern char *const multiply2_4__sum_4__0;  // multiply2_4 > sum_4 size:= 256*char defined in Core0
extern int *const output2__inputA__12;  // splitTensorA_5_output2 > multiply2_5_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__10;  // splitTensorB_5_output2 > multiply2_5_inputB size:= 8*int defined in Core0
extern long *const output__input2__0;  // multiply2_5_output > sum_5_input2 size:= 64*long defined in Core0
extern char *const multiply2_5__sum_5__0;  // multiply2_5 > sum_5 size:= 256*char defined in Core0
extern int *const output2__inputA__13;  // splitTensorA_6_output2 > multiply2_6_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__8;  // splitTensorB_6_output2 > multiply2_6_inputB size:= 8*int defined in Core0
extern long *const output__input2__2;  // multiply2_6_output > sum_6_input2 size:= 64*long defined in Core0
extern char *const multiply2_6__sum_6__0;  // multiply2_6 > sum_6 size:= 256*char defined in Core0
extern int *const output2__inputA__28;  // splitTensorA_7_output2 > multiply2_7_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__31;  // splitTensorB_7_output2 > multiply2_7_inputB size:= 8*int defined in Core0
extern long *const output__input2__27;  // multiply2_7_output > sum_7_input2 size:= 64*long defined in Core0
extern char *const multiply2_7__sum_7__0;  // multiply2_7 > sum_7 size:= 256*char defined in Core0
extern int *const output2__inputA__15;  // splitTensorA_8_output2 > multiply2_8_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__0;  // splitTensorB_8_output2 > multiply2_8_inputB size:= 8*int defined in Core0
extern long *const output__input2__8;  // multiply2_8_output > sum_8_input2 size:= 64*long defined in Core0
extern char *const multiply2_8__sum_8__0;  // multiply2_8 > sum_8 size:= 256*char defined in Core0
extern int *const output2__inputA__22;  // splitTensorA_9_output2 > multiply2_9_inputA size:= 8*int defined in Core0
extern int *const output2__inputB__6;  // splitTensorB_9_output2 > multiply2_9_inputB size:= 8*int defined in Core0
extern long *const output__input2__22;  // multiply2_9_output > sum_9_input2 size:= 64*long defined in Core0
extern char *const multiply2_9__sum_9__0;  // multiply2_9 > sum_9 size:= 256*char defined in Core0
extern char *const multiply3_1__sum_1__0;  // multiply3_1 > sum_1 size:= 256*char defined in Core0
extern char *const multiply3_17__sum_17__0;  // multiply3_17 > sum_17 size:= 256*char defined in Core0
extern char *const multiply4_1__sum_1__0;  // multiply4_1 > sum_1 size:= 256*char defined in Core0
extern char *const multiply4_17__sum_17__0;  // multiply4_17 > sum_17 size:= 256*char defined in Core0
extern char *const multiply5_1__sum_1__0;  // multiply5_1 > sum_1 size:= 256*char defined in Core0
extern char *const multiply5_17__sum_17__0;  // multiply5_17 > sum_17 size:= 256*char defined in Core0
extern char *const multiply6_1__sum_1__0;  // multiply6_1 > sum_1 size:= 256*char defined in Core0
extern char *const multiply6_17__sum_17__0;  // multiply6_17 > sum_17 size:= 256*char defined in Core0
extern char *const multiply7_1__sum_1__0;  // multiply7_1 > sum_1 size:= 256*char defined in Core0
extern char *const multiply7_17__sum_17__0;  // multiply7_17 > sum_17 size:= 256*char defined in Core0
extern long *const output__input0__25;  // multiply0_1_output > sum_1_input0 size:= 64*long defined in Core0
extern long *const output__input1__16;  // multiply1_1_output > sum_1_input1 size:= 64*long defined in Core0
extern long *const output__input3__24;  // multiply3_1_output > sum_1_input3 size:= 64*long defined in Core0
extern long *const output__input4__11;  // multiply4_1_output > sum_1_input4 size:= 64*long defined in Core0
extern long *const output__input5__25;  // multiply5_1_output > sum_1_input5 size:= 64*long defined in Core0
extern long *const output__input6__6;  // multiply6_1_output > sum_1_input6 size:= 64*long defined in Core0
extern long *const output__input7__20;  // multiply7_1_output > sum_1_input7 size:= 64*long defined in Core0
extern long *const output__arrayC_64__0;  // sum_1_output > implode_displayResult_arrayC_arrayC_64 size:= 64*long defined in Core0
extern char *const sum_1__implode_displayResult__0;  // sum_1 > implode_displayResult_arrayC size:= 256*char defined in Core0
extern long *const output__input0__23;  // multiply0_17_output > sum_17_input0 size:= 64*long defined in Core0
extern long *const output__input1__21;  // multiply1_17_output > sum_17_input1 size:= 64*long defined in Core0
extern long *const output__input3__26;  // multiply3_17_output > sum_17_input3 size:= 64*long defined in Core0
extern long *const output__input4__5;  // multiply4_17_output > sum_17_input4 size:= 64*long defined in Core0
extern long *const output__input5__29;  // multiply5_17_output > sum_17_input5 size:= 64*long defined in Core0
extern long *const output__input6__27;  // multiply6_17_output > sum_17_input6 size:= 64*long defined in Core0
extern long *const output__input7__16;  // multiply7_17_output > sum_17_input7 size:= 64*long defined in Core0
extern long *const output__arrayC_1088__0;  // sum_17_output > implode_displayResult_arrayC_arrayC_1088 size:= 64*long defined in Core0
extern char *const sum_17__implode_displayResul__0;  // sum_17 > implode_displayResult_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__25 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__25 
		cache_inv(explode_generateTensors_arra__25, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__41 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__41 
		cache_inv(explode_generateTensors_arra__41, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__44 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__44 
		cache_inv(explode_generateTensors_arra__44, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__33 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__33 
		cache_inv(explode_generateTensors_arra__33, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__10 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__10 
		cache_inv(explode_generateTensors_arra__10, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__53 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__53 
		cache_inv(explode_generateTensors_arra__53, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__27 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__27 
		cache_inv(explode_generateTensors_arra__27, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__58 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__58 
		cache_inv(explode_generateTensors_arra__58, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__23 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__23 
		cache_inv(explode_generateTensors_arra__23, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__51 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__51 
		cache_inv(explode_generateTensors_arra__51, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorA_0__multiply2_0__0 
		receiveEnd(1); // Core1 > Core2: splitTensorA_0__multiply2_0__0 
		cache_inv(splitTensorA_0__multiply2_0__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorA_1__multiply2_1__0 
		receiveEnd(6); // Core6 > Core2: splitTensorA_1__multiply2_1__0 
		cache_inv(splitTensorA_1__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_10__multiply2_1__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_10__multiply2_1__0 
		cache_inv(splitTensorA_10__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorA_11__multiply2_1__0 
		receiveEnd(4); // Core4 > Core2: splitTensorA_11__multiply2_1__0 
		cache_inv(splitTensorA_11__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorA_12__multiply2_1__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_12__multiply2_1__0 
		cache_inv(splitTensorA_12__multiply2_1__0, 32*sizeof(char));
		splitA(8/*rowsA*/,8/*columnsA*/,arrayA_832__input__0,output0__inputA__23,output1__inputA__9,output2__inputA__29,output3__inputA__3,output4__inputA__31,output5__inputA__22,output6__inputA__26,output7__inputA__9); // splitTensorA_13
		cache_inv(arrayA_832__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorA_13__multiply7_1__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorA_13__multiply7_1__0 
		sendEnd(); // Core2 > Core7: splitTensorA_13__multiply7_1__0 
		cache_wbInv(splitTensorA_13__multiply6_1__0, 32*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorA_13__multiply6_1__0 
		sendEnd(); // Core2 > Core6: splitTensorA_13__multiply6_1__0 
		cache_wbInv(splitTensorA_13__multiply5_1__0, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorA_13__multiply5_1__0 
		sendEnd(); // Core2 > Core5: splitTensorA_13__multiply5_1__0 
		cache_wbInv(splitTensorA_13__multiply4_1__0, 32*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorA_13__multiply4_1__0 
		sendEnd(); // Core2 > Core4: splitTensorA_13__multiply4_1__0 
		cache_wbInv(splitTensorA_13__multiply3_1__0, 32*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorA_13__multiply3_1__0 
		sendEnd(); // Core2 > Core3: splitTensorA_13__multiply3_1__0 
		cache_wbInv(splitTensorA_13__multiply1_1__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorA_13__multiply1_1__0 
		sendEnd(); // Core2 > Core1: splitTensorA_13__multiply1_1__0 
		cache_wbInv(splitTensorA_13__multiply0_1__0, 32*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorA_13__multiply0_1__0 
		sendEnd(); // Core2 > Core0: splitTensorA_13__multiply0_1__0 
		receiveStart(); // Core0 > Core2: splitTensorA_14__multiply2_1__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_14__multiply2_1__0 
		cache_inv(splitTensorA_14__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorA_15__multiply2_1__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_15__multiply2_1__0 
		cache_inv(splitTensorA_15__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core3 > Core2: splitTensorA_16__multiply2_1__0 
		receiveEnd(3); // Core3 > Core2: splitTensorA_16__multiply2_1__0 
		cache_inv(splitTensorA_16__multiply2_1__0, 32*sizeof(char));
		splitA(8/*rowsA*/,8/*columnsA*/,arrayA_1088__input__0,output0__inputA__28,output1__inputA__16,output2__inputA__2,output3__inputA__11,output4__inputA__7,output5__inputA__20,output6__inputA__11,output7__inputA__1); // splitTensorA_17
		cache_inv(arrayA_1088__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorA_17__multiply7_1__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorA_17__multiply7_1__0 
		sendEnd(); // Core2 > Core7: splitTensorA_17__multiply7_1__0 
		cache_wbInv(splitTensorA_17__multiply6_1__0, 32*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorA_17__multiply6_1__0 
		sendEnd(); // Core2 > Core6: splitTensorA_17__multiply6_1__0 
		cache_wbInv(splitTensorA_17__multiply5_1__0, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorA_17__multiply5_1__0 
		sendEnd(); // Core2 > Core5: splitTensorA_17__multiply5_1__0 
		cache_wbInv(splitTensorA_17__multiply4_1__0, 32*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorA_17__multiply4_1__0 
		sendEnd(); // Core2 > Core4: splitTensorA_17__multiply4_1__0 
		cache_wbInv(splitTensorA_17__multiply3_1__0, 32*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorA_17__multiply3_1__0 
		sendEnd(); // Core2 > Core3: splitTensorA_17__multiply3_1__0 
		cache_wbInv(splitTensorA_17__multiply1_1__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorA_17__multiply1_1__0 
		sendEnd(); // Core2 > Core1: splitTensorA_17__multiply1_1__0 
		cache_wbInv(splitTensorA_17__multiply0_1__0, 32*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorA_17__multiply0_1__0 
		sendEnd(); // Core2 > Core0: splitTensorA_17__multiply0_1__0 
		receiveStart(); // Core5 > Core2: splitTensorA_18__multiply2_1__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_18__multiply2_1__0 
		cache_inv(splitTensorA_18__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorA_19__multiply2_1__0 
		receiveEnd(7); // Core7 > Core2: splitTensorA_19__multiply2_1__0 
		cache_inv(splitTensorA_19__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorA_2__multiply2_2__0 
		receiveEnd(4); // Core4 > Core2: splitTensorA_2__multiply2_2__0 
		cache_inv(splitTensorA_2__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_20__multiply2_2__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_20__multiply2_2__0 
		cache_inv(splitTensorA_20__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorA_21__multiply2_2__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_21__multiply2_2__0 
		cache_inv(splitTensorA_21__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorA_22__multiply2_2__0 
		receiveEnd(1); // Core1 > Core2: splitTensorA_22__multiply2_2__0 
		cache_inv(splitTensorA_22__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorA_23__multiply2_2__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_23__multiply2_2__0 
		cache_inv(splitTensorA_23__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorA_24__multiply2_2__0 
		receiveEnd(6); // Core6 > Core2: splitTensorA_24__multiply2_2__0 
		cache_inv(splitTensorA_24__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorA_25__multiply2_2__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_25__multiply2_2__0 
		cache_inv(splitTensorA_25__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorA_26__multiply2_2__0 
		receiveEnd(1); // Core1 > Core2: splitTensorA_26__multiply2_2__0 
		cache_inv(splitTensorA_26__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorA_27__multiply2_2__0 
		receiveEnd(1); // Core1 > Core2: splitTensorA_27__multiply2_2__0 
		cache_inv(splitTensorA_27__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_28__multiply2_2__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_28__multiply2_2__0 
		cache_inv(splitTensorA_28__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_29__multiply2_2__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_29__multiply2_2__0 
		cache_inv(splitTensorA_29__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorA_3__multiply2_3__0 
		receiveEnd(6); // Core6 > Core2: splitTensorA_3__multiply2_3__0 
		cache_inv(splitTensorA_3__multiply2_3__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_30__multiply2_3__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_30__multiply2_3__0 
		cache_inv(splitTensorA_30__multiply2_3__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: splitTensorA_31__multiply2_3__0 
		receiveEnd(0); // Core0 > Core2: splitTensorA_31__multiply2_3__0 
		cache_inv(splitTensorA_31__multiply2_3__0, 32*sizeof(char));
		splitA(8/*rowsA*/,8/*columnsA*/,arrayA_256__input__0,output0__inputA__13,output1__inputA__5,output2__inputA__9,output3__inputA__28,output4__inputA__11,output5__inputA__13,output6__inputA__23,output7__inputA__15); // splitTensorA_4
		cache_inv(arrayA_256__input__0, 64*sizeof(int));
		cache_wbInv(splitTensorA_4__multiply7_4__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorA_4__multiply7_4__0 
		sendEnd(); // Core2 > Core7: splitTensorA_4__multiply7_4__0 
		cache_wbInv(splitTensorA_4__multiply6_4__0, 32*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorA_4__multiply6_4__0 
		sendEnd(); // Core2 > Core6: splitTensorA_4__multiply6_4__0 
		cache_wbInv(splitTensorA_4__multiply5_4__0, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorA_4__multiply5_4__0 
		sendEnd(); // Core2 > Core5: splitTensorA_4__multiply5_4__0 
		cache_wbInv(splitTensorA_4__multiply4_4__0, 32*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorA_4__multiply4_4__0 
		sendEnd(); // Core2 > Core4: splitTensorA_4__multiply4_4__0 
		cache_wbInv(splitTensorA_4__multiply3_4__0, 32*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorA_4__multiply3_4__0 
		sendEnd(); // Core2 > Core3: splitTensorA_4__multiply3_4__0 
		cache_wbInv(splitTensorA_4__multiply1_4__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorA_4__multiply1_4__0 
		sendEnd(); // Core2 > Core1: splitTensorA_4__multiply1_4__0 
		cache_wbInv(splitTensorA_4__multiply0_4__0, 32*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorA_4__multiply0_4__0 
		sendEnd(); // Core2 > Core0: splitTensorA_4__multiply0_4__0 
		receiveStart(); // Core5 > Core2: splitTensorA_5__multiply2_5__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_5__multiply2_5__0 
		cache_inv(splitTensorA_5__multiply2_5__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorA_6__multiply2_6__0 
		receiveEnd(4); // Core4 > Core2: splitTensorA_6__multiply2_6__0 
		cache_inv(splitTensorA_6__multiply2_6__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_7__multiply2_7__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_7__multiply2_7__0 
		cache_inv(splitTensorA_7__multiply2_7__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorA_8__multiply2_8__0 
		receiveEnd(5); // Core5 > Core2: splitTensorA_8__multiply2_8__0 
		cache_inv(splitTensorA_8__multiply2_8__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorA_9__multiply2_9__0 
		receiveEnd(6); // Core6 > Core2: splitTensorA_9__multiply2_9__0 
		cache_inv(splitTensorA_9__multiply2_9__0, 32*sizeof(char));
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_704__input__0,output__input__21); // transpose_11
		cache_inv(arrayB_704__input__0, 64*sizeof(int));
		cache_wbInv(transpose_11__splitTensorB_1__0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: transpose_11__splitTensorB_1__0 
		sendEnd(); // Core2 > Core7: transpose_11__splitTensorB_1__0 
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_1088__input__0,output__input__10); // transpose_17
		cache_inv(arrayB_1088__input__0, 64*sizeof(int));
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_1152__input__0,output__input__9); // transpose_18
		cache_inv(arrayB_1152__input__0, 64*sizeof(int));
		cache_wbInv(transpose_18__splitTensorB_1__0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: transpose_18__splitTensorB_1__0 
		sendEnd(); // Core2 > Core7: transpose_18__splitTensorB_1__0 
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_1280__input__0,output__input__8); // transpose_20
		cache_inv(arrayB_1280__input__0, 64*sizeof(int));
		cache_wbInv(transpose_20__splitTensorB_2__0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: transpose_20__splitTensorB_2__0 
		sendEnd(); // Core2 > Core7: transpose_20__splitTensorB_2__0 
		receiveStart(); // Core3 > Core2: transpose_21__splitTensorB_2__0 
		receiveEnd(3); // Core3 > Core2: transpose_21__splitTensorB_2__0 
		cache_inv(transpose_21__splitTensorB_2__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: transpose_22__splitTensorB_2__0 
		receiveEnd(3); // Core3 > Core2: transpose_22__splitTensorB_2__0 
		cache_inv(transpose_22__splitTensorB_2__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: transpose_24__splitTensorB_2__0 
		receiveEnd(3); // Core3 > Core2: transpose_24__splitTensorB_2__0 
		cache_inv(transpose_24__splitTensorB_2__0, 256*sizeof(char));
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_384__input__0,output__input__27); // transpose_6
		cache_inv(arrayB_384__input__0, 64*sizeof(int));
		cache_wbInv(transpose_6__splitTensorB_6__0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: transpose_6__splitTensorB_6__0 
		sendEnd(); // Core2 > Core7: transpose_6__splitTensorB_6__0 
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_448__input__0,output__input__12); // transpose_7
		cache_inv(arrayB_448__input__0, 64*sizeof(int));
		cache_wbInv(transpose_7__splitTensorB_7__0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: transpose_7__splitTensorB_7__0 
		sendEnd(); // Core2 > Core7: transpose_7__splitTensorB_7__0 
		transpose(8/*rowsB*/,8/*columnsB*/,arrayB_512__input__0,output__input__11); // transpose_8
		cache_inv(arrayB_512__input__0, 64*sizeof(int));
		cache_wbInv(transpose_8__splitTensorB_8__0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: transpose_8__splitTensorB_8__0 
		sendEnd(); // Core2 > Core7: transpose_8__splitTensorB_8__0 
		receiveStart(); // Core1 > Core2: splitTensorB_0__multiply2_0__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_0__multiply2_0__0 
		cache_inv(splitTensorB_0__multiply2_0__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorB_1__multiply2_1__0 
		receiveEnd(4); // Core4 > Core2: splitTensorB_1__multiply2_1__0 
		cache_inv(splitTensorB_1__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorB_10__multiply2_1__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_10__multiply2_1__0 
		cache_inv(splitTensorB_10__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_11__multiply2_1__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_11__multiply2_1__0 
		cache_inv(splitTensorB_11__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_12__multiply2_1__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_12__multiply2_1__0 
		cache_inv(splitTensorB_12__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorB_13__multiply2_1__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_13__multiply2_1__0 
		cache_inv(splitTensorB_13__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorB_14__multiply2_1__0 
		receiveEnd(4); // Core4 > Core2: splitTensorB_14__multiply2_1__0 
		cache_inv(splitTensorB_14__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorB_15__multiply2_1__0 
		receiveEnd(4); // Core4 > Core2: splitTensorB_15__multiply2_1__0 
		cache_inv(splitTensorB_15__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core3 > Core2: splitTensorB_16__multiply2_1__0 
		receiveEnd(3); // Core3 > Core2: splitTensorB_16__multiply2_1__0 
		cache_inv(splitTensorB_16__multiply2_1__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__10,output0__inputB__4,output1__inputB__8,output2__inputB__28,output3__inputB__16,output4__inputB__12,output5__inputB__28,output6__inputB__20,output7__inputB__8); // splitTensorB_17
		cache_inv(output__input__10, 64*sizeof(int));
		cache_wbInv(splitTensorB_17__multiply7_1__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorB_17__multiply7_1__0 
		sendEnd(); // Core2 > Core7: splitTensorB_17__multiply7_1__0 
		cache_wbInv(splitTensorB_17__multiply6_1__0, 32*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorB_17__multiply6_1__0 
		sendEnd(); // Core2 > Core6: splitTensorB_17__multiply6_1__0 
		cache_wbInv(splitTensorB_17__multiply5_1__0, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorB_17__multiply5_1__0 
		sendEnd(); // Core2 > Core5: splitTensorB_17__multiply5_1__0 
		cache_wbInv(splitTensorB_17__multiply4_1__0, 32*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorB_17__multiply4_1__0 
		sendEnd(); // Core2 > Core4: splitTensorB_17__multiply4_1__0 
		cache_wbInv(splitTensorB_17__multiply3_1__0, 32*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorB_17__multiply3_1__0 
		sendEnd(); // Core2 > Core3: splitTensorB_17__multiply3_1__0 
		cache_wbInv(splitTensorB_17__multiply1_1__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorB_17__multiply1_1__0 
		sendEnd(); // Core2 > Core1: splitTensorB_17__multiply1_1__0 
		cache_wbInv(splitTensorB_17__multiply0_1__0, 32*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorB_17__multiply0_1__0 
		sendEnd(); // Core2 > Core0: splitTensorB_17__multiply0_1__0 
		receiveStart(); // Core7 > Core2: splitTensorB_18__multiply2_1__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_18__multiply2_1__0 
		cache_inv(splitTensorB_18__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorB_19__multiply2_1__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_19__multiply2_1__0 
		cache_inv(splitTensorB_19__multiply2_1__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core2: splitTensorB_2__multiply2_2__0 
		receiveEnd(4); // Core4 > Core2: splitTensorB_2__multiply2_2__0 
		cache_inv(splitTensorB_2__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_20__multiply2_2__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_20__multiply2_2__0 
		cache_inv(splitTensorB_20__multiply2_2__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__30,output0__inputB__10,output1__inputB__12,output2__inputB__16,output3__inputB__7,output4__inputB__19,output5__inputB__19,output6__inputB__3,output7__inputB__0); // splitTensorB_21
		cache_inv(output__input__30, 64*sizeof(int));
		cache_wbInv(splitTensorB_21__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorB_21__multiply7_2__0 
		sendEnd(); // Core2 > Core7: splitTensorB_21__multiply7_2__0 
		cache_wbInv(splitTensorB_21__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorB_21__multiply6_2__0 
		sendEnd(); // Core2 > Core6: splitTensorB_21__multiply6_2__0 
		cache_wbInv(splitTensorB_21__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorB_21__multiply5_2__0 
		sendEnd(); // Core2 > Core5: splitTensorB_21__multiply5_2__0 
		cache_wbInv(splitTensorB_21__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorB_21__multiply4_2__0 
		sendEnd(); // Core2 > Core4: splitTensorB_21__multiply4_2__0 
		cache_wbInv(splitTensorB_21__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorB_21__multiply3_2__0 
		sendEnd(); // Core2 > Core3: splitTensorB_21__multiply3_2__0 
		cache_wbInv(splitTensorB_21__multiply1_2__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorB_21__multiply1_2__0 
		sendEnd(); // Core2 > Core1: splitTensorB_21__multiply1_2__0 
		cache_wbInv(splitTensorB_21__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorB_21__multiply0_2__0 
		sendEnd(); // Core2 > Core0: splitTensorB_21__multiply0_2__0 
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__20,output0__inputB__1,output1__inputB__27,output2__inputB__4,output3__inputB__18,output4__inputB__31,output5__inputB__24,output6__inputB__9,output7__inputB__9); // splitTensorB_22
		cache_inv(output__input__20, 64*sizeof(int));
		cache_wbInv(splitTensorB_22__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorB_22__multiply7_2__0 
		sendEnd(); // Core2 > Core7: splitTensorB_22__multiply7_2__0 
		cache_wbInv(splitTensorB_22__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorB_22__multiply6_2__0 
		sendEnd(); // Core2 > Core6: splitTensorB_22__multiply6_2__0 
		cache_wbInv(splitTensorB_22__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorB_22__multiply5_2__0 
		sendEnd(); // Core2 > Core5: splitTensorB_22__multiply5_2__0 
		cache_wbInv(splitTensorB_22__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorB_22__multiply4_2__0 
		sendEnd(); // Core2 > Core4: splitTensorB_22__multiply4_2__0 
		cache_wbInv(splitTensorB_22__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorB_22__multiply3_2__0 
		sendEnd(); // Core2 > Core3: splitTensorB_22__multiply3_2__0 
		cache_wbInv(splitTensorB_22__multiply1_2__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorB_22__multiply1_2__0 
		sendEnd(); // Core2 > Core1: splitTensorB_22__multiply1_2__0 
		cache_wbInv(splitTensorB_22__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorB_22__multiply0_2__0 
		sendEnd(); // Core2 > Core0: splitTensorB_22__multiply0_2__0 
		receiveStart(); // Core0 > Core2: splitTensorB_23__multiply2_2__0 
		receiveEnd(0); // Core0 > Core2: splitTensorB_23__multiply2_2__0 
		cache_inv(splitTensorB_23__multiply2_2__0, 32*sizeof(char));
		splitB(8/*rowsB*/,8/*columnsB*/,output__input__24,output0__inputB__7,output1__inputB__15,output2__inputB__7,output3__inputB__15,output4__inputB__6,output5__inputB__7,output6__inputB__30,output7__inputB__10); // splitTensorB_24
		cache_inv(output__input__24, 64*sizeof(int));
		cache_wbInv(splitTensorB_24__multiply7_2__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: splitTensorB_24__multiply7_2__0 
		sendEnd(); // Core2 > Core7: splitTensorB_24__multiply7_2__0 
		cache_wbInv(splitTensorB_24__multiply6_2__0, 32*sizeof(char));
		sendStart(6); // Core2 > Core6: splitTensorB_24__multiply6_2__0 
		sendEnd(); // Core2 > Core6: splitTensorB_24__multiply6_2__0 
		cache_wbInv(splitTensorB_24__multiply5_2__0, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: splitTensorB_24__multiply5_2__0 
		sendEnd(); // Core2 > Core5: splitTensorB_24__multiply5_2__0 
		cache_wbInv(splitTensorB_24__multiply4_2__0, 32*sizeof(char));
		sendStart(4); // Core2 > Core4: splitTensorB_24__multiply4_2__0 
		sendEnd(); // Core2 > Core4: splitTensorB_24__multiply4_2__0 
		cache_wbInv(splitTensorB_24__multiply3_2__0, 32*sizeof(char));
		sendStart(3); // Core2 > Core3: splitTensorB_24__multiply3_2__0 
		sendEnd(); // Core2 > Core3: splitTensorB_24__multiply3_2__0 
		cache_wbInv(splitTensorB_24__multiply1_2__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: splitTensorB_24__multiply1_2__0 
		sendEnd(); // Core2 > Core1: splitTensorB_24__multiply1_2__0 
		cache_wbInv(splitTensorB_24__multiply0_2__0, 32*sizeof(char));
		sendStart(0); // Core2 > Core0: splitTensorB_24__multiply0_2__0 
		sendEnd(); // Core2 > Core0: splitTensorB_24__multiply0_2__0 
		receiveStart(); // Core1 > Core2: splitTensorB_25__multiply2_2__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_25__multiply2_2__0 
		cache_inv(splitTensorB_25__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorB_26__multiply2_2__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_26__multiply2_2__0 
		cache_inv(splitTensorB_26__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorB_27__multiply2_2__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_27__multiply2_2__0 
		cache_inv(splitTensorB_27__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorB_28__multiply2_2__0 
		receiveEnd(6); // Core6 > Core2: splitTensorB_28__multiply2_2__0 
		cache_inv(splitTensorB_28__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: splitTensorB_29__multiply2_2__0 
		receiveEnd(5); // Core5 > Core2: splitTensorB_29__multiply2_2__0 
		cache_inv(splitTensorB_29__multiply2_2__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorB_3__multiply2_3__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_3__multiply2_3__0 
		cache_inv(splitTensorB_3__multiply2_3__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorB_30__multiply2_3__0 
		receiveEnd(6); // Core6 > Core2: splitTensorB_30__multiply2_3__0 
		cache_inv(splitTensorB_30__multiply2_3__0, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: splitTensorB_31__multiply2_3__0 
		receiveEnd(1); // Core1 > Core2: splitTensorB_31__multiply2_3__0 
		cache_inv(splitTensorB_31__multiply2_3__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_4__multiply2_4__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_4__multiply2_4__0 
		cache_inv(splitTensorB_4__multiply2_4__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorB_5__multiply2_5__0 
		receiveEnd(6); // Core6 > Core2: splitTensorB_5__multiply2_5__0 
		cache_inv(splitTensorB_5__multiply2_5__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_6__multiply2_6__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_6__multiply2_6__0 
		cache_inv(splitTensorB_6__multiply2_6__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_7__multiply2_7__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_7__multiply2_7__0 
		cache_inv(splitTensorB_7__multiply2_7__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: splitTensorB_8__multiply2_8__0 
		receiveEnd(7); // Core7 > Core2: splitTensorB_8__multiply2_8__0 
		cache_inv(splitTensorB_8__multiply2_8__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: splitTensorB_9__multiply2_9__0 
		receiveEnd(6); // Core6 > Core2: splitTensorB_9__multiply2_9__0 
		cache_inv(splitTensorB_9__multiply2_9__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: multiply0_1__sum_1__0 
		receiveEnd(0); // Core0 > Core2: multiply0_1__sum_1__0 
		cache_inv(multiply0_1__sum_1__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: multiply0_17__sum_17__0 
		receiveEnd(0); // Core0 > Core2: multiply0_17__sum_17__0 
		cache_inv(multiply0_17__sum_17__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: multiply1_1__sum_1__0 
		receiveEnd(1); // Core1 > Core2: multiply1_1__sum_1__0 
		cache_inv(multiply1_1__sum_1__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: multiply1_17__sum_17__0 
		receiveEnd(1); // Core1 > Core2: multiply1_17__sum_17__0 
		cache_inv(multiply1_17__sum_17__0, 256*sizeof(char));
		multiply(8/*rows*/,8/*columns*/,output2__inputA__3,output2__inputB__24,output__input2__25); // multiply2_0
		cache_inv(output2__inputA__3, 8*sizeof(int));
		cache_inv(output2__inputB__24, 8*sizeof(int));
		cache_wbInv(multiply2_0__sum_0__0, 256*sizeof(char));
		sendStart(1); // Core2 > Core1: multiply2_0__sum_0__0 
		sendEnd(); // Core2 > Core1: multiply2_0__sum_0__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__21,output2__inputB__18,output__input2__26); // multiply2_1
		cache_inv(output2__inputA__21, 8*sizeof(int));
		cache_inv(output2__inputB__18, 8*sizeof(int));
		multiply(8/*rows*/,8/*columns*/,output2__inputA__17,output2__inputB__12,output__input2__11); // multiply2_10
		cache_inv(output2__inputA__17, 8*sizeof(int));
		cache_inv(output2__inputB__12, 8*sizeof(int));
		cache_wbInv(multiply2_10__sum_10__0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_10__sum_10__0 
		sendEnd(); // Core2 > Core0: multiply2_10__sum_10__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__11,output2__inputB__21,output__input2__20); // multiply2_11
		cache_inv(output2__inputA__11, 8*sizeof(int));
		cache_inv(output2__inputB__21, 8*sizeof(int));
		cache_wbInv(multiply2_11__sum_11__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiply2_11__sum_11__0 
		sendEnd(); // Core2 > Core6: multiply2_11__sum_11__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__14,output2__inputB__25,output__input2__13); // multiply2_12
		cache_inv(output2__inputA__14, 8*sizeof(int));
		cache_inv(output2__inputB__25, 8*sizeof(int));
		cache_wbInv(multiply2_12__sum_12__0, 256*sizeof(char));
		sendStart(3); // Core2 > Core3: multiply2_12__sum_12__0 
		sendEnd(); // Core2 > Core3: multiply2_12__sum_12__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__29,output2__inputB__3,output__input2__29); // multiply2_13
		cache_inv(output2__inputA__29, 8*sizeof(int));
		cache_inv(output2__inputB__3, 8*sizeof(int));
		cache_wbInv(multiply2_13__sum_13__0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_13__sum_13__0 
		sendEnd(); // Core2 > Core0: multiply2_13__sum_13__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__10,output2__inputB__5,output__input2__6); // multiply2_14
		cache_inv(output2__inputA__10, 8*sizeof(int));
		cache_inv(output2__inputB__5, 8*sizeof(int));
		cache_wbInv(multiply2_14__sum_14__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiply2_14__sum_14__0 
		sendEnd(); // Core2 > Core5: multiply2_14__sum_14__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__20,output2__inputB__14,output__input2__14); // multiply2_15
		cache_inv(output2__inputA__20, 8*sizeof(int));
		cache_inv(output2__inputB__14, 8*sizeof(int));
		cache_wbInv(multiply2_15__sum_15__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiply2_15__sum_15__0 
		sendEnd(); // Core2 > Core5: multiply2_15__sum_15__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__31,output2__inputB__2,output__input2__10); // multiply2_16
		cache_inv(output2__inputA__31, 8*sizeof(int));
		cache_inv(output2__inputB__2, 8*sizeof(int));
		cache_wbInv(multiply2_16__sum_16__0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_16__sum_16__0 
		sendEnd(); // Core2 > Core0: multiply2_16__sum_16__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__2,output2__inputB__28,output__input2__15); // multiply2_17
		cache_inv(output2__inputA__2, 8*sizeof(int));
		cache_inv(output2__inputB__28, 8*sizeof(int));
		multiply(8/*rows*/,8/*columns*/,output2__inputA__4,output2__inputB__19,output__input2__30); // multiply2_18
		cache_inv(output2__inputA__4, 8*sizeof(int));
		cache_inv(output2__inputB__19, 8*sizeof(int));
		cache_wbInv(multiply2_18__sum_18__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiply2_18__sum_18__0 
		sendEnd(); // Core2 > Core6: multiply2_18__sum_18__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__18,output2__inputB__15,output__input2__3); // multiply2_19
		cache_inv(output2__inputA__18, 8*sizeof(int));
		cache_inv(output2__inputB__15, 8*sizeof(int));
		cache_wbInv(multiply2_19__sum_19__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_19__sum_19__0 
		sendEnd(); // Core2 > Core4: multiply2_19__sum_19__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__8,output2__inputB__23,output__input2__9); // multiply2_2
		cache_inv(output2__inputA__8, 8*sizeof(int));
		cache_inv(output2__inputB__23, 8*sizeof(int));
		cache_wbInv(multiply2_2__sum_2__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_2__sum_2__0 
		sendEnd(); // Core2 > Core4: multiply2_2__sum_2__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__7,output2__inputB__22,output__input2__19); // multiply2_20
		cache_inv(output2__inputA__7, 8*sizeof(int));
		cache_inv(output2__inputB__22, 8*sizeof(int));
		cache_wbInv(multiply2_20__sum_20__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiply2_20__sum_20__0 
		sendEnd(); // Core2 > Core6: multiply2_20__sum_20__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__26,output2__inputB__16,output__input2__31); // multiply2_21
		cache_inv(output2__inputA__26, 8*sizeof(int));
		cache_inv(output2__inputB__16, 8*sizeof(int));
		cache_wbInv(multiply2_21__sum_21__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_21__sum_21__0 
		sendEnd(); // Core2 > Core4: multiply2_21__sum_21__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__1,output2__inputB__4,output__input2__28); // multiply2_22
		cache_inv(output2__inputA__1, 8*sizeof(int));
		cache_inv(output2__inputB__4, 8*sizeof(int));
		cache_wbInv(multiply2_22__sum_22__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_22__sum_22__0 
		sendEnd(); // Core2 > Core4: multiply2_22__sum_22__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__16,output2__inputB__17,output__input2__1); // multiply2_23
		cache_inv(output2__inputA__16, 8*sizeof(int));
		cache_inv(output2__inputB__17, 8*sizeof(int));
		cache_wbInv(multiply2_23__sum_23__0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: multiply2_23__sum_23__0 
		sendEnd(); // Core2 > Core7: multiply2_23__sum_23__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__23,output2__inputB__7,output__input2__5); // multiply2_24
		cache_inv(output2__inputA__23, 8*sizeof(int));
		cache_inv(output2__inputB__7, 8*sizeof(int));
		cache_wbInv(multiply2_24__sum_24__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_24__sum_24__0 
		sendEnd(); // Core2 > Core4: multiply2_24__sum_24__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__6,output2__inputB__30,output__input2__24); // multiply2_25
		cache_inv(output2__inputA__6, 8*sizeof(int));
		cache_inv(output2__inputB__30, 8*sizeof(int));
		cache_wbInv(multiply2_25__sum_25__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiply2_25__sum_25__0 
		sendEnd(); // Core2 > Core5: multiply2_25__sum_25__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__0,output2__inputB__11,output__input2__18); // multiply2_26
		cache_inv(output2__inputA__0, 8*sizeof(int));
		cache_inv(output2__inputB__11, 8*sizeof(int));
		cache_wbInv(multiply2_26__sum_26__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_26__sum_26__0 
		sendEnd(); // Core2 > Core4: multiply2_26__sum_26__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__5,output2__inputB__27,output__input2__21); // multiply2_27
		cache_inv(output2__inputA__5, 8*sizeof(int));
		cache_inv(output2__inputB__27, 8*sizeof(int));
		cache_wbInv(multiply2_27__sum_27__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiply2_27__sum_27__0 
		sendEnd(); // Core2 > Core5: multiply2_27__sum_27__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__19,output2__inputB__13,output__input2__17); // multiply2_28
		cache_inv(output2__inputA__19, 8*sizeof(int));
		cache_inv(output2__inputB__13, 8*sizeof(int));
		cache_wbInv(multiply2_28__sum_28__0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_28__sum_28__0 
		sendEnd(); // Core2 > Core0: multiply2_28__sum_28__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__30,output2__inputB__20,output__input2__4); // multiply2_29
		cache_inv(output2__inputA__30, 8*sizeof(int));
		cache_inv(output2__inputB__20, 8*sizeof(int));
		cache_wbInv(multiply2_29__sum_29__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiply2_29__sum_29__0 
		sendEnd(); // Core2 > Core5: multiply2_29__sum_29__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__27,output2__inputB__9,output__input2__7); // multiply2_3
		cache_inv(output2__inputA__27, 8*sizeof(int));
		cache_inv(output2__inputB__9, 8*sizeof(int));
		cache_wbInv(multiply2_3__sum_3__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_3__sum_3__0 
		sendEnd(); // Core2 > Core4: multiply2_3__sum_3__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__25,output2__inputB__29,output__input2__16); // multiply2_30
		cache_inv(output2__inputA__25, 8*sizeof(int));
		cache_inv(output2__inputB__29, 8*sizeof(int));
		cache_wbInv(multiply2_30__sum_30__0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_30__sum_30__0 
		sendEnd(); // Core2 > Core0: multiply2_30__sum_30__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__24,output2__inputB__26,output__input2__12); // multiply2_31
		cache_inv(output2__inputA__24, 8*sizeof(int));
		cache_inv(output2__inputB__26, 8*sizeof(int));
		cache_wbInv(multiply2_31__sum_31__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiply2_31__sum_31__0 
		sendEnd(); // Core2 > Core4: multiply2_31__sum_31__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__9,output2__inputB__1,output__input2__23); // multiply2_4
		cache_inv(output2__inputA__9, 8*sizeof(int));
		cache_inv(output2__inputB__1, 8*sizeof(int));
		cache_wbInv(multiply2_4__sum_4__0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_4__sum_4__0 
		sendEnd(); // Core2 > Core0: multiply2_4__sum_4__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__12,output2__inputB__10,output__input2__0); // multiply2_5
		cache_inv(output2__inputA__12, 8*sizeof(int));
		cache_inv(output2__inputB__10, 8*sizeof(int));
		cache_wbInv(multiply2_5__sum_5__0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiply2_5__sum_5__0 
		sendEnd(); // Core2 > Core0: multiply2_5__sum_5__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__13,output2__inputB__8,output__input2__2); // multiply2_6
		cache_inv(output2__inputA__13, 8*sizeof(int));
		cache_inv(output2__inputB__8, 8*sizeof(int));
		cache_wbInv(multiply2_6__sum_6__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiply2_6__sum_6__0 
		sendEnd(); // Core2 > Core6: multiply2_6__sum_6__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__28,output2__inputB__31,output__input2__27); // multiply2_7
		cache_inv(output2__inputA__28, 8*sizeof(int));
		cache_inv(output2__inputB__31, 8*sizeof(int));
		cache_wbInv(multiply2_7__sum_7__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiply2_7__sum_7__0 
		sendEnd(); // Core2 > Core6: multiply2_7__sum_7__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__15,output2__inputB__0,output__input2__8); // multiply2_8
		cache_inv(output2__inputA__15, 8*sizeof(int));
		cache_inv(output2__inputB__0, 8*sizeof(int));
		cache_wbInv(multiply2_8__sum_8__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiply2_8__sum_8__0 
		sendEnd(); // Core2 > Core6: multiply2_8__sum_8__0 
		multiply(8/*rows*/,8/*columns*/,output2__inputA__22,output2__inputB__6,output__input2__22); // multiply2_9
		cache_inv(output2__inputA__22, 8*sizeof(int));
		cache_inv(output2__inputB__6, 8*sizeof(int));
		cache_wbInv(multiply2_9__sum_9__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiply2_9__sum_9__0 
		sendEnd(); // Core2 > Core6: multiply2_9__sum_9__0 
		receiveStart(); // Core3 > Core2: multiply3_1__sum_1__0 
		receiveEnd(3); // Core3 > Core2: multiply3_1__sum_1__0 
		cache_inv(multiply3_1__sum_1__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: multiply3_17__sum_17__0 
		receiveEnd(3); // Core3 > Core2: multiply3_17__sum_17__0 
		cache_inv(multiply3_17__sum_17__0, 256*sizeof(char));
		receiveStart(); // Core4 > Core2: multiply4_1__sum_1__0 
		receiveEnd(4); // Core4 > Core2: multiply4_1__sum_1__0 
		cache_inv(multiply4_1__sum_1__0, 256*sizeof(char));
		receiveStart(); // Core4 > Core2: multiply4_17__sum_17__0 
		receiveEnd(4); // Core4 > Core2: multiply4_17__sum_17__0 
		cache_inv(multiply4_17__sum_17__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core2: multiply5_1__sum_1__0 
		receiveEnd(5); // Core5 > Core2: multiply5_1__sum_1__0 
		cache_inv(multiply5_1__sum_1__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core2: multiply5_17__sum_17__0 
		receiveEnd(5); // Core5 > Core2: multiply5_17__sum_17__0 
		cache_inv(multiply5_17__sum_17__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core2: multiply6_1__sum_1__0 
		receiveEnd(6); // Core6 > Core2: multiply6_1__sum_1__0 
		cache_inv(multiply6_1__sum_1__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core2: multiply6_17__sum_17__0 
		receiveEnd(6); // Core6 > Core2: multiply6_17__sum_17__0 
		cache_inv(multiply6_17__sum_17__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: multiply7_1__sum_1__0 
		receiveEnd(7); // Core7 > Core2: multiply7_1__sum_1__0 
		cache_inv(multiply7_1__sum_1__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: multiply7_17__sum_17__0 
		receiveEnd(7); // Core7 > Core2: multiply7_17__sum_17__0 
		cache_inv(multiply7_17__sum_17__0, 256*sizeof(char));
		sum(8/*rows*/,8/*columns*/,output__input0__25,output__input1__16,output__input2__26,output__input3__24,output__input4__11,output__input5__25,output__input6__6,output__input7__20,output__arrayC_64__0); // sum_1
		cache_inv(output__input0__25, 64*sizeof(long));
		cache_inv(output__input1__16, 64*sizeof(long));
		cache_inv(output__input2__26, 64*sizeof(long));
		cache_inv(output__input3__24, 64*sizeof(long));
		cache_inv(output__input4__11, 64*sizeof(long));
		cache_inv(output__input5__25, 64*sizeof(long));
		cache_inv(output__input6__6, 64*sizeof(long));
		cache_inv(output__input7__20, 64*sizeof(long));
		cache_wbInv(sum_1__implode_displayResult__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: sum_1__implode_displayResult__0 
		sendEnd(); // Core2 > Core6: sum_1__implode_displayResult__0 
		sum(8/*rows*/,8/*columns*/,output__input0__23,output__input1__21,output__input2__15,output__input3__26,output__input4__5,output__input5__29,output__input6__27,output__input7__16,output__arrayC_1088__0); // sum_17
		cache_inv(output__input0__23, 64*sizeof(long));
		cache_inv(output__input1__21, 64*sizeof(long));
		cache_inv(output__input2__15, 64*sizeof(long));
		cache_inv(output__input3__26, 64*sizeof(long));
		cache_inv(output__input4__5, 64*sizeof(long));
		cache_inv(output__input5__29, 64*sizeof(long));
		cache_inv(output__input6__27, 64*sizeof(long));
		cache_inv(output__input7__16, 64*sizeof(long));
		cache_wbInv(sum_17__implode_displayResul__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: sum_17__implode_displayResul__0 
		sendEnd(); // Core2 > Core6: sum_17__implode_displayResul__0 
	}
}
