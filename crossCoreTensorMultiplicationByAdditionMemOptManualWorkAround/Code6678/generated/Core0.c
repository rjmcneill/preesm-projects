/** 
 * @file Core0.c
 * @generated by C6678CPrinter
 * @date Sun Apr 19 17:17:02 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration

// Core Global Definitions
// Won't work if the shared memory is >= 512 MB 
#pragma DATA_SECTION(SharedMem, ".mySharedMem")
char SharedMem[75104520]; //  size:= 75104520*char
char *const multiply4_0__sum_0__0 = (char*) (SharedMem+18874624);  // multiply4_0 > sum_0 size:= 1048576*char
char *const multiply5_2__sum_2__0 = (char*) (SharedMem+39846144);  // multiply5_2 > sum_2 size:= 1048576*char
char *const splitTensorB_3__multiply4_3__0 = (char*) (SharedMem+52822272);  // splitTensorB_3 > multiply4_3 size:= 131072*char
char *const splitTensorA_5__multiply7_5__0 = (char*) (SharedMem+62914816);  // splitTensorA_5 > multiply7_5 size:= 131072*char
char *const splitTensorB_0__multiply5_0__0 = (char*) (SharedMem+21364992);  // splitTensorB_0 > multiply5_0 size:= 131072*char
char *const multiply2_7__sum_7__0 = (char*) (SharedMem+65011968);  // multiply2_7 > sum_7 size:= 1048576*char
char *const multiply0_3__sum_3__0 = (char*) (SharedMem+41943296);  // multiply0_3 > sum_3 size:= 1048576*char
char *const multiply6_4__sum_4__0 = (char*) (SharedMem+11534464);  // multiply6_4 > sum_4 size:= 1048576*char
char *const splitTensorA_2__multiply0_2__0 = (char*) (SharedMem+41943296);  // splitTensorA_2 > multiply0_2 size:= 131072*char
char *const splitTensorB_4__multiply0_4__0 = (char*) (SharedMem+12583168);  // splitTensorB_4 > multiply0_4 size:= 131072*char
char *const splitTensorA_3__multiply1_3__0 = (char*) (SharedMem+49414400);  // splitTensorA_3 > multiply1_3 size:= 131072*char
char *const sum_7__implode_displayResult__0 = (char*) (SharedMem+73400576);  // sum_7 > implode_displayResult_arrayC size:= 1048576*char
char *const multiply5_5__sum_5__0 = (char*) (SharedMem+53477632);  // multiply5_5 > sum_5 size:= 1048576*char
char *const sum_5__implode_displayResult__0 = (char*) (SharedMem+15728768);  // sum_5 > implode_displayResult_arrayC size:= 1048576*char
char *const multiply4_7__sum_7__0 = (char*) (SharedMem+67109120);  // multiply4_7 > sum_7 size:= 1048576*char
char *const explode_generateTensors_arra__14 = (char*) (SharedMem+128);  // explode_generateTensors_arrayA > splitTensorA_0 size:= 1048576*char
char *const transpose_1__splitTensorB_1__0 = (char*) (SharedMem+16777472);  // transpose_1 > splitTensorB_1 size:= 1048576*char
char *const sum_3__implode_displayResult__0 = (char*) (SharedMem+72352000);  // sum_3 > implode_displayResult_arrayC size:= 1048576*char
char *const splitTensorB_0__multiply1_0__0 = (char*) (SharedMem+28442880);  // splitTensorB_0 > multiply1_0 size:= 131072*char
char *const splitTensorA_1__multiply3_1__0 = (char*) (SharedMem+37880064);  // splitTensorA_1 > multiply3_1 size:= 131072*char
char *const multiply2_5__sum_5__0 = (char*) (SharedMem+50331904);  // multiply2_5 > sum_5 size:= 1048576*char
char *const splitTensorB_5__multiply7_5__0 = (char*) (SharedMem+63045888);  // splitTensorB_5 > multiply7_5 size:= 131072*char
char *const splitTensorA_1__multiply7_1__0 = (char*) (SharedMem+40894720);  // splitTensorA_1 > multiply7_1 size:= 131072*char
char *const multiply5_1__sum_1__0 = (char*) (SharedMem+31457536);  // multiply5_1 > sum_1 size:= 1048576*char
char *const splitTensorA_1__multiply5_1__0 = (char*) (SharedMem+21102848);  // splitTensorA_1 > multiply5_1 size:= 131072*char
char *const splitTensorA_1__multiply1_1__0 = (char*) (SharedMem+35651840);  // splitTensorA_1 > multiply1_1 size:= 131072*char
char *const splitTensorB_5__multiply2_5__0 = (char*) (SharedMem+13631744);  // splitTensorB_5 > multiply2_5 size:= 131072*char
char *const multiply2_2__sum_2__0 = (char*) (SharedMem+36700416);  // multiply2_2 > sum_2 size:= 1048576*char
char *const splitTensorB_1__multiply1_1__0 = (char*) (SharedMem+35782912);  // splitTensorB_1 > multiply1_1 size:= 131072*char
char *const multiply0_4__sum_4__0 = (char*) (SharedMem+3145856);  // multiply0_4 > sum_4 size:= 1048576*char
char *const splitTensorB_6__multiply1_6__0 = (char*) (SharedMem+14680320);  // splitTensorB_6 > multiply1_6 size:= 131072*char
char *const implode_displayResult_arrayC__0 = (char*) (SharedMem+128);  // implode_displayResult_arrayC > displayResult size:= 8388608*char
char *const splitTensorB_3__multiply1_3__0 = (char*) (SharedMem+49676544);  // splitTensorB_3 > multiply1_3 size:= 131072*char
char *const multiply0_1__sum_1__0 = (char*) (SharedMem+27263232);  // multiply0_1 > sum_1 size:= 1048576*char
char *const splitTensorA_0__multiply7_0__0 = (char*) (SharedMem+33554688);  // splitTensorA_0 > multiply7_0 size:= 131072*char
char *const splitTensorA_3__multiply4_3__0 = (char*) (SharedMem+52560128);  // splitTensorA_3 > multiply4_3 size:= 131072*char
char *const splitTensorA_7__multiply4_7__0 = (char*) (SharedMem+73924864);  // splitTensorA_7 > multiply4_7 size:= 131072*char
char *const splitTensorA_0__multiply1_0__0 = (char*) (SharedMem+28311808);  // splitTensorA_0 > multiply1_0 size:= 131072*char
char *const multiply5_0__sum_0__0 = (char*) (SharedMem+24117504);  // multiply5_0 > sum_0 size:= 1048576*char
char *const splitTensorB_4__multiply6_4__0 = (char*) (SharedMem+54788352);  // splitTensorB_4 > multiply6_4 size:= 131072*char
char *const transpose_7__splitTensorB_7__0 = (char*) (SharedMem+6291584);  // transpose_7 > splitTensorB_7 size:= 1048576*char
char *const multiply4_1__sum_1__0 = (char*) (SharedMem+30408960);  // multiply4_1 > sum_1 size:= 1048576*char
char *const multiply4_3__sum_3__0 = (char*) (SharedMem+46137600);  // multiply4_3 > sum_3 size:= 1048576*char
char *const explode_generateTensors_arra__4 = (char*) (SharedMem+3145856);  // explode_generateTensors_arrayA > splitTensorA_3 size:= 1048576*char
char *const multiply6_3__sum_3__0 = (char*) (SharedMem+47186176);  // multiply6_3 > sum_3 size:= 1048576*char
char *const transpose_2__splitTensorB_2__0 = (char*) (SharedMem+2097280);  // transpose_2 > splitTensorB_2 size:= 1048576*char
char *const explode_generateTensors_arra__11 = (char*) (SharedMem+9437440);  // explode_generateTensors_arrayB > transpose_1 size:= 1048576*char
char *const multiply0_5__sum_5__0 = (char*) (SharedMem+12583040);  // multiply0_5 > sum_5 size:= 1048576*char
char *const splitTensorA_3__multiply2_3__0 = (char*) (SharedMem+50462976);  // splitTensorA_3 > multiply2_3 size:= 131072*char
char *const splitTensorA_7__multiply5_7__0 = (char*) (SharedMem+72352000);  // splitTensorA_7 > multiply5_7 size:= 131072*char
char *const splitTensorA_2__multiply2_2__0 = (char*) (SharedMem+44040448);  // splitTensorA_2 > multiply2_2 size:= 131072*char
char *const splitTensorB_0__multiply4_0__0 = (char*) (SharedMem+30540032);  // splitTensorB_0 > multiply4_0 size:= 131072*char
char *const multiply3_1__sum_1__0 = (char*) (SharedMem+16777472);  // multiply3_1 > sum_1 size:= 1048576*char
char *const multiply7_3__sum_3__0 = (char*) (SharedMem+48234752);  // multiply7_3 > sum_3 size:= 1048576*char
char *const splitTensorB_6__multiply4_6__0 = (char*) (SharedMem+67240192);  // splitTensorB_6 > multiply4_6 size:= 131072*char
char *const explode_generateTensors_arra__1 = (char*) (SharedMem+7340160);  // explode_generateTensors_arrayA > splitTensorA_7 size:= 1048576*char
char *const splitTensorA_2__multiply7_2__0 = (char*) (SharedMem+48234752);  // splitTensorA_2 > multiply7_2 size:= 131072*char
char *const splitTensorA_2__multiply5_2__0 = (char*) (SharedMem+21233920);  // splitTensorA_2 > multiply5_2 size:= 131072*char
char *const multiply3_7__sum_7__0 = (char*) (SharedMem+66060544);  // multiply3_7 > sum_7 size:= 1048576*char
char *const splitTensorA_6__multiply4_6__0 = (char*) (SharedMem+67109120);  // splitTensorA_6 > multiply4_6 size:= 131072*char
char *const splitTensorB_6__multiply2_6__0 = (char*) (SharedMem+65274112);  // splitTensorB_6 > multiply2_6 size:= 131072*char
char *const explode_generateTensors_arra__0 = (char*) (SharedMem+1048704);  // explode_generateTensors_arrayA > splitTensorA_1 size:= 1048576*char
char *const splitTensorB_7__multiply0_7__0 = (char*) (SharedMem+74318080);  // splitTensorB_7 > multiply0_7 size:= 131072*char
char *const splitTensorA_5__multiply4_5__0 = (char*) (SharedMem+59769088);  // splitTensorA_5 > multiply4_5 size:= 131072*char
char *const splitTensorB_1__multiply0_1__0 = (char*) (SharedMem+34734336);  // splitTensorB_1 > multiply0_1 size:= 131072*char
char *const splitTensorA_2__multiply6_2__0 = (char*) (SharedMem+47186176);  // splitTensorA_2 > multiply6_2 size:= 131072*char
char *const transpose_3__splitTensorB_3__0 = (char*) (SharedMem+3145856);  // transpose_3 > splitTensorB_3 size:= 1048576*char
char *const splitTensorB_7__multiply7_7__0 = (char*) (SharedMem+74973440);  // splitTensorB_7 > multiply7_7 size:= 131072*char
char *const splitTensorB_3__multiply5_3__0 = (char*) (SharedMem+53870848);  // splitTensorB_3 > multiply5_3 size:= 131072*char
char *const splitTensorB_6__multiply5_6__0 = (char*) (SharedMem+68288768);  // splitTensorB_6 > multiply5_6 size:= 131072*char
char *const explode_generateTensors_arra__10 = (char*) (SharedMem+13631744);  // explode_generateTensors_arrayB > transpose_5 size:= 1048576*char
char *const multiply3_5__sum_5__0 = (char*) (SharedMem+51380480);  // multiply3_5 > sum_5 size:= 1048576*char
char *const multiply7_5__sum_5__0 = (char*) (SharedMem+55574784);  // multiply7_5 > sum_5 size:= 1048576*char
char *const splitTensorA_6__multiply0_6__0 = (char*) (SharedMem+63963392);  // splitTensorA_6 > multiply0_6 size:= 131072*char
char *const splitTensorA_5__multiply6_5__0 = (char*) (SharedMem+61866240);  // splitTensorA_5 > multiply6_5 size:= 131072*char
char *const splitTensorA_2__multiply1_2__0 = (char*) (SharedMem+42991872);  // splitTensorA_2 > multiply1_2 size:= 131072*char
char *const splitTensorB_1__multiply5_1__0 = (char*) (SharedMem+21496064);  // splitTensorB_1 > multiply5_1 size:= 131072*char
char *const multiply1_5__sum_5__0 = (char*) (SharedMem+49283328);  // multiply1_5 > sum_5 size:= 1048576*char
char *const splitTensorA_1__multiply0_1__0 = (char*) (SharedMem+34603264);  // splitTensorA_1 > multiply0_1 size:= 131072*char
char *const splitTensorB_2__multiply1_2__0 = (char*) (SharedMem+5243008);  // splitTensorB_2 > multiply1_2 size:= 131072*char
char *const explode_generateTensors_arra__3 = (char*) (SharedMem+4194432);  // explode_generateTensors_arrayA > splitTensorA_4 size:= 1048576*char
char *const multiply1_3__sum_3__0 = (char*) (SharedMem+42991872);  // multiply1_3 > sum_3 size:= 1048576*char
char *const transpose_5__splitTensorB_5__0 = (char*) (SharedMem+4194432);  // transpose_5 > splitTensorB_5 size:= 1048576*char
char *const multiply1_6__sum_6__0 = (char*) (SharedMem+57671936);  // multiply1_6 > sum_6 size:= 1048576*char
char *const splitTensorB_7__multiply2_7__0 = (char*) (SharedMem+74580224);  // splitTensorB_7 > multiply2_7 size:= 131072*char
char *const multiply2_0__sum_0__0 = (char*) (SharedMem+17826048);  // multiply2_0 > sum_0 size:= 1048576*char
char *const splitTensorB_0__multiply3_0__0 = (char*) (SharedMem+8388736);  // splitTensorB_0 > multiply3_0 size:= 131072*char
char *const splitTensorB_7__multiply4_7__0 = (char*) (SharedMem+74711296);  // splitTensorB_7 > multiply4_7 size:= 131072*char
char *const splitTensorA_7__multiply2_7__0 = (char*) (SharedMem+73793792);  // splitTensorA_7 > multiply2_7 size:= 131072*char
char *const multiply1_1__sum_1__0 = (char*) (SharedMem+28311808);  // multiply1_1 > sum_1 size:= 1048576*char
char *const multiply6_6__sum_6__0 = (char*) (SharedMem+61866240);  // multiply6_6 > sum_6 size:= 1048576*char
char *const splitTensorA_0__multiply4_0__0 = (char*) (SharedMem+30408960);  // splitTensorA_0 > multiply4_0 size:= 131072*char
char *const generateTensors__explode_gen__1 = (char*) (SharedMem+8388864);  // generateTensors > explode_generateTensors_arrayB size:= 8388608*char
char *const transpose_6__splitTensorB_6__0 = (char*) (SharedMem+17826048);  // transpose_6 > splitTensorB_6 size:= 1048576*char
char *const multiply4_2__sum_2__0 = (char*) (SharedMem+38797568);  // multiply4_2 > sum_2 size:= 1048576*char
char *const splitTensorB_2__multiply6_2__0 = (char*) (SharedMem+47317248);  // splitTensorB_2 > multiply6_2 size:= 131072*char
char *const splitTensorA_3__multiply0_3__0 = (char*) (SharedMem+56754432);  // splitTensorA_3 > multiply0_3 size:= 131072*char
char *const splitTensorA_0__multiply6_0__0 = (char*) (SharedMem+19923200);  // splitTensorA_0 > multiply6_0 size:= 131072*char
char *const splitTensorB_4__multiply5_4__0 = (char*) (SharedMem+53739776);  // splitTensorB_4 > multiply5_4 size:= 131072*char
char *const splitTensorB_4__multiply1_4__0 = (char*) (SharedMem+49545472);  // splitTensorB_4 > multiply1_4 size:= 131072*char
char *const multiply5_4__sum_4__0 = (char*) (SharedMem+10485888);  // multiply5_4 > sum_4 size:= 1048576*char
char *const splitTensorA_7__multiply7_7__0 = (char*) (SharedMem+74187008);  // splitTensorA_7 > multiply7_7 size:= 131072*char
char *const splitTensorA_4__multiply3_4__0 = (char*) (SharedMem+51380480);  // splitTensorA_4 > multiply3_4 size:= 131072*char
char *const splitTensorA_5__multiply0_5__0 = (char*) (SharedMem+56885504);  // splitTensorA_5 > multiply0_5 size:= 131072*char
char *const multiply4_4__sum_4__0 = (char*) (SharedMem+9437312);  // multiply4_4 > sum_4 size:= 1048576*char
char *const splitTensorA_6__multiply2_6__0 = (char*) (SharedMem+65143040);  // splitTensorA_6 > multiply2_6 size:= 131072*char
char *const splitTensorB_7__multiply6_7__0 = (char*) (SharedMem+74842368);  // splitTensorB_7 > multiply6_7 size:= 131072*char
char *const splitTensorB_0__multiply7_0__0 = (char*) (SharedMem+33685760);  // splitTensorB_0 > multiply7_0 size:= 131072*char
char *const splitTensorA_7__multiply1_7__0 = (char*) (SharedMem+73662720);  // splitTensorA_7 > multiply1_7 size:= 131072*char
char *const splitTensorA_1__multiply2_1__0 = (char*) (SharedMem+36700416);  // splitTensorA_1 > multiply2_1 size:= 131072*char
char *const splitTensorB_2__multiply7_2__0 = (char*) (SharedMem+48365824);  // splitTensorB_2 > multiply7_2 size:= 131072*char
char *const splitTensorA_5__multiply2_5__0 = (char*) (SharedMem+65011968);  // splitTensorA_5 > multiply2_5 size:= 131072*char
char *const multiply2_3__sum_3__0 = (char*) (SharedMem+44040448);  // multiply2_3 > sum_3 size:= 1048576*char
char *const splitTensorA_1__multiply4_1__0 = (char*) (SharedMem+38797568);  // splitTensorA_1 > multiply4_1 size:= 131072*char
char *const splitTensorA_4__multiply0_4__0 = (char*) (SharedMem+56623360);  // splitTensorA_4 > multiply0_4 size:= 131072*char
char *const splitTensorA_4__multiply1_4__0 = (char*) (SharedMem+49283328);  // splitTensorA_4 > multiply1_4 size:= 131072*char
char *const splitTensorA_3__multiply5_3__0 = (char*) (SharedMem+53608704);  // splitTensorA_3 > multiply5_3 size:= 131072*char
char *const generateTensors__displayResu__0 = (char*) (SharedMem+75104512);  // generateTensors > displayResult size:= 8*char
char *const multiply0_2__sum_2__0 = (char*) (SharedMem+34603264);  // multiply0_2 > sum_2 size:= 1048576*char
char *const multiply0_6__sum_6__0 = (char*) (SharedMem+56623360);  // multiply0_6 > sum_6 size:= 1048576*char
char *const multiply3_0__sum_0__0 = (char*) (SharedMem+23068928);  // multiply3_0 > sum_0 size:= 1048576*char
char *const splitTensorB_0__multiply0_0__0 = (char*) (SharedMem+27394304);  // splitTensorB_0 > multiply0_0 size:= 131072*char
char *const splitTensorB_1__multiply7_1__0 = (char*) (SharedMem+41025792);  // splitTensorB_1 > multiply7_1 size:= 131072*char
char *const splitTensorA_6__multiply7_6__0 = (char*) (SharedMem+70254848);  // splitTensorA_6 > multiply7_6 size:= 131072*char
char *const splitTensorA_0__multiply3_0__0 = (char*) (SharedMem+37748992);  // splitTensorA_0 > multiply3_0 size:= 131072*char
char *const multiply7_4__sum_4__0 = (char*) (SharedMem+1048704);  // multiply7_4 > sum_4 size:= 1048576*char
char *const explode_generateTensors_arra__9 = (char*) (SharedMem+8388864);  // explode_generateTensors_arrayB > transpose_0 size:= 1048576*char
char *const splitTensorA_7__multiply3_7__0 = (char*) (SharedMem+71303424);  // splitTensorA_7 > multiply3_7 size:= 131072*char
char *const multiply3_6__sum_6__0 = (char*) (SharedMem+58720512);  // multiply3_6 > sum_6 size:= 1048576*char
char *const splitTensorB_6__multiply6_6__0 = (char*) (SharedMem+69337344);  // splitTensorB_6 > multiply6_6 size:= 131072*char
char *const sum_2__implode_displayResult__0 = (char*) (SharedMem+2097280);  // sum_2 > implode_displayResult_arrayC size:= 1048576*char
char *const splitTensorB_2__multiply0_2__0 = (char*) (SharedMem+42074368);  // splitTensorB_2 > multiply0_2 size:= 131072*char
char *const splitTensorA_7__multiply0_7__0 = (char*) (SharedMem+73531648);  // splitTensorA_7 > multiply0_7 size:= 131072*char
char *const explode_generateTensors_arra__13 = (char*) (SharedMem+2097280);  // explode_generateTensors_arrayA > splitTensorA_2 size:= 1048576*char
char *const sum_4__implode_displayResult__0 = (char*) (SharedMem+4194432);  // sum_4 > implode_displayResult_arrayC size:= 1048576*char
char *const splitTensorB_5__multiply5_5__0 = (char*) (SharedMem+60948736);  // splitTensorB_5 > multiply5_5 size:= 131072*char
char *const splitTensorB_5__multiply6_5__0 = (char*) (SharedMem+61997312);  // splitTensorB_5 > multiply6_5 size:= 131072*char
char *const multiply3_4__sum_4__0 = (char*) (SharedMem+8388736);  // multiply3_4 > sum_4 size:= 1048576*char
char *const splitTensorA_4__multiply2_4__0 = (char*) (SharedMem+50331904);  // splitTensorA_4 > multiply2_4 size:= 131072*char
char *const splitTensorA_6__multiply5_6__0 = (char*) (SharedMem+68157696);  // splitTensorA_6 > multiply5_6 size:= 131072*char
char *const splitTensorA_3__multiply7_3__0 = (char*) (SharedMem+55705856);  // splitTensorA_3 > multiply7_3 size:= 131072*char
char *const multiply2_4__sum_4__0 = (char*) (SharedMem+7340160);  // multiply2_4 > sum_4 size:= 1048576*char
char *const splitTensorA_4__multiply7_4__0 = (char*) (SharedMem+55574784);  // splitTensorA_4 > multiply7_4 size:= 131072*char
char *const splitTensorB_6__multiply3_6__0 = (char*) (SharedMem+66191616);  // splitTensorB_6 > multiply3_6 size:= 131072*char
char *const multiply5_3__sum_3__0 = (char*) (SharedMem+20971776);  // multiply5_3 > sum_3 size:= 1048576*char
char *const splitTensorA_3__multiply6_3__0 = (char*) (SharedMem+54657280);  // splitTensorA_3 > multiply6_3 size:= 131072*char
char *const explode_generateTensors_arra__12 = (char*) (SharedMem+11534592);  // explode_generateTensors_arrayB > transpose_3 size:= 1048576*char
char *const multiply6_0__sum_0__0 = (char*) (SharedMem+25166080);  // multiply6_0 > sum_0 size:= 1048576*char
char *const multiply7_6__sum_6__0 = (char*) (SharedMem+62914816);  // multiply7_6 > sum_6 size:= 1048576*char
char *const multiply1_0__sum_0__0 = (char*) (SharedMem+15728896);  // multiply1_0 > sum_0 size:= 1048576*char
char *const splitTensorA_6__multiply3_6__0 = (char*) (SharedMem+66060544);  // splitTensorA_6 > multiply3_6 size:= 131072*char
char *const splitTensorA_4__multiply6_4__0 = (char*) (SharedMem+54526208);  // splitTensorA_4 > multiply6_4 size:= 131072*char
char *const multiply0_0__sum_0__0 = (char*) (SharedMem+22020352);  // multiply0_0 > sum_0 size:= 1048576*char
char *const splitTensorB_2__multiply3_2__0 = (char*) (SharedMem+45220096);  // splitTensorB_2 > multiply3_2 size:= 131072*char
char *const splitTensorB_0__multiply2_0__0 = (char*) (SharedMem+29491456);  // splitTensorB_0 > multiply2_0 size:= 131072*char
char *const multiply6_1__sum_1__0 = (char*) (SharedMem+32506112);  // multiply6_1 > sum_1 size:= 1048576*char
char *const multiply5_7__sum_7__0 = (char*) (SharedMem+68157696);  // multiply5_7 > sum_7 size:= 1048576*char
char *const splitTensorB_4__multiply2_4__0 = (char*) (SharedMem+50594048);  // splitTensorB_4 > multiply2_4 size:= 131072*char
char *const splitTensorA_1__multiply6_1__0 = (char*) (SharedMem+20054272);  // splitTensorA_1 > multiply6_1 size:= 131072*char
char *const multiply7_1__sum_1__0 = (char*) (SharedMem+33554688);  // multiply7_1 > sum_1 size:= 1048576*char
char *const sum_6__implode_displayResult__0 = (char*) (SharedMem+6291584);  // sum_6 > implode_displayResult_arrayC size:= 1048576*char
char *const splitTensorB_2__multiply2_2__0 = (char*) (SharedMem+44171520);  // splitTensorB_2 > multiply2_2 size:= 131072*char
char *const sum_1__implode_displayResult__0 = (char*) (SharedMem+71303424);  // sum_1 > implode_displayResult_arrayC size:= 1048576*char
char *const explode_generateTensors_arra__2 = (char*) (SharedMem+14680320);  // explode_generateTensors_arrayB > transpose_6 size:= 1048576*char
char *const multiply2_1__sum_1__0 = (char*) (SharedMem+29360384);  // multiply2_1 > sum_1 size:= 1048576*char
char *const splitTensorB_5__multiply3_5__0 = (char*) (SharedMem+58851584);  // splitTensorB_5 > multiply3_5 size:= 131072*char
char *const multiply6_7__sum_7__0 = (char*) (SharedMem+69206272);  // multiply6_7 > sum_7 size:= 1048576*char
char *const splitTensorB_5__multiply0_5__0 = (char*) (SharedMem+57147648);  // splitTensorB_5 > multiply0_5 size:= 131072*char
char *const splitTensorB_1__multiply3_1__0 = (char*) (SharedMem+38011136);  // splitTensorB_1 > multiply3_1 size:= 131072*char
char *const splitTensorA_3__multiply3_3__0 = (char*) (SharedMem+51511552);  // splitTensorA_3 > multiply3_3 size:= 131072*char
char *const splitTensorB_4__multiply7_4__0 = (char*) (SharedMem+55836928);  // splitTensorB_4 > multiply7_4 size:= 131072*char
char *const splitTensorB_3__multiply6_3__0 = (char*) (SharedMem+11534592);  // splitTensorB_3 > multiply6_3 size:= 131072*char
char *const splitTensorB_1__multiply6_1__0 = (char*) (SharedMem+20316416);  // splitTensorB_1 > multiply6_1 size:= 131072*char
char *const splitTensorA_0__multiply5_0__0 = (char*) (SharedMem+20971776);  // splitTensorA_0 > multiply5_0 size:= 131072*char
char *const explode_generateTensors_arra__6 = (char*) (SharedMem+5243008);  // explode_generateTensors_arrayA > splitTensorA_5 size:= 1048576*char
char *const splitTensorB_6__multiply7_6__0 = (char*) (SharedMem+70385920);  // splitTensorB_6 > multiply7_6 size:= 131072*char
char *const splitTensorB_3__multiply0_3__0 = (char*) (SharedMem+57016576);  // splitTensorB_3 > multiply0_3 size:= 131072*char
char *const splitTensorA_0__multiply0_0__0 = (char*) (SharedMem+27263232);  // splitTensorA_0 > multiply0_0 size:= 131072*char
char *const multiply1_2__sum_2__0 = (char*) (SharedMem+35651840);  // multiply1_2 > sum_2 size:= 1048576*char
char *const splitTensorB_3__multiply2_3__0 = (char*) (SharedMem+50725120);  // splitTensorB_3 > multiply2_3 size:= 131072*char
char *const transpose_4__splitTensorB_4__0 = (char*) (SharedMem+7340160);  // transpose_4 > splitTensorB_4 size:= 1048576*char
char *const multiply4_6__sum_6__0 = (char*) (SharedMem+59769088);  // multiply4_6 > sum_6 size:= 1048576*char
char *const splitTensorA_5__multiply1_5__0 = (char*) (SharedMem+57671936);  // splitTensorA_5 > multiply1_5 size:= 131072*char
char *const splitTensorA_6__multiply1_6__0 = (char*) (SharedMem+73400576);  // splitTensorA_6 > multiply1_6 size:= 131072*char
char *const splitTensorB_4__multiply4_4__0 = (char*) (SharedMem+52691200);  // splitTensorB_4 > multiply4_4 size:= 131072*char
char *const splitTensorB_3__multiply3_3__0 = (char*) (SharedMem+51773696);  // splitTensorB_3 > multiply3_3 size:= 131072*char
char *const splitTensorA_7__multiply6_7__0 = (char*) (SharedMem+74055936);  // splitTensorA_7 > multiply6_7 size:= 131072*char
char *const splitTensorA_0__multiply2_0__0 = (char*) (SharedMem+29360384);  // splitTensorA_0 > multiply2_0 size:= 131072*char
char *const splitTensorB_1__multiply4_1__0 = (char*) (SharedMem+9437440);  // splitTensorB_1 > multiply4_1 size:= 131072*char
char *const splitTensorB_4__multiply3_4__0 = (char*) (SharedMem+51642624);  // splitTensorB_4 > multiply3_4 size:= 131072*char
char *const explode_generateTensors_arra__5 = (char*) (SharedMem+15728896);  // explode_generateTensors_arrayB > transpose_7 size:= 1048576*char
char *const multiply5_6__sum_6__0 = (char*) (SharedMem+60817664);  // multiply5_6 > sum_6 size:= 1048576*char
char *const splitTensorB_2__multiply5_2__0 = (char*) (SharedMem+10486016);  // splitTensorB_2 > multiply5_2 size:= 131072*char
char *const splitTensorA_2__multiply3_2__0 = (char*) (SharedMem+45089024);  // splitTensorA_2 > multiply3_2 size:= 131072*char
char *const multiply3_2__sum_2__0 = (char*) (SharedMem+37748992);  // multiply3_2 > sum_2 size:= 1048576*char
char *const multiply4_5__sum_5__0 = (char*) (SharedMem+52429056);  // multiply4_5 > sum_5 size:= 1048576*char
char *const explode_generateTensors_arra__7 = (char*) (SharedMem+6291584);  // explode_generateTensors_arrayA > splitTensorA_6 size:= 1048576*char
char *const multiply7_7__sum_7__0 = (char*) (SharedMem+70254848);  // multiply7_7 > sum_7 size:= 1048576*char
char *const multiply7_2__sum_2__0 = (char*) (SharedMem+40894720);  // multiply7_2 > sum_2 size:= 1048576*char
char *const splitTensorA_4__multiply4_4__0 = (char*) (SharedMem+52429056);  // splitTensorA_4 > multiply4_4 size:= 131072*char
char *const splitTensorA_2__multiply4_2__0 = (char*) (SharedMem+46137600);  // splitTensorA_2 > multiply4_2 size:= 131072*char
char *const sum_0__implode_displayResult__0 = (char*) (SharedMem+128);  // sum_0 > implode_displayResult_arrayC size:= 1048576*char
char *const multiply6_2__sum_2__0 = (char*) (SharedMem+19923200);  // multiply6_2 > sum_2 size:= 1048576*char
char *const generateTensors__explode_gen__0 = (char*) (SharedMem+128);  // generateTensors > explode_generateTensors_arrayA size:= 8388608*char
char *const splitTensorB_0__multiply6_0__0 = (char*) (SharedMem+20185344);  // splitTensorB_0 > multiply6_0 size:= 131072*char
char *const transpose_0__splitTensorB_0__0 = (char*) (SharedMem+0);  // transpose_0 > splitTensorB_0 size:= 1048576*char
char *const multiply2_6__sum_6__0 = (char*) (SharedMem+13631616);  // multiply2_6 > sum_6 size:= 1048576*char
char *const splitTensorB_2__multiply4_2__0 = (char*) (SharedMem+46268672);  // splitTensorB_2 > multiply4_2 size:= 131072*char
char *const splitTensorA_5__multiply5_5__0 = (char*) (SharedMem+60817664);  // splitTensorA_5 > multiply5_5 size:= 131072*char
char *const splitTensorA_4__multiply5_4__0 = (char*) (SharedMem+53477632);  // splitTensorA_4 > multiply5_4 size:= 131072*char
char *const splitTensorB_6__multiply0_6__0 = (char*) (SharedMem+64094464);  // splitTensorB_6 > multiply0_6 size:= 131072*char
char *const splitTensorB_5__multiply1_5__0 = (char*) (SharedMem+57803008);  // splitTensorB_5 > multiply1_5 size:= 131072*char
char *const multiply1_7__sum_7__0 = (char*) (SharedMem+14680192);  // multiply1_7 > sum_7 size:= 1048576*char
char *const multiply1_4__sum_4__0 = (char*) (SharedMem+5243008);  // multiply1_4 > sum_4 size:= 1048576*char
char *const explode_generateTensors_arra__8 = (char*) (SharedMem+12583168);  // explode_generateTensors_arrayB > transpose_4 size:= 1048576*char
char *const multiply0_7__sum_7__0 = (char*) (SharedMem+63963392);  // multiply0_7 > sum_7 size:= 1048576*char
char *const splitTensorB_3__multiply7_3__0 = (char*) (SharedMem+55968000);  // splitTensorB_3 > multiply7_3 size:= 131072*char
char *const multiply6_5__sum_5__0 = (char*) (SharedMem+54526208);  // multiply6_5 > sum_5 size:= 1048576*char
char *const splitTensorB_7__multiply5_7__0 = (char*) (SharedMem+72483072);  // splitTensorB_7 > multiply5_7 size:= 131072*char
char *const splitTensorB_7__multiply1_7__0 = (char*) (SharedMem+74449152);  // splitTensorB_7 > multiply1_7 size:= 131072*char
char *const multiply3_3__sum_3__0 = (char*) (SharedMem+45089024);  // multiply3_3 > sum_3 size:= 1048576*char
char *const splitTensorB_1__multiply2_1__0 = (char*) (SharedMem+36831488);  // splitTensorB_1 > multiply2_1 size:= 131072*char
char *const splitTensorA_6__multiply6_6__0 = (char*) (SharedMem+69206272);  // splitTensorA_6 > multiply6_6 size:= 131072*char
char *const splitTensorA_5__multiply3_5__0 = (char*) (SharedMem+58720512);  // splitTensorA_5 > multiply3_5 size:= 131072*char
char *const explode_generateTensors_arra__15 = (char*) (SharedMem+10486016);  // explode_generateTensors_arrayB > transpose_2 size:= 1048576*char
char *const splitTensorB_7__multiply3_7__0 = (char*) (SharedMem+71434496);  // splitTensorB_7 > multiply3_7 size:= 131072*char
char *const splitTensorB_5__multiply4_5__0 = (char*) (SharedMem+59900160);  // splitTensorB_5 > multiply4_5 size:= 131072*char
char *const multiply7_0__sum_0__0 = (char*) (SharedMem+26214656);  // multiply7_0 > sum_0 size:= 1048576*char
int *const output__input__5 = (int*) (SharedMem+0);  // transpose_0_output > splitTensorB_0_input size:= 262144*int
int *const output6__inputA__1 = (int*) (SharedMem+61866240);  // splitTensorA_5_output6 > multiply6_5_inputA size:= 32768*int
long *const output__input7__7 = (long*) (SharedMem+55574784);  // multiply7_5_output > sum_5_input7 size:= 262144*long
int *const output7__inputA__1 = (int*) (SharedMem+48234752);  // splitTensorA_2_output7 > multiply7_2_inputA size:= 32768*int
int *const output2__inputB__4 = (int*) (SharedMem+50725120);  // splitTensorB_3_output2 > multiply2_3_inputB size:= 32768*int
long *const output__input4__5 = (long*) (SharedMem+18874624);  // multiply4_0_output > sum_0_input4 size:= 262144*long
long *const output__input3__6 = (long*) (SharedMem+8388736);  // multiply3_4_output > sum_4_input3 size:= 262144*long
int *const arrayB__input__0 = (int*) (SharedMem+8388864);  // generateTensors_arrayB > explode_generateTensors_arrayB_input size:= 2097152*int
int *const arrayA_1572864__input__0 = (int*) (SharedMem+6291584);  // explode_generateTensors_arrayA_arrayA_1572864 > splitTensorA_6_input size:= 262144*int
int *const output2__inputB__2 = (int*) (SharedMem+50594048);  // splitTensorB_4_output2 > multiply2_4_inputB size:= 32768*int
long *const output__arrayC_524288__0 = (long*) (SharedMem+2097280);  // sum_2_output > implode_displayResult_arrayC_arrayC_524288 size:= 262144*long
int *const output0__inputA__7 = (int*) (SharedMem+27263232);  // splitTensorA_0_output0 > multiply0_0_inputA size:= 32768*int
int *const output5__inputB__7 = (int*) (SharedMem+60948736);  // splitTensorB_5_output5 > multiply5_5_inputB size:= 32768*int
long *const output__input0__7 = (long*) (SharedMem+27263232);  // multiply0_1_output > sum_1_input0 size:= 262144*long
int *const output1__inputA__6 = (int*) (SharedMem+49283328);  // splitTensorA_4_output1 > multiply1_4_inputA size:= 32768*int
int *const output1__inputA__7 = (int*) (SharedMem+35651840);  // splitTensorA_1_output1 > multiply1_1_inputA size:= 32768*int
int *const output6__inputA__0 = (int*) (SharedMem+54526208);  // splitTensorA_4_output6 > multiply6_4_inputA size:= 32768*int
int *const output1__inputB__2 = (int*) (SharedMem+28442880);  // splitTensorB_0_output1 > multiply1_0_inputB size:= 32768*int
int *const arrayA_1048576__input__0 = (int*) (SharedMem+4194432);  // explode_generateTensors_arrayA_arrayA_1048576 > splitTensorA_4_input size:= 262144*int
long *const output__input2__0 = (long*) (SharedMem+17826048);  // multiply2_0_output > sum_0_input2 size:= 262144*long
int *const output7__inputB__0 = (int*) (SharedMem+74973440);  // splitTensorB_7_output7 > multiply7_7_inputB size:= 32768*int
int *const output3__inputA__5 = (int*) (SharedMem+51511552);  // splitTensorA_3_output3 > multiply3_3_inputA size:= 32768*int
long *const output__input6__1 = (long*) (SharedMem+69206272);  // multiply6_7_output > sum_7_input6 size:= 262144*long
long *const output__input7__4 = (long*) (SharedMem+62914816);  // multiply7_6_output > sum_6_input7 size:= 262144*long
long *const output__input7__3 = (long*) (SharedMem+33554688);  // multiply7_1_output > sum_1_input7 size:= 262144*long
int *const output7__inputA__3 = (int*) (SharedMem+55705856);  // splitTensorA_3_output7 > multiply7_3_inputA size:= 32768*int
int *const output5__inputB__2 = (int*) (SharedMem+72483072);  // splitTensorB_7_output5 > multiply5_7_inputB size:= 32768*int
int *const output1__inputB__7 = (int*) (SharedMem+14680320);  // splitTensorB_6_output1 > multiply1_6_inputB size:= 32768*int
int *const output4__inputA__4 = (int*) (SharedMem+67109120);  // splitTensorA_6_output4 > multiply4_6_inputA size:= 32768*int
long *const output__input7__0 = (long*) (SharedMem+40894720);  // multiply7_2_output > sum_2_input7 size:= 262144*long
int *const output4__inputA__1 = (int*) (SharedMem+46137600);  // splitTensorA_2_output4 > multiply4_2_inputA size:= 32768*int
long *const output__input2__6 = (long*) (SharedMem+29360384);  // multiply2_1_output > sum_1_input2 size:= 262144*long
int *const output6__inputB__2 = (int*) (SharedMem+54788352);  // splitTensorB_4_output6 > multiply6_4_inputB size:= 32768*int
long *const output__input1__1 = (long*) (SharedMem+28311808);  // multiply1_1_output > sum_1_input1 size:= 262144*long
int *const output5__inputA__2 = (int*) (SharedMem+68157696);  // splitTensorA_6_output5 > multiply5_6_inputA size:= 32768*int
int *const output4__inputB__7 = (int*) (SharedMem+30540032);  // splitTensorB_0_output4 > multiply4_0_inputB size:= 32768*int
long *const output__input5__0 = (long*) (SharedMem+39846144);  // multiply5_2_output > sum_2_input5 size:= 262144*long
int *const output1__inputA__4 = (int*) (SharedMem+73662720);  // splitTensorA_7_output1 > multiply1_7_inputA size:= 32768*int
int *const output3__inputB__7 = (int*) (SharedMem+66191616);  // splitTensorB_6_output3 > multiply3_6_inputB size:= 32768*int
int *const output7__inputB__7 = (int*) (SharedMem+70385920);  // splitTensorB_6_output7 > multiply7_6_inputB size:= 32768*int
int *const output__input__1 = (int*) (SharedMem+2097280);  // transpose_2_output > splitTensorB_2_input size:= 262144*int
long *const output__input0__6 = (long*) (SharedMem+34603264);  // multiply0_2_output > sum_2_input0 size:= 262144*long
long *const output__input2__2 = (long*) (SharedMem+36700416);  // multiply2_2_output > sum_2_input2 size:= 262144*long
int *const output7__inputA__2 = (int*) (SharedMem+40894720);  // splitTensorA_1_output7 > multiply7_1_inputA size:= 32768*int
int *const output4__inputA__3 = (int*) (SharedMem+52429056);  // splitTensorA_4_output4 > multiply4_4_inputA size:= 32768*int
int *const output0__inputA__3 = (int*) (SharedMem+34603264);  // splitTensorA_1_output0 > multiply0_1_inputA size:= 32768*int
int *const output6__inputA__5 = (int*) (SharedMem+69206272);  // splitTensorA_6_output6 > multiply6_6_inputA size:= 32768*int
int *const output4__inputA__6 = (int*) (SharedMem+30408960);  // splitTensorA_0_output4 > multiply4_0_inputA size:= 32768*int
int *const output5__inputA__6 = (int*) (SharedMem+20971776);  // splitTensorA_0_output5 > multiply5_0_inputA size:= 32768*int
int *const arrayB_524288__input__0 = (int*) (SharedMem+10486016);  // explode_generateTensors_arrayB_arrayB_524288 > transpose_2_input size:= 262144*int
int *const output7__inputB__5 = (int*) (SharedMem+63045888);  // splitTensorB_5_output7 > multiply7_5_inputB size:= 32768*int
int *const output6__inputB__5 = (int*) (SharedMem+20316416);  // splitTensorB_1_output6 > multiply6_1_inputB size:= 32768*int
long *const output__input1__4 = (long*) (SharedMem+42991872);  // multiply1_3_output > sum_3_input1 size:= 262144*long
long *const output__input3__1 = (long*) (SharedMem+66060544);  // multiply3_7_output > sum_7_input3 size:= 262144*long
int *const output5__inputA__0 = (int*) (SharedMem+53608704);  // splitTensorA_3_output5 > multiply5_3_inputA size:= 32768*int
int *const output0__inputB__1 = (int*) (SharedMem+12583168);  // splitTensorB_4_output0 > multiply0_4_inputB size:= 32768*int
int *const output6__inputB__3 = (int*) (SharedMem+61997312);  // splitTensorB_5_output6 > multiply6_5_inputB size:= 32768*int
int *const output3__inputA__4 = (int*) (SharedMem+51380480);  // splitTensorA_4_output3 > multiply3_4_inputA size:= 32768*int
int *const output3__inputA__0 = (int*) (SharedMem+37748992);  // splitTensorA_0_output3 > multiply3_0_inputA size:= 32768*int
int *const output0__inputB__6 = (int*) (SharedMem+57147648);  // splitTensorB_5_output0 > multiply0_5_inputB size:= 32768*int
int *const output6__inputA__2 = (int*) (SharedMem+19923200);  // splitTensorA_0_output6 > multiply6_0_inputA size:= 32768*int
long *const output__input1__2 = (long*) (SharedMem+5243008);  // multiply1_4_output > sum_4_input1 size:= 262144*long
int *const output0__inputA__6 = (int*) (SharedMem+56754432);  // splitTensorA_3_output0 > multiply0_3_inputA size:= 32768*int
int *const output0__inputA__1 = (int*) (SharedMem+56623360);  // splitTensorA_4_output0 > multiply0_4_inputA size:= 32768*int
int *const output7__inputB__6 = (int*) (SharedMem+55836928);  // splitTensorB_4_output7 > multiply7_4_inputB size:= 32768*int
int *const output2__inputA__3 = (int*) (SharedMem+29360384);  // splitTensorA_0_output2 > multiply2_0_inputA size:= 32768*int
int *const output7__inputA__4 = (int*) (SharedMem+62914816);  // splitTensorA_5_output7 > multiply7_5_inputA size:= 32768*int
long *const output__input2__1 = (long*) (SharedMem+44040448);  // multiply2_3_output > sum_3_input2 size:= 262144*long
long *const output__input0__4 = (long*) (SharedMem+56623360);  // multiply0_6_output > sum_6_input0 size:= 262144*long
int *const output__input__3 = (int*) (SharedMem+16777472);  // transpose_1_output > splitTensorB_1_input size:= 262144*int
int *const output4__inputB__6 = (int*) (SharedMem+59900160);  // splitTensorB_5_output4 > multiply4_5_inputB size:= 32768*int
long *const output__input4__1 = (long*) (SharedMem+38797568);  // multiply4_2_output > sum_2_input4 size:= 262144*long
int *const output__input__2 = (int*) (SharedMem+6291584);  // transpose_7_output > splitTensorB_7_input size:= 262144*int
int *const output7__inputB__1 = (int*) (SharedMem+41025792);  // splitTensorB_1_output7 > multiply7_1_inputB size:= 32768*int
int *const output6__inputB__7 = (int*) (SharedMem+11534592);  // splitTensorB_3_output6 > multiply6_3_inputB size:= 32768*int
long *const output__input1__0 = (long*) (SharedMem+14680192);  // multiply1_7_output > sum_7_input1 size:= 262144*long
long *const output__input4__0 = (long*) (SharedMem+9437312);  // multiply4_4_output > sum_4_input4 size:= 262144*long
long *const output__arrayC__0 = (long*) (SharedMem+128);  // implode_displayResult_arrayC_output > displayResult_arrayC size:= 2097152*long
int *const output5__inputB__6 = (int*) (SharedMem+68288768);  // splitTensorB_6_output5 > multiply5_6_inputB size:= 32768*int
int *const output5__inputB__0 = (int*) (SharedMem+21496064);  // splitTensorB_1_output5 > multiply5_1_inputB size:= 32768*int
int *const output1__inputA__1 = (int*) (SharedMem+57671936);  // splitTensorA_5_output1 > multiply1_5_inputA size:= 32768*int
long *const output__input6__0 = (long*) (SharedMem+54526208);  // multiply6_5_output > sum_5_input6 size:= 262144*long
long *const output__input3__4 = (long*) (SharedMem+58720512);  // multiply3_6_output > sum_6_input3 size:= 262144*long
int *const output5__inputA__5 = (int*) (SharedMem+21233920);  // splitTensorA_2_output5 > multiply5_2_inputA size:= 32768*int
long *const output__arrayC_262144__0 = (long*) (SharedMem+71303424);  // sum_1_output > implode_displayResult_arrayC_arrayC_262144 size:= 262144*long
int *const output4__inputB__3 = (int*) (SharedMem+52822272);  // splitTensorB_3_output4 > multiply4_3_inputB size:= 32768*int
int *const output__input__7 = (int*) (SharedMem+3145856);  // transpose_3_output > splitTensorB_3_input size:= 262144*int
long *const output__input5__4 = (long*) (SharedMem+53477632);  // multiply5_5_output > sum_5_input5 size:= 262144*long
long *const output__input3__5 = (long*) (SharedMem+16777472);  // multiply3_1_output > sum_1_input3 size:= 262144*long
long *const output__input0__3 = (long*) (SharedMem+41943296);  // multiply0_3_output > sum_3_input0 size:= 262144*long
long *const output__input7__1 = (long*) (SharedMem+48234752);  // multiply7_3_output > sum_3_input7 size:= 262144*long
int *const output4__inputA__5 = (int*) (SharedMem+38797568);  // splitTensorA_1_output4 > multiply4_1_inputA size:= 32768*int
int *const output2__inputA__2 = (int*) (SharedMem+50331904);  // splitTensorA_4_output2 > multiply2_4_inputA size:= 32768*int
int *const arrayB_1310720__input__0 = (int*) (SharedMem+13631744);  // explode_generateTensors_arrayB_arrayB_1310720 > transpose_5_input size:= 262144*int
int *const output2__inputB__7 = (int*) (SharedMem+74580224);  // splitTensorB_7_output2 > multiply2_7_inputB size:= 32768*int
long *const output__input7__6 = (long*) (SharedMem+70254848);  // multiply7_7_output > sum_7_input7 size:= 262144*long
int *const output1__inputB__6 = (int*) (SharedMem+35782912);  // splitTensorB_1_output1 > multiply1_1_inputB size:= 32768*int
long *const output__input2__5 = (long*) (SharedMem+65011968);  // multiply2_7_output > sum_7_input2 size:= 262144*long
int *const output5__inputA__7 = (int*) (SharedMem+21102848);  // splitTensorA_1_output5 > multiply5_1_inputA size:= 32768*int
int *const output4__inputA__0 = (int*) (SharedMem+59769088);  // splitTensorA_5_output4 > multiply4_5_inputA size:= 32768*int
long *const output__input6__5 = (long*) (SharedMem+19923200);  // multiply6_2_output > sum_2_input6 size:= 262144*long
long *const output__input7__2 = (long*) (SharedMem+26214656);  // multiply7_0_output > sum_0_input7 size:= 262144*long
int *const arrayB_786432__input__0 = (int*) (SharedMem+11534592);  // explode_generateTensors_arrayB_arrayB_786432 > transpose_3_input size:= 262144*int
int *const output5__inputB__3 = (int*) (SharedMem+21364992);  // splitTensorB_0_output5 > multiply5_0_inputB size:= 32768*int
long *const output__input0__2 = (long*) (SharedMem+12583040);  // multiply0_5_output > sum_5_input0 size:= 262144*long
int *const output5__inputB__1 = (int*) (SharedMem+53739776);  // splitTensorB_4_output5 > multiply5_4_inputB size:= 32768*int
double *const startTime__startTime__0 = (double*) (SharedMem+75104512);  // generateTensors_startTime > displayResult_startTime size:= 1*double
long *const output__input6__2 = (long*) (SharedMem+47186176);  // multiply6_3_output > sum_3_input6 size:= 262144*long
int *const arrayA_0__input__0 = (int*) (SharedMem+128);  // explode_generateTensors_arrayA_arrayA_0 > splitTensorA_0_input size:= 262144*int
int *const output6__inputA__6 = (int*) (SharedMem+20054272);  // splitTensorA_1_output6 > multiply6_1_inputA size:= 32768*int
long *const output__arrayC_1572864__0 = (long*) (SharedMem+6291584);  // sum_6_output > implode_displayResult_arrayC_arrayC_1572864 size:= 262144*long
long *const output__input1__6 = (long*) (SharedMem+15728896);  // multiply1_0_output > sum_0_input1 size:= 262144*long
int *const output4__inputB__5 = (int*) (SharedMem+74711296);  // splitTensorB_7_output4 > multiply4_7_inputB size:= 32768*int
int *const output1__inputA__3 = (int*) (SharedMem+73400576);  // splitTensorA_6_output1 > multiply1_6_inputA size:= 32768*int
int *const output0__inputA__4 = (int*) (SharedMem+56885504);  // splitTensorA_5_output0 > multiply0_5_inputA size:= 32768*int
long *const output__input4__7 = (long*) (SharedMem+67109120);  // multiply4_7_output > sum_7_input4 size:= 262144*long
int *const output__input__6 = (int*) (SharedMem+17826048);  // transpose_6_output > splitTensorB_6_input size:= 262144*int
long *const output__input1__7 = (long*) (SharedMem+35651840);  // multiply1_2_output > sum_2_input1 size:= 262144*long
int *const output3__inputB__4 = (int*) (SharedMem+8388736);  // splitTensorB_0_output3 > multiply3_0_inputB size:= 32768*int
long *const output__input0__5 = (long*) (SharedMem+63963392);  // multiply0_7_output > sum_7_input0 size:= 262144*long
int *const output1__inputB__1 = (int*) (SharedMem+49676544);  // splitTensorB_3_output1 > multiply1_3_inputB size:= 32768*int
int *const output2__inputA__4 = (int*) (SharedMem+44040448);  // splitTensorA_2_output2 > multiply2_2_inputA size:= 32768*int
long *const output__input4__6 = (long*) (SharedMem+30408960);  // multiply4_1_output > sum_1_input4 size:= 262144*long
long *const output__input2__4 = (long*) (SharedMem+50331904);  // multiply2_5_output > sum_5_input2 size:= 262144*long
int *const output5__inputB__5 = (int*) (SharedMem+10486016);  // splitTensorB_2_output5 > multiply5_2_inputB size:= 32768*int
int *const output1__inputA__0 = (int*) (SharedMem+49414400);  // splitTensorA_3_output1 > multiply1_3_inputA size:= 32768*int
int *const output3__inputB__1 = (int*) (SharedMem+58851584);  // splitTensorB_5_output3 > multiply3_5_inputB size:= 32768*int
int *const arrayA_1310720__input__0 = (int*) (SharedMem+5243008);  // explode_generateTensors_arrayA_arrayA_1310720 > splitTensorA_5_input size:= 262144*int
int *const output5__inputA__1 = (int*) (SharedMem+60817664);  // splitTensorA_5_output5 > multiply5_5_inputA size:= 32768*int
int *const arrayA_1835008__input__0 = (int*) (SharedMem+7340160);  // explode_generateTensors_arrayA_arrayA_1835008 > splitTensorA_7_input size:= 262144*int
int *const output2__inputA__6 = (int*) (SharedMem+73793792);  // splitTensorA_7_output2 > multiply2_7_inputA size:= 32768*int
long *const output__input3__7 = (long*) (SharedMem+37748992);  // multiply3_2_output > sum_2_input3 size:= 262144*long
int *const arrayB_262144__input__0 = (int*) (SharedMem+9437440);  // explode_generateTensors_arrayB_arrayB_262144 > transpose_1_input size:= 262144*int
int *const output3__inputA__6 = (int*) (SharedMem+45089024);  // splitTensorA_2_output3 > multiply3_2_inputA size:= 32768*int
int *const output2__inputB__0 = (int*) (SharedMem+44171520);  // splitTensorB_2_output2 > multiply2_2_inputB size:= 32768*int
long *const output__input2__3 = (long*) (SharedMem+13631616);  // multiply2_6_output > sum_6_input2 size:= 262144*long
int *const output6__inputB__4 = (int*) (SharedMem+74842368);  // splitTensorB_7_output6 > multiply6_7_inputB size:= 32768*int
int *const output2__inputB__6 = (int*) (SharedMem+36831488);  // splitTensorB_1_output2 > multiply2_1_inputB size:= 32768*int
long *const output__input2__7 = (long*) (SharedMem+7340160);  // multiply2_4_output > sum_4_input2 size:= 262144*long
long *const output__arrayC_0__0 = (long*) (SharedMem+128);  // sum_0_output > implode_displayResult_arrayC_arrayC_0 size:= 262144*long
int *const output1__inputB__3 = (int*) (SharedMem+74449152);  // splitTensorB_7_output1 > multiply1_7_inputB size:= 32768*int
int *const output0__inputA__0 = (int*) (SharedMem+63963392);  // splitTensorA_6_output0 > multiply0_6_inputA size:= 32768*int
int *const output2__inputA__5 = (int*) (SharedMem+50462976);  // splitTensorA_3_output2 > multiply2_3_inputA size:= 32768*int
int *const output1__inputB__5 = (int*) (SharedMem+5243008);  // splitTensorB_2_output1 > multiply1_2_inputB size:= 32768*int
int *const output6__inputA__3 = (int*) (SharedMem+54657280);  // splitTensorA_3_output6 > multiply6_3_inputA size:= 32768*int
int *const output3__inputB__3 = (int*) (SharedMem+71434496);  // splitTensorB_7_output3 > multiply3_7_inputB size:= 32768*int
long *const output__input5__2 = (long*) (SharedMem+10485888);  // multiply5_4_output > sum_4_input5 size:= 262144*long
long *const output__input5__1 = (long*) (SharedMem+60817664);  // multiply5_6_output > sum_6_input5 size:= 262144*long
int *const arrayB_1835008__input__0 = (int*) (SharedMem+15728896);  // explode_generateTensors_arrayB_arrayB_1835008 > transpose_7_input size:= 262144*int
int *const output5__inputA__4 = (int*) (SharedMem+53477632);  // splitTensorA_4_output5 > multiply5_4_inputA size:= 32768*int
int *const output3__inputA__2 = (int*) (SharedMem+66060544);  // splitTensorA_6_output3 > multiply3_6_inputA size:= 32768*int
int *const arrayB_1048576__input__0 = (int*) (SharedMem+12583168);  // explode_generateTensors_arrayB_arrayB_1048576 > transpose_4_input size:= 262144*int
int *const output3__inputA__3 = (int*) (SharedMem+71303424);  // splitTensorA_7_output3 > multiply3_7_inputA size:= 32768*int
int *const arrayA_786432__input__0 = (int*) (SharedMem+3145856);  // explode_generateTensors_arrayA_arrayA_786432 > splitTensorA_3_input size:= 262144*int
int *const output2__inputA__7 = (int*) (SharedMem+65143040);  // splitTensorA_6_output2 > multiply2_6_inputA size:= 32768*int
int *const output6__inputB__6 = (int*) (SharedMem+69337344);  // splitTensorB_6_output6 > multiply6_6_inputB size:= 32768*int
int *const output__input__0 = (int*) (SharedMem+4194432);  // transpose_5_output > splitTensorB_5_input size:= 262144*int
int *const arrayA_262144__input__0 = (int*) (SharedMem+1048704);  // explode_generateTensors_arrayA_arrayA_262144 > splitTensorA_1_input size:= 262144*int
long *const output__input7__5 = (long*) (SharedMem+1048704);  // multiply7_4_output > sum_4_input7 size:= 262144*long
int *const output7__inputB__2 = (int*) (SharedMem+55968000);  // splitTensorB_3_output7 > multiply7_3_inputB size:= 32768*int
long *const output__input5__5 = (long*) (SharedMem+20971776);  // multiply5_3_output > sum_3_input5 size:= 262144*long
int *const output0__inputA__2 = (int*) (SharedMem+73531648);  // splitTensorA_7_output0 > multiply0_7_inputA size:= 32768*int
int *const arrayB_0__input__0 = (int*) (SharedMem+8388864);  // explode_generateTensors_arrayB_arrayB_0 > transpose_0_input size:= 262144*int
int *const output1__inputB__0 = (int*) (SharedMem+49545472);  // splitTensorB_4_output1 > multiply1_4_inputB size:= 32768*int
int *const output4__inputB__1 = (int*) (SharedMem+52691200);  // splitTensorB_4_output4 > multiply4_4_inputB size:= 32768*int
long *const output__input3__0 = (long*) (SharedMem+23068928);  // multiply3_0_output > sum_0_input3 size:= 262144*long
int *const arrayB_1572864__input__0 = (int*) (SharedMem+14680320);  // explode_generateTensors_arrayB_arrayB_1572864 > transpose_6_input size:= 262144*int
long *const output__input6__4 = (long*) (SharedMem+61866240);  // multiply6_6_output > sum_6_input6 size:= 262144*long
int *const output0__inputB__7 = (int*) (SharedMem+64094464);  // splitTensorB_6_output0 > multiply0_6_inputB size:= 32768*int
long *const output__input3__3 = (long*) (SharedMem+51380480);  // multiply3_5_output > sum_5_input3 size:= 262144*long
long *const output__input4__4 = (long*) (SharedMem+46137600);  // multiply4_3_output > sum_3_input4 size:= 262144*long
int *const output7__inputA__6 = (int*) (SharedMem+55574784);  // splitTensorA_4_output7 > multiply7_4_inputA size:= 32768*int
int *const output5__inputA__3 = (int*) (SharedMem+72352000);  // splitTensorA_7_output5 > multiply5_7_inputA size:= 32768*int
int *const arrayA__input__0 = (int*) (SharedMem+128);  // generateTensors_arrayA > explode_generateTensors_arrayA_input size:= 2097152*int
int *const output3__inputA__1 = (int*) (SharedMem+37880064);  // splitTensorA_1_output3 > multiply3_1_inputA size:= 32768*int
int *const output0__inputB__5 = (int*) (SharedMem+27394304);  // splitTensorB_0_output0 > multiply0_0_inputB size:= 32768*int
int *const output7__inputA__0 = (int*) (SharedMem+74187008);  // splitTensorA_7_output7 > multiply7_7_inputA size:= 32768*int
long *const output__input5__7 = (long*) (SharedMem+31457536);  // multiply5_1_output > sum_1_input5 size:= 262144*long
long *const output__input1__5 = (long*) (SharedMem+57671936);  // multiply1_6_output > sum_6_input1 size:= 262144*long
long *const output__input6__6 = (long*) (SharedMem+11534464);  // multiply6_4_output > sum_4_input6 size:= 262144*long
int *const output0__inputB__2 = (int*) (SharedMem+57016576);  // splitTensorB_3_output0 > multiply0_3_inputB size:= 32768*int
int *const output5__inputB__4 = (int*) (SharedMem+53870848);  // splitTensorB_3_output5 > multiply5_3_inputB size:= 32768*int
int *const output1__inputA__5 = (int*) (SharedMem+42991872);  // splitTensorA_2_output1 > multiply1_2_inputA size:= 32768*int
int *const output7__inputA__5 = (int*) (SharedMem+70254848);  // splitTensorA_6_output7 > multiply7_6_inputA size:= 32768*int
long *const output__arrayC_1310720__0 = (long*) (SharedMem+15728768);  // sum_5_output > implode_displayResult_arrayC_arrayC_1310720 size:= 262144*long
long *const output__input6__7 = (long*) (SharedMem+25166080);  // multiply6_0_output > sum_0_input6 size:= 262144*long
int *const output7__inputB__4 = (int*) (SharedMem+33685760);  // splitTensorB_0_output7 > multiply7_0_inputB size:= 32768*int
int *const output2__inputA__1 = (int*) (SharedMem+36700416);  // splitTensorA_1_output2 > multiply2_1_inputA size:= 32768*int
int *const output7__inputB__3 = (int*) (SharedMem+48365824);  // splitTensorB_2_output7 > multiply7_2_inputB size:= 32768*int
long *const output__input3__2 = (long*) (SharedMem+45089024);  // multiply3_3_output > sum_3_input3 size:= 262144*long
int *const arrayA_524288__input__0 = (int*) (SharedMem+2097280);  // explode_generateTensors_arrayA_arrayA_524288 > splitTensorA_2_input size:= 262144*int
int *const output7__inputA__7 = (int*) (SharedMem+33554688);  // splitTensorA_0_output7 > multiply7_0_inputA size:= 32768*int
int *const output4__inputB__2 = (int*) (SharedMem+9437440);  // splitTensorB_1_output4 > multiply4_1_inputB size:= 32768*int
int *const output0__inputB__4 = (int*) (SharedMem+74318080);  // splitTensorB_7_output0 > multiply0_7_inputB size:= 32768*int
int *const output3__inputA__7 = (int*) (SharedMem+58720512);  // splitTensorA_5_output3 > multiply3_5_inputA size:= 32768*int
int *const output1__inputA__2 = (int*) (SharedMem+28311808);  // splitTensorA_0_output1 > multiply1_0_inputA size:= 32768*int
int *const output6__inputB__0 = (int*) (SharedMem+47317248);  // splitTensorB_2_output6 > multiply6_2_inputB size:= 32768*int
int *const output2__inputB__3 = (int*) (SharedMem+29491456);  // splitTensorB_0_output2 > multiply2_0_inputB size:= 32768*int
long *const output__input5__3 = (long*) (SharedMem+68157696);  // multiply5_7_output > sum_7_input5 size:= 262144*long
int *const output2__inputA__0 = (int*) (SharedMem+65011968);  // splitTensorA_5_output2 > multiply2_5_inputA size:= 32768*int
int *const output3__inputB__2 = (int*) (SharedMem+51642624);  // splitTensorB_4_output3 > multiply3_4_inputB size:= 32768*int
int *const output6__inputB__1 = (int*) (SharedMem+20185344);  // splitTensorB_0_output6 > multiply6_0_inputB size:= 32768*int
long *const output__input1__3 = (long*) (SharedMem+49283328);  // multiply1_5_output > sum_5_input1 size:= 262144*long
int *const output__input__4 = (int*) (SharedMem+7340160);  // transpose_4_output > splitTensorB_4_input size:= 262144*int
int *const output2__inputB__1 = (int*) (SharedMem+13631744);  // splitTensorB_5_output2 > multiply2_5_inputB size:= 32768*int
int *const output3__inputB__5 = (int*) (SharedMem+45220096);  // splitTensorB_2_output3 > multiply3_2_inputB size:= 32768*int
long *const output__input4__2 = (long*) (SharedMem+52429056);  // multiply4_5_output > sum_5_input4 size:= 262144*long
int *const output6__inputA__7 = (int*) (SharedMem+74055936);  // splitTensorA_7_output6 > multiply6_7_inputA size:= 32768*int
int *const output2__inputB__5 = (int*) (SharedMem+65274112);  // splitTensorB_6_output2 > multiply2_6_inputB size:= 32768*int
long *const output__arrayC_786432__0 = (long*) (SharedMem+72352000);  // sum_3_output > implode_displayResult_arrayC_arrayC_786432 size:= 262144*long
int *const output3__inputB__6 = (int*) (SharedMem+51773696);  // splitTensorB_3_output3 > multiply3_3_inputB size:= 32768*int
int *const output1__inputB__4 = (int*) (SharedMem+57803008);  // splitTensorB_5_output1 > multiply1_5_inputB size:= 32768*int
long *const output__arrayC_1835008__0 = (long*) (SharedMem+73400576);  // sum_7_output > implode_displayResult_arrayC_arrayC_1835008 size:= 262144*long
int *const output6__inputA__4 = (int*) (SharedMem+47186176);  // splitTensorA_2_output6 > multiply6_2_inputA size:= 32768*int
int *const output4__inputA__2 = (int*) (SharedMem+73924864);  // splitTensorA_7_output4 > multiply4_7_inputA size:= 32768*int
long *const output__input4__3 = (long*) (SharedMem+59769088);  // multiply4_6_output > sum_6_input4 size:= 262144*long
long *const output__input5__6 = (long*) (SharedMem+24117504);  // multiply5_0_output > sum_0_input5 size:= 262144*long
int *const output4__inputB__0 = (int*) (SharedMem+67240192);  // splitTensorB_6_output4 > multiply4_6_inputB size:= 32768*int
int *const output4__inputB__4 = (int*) (SharedMem+46268672);  // splitTensorB_2_output4 > multiply4_2_inputB size:= 32768*int
int *const output4__inputA__7 = (int*) (SharedMem+52560128);  // splitTensorA_3_output4 > multiply4_3_inputA size:= 32768*int
int *const output0__inputB__0 = (int*) (SharedMem+42074368);  // splitTensorB_2_output0 > multiply0_2_inputB size:= 32768*int
long *const output__input0__0 = (long*) (SharedMem+3145856);  // multiply0_4_output > sum_4_input0 size:= 262144*long
int *const output0__inputB__3 = (int*) (SharedMem+34734336);  // splitTensorB_1_output0 > multiply0_1_inputB size:= 32768*int
int *const output0__inputA__5 = (int*) (SharedMem+41943296);  // splitTensorA_2_output0 > multiply0_2_inputA size:= 32768*int
long *const output__input0__1 = (long*) (SharedMem+22020352);  // multiply0_0_output > sum_0_input0 size:= 262144*long
int *const output3__inputB__0 = (int*) (SharedMem+38011136);  // splitTensorB_1_output3 > multiply3_1_inputB size:= 32768*int
long *const output__arrayC_1048576__0 = (long*) (SharedMem+4194432);  // sum_4_output > implode_displayResult_arrayC_arrayC_1048576 size:= 262144*long
long *const output__input6__3 = (long*) (SharedMem+32506112);  // multiply6_1_output > sum_1_input6 size:= 262144*long

void core0(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		generate(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,arrayA__input__0,arrayB__input__0,startTime__startTime__0); // generateTensors
		cache_wbInv(generateTensors__explode_gen__1, 8388608*sizeof(char));
		sendStart(7); // Core0 > Core7: generateTensors__explode_gen__1 
		sendEnd(); // Core0 > Core7: generateTensors__explode_gen__1 
		// Fork explode_generateTensors_arrayA
		{
			cache_wb(arrayA__input__0, 2097152*sizeof(int));
		}
		cache_wb(((char*)arrayA__input__0) + 0, 8388608);
		cache_inv(arrayA__input__0, 2097152*sizeof(int));
		cache_wbInv(explode_generateTensors_arra__1, 1048576*sizeof(char));
		sendStart(7); // Core0 > Core7: explode_generateTensors_arra__1 
		sendEnd(); // Core0 > Core7: explode_generateTensors_arra__1 
		cache_wbInv(explode_generateTensors_arra__7, 1048576*sizeof(char));
		sendStart(1); // Core0 > Core1: explode_generateTensors_arra__7 
		sendEnd(); // Core0 > Core1: explode_generateTensors_arra__7 
		cache_wbInv(explode_generateTensors_arra__6, 1048576*sizeof(char));
		sendStart(6); // Core0 > Core6: explode_generateTensors_arra__6 
		sendEnd(); // Core0 > Core6: explode_generateTensors_arra__6 
		cache_wbInv(explode_generateTensors_arra__4, 1048576*sizeof(char));
		sendStart(5); // Core0 > Core5: explode_generateTensors_arra__4 
		sendEnd(); // Core0 > Core5: explode_generateTensors_arra__4 
		cache_wbInv(explode_generateTensors_arra__13, 1048576*sizeof(char));
		sendStart(6); // Core0 > Core6: explode_generateTensors_arra__13 
		sendEnd(); // Core0 > Core6: explode_generateTensors_arra__13 
		cache_wbInv(explode_generateTensors_arra__0, 1048576*sizeof(char));
		sendStart(2); // Core0 > Core2: explode_generateTensors_arra__0 
		sendEnd(); // Core0 > Core2: explode_generateTensors_arra__0 
		cache_wbInv(explode_generateTensors_arra__14, 1048576*sizeof(char));
		sendStart(4); // Core0 > Core4: explode_generateTensors_arra__14 
		sendEnd(); // Core0 > Core4: explode_generateTensors_arra__14 
		receiveStart(); // Core7 > Core0: explode_generateTensors_arra__10 
		receiveEnd(7); // Core7 > Core0: explode_generateTensors_arra__10 
		cache_inv(explode_generateTensors_arra__10, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core0: splitTensorA_0__multiply0_0__0 
		receiveEnd(4); // Core4 > Core0: splitTensorA_0__multiply0_0__0 
		cache_inv(splitTensorA_0__multiply0_0__0, 131072*sizeof(char));
		receiveStart(); // Core2 > Core0: splitTensorA_1__multiply0_1__0 
		receiveEnd(2); // Core2 > Core0: splitTensorA_1__multiply0_1__0 
		cache_inv(splitTensorA_1__multiply0_1__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core0: splitTensorA_2__multiply0_2__0 
		receiveEnd(6); // Core6 > Core0: splitTensorA_2__multiply0_2__0 
		cache_inv(splitTensorA_2__multiply0_2__0, 131072*sizeof(char));
		receiveStart(); // Core5 > Core0: splitTensorA_3__multiply0_3__0 
		receiveEnd(5); // Core5 > Core0: splitTensorA_3__multiply0_3__0 
		cache_inv(splitTensorA_3__multiply0_3__0, 131072*sizeof(char));
		splitA(512/*rowsA*/,512/*columnsA*/,arrayA_1048576__input__0,output0__inputA__1,output1__inputA__6,output2__inputA__2,output3__inputA__4,output4__inputA__3,output5__inputA__4,output6__inputA__0,output7__inputA__6); // splitTensorA_4
		cache_inv(arrayA_1048576__input__0, 262144*sizeof(int));
		cache_wbInv(splitTensorA_4__multiply7_4__0, 131072*sizeof(char));
		sendStart(7); // Core0 > Core7: splitTensorA_4__multiply7_4__0 
		sendEnd(); // Core0 > Core7: splitTensorA_4__multiply7_4__0 
		cache_wbInv(splitTensorA_4__multiply6_4__0, 131072*sizeof(char));
		sendStart(6); // Core0 > Core6: splitTensorA_4__multiply6_4__0 
		sendEnd(); // Core0 > Core6: splitTensorA_4__multiply6_4__0 
		cache_wbInv(splitTensorA_4__multiply5_4__0, 131072*sizeof(char));
		sendStart(5); // Core0 > Core5: splitTensorA_4__multiply5_4__0 
		sendEnd(); // Core0 > Core5: splitTensorA_4__multiply5_4__0 
		cache_wbInv(splitTensorA_4__multiply4_4__0, 131072*sizeof(char));
		sendStart(4); // Core0 > Core4: splitTensorA_4__multiply4_4__0 
		sendEnd(); // Core0 > Core4: splitTensorA_4__multiply4_4__0 
		cache_wbInv(splitTensorA_4__multiply3_4__0, 131072*sizeof(char));
		sendStart(3); // Core0 > Core3: splitTensorA_4__multiply3_4__0 
		sendEnd(); // Core0 > Core3: splitTensorA_4__multiply3_4__0 
		cache_wbInv(splitTensorA_4__multiply2_4__0, 131072*sizeof(char));
		sendStart(2); // Core0 > Core2: splitTensorA_4__multiply2_4__0 
		sendEnd(); // Core0 > Core2: splitTensorA_4__multiply2_4__0 
		cache_wbInv(splitTensorA_4__multiply1_4__0, 131072*sizeof(char));
		sendStart(1); // Core0 > Core1: splitTensorA_4__multiply1_4__0 
		sendEnd(); // Core0 > Core1: splitTensorA_4__multiply1_4__0 
		receiveStart(); // Core6 > Core0: splitTensorA_5__multiply0_5__0 
		receiveEnd(6); // Core6 > Core0: splitTensorA_5__multiply0_5__0 
		cache_inv(splitTensorA_5__multiply0_5__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core0: splitTensorA_6__multiply0_6__0 
		receiveEnd(1); // Core1 > Core0: splitTensorA_6__multiply0_6__0 
		cache_inv(splitTensorA_6__multiply0_6__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core0: splitTensorA_7__multiply0_7__0 
		receiveEnd(7); // Core7 > Core0: splitTensorA_7__multiply0_7__0 
		cache_inv(splitTensorA_7__multiply0_7__0, 131072*sizeof(char));
		transpose(512/*rowsB*/,512/*columnsB*/,arrayB_1310720__input__0,output__input__0); // transpose_5
		cache_inv(arrayB_1310720__input__0, 262144*sizeof(int));
		receiveStart(); // Core4 > Core0: splitTensorB_0__multiply0_0__0 
		receiveEnd(4); // Core4 > Core0: splitTensorB_0__multiply0_0__0 
		cache_inv(splitTensorB_0__multiply0_0__0, 131072*sizeof(char));
		receiveStart(); // Core3 > Core0: splitTensorB_1__multiply0_1__0 
		receiveEnd(3); // Core3 > Core0: splitTensorB_1__multiply0_1__0 
		cache_inv(splitTensorB_1__multiply0_1__0, 131072*sizeof(char));
		receiveStart(); // Core6 > Core0: splitTensorB_2__multiply0_2__0 
		receiveEnd(6); // Core6 > Core0: splitTensorB_2__multiply0_2__0 
		cache_inv(splitTensorB_2__multiply0_2__0, 131072*sizeof(char));
		receiveStart(); // Core5 > Core0: splitTensorB_3__multiply0_3__0 
		receiveEnd(5); // Core5 > Core0: splitTensorB_3__multiply0_3__0 
		cache_inv(splitTensorB_3__multiply0_3__0, 131072*sizeof(char));
		receiveStart(); // Core7 > Core0: splitTensorB_4__multiply0_4__0 
		receiveEnd(7); // Core7 > Core0: splitTensorB_4__multiply0_4__0 
		cache_inv(splitTensorB_4__multiply0_4__0, 131072*sizeof(char));
		splitB(512/*rowsB*/,512/*columnsB*/,output__input__0,output0__inputB__6,output1__inputB__4,output2__inputB__1,output3__inputB__1,output4__inputB__6,output5__inputB__7,output6__inputB__3,output7__inputB__5); // splitTensorB_5
		cache_inv(output__input__0, 262144*sizeof(int));
		cache_wbInv(splitTensorB_5__multiply7_5__0, 131072*sizeof(char));
		sendStart(7); // Core0 > Core7: splitTensorB_5__multiply7_5__0 
		sendEnd(); // Core0 > Core7: splitTensorB_5__multiply7_5__0 
		cache_wbInv(splitTensorB_5__multiply6_5__0, 131072*sizeof(char));
		sendStart(6); // Core0 > Core6: splitTensorB_5__multiply6_5__0 
		sendEnd(); // Core0 > Core6: splitTensorB_5__multiply6_5__0 
		cache_wbInv(splitTensorB_5__multiply5_5__0, 131072*sizeof(char));
		sendStart(5); // Core0 > Core5: splitTensorB_5__multiply5_5__0 
		sendEnd(); // Core0 > Core5: splitTensorB_5__multiply5_5__0 
		cache_wbInv(splitTensorB_5__multiply4_5__0, 131072*sizeof(char));
		sendStart(4); // Core0 > Core4: splitTensorB_5__multiply4_5__0 
		sendEnd(); // Core0 > Core4: splitTensorB_5__multiply4_5__0 
		cache_wbInv(splitTensorB_5__multiply3_5__0, 131072*sizeof(char));
		sendStart(3); // Core0 > Core3: splitTensorB_5__multiply3_5__0 
		sendEnd(); // Core0 > Core3: splitTensorB_5__multiply3_5__0 
		cache_wbInv(splitTensorB_5__multiply2_5__0, 131072*sizeof(char));
		sendStart(2); // Core0 > Core2: splitTensorB_5__multiply2_5__0 
		sendEnd(); // Core0 > Core2: splitTensorB_5__multiply2_5__0 
		cache_wbInv(splitTensorB_5__multiply1_5__0, 131072*sizeof(char));
		sendStart(1); // Core0 > Core1: splitTensorB_5__multiply1_5__0 
		sendEnd(); // Core0 > Core1: splitTensorB_5__multiply1_5__0 
		receiveStart(); // Core2 > Core0: splitTensorB_6__multiply0_6__0 
		receiveEnd(2); // Core2 > Core0: splitTensorB_6__multiply0_6__0 
		cache_inv(splitTensorB_6__multiply0_6__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core0: splitTensorB_7__multiply0_7__0 
		receiveEnd(1); // Core1 > Core0: splitTensorB_7__multiply0_7__0 
		cache_inv(splitTensorB_7__multiply0_7__0, 131072*sizeof(char));
		multiply(512/*rows*/,512/*columns*/,output0__inputA__7,output0__inputB__5,output__input0__1); // multiply0_0
		cache_inv(output0__inputA__7, 32768*sizeof(int));
		cache_inv(output0__inputB__5, 32768*sizeof(int));
		cache_wbInv(multiply0_0__sum_0__0, 1048576*sizeof(char));
		sendStart(4); // Core0 > Core4: multiply0_0__sum_0__0 
		sendEnd(); // Core0 > Core4: multiply0_0__sum_0__0 
		multiply(512/*rows*/,512/*columns*/,output0__inputA__3,output0__inputB__3,output__input0__7); // multiply0_1
		cache_inv(output0__inputA__3, 32768*sizeof(int));
		cache_inv(output0__inputB__3, 32768*sizeof(int));
		cache_wbInv(multiply0_1__sum_1__0, 1048576*sizeof(char));
		sendStart(3); // Core0 > Core3: multiply0_1__sum_1__0 
		sendEnd(); // Core0 > Core3: multiply0_1__sum_1__0 
		multiply(512/*rows*/,512/*columns*/,output0__inputA__5,output0__inputB__0,output__input0__6); // multiply0_2
		cache_inv(output0__inputA__5, 32768*sizeof(int));
		cache_inv(output0__inputB__0, 32768*sizeof(int));
		cache_wbInv(multiply0_2__sum_2__0, 1048576*sizeof(char));
		sendStart(2); // Core0 > Core2: multiply0_2__sum_2__0 
		sendEnd(); // Core0 > Core2: multiply0_2__sum_2__0 
		multiply(512/*rows*/,512/*columns*/,output0__inputA__6,output0__inputB__2,output__input0__3); // multiply0_3
		cache_inv(output0__inputA__6, 32768*sizeof(int));
		cache_inv(output0__inputB__2, 32768*sizeof(int));
		cache_wbInv(multiply0_3__sum_3__0, 1048576*sizeof(char));
		sendStart(5); // Core0 > Core5: multiply0_3__sum_3__0 
		sendEnd(); // Core0 > Core5: multiply0_3__sum_3__0 
		multiply(512/*rows*/,512/*columns*/,output0__inputA__1,output0__inputB__1,output__input0__0); // multiply0_4
		cache_inv(output0__inputA__1, 32768*sizeof(int));
		cache_inv(output0__inputB__1, 32768*sizeof(int));
		multiply(512/*rows*/,512/*columns*/,output0__inputA__4,output0__inputB__6,output__input0__2); // multiply0_5
		cache_inv(output0__inputA__4, 32768*sizeof(int));
		cache_inv(output0__inputB__6, 32768*sizeof(int));
		cache_wbInv(multiply0_5__sum_5__0, 1048576*sizeof(char));
		sendStart(4); // Core0 > Core4: multiply0_5__sum_5__0 
		sendEnd(); // Core0 > Core4: multiply0_5__sum_5__0 
		multiply(512/*rows*/,512/*columns*/,output0__inputA__0,output0__inputB__7,output__input0__4); // multiply0_6
		cache_inv(output0__inputA__0, 32768*sizeof(int));
		cache_inv(output0__inputB__7, 32768*sizeof(int));
		cache_wbInv(multiply0_6__sum_6__0, 1048576*sizeof(char));
		sendStart(1); // Core0 > Core1: multiply0_6__sum_6__0 
		sendEnd(); // Core0 > Core1: multiply0_6__sum_6__0 
		multiply(512/*rows*/,512/*columns*/,output0__inputA__2,output0__inputB__4,output__input0__5); // multiply0_7
		cache_inv(output0__inputA__2, 32768*sizeof(int));
		cache_inv(output0__inputB__4, 32768*sizeof(int));
		cache_wbInv(multiply0_7__sum_7__0, 1048576*sizeof(char));
		sendStart(7); // Core0 > Core7: multiply0_7__sum_7__0 
		sendEnd(); // Core0 > Core7: multiply0_7__sum_7__0 
		receiveStart(); // Core1 > Core0: multiply1_4__sum_4__0 
		receiveEnd(1); // Core1 > Core0: multiply1_4__sum_4__0 
		cache_inv(multiply1_4__sum_4__0, 1048576*sizeof(char));
		receiveStart(); // Core2 > Core0: multiply2_4__sum_4__0 
		receiveEnd(2); // Core2 > Core0: multiply2_4__sum_4__0 
		cache_inv(multiply2_4__sum_4__0, 1048576*sizeof(char));
		receiveStart(); // Core3 > Core0: multiply3_4__sum_4__0 
		receiveEnd(3); // Core3 > Core0: multiply3_4__sum_4__0 
		cache_inv(multiply3_4__sum_4__0, 1048576*sizeof(char));
		receiveStart(); // Core4 > Core0: multiply4_4__sum_4__0 
		receiveEnd(4); // Core4 > Core0: multiply4_4__sum_4__0 
		cache_inv(multiply4_4__sum_4__0, 1048576*sizeof(char));
		receiveStart(); // Core5 > Core0: multiply5_4__sum_4__0 
		receiveEnd(5); // Core5 > Core0: multiply5_4__sum_4__0 
		cache_inv(multiply5_4__sum_4__0, 1048576*sizeof(char));
		receiveStart(); // Core6 > Core0: multiply6_4__sum_4__0 
		receiveEnd(6); // Core6 > Core0: multiply6_4__sum_4__0 
		cache_inv(multiply6_4__sum_4__0, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core0: multiply7_4__sum_4__0 
		receiveEnd(7); // Core7 > Core0: multiply7_4__sum_4__0 
		cache_inv(multiply7_4__sum_4__0, 1048576*sizeof(char));
		sum(512/*rows*/,512/*columns*/,output__input0__0,output__input1__2,output__input2__7,output__input3__6,output__input4__0,output__input5__2,output__input6__6,output__input7__5,output__arrayC_1048576__0); // sum_4
		cache_inv(output__input0__0, 262144*sizeof(long));
		cache_inv(output__input1__2, 262144*sizeof(long));
		cache_inv(output__input2__7, 262144*sizeof(long));
		cache_inv(output__input3__6, 262144*sizeof(long));
		cache_inv(output__input4__0, 262144*sizeof(long));
		cache_inv(output__input5__2, 262144*sizeof(long));
		cache_inv(output__input6__6, 262144*sizeof(long));
		cache_inv(output__input7__5, 262144*sizeof(long));
		cache_wbInv(sum_4__implode_displayResult__0, 1048576*sizeof(char));
		sendStart(7); // Core0 > Core7: sum_4__implode_displayResult__0 
		sendEnd(); // Core0 > Core7: sum_4__implode_displayResult__0 
		receiveStart(); // Core7 > Core0: implode_displayResult_arrayC__0 
		receiveEnd(7); // Core7 > Core0: implode_displayResult_arrayC__0 
		cache_inv(implode_displayResult_arrayC__0, 8388608*sizeof(char));
		display(512/*rows*/,512/*columns*/,8/*depth*/,output__arrayC__0,startTime__startTime__0); // displayResult
		cache_inv(output__arrayC__0, 2097152*sizeof(long));
		cache_inv(startTime__startTime__0, 1*sizeof(double));
	}
}
