/** 
 * @file Core0.c
 * @generated by C6678CPrinter
 * @date Wed Mar 11 15:03:56 GMT 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration

// Core Global Definitions
// Won't work if the shared memory is >= 512 MB 
#pragma DATA_SECTION(SharedMem, ".mySharedMem")
char SharedMem[6720]; //  size:= 6720*char
char *const broadcastTensorB__multiplyTe__4 = (char*) (SharedMem+5568);  // broadcastTensorB > multiplyTensors_7 size:= 512*char
char *const explode_generateTensors_arra__4 = (char*) (SharedMem+5440);  // explode_generateTensors_arrayA > multiplyTensors_4 size:= 64*char
char *const multiplyTensors_7__implode_d__0 = (char*) (SharedMem+3136);  // multiplyTensors_7 > implode_displayTensor_arrayC size:= 64*char
char *const generateTensors__displayTens__0 = (char*) (SharedMem+6080);  // generateTensors > displayTensor size:= 8*char
char *const implode_displayTensor_arrayC__0 = (char*) (SharedMem+1984);  // implode_displayTensor_arrayC > displayTensor size:= 512*char
char *const broadcastTensorB__multiplyTe__1 = (char*) (SharedMem+2624);  // broadcastTensorB > multiplyTensors_0 size:= 512*char
char *const multiplyTensors_6__implode_d__0 = (char*) (SharedMem+1792);  // multiplyTensors_6 > implode_displayTensor_arrayC size:= 64*char
char *const generateTensors__explode_gen__0 = (char*) (SharedMem+0);  // generateTensors > explode_generateTensors_arrayA size:= 512*char
char *const explode_generateTensors_arra__2 = (char*) (SharedMem+5376);  // explode_generateTensors_arrayA > multiplyTensors_1 size:= 64*char
char *const multiplyTensors_1__implode_d__0 = (char*) (SharedMem+2496);  // multiplyTensors_1 > implode_displayTensor_arrayC size:= 64*char
char *const multiplyTensors_4__implode_d__0 = (char*) (SharedMem+1664);  // multiplyTensors_4 > implode_displayTensor_arrayC size:= 64*char
char *const broadcastTensorB__multiplyTe__6 = (char*) (SharedMem+4224);  // broadcastTensorB > multiplyTensors_3 size:= 512*char
char *const multiplyTensors_0__implode_d__0 = (char*) (SharedMem+1856);  // multiplyTensors_0 > implode_displayTensor_arrayC size:= 64*char
char *const explode_generateTensors_arra__6 = (char*) (SharedMem+5248);  // explode_generateTensors_arrayA > multiplyTensors_0 size:= 64*char
char *const multiplyTensors_3__implode_d__0 = (char*) (SharedMem+1600);  // multiplyTensors_3 > implode_displayTensor_arrayC size:= 64*char
char *const multiplyTensors_5__implode_d__0 = (char*) (SharedMem+1728);  // multiplyTensors_5 > implode_displayTensor_arrayC size:= 64*char
char *const broadcastTensorB__multiplyTe__5 = (char*) (SharedMem+512);  // broadcastTensorB > multiplyTensors_6 size:= 512*char
char *const broadcastTensorB__multiplyTe__7 = (char*) (SharedMem+3200);  // broadcastTensorB > multiplyTensors_5 size:= 512*char
char *const explode_generateTensors_arra__1 = (char*) (SharedMem+5312);  // explode_generateTensors_arrayA > multiplyTensors_7 size:= 64*char
char *const multiplyTensors_2__implode_d__0 = (char*) (SharedMem+2560);  // multiplyTensors_2 > implode_displayTensor_arrayC size:= 64*char
char *const explode_generateTensors_arra__0 = (char*) (SharedMem+6144);  // explode_generateTensors_arrayA > multiplyTensors_2 size:= 64*char
char *const broadcastTensorB__multiplyTe__3 = (char*) (SharedMem+4736);  // broadcastTensorB > multiplyTensors_2 size:= 512*char
char *const explode_generateTensors_arra__3 = (char*) (SharedMem+1920);  // explode_generateTensors_arrayA > multiplyTensors_5 size:= 64*char
char *const broadcastTensorB__multiplyTe__2 = (char*) (SharedMem+3712);  // broadcastTensorB > multiplyTensors_4 size:= 512*char
char *const broadcastTensorB__multiplyTe__0 = (char*) (SharedMem+6208);  // broadcastTensorB > multiplyTensors_1 size:= 512*char
char *const explode_generateTensors_arra__5 = (char*) (SharedMem+5504);  // explode_generateTensors_arrayA > multiplyTensors_3 size:= 64*char
char *const explode_generateTensors_arra__7 = (char*) (SharedMem+1536);  // explode_generateTensors_arrayA > multiplyTensors_6 size:= 64*char
char *const generateTensors__broadcastTe__0 = (char*) (SharedMem+1024);  // generateTensors > broadcastTensorB size:= 512*char
int *const output_896__arrayB__0 = (int*) (SharedMem+5568);  // broadcastTensorB_output_896 > multiplyTensors_7_arrayB size:= 128*int
int *const output_0__arrayB__0 = (int*) (SharedMem+2624);  // broadcastTensorB_output_0 > multiplyTensors_0_arrayB size:= 128*int
int *const arrayA_32__arrayA__0 = (int*) (SharedMem+6144);  // explode_generateTensors_arrayA_arrayA_32 > multiplyTensors_2_arrayA size:= 16*int
long *const arrayC__arrayC_96__0 = (long*) (SharedMem+1792);  // multiplyTensors_6_arrayC > implode_displayTensor_arrayC_arrayC_96 size:= 16*long
long *const arrayC__arrayC_32__0 = (long*) (SharedMem+2560);  // multiplyTensors_2_arrayC > implode_displayTensor_arrayC_arrayC_32 size:= 16*long
int *const arrayA_16__arrayA__0 = (int*) (SharedMem+5376);  // explode_generateTensors_arrayA_arrayA_16 > multiplyTensors_1_arrayA size:= 16*int
long *const arrayC__arrayC_80__0 = (long*) (SharedMem+1728);  // multiplyTensors_5_arrayC > implode_displayTensor_arrayC_arrayC_80 size:= 16*long
int *const arrayA_96__arrayA__0 = (int*) (SharedMem+1536);  // explode_generateTensors_arrayA_arrayA_96 > multiplyTensors_6_arrayA size:= 16*int
long *const arrayC__arrayC_64__0 = (long*) (SharedMem+1664);  // multiplyTensors_4_arrayC > implode_displayTensor_arrayC_arrayC_64 size:= 16*long
long *const arrayC__arrayC_48__0 = (long*) (SharedMem+1600);  // multiplyTensors_3_arrayC > implode_displayTensor_arrayC_arrayC_48 size:= 16*long
int *const arrayA_64__arrayA__0 = (int*) (SharedMem+5440);  // explode_generateTensors_arrayA_arrayA_64 > multiplyTensors_4_arrayA size:= 16*int
long *const arrayC__arrayC_112__0 = (long*) (SharedMem+3136);  // multiplyTensors_7_arrayC > implode_displayTensor_arrayC_arrayC_112 size:= 16*long
int *const arrayA_0__arrayA__0 = (int*) (SharedMem+5248);  // explode_generateTensors_arrayA_arrayA_0 > multiplyTensors_0_arrayA size:= 16*int
int *const output_768__arrayB__0 = (int*) (SharedMem+512);  // broadcastTensorB_output_768 > multiplyTensors_6_arrayB size:= 128*int
double *const startTime__startTime__0 = (double*) (SharedMem+6080);  // generateTensors_startTime > displayTensor_startTime size:= 1*double
int *const arrayA_48__arrayA__0 = (int*) (SharedMem+5504);  // explode_generateTensors_arrayA_arrayA_48 > multiplyTensors_3_arrayA size:= 16*int
int *const output_256__arrayB__0 = (int*) (SharedMem+4736);  // broadcastTensorB_output_256 > multiplyTensors_2_arrayB size:= 128*int
int *const output_512__arrayB__0 = (int*) (SharedMem+3712);  // broadcastTensorB_output_512 > multiplyTensors_4_arrayB size:= 128*int
int *const arrayA_80__arrayA__0 = (int*) (SharedMem+1920);  // explode_generateTensors_arrayA_arrayA_80 > multiplyTensors_5_arrayA size:= 16*int
long *const arrayC__arrayC_0__0 = (long*) (SharedMem+1856);  // multiplyTensors_0_arrayC > implode_displayTensor_arrayC_arrayC_0 size:= 16*long
int *const arrayB__input__0 = (int*) (SharedMem+1024);  // generateTensors_arrayB > broadcastTensorB_input size:= 128*int
long *const arrayC__arrayC_16__0 = (long*) (SharedMem+2496);  // multiplyTensors_1_arrayC > implode_displayTensor_arrayC_arrayC_16 size:= 16*long
long *const arrayC__arrayC__0 = (long*) (SharedMem+1984);  // implode_displayTensor_arrayC_arrayC > displayTensor_arrayC size:= 128*long
int *const output_384__arrayB__0 = (int*) (SharedMem+4224);  // broadcastTensorB_output_384 > multiplyTensors_3_arrayB size:= 128*int
int *const arrayA_112__arrayA__0 = (int*) (SharedMem+5312);  // explode_generateTensors_arrayA_arrayA_112 > multiplyTensors_7_arrayA size:= 16*int
int *const arrayA__arrayA__0 = (int*) (SharedMem+0);  // generateTensors_arrayA > explode_generateTensors_arrayA_arrayA size:= 128*int
int *const output_640__arrayB__0 = (int*) (SharedMem+3200);  // broadcastTensorB_output_640 > multiplyTensors_5_arrayB size:= 128*int
int *const output_128__arrayB__0 = (int*) (SharedMem+6208);  // broadcastTensorB_output_128 > multiplyTensors_1_arrayB size:= 128*int

void core0(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		generate(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,arrayA__arrayA__0,arrayB__input__0,startTime__startTime__0); // generateTensors
		cache_wbInv(generateTensors__broadcastTe__0, 512*sizeof(char));
		sendStart(7); // Core0 > Core7: generateTensors__broadcastTe__0 
		sendEnd(); // Core0 > Core7: generateTensors__broadcastTe__0 
		receiveStart(); // Core7 > Core0: broadcastTensorB__multiplyTe__1 
		receiveEnd(7); // Core7 > Core0: broadcastTensorB__multiplyTe__1 
		cache_inv(broadcastTensorB__multiplyTe__1, 512*sizeof(char));
		// Fork explode_generateTensors_arrayA
		{
			memcpy((void*)(arrayA_0__arrayA__0+0),(void*)( arrayA__arrayA__0+0), 16*sizeof(int));
			memcpy((void*)(arrayA_16__arrayA__0+0),(void*)( arrayA__arrayA__0+16), 16*sizeof(int));
			memcpy((void*)(arrayA_32__arrayA__0+0),(void*)( arrayA__arrayA__0+32), 16*sizeof(int));
			memcpy((void*)(arrayA_48__arrayA__0+0),(void*)( arrayA__arrayA__0+48), 16*sizeof(int));
			memcpy((void*)(arrayA_64__arrayA__0+0),(void*)( arrayA__arrayA__0+64), 16*sizeof(int));
			memcpy((void*)(arrayA_80__arrayA__0+0),(void*)( arrayA__arrayA__0+80), 16*sizeof(int));
			memcpy((void*)(arrayA_96__arrayA__0+0),(void*)( arrayA__arrayA__0+96), 16*sizeof(int));
			memcpy((void*)(arrayA_112__arrayA__0+0),(void*)( arrayA__arrayA__0+112), 16*sizeof(int));
		}
		cache_inv(arrayA__arrayA__0, 128*sizeof(int));
		cache_wbInv(explode_generateTensors_arra__1, 64*sizeof(char));
		sendStart(7); // Core0 > Core7: explode_generateTensors_arra__1 
		sendEnd(); // Core0 > Core7: explode_generateTensors_arra__1 
		cache_wbInv(explode_generateTensors_arra__7, 64*sizeof(char));
		sendStart(1); // Core0 > Core1: explode_generateTensors_arra__7 
		sendEnd(); // Core0 > Core1: explode_generateTensors_arra__7 
		cache_wbInv(explode_generateTensors_arra__3, 64*sizeof(char));
		sendStart(6); // Core0 > Core6: explode_generateTensors_arra__3 
		sendEnd(); // Core0 > Core6: explode_generateTensors_arra__3 
		cache_wbInv(explode_generateTensors_arra__4, 64*sizeof(char));
		sendStart(3); // Core0 > Core3: explode_generateTensors_arra__4 
		sendEnd(); // Core0 > Core3: explode_generateTensors_arra__4 
		cache_wbInv(explode_generateTensors_arra__5, 64*sizeof(char));
		sendStart(4); // Core0 > Core4: explode_generateTensors_arra__5 
		sendEnd(); // Core0 > Core4: explode_generateTensors_arra__5 
		cache_wbInv(explode_generateTensors_arra__0, 64*sizeof(char));
		sendStart(5); // Core0 > Core5: explode_generateTensors_arra__0 
		sendEnd(); // Core0 > Core5: explode_generateTensors_arra__0 
		cache_wbInv(explode_generateTensors_arra__2, 64*sizeof(char));
		sendStart(2); // Core0 > Core2: explode_generateTensors_arra__2 
		sendEnd(); // Core0 > Core2: explode_generateTensors_arra__2 
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,arrayA_0__arrayA__0,output_0__arrayB__0,arrayC__arrayC_0__0); // multiplyTensors_0
		cache_inv(arrayA_0__arrayA__0, 16*sizeof(int));
		cache_inv(output_0__arrayB__0, 128*sizeof(int));
		cache_wbInv(multiplyTensors_0__implode_d__0, 64*sizeof(char));
		sendStart(7); // Core0 > Core7: multiplyTensors_0__implode_d__0 
		sendEnd(); // Core0 > Core7: multiplyTensors_0__implode_d__0 
		receiveStart(); // Core7 > Core0: implode_displayTensor_arrayC__0 
		receiveEnd(7); // Core7 > Core0: implode_displayTensor_arrayC__0 
		cache_inv(implode_displayTensor_arrayC__0, 512*sizeof(char));
		display(8/*rowsA*/,8/*columnsB*/,2/*depthA*/,arrayC__arrayC__0,startTime__startTime__0); // displayTensor
		cache_inv(arrayC__arrayC__0, 128*sizeof(long));
		cache_inv(startTime__startTime__0, 1*sizeof(double));
	}
}
