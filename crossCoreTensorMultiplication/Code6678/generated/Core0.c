/** 
 * @file Core0.c
 * @generated by C6678CPrinter
 * @date Thu Mar 12 22:30:19 GMT 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration

// Core Global Definitions
// Won't work if the shared memory is >= 512 MB 
#pragma DATA_SECTION(SharedMem, ".mySharedMem")
char SharedMem[469762112]; //  size:= 469762112*char
char *const multiplyTensors_7__implode_d__0 = (char*) (SharedMem+348127296);  // multiplyTensors_7 > implode_displayTensor_arrayC size:= 2097152*char
char *const broadcastTensorB_0__multiply__1 = (char*) (SharedMem+190840832);  // broadcastTensorB_0 > multiplyTensors_1 size:= 16777216*char
char *const explode_generateTensors_arra__13 = (char*) (SharedMem+293601344);  // explode_generateTensors_arrayB > broadcastTensorB_1 size:= 16777216*char
char *const multiplyTensors_11__implode___0 = (char*) (SharedMem+75497472);  // multiplyTensors_11 > implode_displayTensor_arrayC size:= 2097152*char
char *const explode_generateTensors_arra__4 = (char*) (SharedMem+310378560);  // explode_generateTensors_arrayA > multiplyTensors_6 size:= 2097152*char
char *const multiplyTensors_12__implode___0 = (char*) (SharedMem+73400320);  // multiplyTensors_12 > implode_displayTensor_arrayC size:= 2097152*char
char *const multiplyTensors_4__implode_d__0 = (char*) (SharedMem+314572864);  // multiplyTensors_4 > implode_displayTensor_arrayC size:= 2097152*char
char *const explode_generateTensors_arra__8 = (char*) (SharedMem+207618048);  // explode_generateTensors_arrayA > multiplyTensors_3 size:= 2097152*char
char *const broadcastTensorB_1__multiply__6 = (char*) (SharedMem+375390272);  // broadcastTensorB_1 > multiplyTensors_8 size:= 16777216*char
char *const explode_generateTensors_arra__5 = (char*) (SharedMem+373293120);  // explode_generateTensors_arrayA > multiplyTensors_13 size:= 2097152*char
char *const broadcastTensorB_1__multiply__5 = (char*) (SharedMem+209715264);  // broadcastTensorB_1 > multiplyTensors_10 size:= 16777216*char
char *const explode_generateTensors_arra__9 = (char*) (SharedMem+450887744);  // explode_generateTensors_arrayA > multiplyTensors_2 size:= 2097152*char
char *const multiplyTensors_13__implode___0 = (char*) (SharedMem+71303168);  // multiplyTensors_13 > implode_displayTensor_arrayC size:= 2097152*char
char *const explode_generateTensors_arra__0 = (char*) (SharedMem+371195968);  // explode_generateTensors_arrayA > multiplyTensors_14 size:= 2097152*char
char *const explode_generateTensors_arra__17 = (char*) (SharedMem+322961472);  // explode_generateTensors_arrayA > multiplyTensors_5 size:= 2097152*char
char *const multiplyTensors_8__implode_d__0 = (char*) (SharedMem+346030144);  // multiplyTensors_8 > implode_displayTensor_arrayC size:= 2097152*char
char *const broadcastTensorB_0__multiply__5 = (char*) (SharedMem+0);  // broadcastTensorB_0 > multiplyTensors_2 size:= 16777216*char
char *const implode_displayTensor_arrayC__0 = (char*) (SharedMem+98566144);  // implode_displayTensor_arrayC > displayTensor size:= 33554432*char
char *const explode_generateTensors_arra__3 = (char*) (SharedMem+188743680);  // explode_generateTensors_arrayA > multiplyTensors_12 size:= 2097152*char
char *const explode_generateTensors_arra__12 = (char*) (SharedMem+186646528);  // explode_generateTensors_arrayA > multiplyTensors_1 size:= 2097152*char
char *const multiplyTensors_5__implode_d__0 = (char*) (SharedMem+316670016);  // multiplyTensors_5 > implode_displayTensor_arrayC size:= 2097152*char
char *const explode_generateTensors_arra__7 = (char*) (SharedMem+429916224);  // explode_generateTensors_arrayA > multiplyTensors_11 size:= 2097152*char
char *const broadcastTensorB_0__multiply__0 = (char*) (SharedMem+226492480);  // broadcastTensorB_0 > multiplyTensors_5 size:= 16777216*char
char *const explode_generateTensors_arra__11 = (char*) (SharedMem+350224448);  // explode_generateTensors_arrayB > broadcastTensorB_0 size:= 16777216*char
char *const explode_generateTensors_arra__14 = (char*) (SharedMem+96468992);  // explode_generateTensors_arrayA > multiplyTensors_10 size:= 2097152*char
char *const explode_generateTensors_arra__16 = (char*) (SharedMem+369098816);  // explode_generateTensors_arrayA > multiplyTensors_9 size:= 2097152*char
char *const explode_generateTensors_arra__15 = (char*) (SharedMem+432013376);  // explode_generateTensors_arrayA > multiplyTensors_4 size:= 2097152*char
char *const broadcastTensorB_1__multiply__7 = (char*) (SharedMem+54525952);  // broadcastTensorB_1 > multiplyTensors_15 size:= 16777216*char
char *const explode_generateTensors_arra__10 = (char*) (SharedMem+132120576);  // explode_generateTensors_arrayA > multiplyTensors_8 size:= 2097152*char
char *const broadcastTensorB_1__multiply__1 = (char*) (SharedMem+452984896);  // broadcastTensorB_1 > multiplyTensors_14 size:= 16777216*char
char *const multiplyTensors_15__implode___0 = (char*) (SharedMem+33554432);  // multiplyTensors_15 > implode_displayTensor_arrayC size:= 2097152*char
char *const broadcastTensorB_1__multiply__2 = (char*) (SharedMem+329252928);  // broadcastTensorB_1 > multiplyTensors_13 size:= 16777216*char
char *const multiplyTensors_1__implode_d__0 = (char*) (SharedMem+325058624);  // multiplyTensors_1 > implode_displayTensor_arrayC size:= 2097152*char
char *const explode_generateTensors_arra__1 = (char*) (SharedMem+392167488);  // explode_generateTensors_arrayA > multiplyTensors_0 size:= 2097152*char
char *const multiplyTensors_10__implode___0 = (char*) (SharedMem+94371840);  // multiplyTensors_10 > implode_displayTensor_arrayC size:= 2097152*char
char *const generateTensors__explode_gen__0 = (char*) (SharedMem+134217728);  // generateTensors > explode_generateTensors_arrayB size:= 33554432*char
char *const multiplyTensors_2__implode_d__0 = (char*) (SharedMem+327155776);  // multiplyTensors_2 > implode_displayTensor_arrayC size:= 2097152*char
char *const broadcastTensorB_1__multiply__4 = (char*) (SharedMem+434110528);  // broadcastTensorB_1 > multiplyTensors_9 size:= 16777216*char
char *const broadcastTensorB_0__multiply__3 = (char*) (SharedMem+413139008);  // broadcastTensorB_0 > multiplyTensors_7 size:= 16777216*char
char *const explode_generateTensors_arra__2 = (char*) (SharedMem+184549376);  // explode_generateTensors_arrayA > multiplyTensors_15 size:= 2097152*char
char *const generateTensors__displayTens__0 = (char*) (SharedMem+209715200);  // generateTensors > displayTensor size:= 8*char
char *const broadcastTensorB_0__multiply__4 = (char*) (SharedMem+276824128);  // broadcastTensorB_0 > multiplyTensors_3 size:= 16777216*char
char *const broadcastTensorB_0__multiply__6 = (char*) (SharedMem+396361792);  // broadcastTensorB_0 > multiplyTensors_4 size:= 16777216*char
char *const multiplyTensors_14__implode___0 = (char*) (SharedMem+52428800);  // multiplyTensors_14 > implode_displayTensor_arrayC size:= 2097152*char
char *const multiplyTensors_9__implode_d__0 = (char*) (SharedMem+367001664);  // multiplyTensors_9 > implode_displayTensor_arrayC size:= 2097152*char
char *const multiplyTensors_0__implode_d__0 = (char*) (SharedMem+320864320);  // multiplyTensors_0 > implode_displayTensor_arrayC size:= 2097152*char
char *const broadcastTensorB_1__multiply__0 = (char*) (SharedMem+77594624);  // broadcastTensorB_1 > multiplyTensors_12 size:= 16777216*char
char *const broadcastTensorB_0__multiply__2 = (char*) (SharedMem+35651584);  // broadcastTensorB_0 > multiplyTensors_0 size:= 16777216*char
char *const multiplyTensors_3__implode_d__0 = (char*) (SharedMem+312475712);  // multiplyTensors_3 > implode_displayTensor_arrayC size:= 2097152*char
char *const multiplyTensors_6__implode_d__0 = (char*) (SharedMem+318767168);  // multiplyTensors_6 > implode_displayTensor_arrayC size:= 2097152*char
char *const broadcastTensorB_0__multiply__7 = (char*) (SharedMem+16777216);  // broadcastTensorB_0 > multiplyTensors_6 size:= 16777216*char
char *const explode_generateTensors_arra__6 = (char*) (SharedMem+394264640);  // explode_generateTensors_arrayA > multiplyTensors_7 size:= 2097152*char
char *const broadcastTensorB_1__multiply__3 = (char*) (SharedMem+167772160);  // broadcastTensorB_1 > multiplyTensors_11 size:= 16777216*char
char *const generateTensors__explode_gen__1 = (char*) (SharedMem+243269696);  // generateTensors > explode_generateTensors_arrayA size:= 33554432*char
long *const arrayC__arrayC_2097152__0 = (long*) (SharedMem+314572864);  // multiplyTensors_4_arrayC > implode_displayTensor_arrayC_arrayC_2097152 size:= 524288*long
int *const arrayA_2621440__arrayA__0 = (int*) (SharedMem+322961472);  // explode_generateTensors_arrayA_arrayA_2621440 > multiplyTensors_5_arrayA size:= 524288*int
int *const output_8388608__arrayB__1 = (int*) (SharedMem+209715264);  // broadcastTensorB_1_output_8388608 > multiplyTensors_10_arrayB size:= 4194304*int
long *const arrayC__arrayC_4718592__0 = (long*) (SharedMem+367001664);  // multiplyTensors_9_arrayC > implode_displayTensor_arrayC_arrayC_4718592 size:= 524288*long
int *const output_29360128__arrayB__1 = (int*) (SharedMem+54525952);  // broadcastTensorB_1_output_29360128 > multiplyTensors_15_arrayB size:= 4194304*int
int *const output_0__arrayB__0 = (int*) (SharedMem+35651584);  // broadcastTensorB_0_output_0 > multiplyTensors_0_arrayB size:= 4194304*int
long *const arrayC__arrayC_1048576__0 = (long*) (SharedMem+327155776);  // multiplyTensors_2_arrayC > implode_displayTensor_arrayC_arrayC_1048576 size:= 524288*long
int *const arrayA_3670016__arrayA__0 = (int*) (SharedMem+394264640);  // explode_generateTensors_arrayA_arrayA_3670016 > multiplyTensors_7_arrayA size:= 524288*int
int *const arrayA_4718592__arrayA__0 = (int*) (SharedMem+369098816);  // explode_generateTensors_arrayA_arrayA_4718592 > multiplyTensors_9_arrayA size:= 524288*int
int *const arrayA_0__arrayA__0 = (int*) (SharedMem+392167488);  // explode_generateTensors_arrayA_arrayA_0 > multiplyTensors_0_arrayA size:= 524288*int
double *const startTime__startTime__0 = (double*) (SharedMem+209715200);  // generateTensors_startTime > displayTensor_startTime size:= 1*double
int *const output_20971520__arrayB__1 = (int*) (SharedMem+329252928);  // broadcastTensorB_1_output_20971520 > multiplyTensors_13_arrayB size:= 4194304*int
int *const arrayA_6815744__arrayA__0 = (int*) (SharedMem+373293120);  // explode_generateTensors_arrayA_arrayA_6815744 > multiplyTensors_13_arrayA size:= 524288*int
int *const output_16777216__arrayB__1 = (int*) (SharedMem+396361792);  // broadcastTensorB_0_output_16777216 > multiplyTensors_4_arrayB size:= 4194304*int
long *const arrayC__arrayC_6291456__0 = (long*) (SharedMem+73400320);  // multiplyTensors_12_arrayC > implode_displayTensor_arrayC_arrayC_6291456 size:= 524288*long
long *const arrayC__arrayC_7340032__0 = (long*) (SharedMem+52428800);  // multiplyTensors_14_arrayC > implode_displayTensor_arrayC_arrayC_7340032 size:= 524288*long
int *const output_4194304__arrayB__0 = (int*) (SharedMem+190840832);  // broadcastTensorB_0_output_4194304 > multiplyTensors_1_arrayB size:= 4194304*int
int *const arrayA_524288__arrayA__0 = (int*) (SharedMem+186646528);  // explode_generateTensors_arrayA_arrayA_524288 > multiplyTensors_1_arrayA size:= 524288*int
long *const arrayC__arrayC_2621440__0 = (long*) (SharedMem+316670016);  // multiplyTensors_5_arrayC > implode_displayTensor_arrayC_arrayC_2621440 size:= 524288*long
int *const arrayA_5767168__arrayA__0 = (int*) (SharedMem+429916224);  // explode_generateTensors_arrayA_arrayA_5767168 > multiplyTensors_11_arrayA size:= 524288*int
int *const output_20971520__arrayB__0 = (int*) (SharedMem+226492480);  // broadcastTensorB_0_output_20971520 > multiplyTensors_5_arrayB size:= 4194304*int
long *const arrayC__arrayC_3145728__0 = (long*) (SharedMem+318767168);  // multiplyTensors_6_arrayC > implode_displayTensor_arrayC_arrayC_3145728 size:= 524288*long
long *const arrayC__arrayC_524288__0 = (long*) (SharedMem+325058624);  // multiplyTensors_1_arrayC > implode_displayTensor_arrayC_arrayC_524288 size:= 524288*long
int *const arrayA_1572864__arrayA__0 = (int*) (SharedMem+207618048);  // explode_generateTensors_arrayA_arrayA_1572864 > multiplyTensors_3_arrayA size:= 524288*int
int *const output_16777216__arrayB__0 = (int*) (SharedMem+77594624);  // broadcastTensorB_1_output_16777216 > multiplyTensors_12_arrayB size:= 4194304*int
int *const output_25165824__arrayB__1 = (int*) (SharedMem+16777216);  // broadcastTensorB_0_output_25165824 > multiplyTensors_6_arrayB size:= 4194304*int
int *const output_12582912__arrayB__0 = (int*) (SharedMem+276824128);  // broadcastTensorB_0_output_12582912 > multiplyTensors_3_arrayB size:= 4194304*int
long *const arrayC__arrayC_6815744__0 = (long*) (SharedMem+71303168);  // multiplyTensors_13_arrayC > implode_displayTensor_arrayC_arrayC_6815744 size:= 524288*long
long *const arrayC__arrayC_3670016__0 = (long*) (SharedMem+348127296);  // multiplyTensors_7_arrayC > implode_displayTensor_arrayC_arrayC_3670016 size:= 524288*long
int *const output_8388608__arrayB__0 = (int*) (SharedMem+0);  // broadcastTensorB_0_output_8388608 > multiplyTensors_2_arrayB size:= 4194304*int
long *const arrayC__arrayC_1572864__0 = (long*) (SharedMem+312475712);  // multiplyTensors_3_arrayC > implode_displayTensor_arrayC_arrayC_1572864 size:= 524288*long
int *const arrayB__input__0 = (int*) (SharedMem+134217728);  // generateTensors_arrayB > explode_generateTensors_arrayB_input size:= 8388608*int
int *const arrayA_7864320__arrayA__0 = (int*) (SharedMem+184549376);  // explode_generateTensors_arrayA_arrayA_7864320 > multiplyTensors_15_arrayA size:= 524288*int
int *const arrayA_2097152__arrayA__0 = (int*) (SharedMem+432013376);  // explode_generateTensors_arrayA_arrayA_2097152 > multiplyTensors_4_arrayA size:= 524288*int
int *const arrayA_6291456__arrayA__0 = (int*) (SharedMem+188743680);  // explode_generateTensors_arrayA_arrayA_6291456 > multiplyTensors_12_arrayA size:= 524288*int
long *const arrayC__arrayC_5242880__0 = (long*) (SharedMem+94371840);  // multiplyTensors_10_arrayC > implode_displayTensor_arrayC_arrayC_5242880 size:= 524288*long
long *const arrayC__arrayC_0__0 = (long*) (SharedMem+320864320);  // multiplyTensors_0_arrayC > implode_displayTensor_arrayC_arrayC_0 size:= 524288*long
int *const arrayB_0__input__0 = (int*) (SharedMem+350224448);  // explode_generateTensors_arrayB_arrayB_0 > broadcastTensorB_0_input size:= 4194304*int
long *const arrayC__arrayC__0 = (long*) (SharedMem+98566144);  // implode_displayTensor_arrayC_arrayC > displayTensor_arrayC size:= 8388608*long
int *const output_25165824__arrayB__0 = (int*) (SharedMem+452984896);  // broadcastTensorB_1_output_25165824 > multiplyTensors_14_arrayB size:= 4194304*int
int *const arrayA__arrayA__0 = (int*) (SharedMem+243269696);  // generateTensors_arrayA > explode_generateTensors_arrayA_arrayA size:= 8388608*int
int *const arrayA_5242880__arrayA__0 = (int*) (SharedMem+96468992);  // explode_generateTensors_arrayA_arrayA_5242880 > multiplyTensors_10_arrayA size:= 524288*int
int *const output_4194304__arrayB__1 = (int*) (SharedMem+434110528);  // broadcastTensorB_1_output_4194304 > multiplyTensors_9_arrayB size:= 4194304*int
int *const output_12582912__arrayB__1 = (int*) (SharedMem+167772160);  // broadcastTensorB_1_output_12582912 > multiplyTensors_11_arrayB size:= 4194304*int
int *const arrayA_4194304__arrayA__0 = (int*) (SharedMem+132120576);  // explode_generateTensors_arrayA_arrayA_4194304 > multiplyTensors_8_arrayA size:= 524288*int
int *const output_0__arrayB__1 = (int*) (SharedMem+375390272);  // broadcastTensorB_1_output_0 > multiplyTensors_8_arrayB size:= 4194304*int
int *const arrayB_4194304__input__0 = (int*) (SharedMem+293601344);  // explode_generateTensors_arrayB_arrayB_4194304 > broadcastTensorB_1_input size:= 4194304*int
long *const arrayC__arrayC_7864320__0 = (long*) (SharedMem+33554432);  // multiplyTensors_15_arrayC > implode_displayTensor_arrayC_arrayC_7864320 size:= 524288*long
int *const arrayA_3145728__arrayA__0 = (int*) (SharedMem+310378560);  // explode_generateTensors_arrayA_arrayA_3145728 > multiplyTensors_6_arrayA size:= 524288*int
long *const arrayC__arrayC_4194304__0 = (long*) (SharedMem+346030144);  // multiplyTensors_8_arrayC > implode_displayTensor_arrayC_arrayC_4194304 size:= 524288*long
int *const output_29360128__arrayB__0 = (int*) (SharedMem+413139008);  // broadcastTensorB_0_output_29360128 > multiplyTensors_7_arrayB size:= 4194304*int
int *const arrayA_1048576__arrayA__0 = (int*) (SharedMem+450887744);  // explode_generateTensors_arrayA_arrayA_1048576 > multiplyTensors_2_arrayA size:= 524288*int
long *const arrayC__arrayC_5767168__0 = (long*) (SharedMem+75497472);  // multiplyTensors_11_arrayC > implode_displayTensor_arrayC_arrayC_5767168 size:= 524288*long
int *const arrayA_7340032__arrayA__0 = (int*) (SharedMem+371195968);  // explode_generateTensors_arrayA_arrayA_7340032 > multiplyTensors_14_arrayA size:= 524288*int

void core0(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		generate(2048/*rowsA*/,2048/*columnsA*/,2/*depthA*/,2048/*rowsB*/,2048/*columnsB*/,2/*depthB*/,arrayA__arrayA__0,arrayB__input__0,startTime__startTime__0); // generateTensors
		cache_wbInv(generateTensors__explode_gen__0, 33554432*sizeof(char));
		sendStart(7); // Core0 > Core7: generateTensors__explode_gen__0 
		sendEnd(); // Core0 > Core7: generateTensors__explode_gen__0 
		// Fork explode_generateTensors_arrayA
		{
			memcpy((void*)(arrayA_0__arrayA__0+0),(void*)( arrayA__arrayA__0+0), 524288*sizeof(int));
			memcpy((void*)(arrayA_524288__arrayA__0+0),(void*)( arrayA__arrayA__0+524288), 524288*sizeof(int));
			memcpy((void*)(arrayA_1048576__arrayA__0+0),(void*)( arrayA__arrayA__0+1048576), 524288*sizeof(int));
			memcpy((void*)(arrayA_1572864__arrayA__0+0),(void*)( arrayA__arrayA__0+1572864), 524288*sizeof(int));
			memcpy((void*)(arrayA_2097152__arrayA__0+0),(void*)( arrayA__arrayA__0+2097152), 524288*sizeof(int));
			memcpy((void*)(arrayA_2621440__arrayA__0+0),(void*)( arrayA__arrayA__0+2621440), 524288*sizeof(int));
			memcpy((void*)(arrayA_3145728__arrayA__0+0),(void*)( arrayA__arrayA__0+3145728), 524288*sizeof(int));
			memcpy((void*)(arrayA_3670016__arrayA__0+0),(void*)( arrayA__arrayA__0+3670016), 524288*sizeof(int));
			memcpy((void*)(arrayA_4194304__arrayA__0+0),(void*)( arrayA__arrayA__0+4194304), 524288*sizeof(int));
			memcpy((void*)(arrayA_4718592__arrayA__0+0),(void*)( arrayA__arrayA__0+4718592), 524288*sizeof(int));
			memcpy((void*)(arrayA_5242880__arrayA__0+0),(void*)( arrayA__arrayA__0+5242880), 524288*sizeof(int));
			memcpy((void*)(arrayA_5767168__arrayA__0+0),(void*)( arrayA__arrayA__0+5767168), 524288*sizeof(int));
			memcpy((void*)(arrayA_6291456__arrayA__0+0),(void*)( arrayA__arrayA__0+6291456), 524288*sizeof(int));
			memcpy((void*)(arrayA_6815744__arrayA__0+0),(void*)( arrayA__arrayA__0+6815744), 524288*sizeof(int));
			memcpy((void*)(arrayA_7340032__arrayA__0+0),(void*)( arrayA__arrayA__0+7340032), 524288*sizeof(int));
			memcpy((void*)(arrayA_7864320__arrayA__0+0),(void*)( arrayA__arrayA__0+7864320), 524288*sizeof(int));
		}
		cache_inv(arrayA__arrayA__0, 8388608*sizeof(int));
		cache_wbInv(explode_generateTensors_arra__2, 2097152*sizeof(char));
		sendStart(6); // Core0 > Core6: explode_generateTensors_arra__2 
		sendEnd(); // Core0 > Core6: explode_generateTensors_arra__2 
		cache_wbInv(explode_generateTensors_arra__5, 2097152*sizeof(char));
		sendStart(7); // Core0 > Core7: explode_generateTensors_arra__5 
		sendEnd(); // Core0 > Core7: explode_generateTensors_arra__5 
		cache_wbInv(explode_generateTensors_arra__3, 2097152*sizeof(char));
		sendStart(5); // Core0 > Core5: explode_generateTensors_arra__3 
		sendEnd(); // Core0 > Core5: explode_generateTensors_arra__3 
		cache_wbInv(explode_generateTensors_arra__7, 2097152*sizeof(char));
		sendStart(4); // Core0 > Core4: explode_generateTensors_arra__7 
		sendEnd(); // Core0 > Core4: explode_generateTensors_arra__7 
		cache_wbInv(explode_generateTensors_arra__14, 2097152*sizeof(char));
		sendStart(4); // Core0 > Core4: explode_generateTensors_arra__14 
		sendEnd(); // Core0 > Core4: explode_generateTensors_arra__14 
		cache_wbInv(explode_generateTensors_arra__16, 2097152*sizeof(char));
		sendStart(7); // Core0 > Core7: explode_generateTensors_arra__16 
		sendEnd(); // Core0 > Core7: explode_generateTensors_arra__16 
		cache_wbInv(explode_generateTensors_arra__6, 2097152*sizeof(char));
		sendStart(1); // Core0 > Core1: explode_generateTensors_arra__6 
		sendEnd(); // Core0 > Core1: explode_generateTensors_arra__6 
		cache_wbInv(explode_generateTensors_arra__4, 2097152*sizeof(char));
		sendStart(2); // Core0 > Core2: explode_generateTensors_arra__4 
		sendEnd(); // Core0 > Core2: explode_generateTensors_arra__4 
		cache_wbInv(explode_generateTensors_arra__17, 2097152*sizeof(char));
		sendStart(3); // Core0 > Core3: explode_generateTensors_arra__17 
		sendEnd(); // Core0 > Core3: explode_generateTensors_arra__17 
		cache_wbInv(explode_generateTensors_arra__15, 2097152*sizeof(char));
		sendStart(3); // Core0 > Core3: explode_generateTensors_arra__15 
		sendEnd(); // Core0 > Core3: explode_generateTensors_arra__15 
		cache_wbInv(explode_generateTensors_arra__8, 2097152*sizeof(char));
		sendStart(6); // Core0 > Core6: explode_generateTensors_arra__8 
		sendEnd(); // Core0 > Core6: explode_generateTensors_arra__8 
		cache_wbInv(explode_generateTensors_arra__9, 2097152*sizeof(char));
		sendStart(5); // Core0 > Core5: explode_generateTensors_arra__9 
		sendEnd(); // Core0 > Core5: explode_generateTensors_arra__9 
		cache_wbInv(explode_generateTensors_arra__12, 2097152*sizeof(char));
		sendStart(1); // Core0 > Core1: explode_generateTensors_arra__12 
		sendEnd(); // Core0 > Core1: explode_generateTensors_arra__12 
		cache_wbInv(explode_generateTensors_arra__1, 2097152*sizeof(char));
		sendStart(2); // Core0 > Core2: explode_generateTensors_arra__1 
		sendEnd(); // Core0 > Core2: explode_generateTensors_arra__1 
		receiveStart(); // Core7 > Core0: broadcastTensorB_1__multiply__1 
		receiveEnd(7); // Core7 > Core0: broadcastTensorB_1__multiply__1 
		cache_inv(broadcastTensorB_1__multiply__1, 16777216*sizeof(char));
		receiveStart(); // Core7 > Core0: broadcastTensorB_1__multiply__6 
		receiveEnd(7); // Core7 > Core0: broadcastTensorB_1__multiply__6 
		cache_inv(broadcastTensorB_1__multiply__6, 16777216*sizeof(char));
		multiply(2048/*rowsA*/,2048/*columnsA*/,2/*depthA*/,2048/*rowsB*/,2048/*columnsB*/,2/*depthB*/,arrayA_7340032__arrayA__0,output_25165824__arrayB__0,arrayC__arrayC_7340032__0); // multiplyTensors_14
		cache_inv(arrayA_7340032__arrayA__0, 524288*sizeof(int));
		cache_inv(output_25165824__arrayB__0, 4194304*sizeof(int));
		cache_wbInv(multiplyTensors_14__implode___0, 2097152*sizeof(char));
		sendStart(7); // Core0 > Core7: multiplyTensors_14__implode___0 
		sendEnd(); // Core0 > Core7: multiplyTensors_14__implode___0 
		multiply(2048/*rowsA*/,2048/*columnsA*/,2/*depthA*/,2048/*rowsB*/,2048/*columnsB*/,2/*depthB*/,arrayA_4194304__arrayA__0,output_0__arrayB__1,arrayC__arrayC_4194304__0); // multiplyTensors_8
		cache_inv(arrayA_4194304__arrayA__0, 524288*sizeof(int));
		cache_inv(output_0__arrayB__1, 4194304*sizeof(int));
		cache_wbInv(multiplyTensors_8__implode_d__0, 2097152*sizeof(char));
		sendStart(7); // Core0 > Core7: multiplyTensors_8__implode_d__0 
		sendEnd(); // Core0 > Core7: multiplyTensors_8__implode_d__0 
		receiveStart(); // Core7 > Core0: implode_displayTensor_arrayC__0 
		receiveEnd(7); // Core7 > Core0: implode_displayTensor_arrayC__0 
		cache_inv(implode_displayTensor_arrayC__0, 33554432*sizeof(char));
		display(2048/*rowsA*/,2048/*columnsB*/,2/*depthA*/,arrayC__arrayC__0,startTime__startTime__0); // displayTensor
		cache_inv(arrayC__arrayC__0, 8388608*sizeof(long));
		cache_inv(startTime__startTime__0, 1*sizeof(double));
	}
}
