/** 
 * @file Core7.c
 * @generated by C6678CPrinter
 * @date Wed Mar 11 15:03:56 GMT 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const generateTensors__broadcastTe__0;  // generateTensors > broadcastTensorB size:= 512*char defined in Core0
extern int *const output_0__arrayB__0;  // broadcastTensorB_output_0 > multiplyTensors_0_arrayB size:= 128*int defined in Core0
extern int *const output_128__arrayB__0;  // broadcastTensorB_output_128 > multiplyTensors_1_arrayB size:= 128*int defined in Core0
extern int *const output_256__arrayB__0;  // broadcastTensorB_output_256 > multiplyTensors_2_arrayB size:= 128*int defined in Core0
extern int *const output_384__arrayB__0;  // broadcastTensorB_output_384 > multiplyTensors_3_arrayB size:= 128*int defined in Core0
extern int *const output_512__arrayB__0;  // broadcastTensorB_output_512 > multiplyTensors_4_arrayB size:= 128*int defined in Core0
extern int *const output_640__arrayB__0;  // broadcastTensorB_output_640 > multiplyTensors_5_arrayB size:= 128*int defined in Core0
extern int *const output_768__arrayB__0;  // broadcastTensorB_output_768 > multiplyTensors_6_arrayB size:= 128*int defined in Core0
extern int *const output_896__arrayB__0;  // broadcastTensorB_output_896 > multiplyTensors_7_arrayB size:= 128*int defined in Core0
extern int *const arrayB__input__0;  // generateTensors_arrayB > broadcastTensorB_input size:= 128*int defined in Core0
extern char *const broadcastTensorB__multiplyTe__5;  // broadcastTensorB > multiplyTensors_6 size:= 512*char defined in Core0
extern char *const broadcastTensorB__multiplyTe__7;  // broadcastTensorB > multiplyTensors_5 size:= 512*char defined in Core0
extern char *const broadcastTensorB__multiplyTe__2;  // broadcastTensorB > multiplyTensors_4 size:= 512*char defined in Core0
extern char *const broadcastTensorB__multiplyTe__6;  // broadcastTensorB > multiplyTensors_3 size:= 512*char defined in Core0
extern char *const broadcastTensorB__multiplyTe__3;  // broadcastTensorB > multiplyTensors_2 size:= 512*char defined in Core0
extern char *const broadcastTensorB__multiplyTe__0;  // broadcastTensorB > multiplyTensors_1 size:= 512*char defined in Core0
extern char *const broadcastTensorB__multiplyTe__1;  // broadcastTensorB > multiplyTensors_0 size:= 512*char defined in Core0
extern char *const explode_generateTensors_arra__1;  // explode_generateTensors_arrayA > multiplyTensors_7 size:= 64*char defined in Core0
extern char *const multiplyTensors_0__implode_d__0;  // multiplyTensors_0 > implode_displayTensor_arrayC size:= 64*char defined in Core0
extern char *const multiplyTensors_1__implode_d__0;  // multiplyTensors_1 > implode_displayTensor_arrayC size:= 64*char defined in Core0
extern char *const multiplyTensors_2__implode_d__0;  // multiplyTensors_2 > implode_displayTensor_arrayC size:= 64*char defined in Core0
extern char *const multiplyTensors_3__implode_d__0;  // multiplyTensors_3 > implode_displayTensor_arrayC size:= 64*char defined in Core0
extern char *const multiplyTensors_4__implode_d__0;  // multiplyTensors_4 > implode_displayTensor_arrayC size:= 64*char defined in Core0
extern char *const multiplyTensors_5__implode_d__0;  // multiplyTensors_5 > implode_displayTensor_arrayC size:= 64*char defined in Core0
extern char *const multiplyTensors_6__implode_d__0;  // multiplyTensors_6 > implode_displayTensor_arrayC size:= 64*char defined in Core0
extern int *const arrayA_112__arrayA__0;  // explode_generateTensors_arrayA_arrayA_112 > multiplyTensors_7_arrayA size:= 16*int defined in Core0
extern long *const arrayC__arrayC_112__0;  // multiplyTensors_7_arrayC > implode_displayTensor_arrayC_arrayC_112 size:= 16*long defined in Core0
extern long *const arrayC__arrayC_0__0;  // multiplyTensors_0_arrayC > implode_displayTensor_arrayC_arrayC_0 size:= 16*long defined in Core0
extern long *const arrayC__arrayC_16__0;  // multiplyTensors_1_arrayC > implode_displayTensor_arrayC_arrayC_16 size:= 16*long defined in Core0
extern long *const arrayC__arrayC_32__0;  // multiplyTensors_2_arrayC > implode_displayTensor_arrayC_arrayC_32 size:= 16*long defined in Core0
extern long *const arrayC__arrayC_48__0;  // multiplyTensors_3_arrayC > implode_displayTensor_arrayC_arrayC_48 size:= 16*long defined in Core0
extern long *const arrayC__arrayC_64__0;  // multiplyTensors_4_arrayC > implode_displayTensor_arrayC_arrayC_64 size:= 16*long defined in Core0
extern long *const arrayC__arrayC_80__0;  // multiplyTensors_5_arrayC > implode_displayTensor_arrayC_arrayC_80 size:= 16*long defined in Core0
extern long *const arrayC__arrayC_96__0;  // multiplyTensors_6_arrayC > implode_displayTensor_arrayC_arrayC_96 size:= 16*long defined in Core0
extern long *const arrayC__arrayC__0;  // implode_displayTensor_arrayC_arrayC > displayTensor_arrayC size:= 128*long defined in Core0
extern char *const implode_displayTensor_arrayC__0;  // implode_displayTensor_arrayC > displayTensor size:= 512*char defined in Core0

// Core Global Definitions

void core7(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core7: generateTensors__broadcastTe__0 
		receiveEnd(0); // Core0 > Core7: generateTensors__broadcastTe__0 
		cache_inv(generateTensors__broadcastTe__0, 512*sizeof(char));
		// Broadcast broadcastTensorB
		{
			memcpy((void*)(output_0__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
			memcpy((void*)(output_128__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
			memcpy((void*)(output_256__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
			memcpy((void*)(output_384__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
			memcpy((void*)(output_512__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
			memcpy((void*)(output_640__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
			memcpy((void*)(output_768__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
			memcpy((void*)(output_896__arrayB__0+0),(void*)( arrayB__input__0+0), 128*sizeof(int));
		}
		cache_inv(arrayB__input__0, 128*sizeof(int));
		cache_wbInv(broadcastTensorB__multiplyTe__5, 512*sizeof(char));
		sendStart(1); // Core7 > Core1: broadcastTensorB__multiplyTe__5 
		sendEnd(); // Core7 > Core1: broadcastTensorB__multiplyTe__5 
		cache_wbInv(broadcastTensorB__multiplyTe__7, 512*sizeof(char));
		sendStart(6); // Core7 > Core6: broadcastTensorB__multiplyTe__7 
		sendEnd(); // Core7 > Core6: broadcastTensorB__multiplyTe__7 
		cache_wbInv(broadcastTensorB__multiplyTe__2, 512*sizeof(char));
		sendStart(3); // Core7 > Core3: broadcastTensorB__multiplyTe__2 
		sendEnd(); // Core7 > Core3: broadcastTensorB__multiplyTe__2 
		cache_wbInv(broadcastTensorB__multiplyTe__6, 512*sizeof(char));
		sendStart(4); // Core7 > Core4: broadcastTensorB__multiplyTe__6 
		sendEnd(); // Core7 > Core4: broadcastTensorB__multiplyTe__6 
		cache_wbInv(broadcastTensorB__multiplyTe__3, 512*sizeof(char));
		sendStart(5); // Core7 > Core5: broadcastTensorB__multiplyTe__3 
		sendEnd(); // Core7 > Core5: broadcastTensorB__multiplyTe__3 
		cache_wbInv(broadcastTensorB__multiplyTe__0, 512*sizeof(char));
		sendStart(2); // Core7 > Core2: broadcastTensorB__multiplyTe__0 
		sendEnd(); // Core7 > Core2: broadcastTensorB__multiplyTe__0 
		cache_wbInv(broadcastTensorB__multiplyTe__1, 512*sizeof(char));
		sendStart(0); // Core7 > Core0: broadcastTensorB__multiplyTe__1 
		sendEnd(); // Core7 > Core0: broadcastTensorB__multiplyTe__1 
		receiveStart(); // Core0 > Core7: explode_generateTensors_arra__1 
		receiveEnd(0); // Core0 > Core7: explode_generateTensors_arra__1 
		cache_inv(explode_generateTensors_arra__1, 64*sizeof(char));
		receiveStart(); // Core0 > Core7: multiplyTensors_0__implode_d__0 
		receiveEnd(0); // Core0 > Core7: multiplyTensors_0__implode_d__0 
		cache_inv(multiplyTensors_0__implode_d__0, 64*sizeof(char));
		receiveStart(); // Core2 > Core7: multiplyTensors_1__implode_d__0 
		receiveEnd(2); // Core2 > Core7: multiplyTensors_1__implode_d__0 
		cache_inv(multiplyTensors_1__implode_d__0, 64*sizeof(char));
		receiveStart(); // Core5 > Core7: multiplyTensors_2__implode_d__0 
		receiveEnd(5); // Core5 > Core7: multiplyTensors_2__implode_d__0 
		cache_inv(multiplyTensors_2__implode_d__0, 64*sizeof(char));
		receiveStart(); // Core4 > Core7: multiplyTensors_3__implode_d__0 
		receiveEnd(4); // Core4 > Core7: multiplyTensors_3__implode_d__0 
		cache_inv(multiplyTensors_3__implode_d__0, 64*sizeof(char));
		receiveStart(); // Core3 > Core7: multiplyTensors_4__implode_d__0 
		receiveEnd(3); // Core3 > Core7: multiplyTensors_4__implode_d__0 
		cache_inv(multiplyTensors_4__implode_d__0, 64*sizeof(char));
		receiveStart(); // Core6 > Core7: multiplyTensors_5__implode_d__0 
		receiveEnd(6); // Core6 > Core7: multiplyTensors_5__implode_d__0 
		cache_inv(multiplyTensors_5__implode_d__0, 64*sizeof(char));
		receiveStart(); // Core1 > Core7: multiplyTensors_6__implode_d__0 
		receiveEnd(1); // Core1 > Core7: multiplyTensors_6__implode_d__0 
		cache_inv(multiplyTensors_6__implode_d__0, 64*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,arrayA_112__arrayA__0,output_896__arrayB__0,arrayC__arrayC_112__0); // multiplyTensors_7
		cache_inv(arrayA_112__arrayA__0, 16*sizeof(int));
		cache_inv(output_896__arrayB__0, 128*sizeof(int));
		// Join implode_displayTensor_arrayC
		{
			memcpy((void*)(arrayC__arrayC__0+0),(void*)( arrayC__arrayC_0__0+0), 16*sizeof(long));
			memcpy((void*)(arrayC__arrayC__0+16),(void*)( arrayC__arrayC_16__0+0), 16*sizeof(long));
			memcpy((void*)(arrayC__arrayC__0+32),(void*)( arrayC__arrayC_32__0+0), 16*sizeof(long));
			memcpy((void*)(arrayC__arrayC__0+48),(void*)( arrayC__arrayC_48__0+0), 16*sizeof(long));
			memcpy((void*)(arrayC__arrayC__0+64),(void*)( arrayC__arrayC_64__0+0), 16*sizeof(long));
			memcpy((void*)(arrayC__arrayC__0+80),(void*)( arrayC__arrayC_80__0+0), 16*sizeof(long));
			memcpy((void*)(arrayC__arrayC__0+96),(void*)( arrayC__arrayC_96__0+0), 16*sizeof(long));
			memcpy((void*)(arrayC__arrayC__0+112),(void*)( arrayC__arrayC_112__0+0), 16*sizeof(long));
		}
		cache_inv(arrayC__arrayC_0__0, 16*sizeof(long));
		cache_inv(arrayC__arrayC_16__0, 16*sizeof(long));
		cache_inv(arrayC__arrayC_32__0, 16*sizeof(long));
		cache_inv(arrayC__arrayC_48__0, 16*sizeof(long));
		cache_inv(arrayC__arrayC_64__0, 16*sizeof(long));
		cache_inv(arrayC__arrayC_80__0, 16*sizeof(long));
		cache_inv(arrayC__arrayC_96__0, 16*sizeof(long));
		cache_inv(arrayC__arrayC_112__0, 16*sizeof(long));
		cache_wbInv(implode_displayTensor_arrayC__0, 512*sizeof(char));
		sendStart(0); // Core7 > Core0: implode_displayTensor_arrayC__0 
		sendEnd(); // Core7 > Core0: implode_displayTensor_arrayC__0 
	}
}
