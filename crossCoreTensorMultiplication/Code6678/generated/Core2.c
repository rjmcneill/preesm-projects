/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Wed Mar 11 22:27:57 GMT 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__16;  // explode_generateTensors_arrayA > multiplyTensors_5 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__5;  // explode_generateTensors_arrayA > multiplyTensors_1 size:= 32*char defined in Core0
extern char *const broadcastTensorB_0__multiply__6;  // broadcastTensorB_0 > multiplyTensors_5 size:= 256*char defined in Core0
extern char *const broadcastTensorB_0__multiply__0;  // broadcastTensorB_0 > multiplyTensors_1 size:= 256*char defined in Core0
extern int *const arrayA_8__arrayA__0;  // explode_generateTensors_arrayA_arrayA_8 > multiplyTensors_1_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__0;  // broadcastTensorB_0_output_64 > multiplyTensors_1_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_8__0;  // multiplyTensors_1_arrayC > implode_displayTensor_arrayC_arrayC_8 size:= 8*long defined in Core0
extern char *const multiplyTensors_1__implode_d__0;  // multiplyTensors_1 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_40__arrayA__0;  // explode_generateTensors_arrayA_arrayA_40 > multiplyTensors_5_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__1;  // broadcastTensorB_0_output_320 > multiplyTensors_5_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_40__0;  // multiplyTensors_5_arrayC > implode_displayTensor_arrayC_arrayC_40 size:= 8*long defined in Core0
extern char *const multiplyTensors_5__implode_d__0;  // multiplyTensors_5 > implode_displayTensor_arrayC size:= 32*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__16 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__16 
		cache_inv(explode_generateTensors_arra__16, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__5 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__5 
		cache_inv(explode_generateTensors_arra__5, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_0__multiply__6 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_0__multiply__6 
		cache_inv(broadcastTensorB_0__multiply__6, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_0__multiply__0 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_0__multiply__0 
		cache_inv(broadcastTensorB_0__multiply__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,arrayA_8__arrayA__0,output_64__arrayB__0,arrayC__arrayC_8__0); // multiplyTensors_1
		cache_inv(arrayA_8__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__0, 64*sizeof(int));
		cache_wbInv(multiplyTensors_1__implode_d__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_1__implode_d__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_1__implode_d__0 
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,arrayA_40__arrayA__0,output_320__arrayB__1,arrayC__arrayC_40__0); // multiplyTensors_5
		cache_inv(arrayA_40__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__1, 64*sizeof(int));
		cache_wbInv(multiplyTensors_5__implode_d__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_5__implode_d__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_5__implode_d__0 
	}
}
