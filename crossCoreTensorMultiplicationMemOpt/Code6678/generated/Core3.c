/** 
 * @file Core3.c
 * @generated by C6678CPrinter
 * @date Fri Mar 13 01:30:27 GMT 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__9;  // explode_generateTensors_arrayA > multiplyTensors_15 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__15;  // explode_generateTensors_arrayA > multiplyTensors_7 size:= 32*char defined in Core0
extern char *const broadcastTensorB_0__multiply__1;  // broadcastTensorB_0 > multiplyTensors_7 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__7;  // broadcastTensorB_1 > multiplyTensors_15 size:= 256*char defined in Core0
extern int *const arrayA_120__arrayA__0;  // explode_generateTensors_arrayA_arrayA_120 > multiplyTensors_15_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__1;  // broadcastTensorB_1_output_448 > multiplyTensors_15_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_120__0;  // multiplyTensors_15_arrayC > implode_displayTensor_arrayC_arrayC_120 size:= 8*long defined in Core0
extern char *const multiplyTensors_15__implode___0;  // multiplyTensors_15 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_56__arrayA__0;  // explode_generateTensors_arrayA_arrayA_56 > multiplyTensors_7_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__0;  // broadcastTensorB_0_output_448 > multiplyTensors_7_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_56__0;  // multiplyTensors_7_arrayC > implode_displayTensor_arrayC_arrayC_56 size:= 8*long defined in Core0
extern char *const multiplyTensors_7__implode_d__0;  // multiplyTensors_7 > implode_displayTensor_arrayC size:= 32*char defined in Core0

// Core Global Definitions

void core3(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__9 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__9 
		cache_inv(explode_generateTensors_arra__9, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__15 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__15 
		cache_inv(explode_generateTensors_arra__15, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: broadcastTensorB_0__multiply__1 
		receiveEnd(7); // Core7 > Core3: broadcastTensorB_0__multiply__1 
		cache_inv(broadcastTensorB_0__multiply__1, 256*sizeof(char));
		receiveStart(); // Core0 > Core3: broadcastTensorB_1__multiply__7 
		receiveEnd(0); // Core0 > Core3: broadcastTensorB_1__multiply__7 
		cache_inv(broadcastTensorB_1__multiply__7, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,arrayA_120__arrayA__0,output_448__arrayB__1,arrayC__arrayC_120__0); // multiplyTensors_15
		cache_inv(arrayA_120__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__1, 64*sizeof(int));
		cache_wbInv(multiplyTensors_15__implode___0, 32*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_15__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_15__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,arrayA_56__arrayA__0,output_448__arrayB__0,arrayC__arrayC_56__0); // multiplyTensors_7
		cache_inv(arrayA_56__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__0, 64*sizeof(int));
		cache_wbInv(multiplyTensors_7__implode_d__0, 32*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_7__implode_d__0 
		sendEnd(); // Core3 > Core2: multiplyTensors_7__implode_d__0 
	}
}
