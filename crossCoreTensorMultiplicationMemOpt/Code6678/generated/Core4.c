/** 
 * @file Core4.c
 * @generated by C6678CPrinter
 * @date Fri Mar 13 00:17:40 GMT 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__14;  // explode_generateTensors_arrayA > multiplyTensors_4 size:= 512*char defined in Core0
extern char *const explode_generateTensors_arra__11;  // explode_generateTensors_arrayA > multiplyTensors_0 size:= 512*char defined in Core0
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayB > broadcastTensorB_0 size:= 4096*char defined in Core0
extern int *const output_0__arrayB__0;  // broadcastTensorB_0_output_0 > multiplyTensors_0_arrayB size:= 1024*int defined in Core0
extern int *const output_1024__arrayB__0;  // broadcastTensorB_0_output_1024 > multiplyTensors_1_arrayB size:= 1024*int defined in Core0
extern int *const output_2048__arrayB__1;  // broadcastTensorB_0_output_2048 > multiplyTensors_2_arrayB size:= 1024*int defined in Core0
extern int *const output_3072__arrayB__1;  // broadcastTensorB_0_output_3072 > multiplyTensors_3_arrayB size:= 1024*int defined in Core0
extern int *const output_4096__arrayB__0;  // broadcastTensorB_0_output_4096 > multiplyTensors_4_arrayB size:= 1024*int defined in Core0
extern int *const output_5120__arrayB__0;  // broadcastTensorB_0_output_5120 > multiplyTensors_5_arrayB size:= 1024*int defined in Core0
extern int *const output_6144__arrayB__0;  // broadcastTensorB_0_output_6144 > multiplyTensors_6_arrayB size:= 1024*int defined in Core0
extern int *const output_7168__arrayB__1;  // broadcastTensorB_0_output_7168 > multiplyTensors_7_arrayB size:= 1024*int defined in Core0
extern int *const arrayB_0__input__0;  // explode_generateTensors_arrayB_arrayB_0 > broadcastTensorB_0_input size:= 1024*int defined in Core0
extern char *const broadcastTensorB_0__multiply__4;  // broadcastTensorB_0 > multiplyTensors_7 size:= 4096*char defined in Core0
extern char *const broadcastTensorB_0__multiply__5;  // broadcastTensorB_0 > multiplyTensors_6 size:= 4096*char defined in Core0
extern char *const broadcastTensorB_0__multiply__3;  // broadcastTensorB_0 > multiplyTensors_5 size:= 4096*char defined in Core0
extern char *const broadcastTensorB_0__multiply__6;  // broadcastTensorB_0 > multiplyTensors_3 size:= 4096*char defined in Core0
extern char *const broadcastTensorB_0__multiply__7;  // broadcastTensorB_0 > multiplyTensors_2 size:= 4096*char defined in Core0
extern char *const broadcastTensorB_0__multiply__0;  // broadcastTensorB_0 > multiplyTensors_1 size:= 4096*char defined in Core0
extern int *const arrayA_0__arrayA__0;  // explode_generateTensors_arrayA_arrayA_0 > multiplyTensors_0_arrayA size:= 128*int defined in Core0
extern long *const arrayC__arrayC_0__0;  // multiplyTensors_0_arrayC > implode_displayTensor_arrayC_arrayC_0 size:= 128*long defined in Core0
extern char *const multiplyTensors_0__implode_d__0;  // multiplyTensors_0 > implode_displayTensor_arrayC size:= 512*char defined in Core0
extern int *const arrayA_512__arrayA__0;  // explode_generateTensors_arrayA_arrayA_512 > multiplyTensors_4_arrayA size:= 128*int defined in Core0
extern long *const arrayC__arrayC_512__0;  // multiplyTensors_4_arrayC > implode_displayTensor_arrayC_arrayC_512 size:= 128*long defined in Core0
extern char *const multiplyTensors_4__implode_d__0;  // multiplyTensors_4 > implode_displayTensor_arrayC size:= 512*char defined in Core0

// Core Global Definitions

void core4(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core4: explode_generateTensors_arra__14 
		receiveEnd(7); // Core7 > Core4: explode_generateTensors_arra__14 
		cache_inv(explode_generateTensors_arra__14, 512*sizeof(char));
		receiveStart(); // Core7 > Core4: explode_generateTensors_arra__11 
		receiveEnd(7); // Core7 > Core4: explode_generateTensors_arra__11 
		cache_inv(explode_generateTensors_arra__11, 512*sizeof(char));
		receiveStart(); // Core0 > Core4: explode_generateTensors_arra__6 
		receiveEnd(0); // Core0 > Core4: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 4096*sizeof(char));
		// Broadcast broadcastTensorB_0
		{
			cache_wb(arrayB_0__input__0, 1024*sizeof(int));
		}
		cache_wb(((char*)arrayB_0__input__0) + 0, 4096);
		cache_inv(arrayB_0__input__0, 1024*sizeof(int));
		cache_wbInv(broadcastTensorB_0__multiply__4, 4096*sizeof(char));
		sendStart(3); // Core4 > Core3: broadcastTensorB_0__multiply__4 
		sendEnd(); // Core4 > Core3: broadcastTensorB_0__multiply__4 
		cache_wbInv(broadcastTensorB_0__multiply__5, 4096*sizeof(char));
		sendStart(5); // Core4 > Core5: broadcastTensorB_0__multiply__5 
		sendEnd(); // Core4 > Core5: broadcastTensorB_0__multiply__5 
		cache_wbInv(broadcastTensorB_0__multiply__3, 4096*sizeof(char));
		sendStart(6); // Core4 > Core6: broadcastTensorB_0__multiply__3 
		sendEnd(); // Core4 > Core6: broadcastTensorB_0__multiply__3 
		cache_wbInv(broadcastTensorB_0__multiply__6, 4096*sizeof(char));
		sendStart(6); // Core4 > Core6: broadcastTensorB_0__multiply__6 
		sendEnd(); // Core4 > Core6: broadcastTensorB_0__multiply__6 
		cache_wbInv(broadcastTensorB_0__multiply__7, 4096*sizeof(char));
		sendStart(1); // Core4 > Core1: broadcastTensorB_0__multiply__7 
		sendEnd(); // Core4 > Core1: broadcastTensorB_0__multiply__7 
		cache_wbInv(broadcastTensorB_0__multiply__0, 4096*sizeof(char));
		sendStart(1); // Core4 > Core1: broadcastTensorB_0__multiply__0 
		sendEnd(); // Core4 > Core1: broadcastTensorB_0__multiply__0 
		multiply(32/*rowsA*/,32/*columnsA*/,2/*depthA*/,32/*rowsB*/,32/*columnsB*/,2/*depthB*/,arrayA_0__arrayA__0,output_0__arrayB__0,arrayC__arrayC_0__0); // multiplyTensors_0
		cache_inv(arrayA_0__arrayA__0, 128*sizeof(int));
		cache_inv(output_0__arrayB__0, 1024*sizeof(int));
		cache_wbInv(multiplyTensors_0__implode_d__0, 512*sizeof(char));
		sendStart(7); // Core4 > Core7: multiplyTensors_0__implode_d__0 
		sendEnd(); // Core4 > Core7: multiplyTensors_0__implode_d__0 
		multiply(32/*rowsA*/,32/*columnsA*/,2/*depthA*/,32/*rowsB*/,32/*columnsB*/,2/*depthB*/,arrayA_512__arrayA__0,output_4096__arrayB__0,arrayC__arrayC_512__0); // multiplyTensors_4
		cache_inv(arrayA_512__arrayA__0, 128*sizeof(int));
		cache_inv(output_4096__arrayB__0, 1024*sizeof(int));
		cache_wbInv(multiplyTensors_4__implode_d__0, 512*sizeof(char));
		sendStart(7); // Core4 > Core7: multiplyTensors_4__implode_d__0 
		sendEnd(); // Core4 > Core7: multiplyTensors_4__implode_d__0 
	}
}
