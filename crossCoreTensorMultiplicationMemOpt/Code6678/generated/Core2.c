/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Fri Mar 13 00:17:40 GMT 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayA > multiplyTensors_10 size:= 512*char defined in Core0
extern char *const explode_generateTensors_arra__0;  // explode_generateTensors_arrayA > multiplyTensors_9 size:= 512*char defined in Core0
extern char *const broadcastTensorB_1__multiply__0;  // broadcastTensorB_1 > multiplyTensors_10 size:= 4096*char defined in Core0
extern char *const broadcastTensorB_1__multiply__6;  // broadcastTensorB_1 > multiplyTensors_9 size:= 4096*char defined in Core0
extern int *const arrayA_1280__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1280 > multiplyTensors_10_arrayA size:= 128*int defined in Core0
extern int *const output_2048__arrayB__0;  // broadcastTensorB_1_output_2048 > multiplyTensors_10_arrayB size:= 1024*int defined in Core0
extern long *const arrayC__arrayC_1280__0;  // multiplyTensors_10_arrayC > implode_displayTensor_arrayC_arrayC_1280 size:= 128*long defined in Core0
extern char *const multiplyTensors_10__implode___0;  // multiplyTensors_10 > implode_displayTensor_arrayC size:= 512*char defined in Core0
extern int *const arrayA_1152__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1152 > multiplyTensors_9_arrayA size:= 128*int defined in Core0
extern int *const output_1024__arrayB__1;  // broadcastTensorB_1_output_1024 > multiplyTensors_9_arrayB size:= 1024*int defined in Core0
extern long *const arrayC__arrayC_1152__0;  // multiplyTensors_9_arrayC > implode_displayTensor_arrayC_arrayC_1152 size:= 128*long defined in Core0
extern char *const multiplyTensors_9__implode_d__0;  // multiplyTensors_9 > implode_displayTensor_arrayC size:= 512*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__12 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 512*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__0 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__0 
		cache_inv(explode_generateTensors_arra__0, 512*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_1__multiply__0 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_1__multiply__0 
		cache_inv(broadcastTensorB_1__multiply__0, 4096*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_1__multiply__6 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_1__multiply__6 
		cache_inv(broadcastTensorB_1__multiply__6, 4096*sizeof(char));
		multiply(32/*rowsA*/,32/*columnsA*/,2/*depthA*/,32/*rowsB*/,32/*columnsB*/,2/*depthB*/,arrayA_1280__arrayA__0,output_2048__arrayB__0,arrayC__arrayC_1280__0); // multiplyTensors_10
		cache_inv(arrayA_1280__arrayA__0, 128*sizeof(int));
		cache_inv(output_2048__arrayB__0, 1024*sizeof(int));
		cache_wbInv(multiplyTensors_10__implode___0, 512*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_10__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_10__implode___0 
		multiply(32/*rowsA*/,32/*columnsA*/,2/*depthA*/,32/*rowsB*/,32/*columnsB*/,2/*depthB*/,arrayA_1152__arrayA__0,output_1024__arrayB__1,arrayC__arrayC_1152__0); // multiplyTensors_9
		cache_inv(arrayA_1152__arrayA__0, 128*sizeof(int));
		cache_inv(output_1024__arrayB__1, 1024*sizeof(int));
		cache_wbInv(multiplyTensors_9__implode_d__0, 512*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_9__implode_d__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_9__implode_d__0 
	}
}
