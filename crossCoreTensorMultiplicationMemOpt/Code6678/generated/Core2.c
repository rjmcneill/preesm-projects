/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Tue Apr 21 00:59:48 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__196;  // explode_generateTensors_arrayA > multiplyTensors_250 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__273;  // explode_generateTensors_arrayA > multiplyTensors_248 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__172;  // explode_generateTensors_arrayA > multiplyTensors_246 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__109;  // explode_generateTensors_arrayA > multiplyTensors_242 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__190;  // explode_generateTensors_arrayA > multiplyTensors_228 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__102;  // explode_generateTensors_arrayA > multiplyTensors_224 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__81;  // explode_generateTensors_arrayA > multiplyTensors_219 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__178;  // explode_generateTensors_arrayA > multiplyTensors_214 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__208;  // explode_generateTensors_arrayA > multiplyTensors_208 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__49;  // explode_generateTensors_arrayA > multiplyTensors_207 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__224;  // explode_generateTensors_arrayA > multiplyTensors_202 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__118;  // explode_generateTensors_arrayA > multiplyTensors_189 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__214;  // explode_generateTensors_arrayA > multiplyTensors_183 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__276;  // explode_generateTensors_arrayA > multiplyTensors_173 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__221;  // explode_generateTensors_arrayA > multiplyTensors_168 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__1;  // explode_generateTensors_arrayA > multiplyTensors_166 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__83;  // explode_generateTensors_arrayA > multiplyTensors_120 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__46;  // explode_generateTensors_arrayA > multiplyTensors_117 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__85;  // explode_generateTensors_arrayA > multiplyTensors_115 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__135;  // explode_generateTensors_arrayA > multiplyTensors_109 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__79;  // explode_generateTensors_arrayA > multiplyTensors_98 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__249;  // explode_generateTensors_arrayA > multiplyTensors_91 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__230;  // explode_generateTensors_arrayA > multiplyTensors_79 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__108;  // explode_generateTensors_arrayA > multiplyTensors_75 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__107;  // explode_generateTensors_arrayA > multiplyTensors_51 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__225;  // explode_generateTensors_arrayA > multiplyTensors_50 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__239;  // explode_generateTensors_arrayA > multiplyTensors_47 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__89;  // explode_generateTensors_arrayA > multiplyTensors_32 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__57;  // explode_generateTensors_arrayA > multiplyTensors_24 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__152;  // explode_generateTensors_arrayA > multiplyTensors_22 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__235;  // explode_generateTensors_arrayA > multiplyTensors_8 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__2;  // explode_generateTensors_arrayA > multiplyTensors_7 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__209;  // explode_generateTensors_arrayB > broadcastTensorB_30 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__38;  // explode_generateTensors_arrayB > broadcastTensorB_12 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__268;  // explode_generateTensors_arrayB > broadcastTensorB_10 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__223;  // explode_generateTensors_arrayB > broadcastTensorB_1 size:= 256*char defined in Core0
extern char *const broadcastTensorB_0__multiply__4;  // broadcastTensorB_0 > multiplyTensors_7 size:= 256*char defined in Core0
extern int *const output_0__arrayB__21;  // broadcastTensorB_1_output_0 > multiplyTensors_8_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__1;  // broadcastTensorB_1_output_64 > multiplyTensors_9_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__31;  // broadcastTensorB_1_output_128 > multiplyTensors_10_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__20;  // broadcastTensorB_1_output_192 > multiplyTensors_11_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__10;  // broadcastTensorB_1_output_256 > multiplyTensors_12_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__18;  // broadcastTensorB_1_output_320 > multiplyTensors_13_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__3;  // broadcastTensorB_1_output_384 > multiplyTensors_14_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__21;  // broadcastTensorB_1_output_448 > multiplyTensors_15_arrayB size:= 64*int defined in Core0
extern int *const arrayB_64__input__0;  // explode_generateTensors_arrayB_arrayB_64 > broadcastTensorB_1_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_1__multiply__5;  // broadcastTensorB_1 > multiplyTensors_15 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__1;  // broadcastTensorB_1 > multiplyTensors_14 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__3;  // broadcastTensorB_1 > multiplyTensors_13 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__2;  // broadcastTensorB_1 > multiplyTensors_12 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__4;  // broadcastTensorB_1 > multiplyTensors_11 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__7;  // broadcastTensorB_1 > multiplyTensors_10 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__0;  // broadcastTensorB_1 > multiplyTensors_9 size:= 256*char defined in Core0
extern int *const output_0__arrayB__13;  // broadcastTensorB_10_output_0 > multiplyTensors_80_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__24;  // broadcastTensorB_10_output_64 > multiplyTensors_81_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__27;  // broadcastTensorB_10_output_128 > multiplyTensors_82_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__28;  // broadcastTensorB_10_output_192 > multiplyTensors_83_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__2;  // broadcastTensorB_10_output_256 > multiplyTensors_84_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__2;  // broadcastTensorB_10_output_320 > multiplyTensors_85_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__11;  // broadcastTensorB_10_output_384 > multiplyTensors_86_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__6;  // broadcastTensorB_10_output_448 > multiplyTensors_87_arrayB size:= 64*int defined in Core0
extern int *const arrayB_640__input__0;  // explode_generateTensors_arrayB_arrayB_640 > broadcastTensorB_10_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_10__multipl__2;  // broadcastTensorB_10 > multiplyTensors_87 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__4;  // broadcastTensorB_10 > multiplyTensors_86 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__1;  // broadcastTensorB_10 > multiplyTensors_85 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__0;  // broadcastTensorB_10 > multiplyTensors_84 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__7;  // broadcastTensorB_10 > multiplyTensors_83 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__6;  // broadcastTensorB_10 > multiplyTensors_82 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__5;  // broadcastTensorB_10 > multiplyTensors_81 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__3;  // broadcastTensorB_10 > multiplyTensors_80 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__6;  // broadcastTensorB_11 > multiplyTensors_91 size:= 256*char defined in Core0
extern int *const output_0__arrayB__5;  // broadcastTensorB_12_output_0 > multiplyTensors_96_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__27;  // broadcastTensorB_12_output_64 > multiplyTensors_97_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__17;  // broadcastTensorB_12_output_128 > multiplyTensors_98_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__9;  // broadcastTensorB_12_output_192 > multiplyTensors_99_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__5;  // broadcastTensorB_12_output_256 > multiplyTensors_100_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__12;  // broadcastTensorB_12_output_320 > multiplyTensors_101_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__30;  // broadcastTensorB_12_output_384 > multiplyTensors_102_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__13;  // broadcastTensorB_12_output_448 > multiplyTensors_103_arrayB size:= 64*int defined in Core0
extern int *const arrayB_768__input__0;  // explode_generateTensors_arrayB_arrayB_768 > broadcastTensorB_12_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_12__multipl__4;  // broadcastTensorB_12 > multiplyTensors_103 size:= 256*char defined in Core0
extern char *const broadcastTensorB_12__multipl__7;  // broadcastTensorB_12 > multiplyTensors_102 size:= 256*char defined in Core0
extern char *const broadcastTensorB_12__multipl__3;  // broadcastTensorB_12 > multiplyTensors_101 size:= 256*char defined in Core0
extern char *const broadcastTensorB_12__multipl__0;  // broadcastTensorB_12 > multiplyTensors_100 size:= 256*char defined in Core0
extern char *const broadcastTensorB_12__multipl__2;  // broadcastTensorB_12 > multiplyTensors_99 size:= 256*char defined in Core0
extern char *const broadcastTensorB_12__multipl__6;  // broadcastTensorB_12 > multiplyTensors_97 size:= 256*char defined in Core0
extern char *const broadcastTensorB_12__multipl__1;  // broadcastTensorB_12 > multiplyTensors_96 size:= 256*char defined in Core0
extern char *const broadcastTensorB_13__multipl__2;  // broadcastTensorB_13 > multiplyTensors_109 size:= 256*char defined in Core0
extern char *const broadcastTensorB_14__multipl__0;  // broadcastTensorB_14 > multiplyTensors_117 size:= 256*char defined in Core0
extern char *const broadcastTensorB_14__multipl__2;  // broadcastTensorB_14 > multiplyTensors_115 size:= 256*char defined in Core0
extern char *const broadcastTensorB_15__multipl__7;  // broadcastTensorB_15 > multiplyTensors_120 size:= 256*char defined in Core0
extern char *const broadcastTensorB_2__multiply__7;  // broadcastTensorB_2 > multiplyTensors_22 size:= 256*char defined in Core0
extern char *const broadcastTensorB_20__multipl__2;  // broadcastTensorB_20 > multiplyTensors_166 size:= 256*char defined in Core0
extern char *const broadcastTensorB_21__multipl__2;  // broadcastTensorB_21 > multiplyTensors_173 size:= 256*char defined in Core0
extern char *const broadcastTensorB_21__multipl__6;  // broadcastTensorB_21 > multiplyTensors_168 size:= 256*char defined in Core0
extern char *const broadcastTensorB_22__multipl__7;  // broadcastTensorB_22 > multiplyTensors_183 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__2;  // broadcastTensorB_23 > multiplyTensors_189 size:= 256*char defined in Core0
extern char *const broadcastTensorB_25__multipl__6;  // broadcastTensorB_25 > multiplyTensors_207 size:= 256*char defined in Core0
extern char *const broadcastTensorB_25__multipl__1;  // broadcastTensorB_25 > multiplyTensors_202 size:= 256*char defined in Core0
extern char *const broadcastTensorB_26__multipl__4;  // broadcastTensorB_26 > multiplyTensors_214 size:= 256*char defined in Core0
extern char *const broadcastTensorB_26__multipl__6;  // broadcastTensorB_26 > multiplyTensors_208 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__0;  // broadcastTensorB_27 > multiplyTensors_219 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__0;  // broadcastTensorB_28 > multiplyTensors_228 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__5;  // broadcastTensorB_28 > multiplyTensors_224 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__3;  // broadcastTensorB_3 > multiplyTensors_24 size:= 256*char defined in Core0
extern int *const output_0__arrayB__6;  // broadcastTensorB_30_output_0 > multiplyTensors_240_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__20;  // broadcastTensorB_30_output_64 > multiplyTensors_241_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__18;  // broadcastTensorB_30_output_128 > multiplyTensors_242_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__12;  // broadcastTensorB_30_output_192 > multiplyTensors_243_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__6;  // broadcastTensorB_30_output_256 > multiplyTensors_244_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__8;  // broadcastTensorB_30_output_320 > multiplyTensors_245_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__4;  // broadcastTensorB_30_output_384 > multiplyTensors_246_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__30;  // broadcastTensorB_30_output_448 > multiplyTensors_247_arrayB size:= 64*int defined in Core0
extern int *const arrayB_1920__input__0;  // explode_generateTensors_arrayB_arrayB_1920 > broadcastTensorB_30_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_30__multipl__7;  // broadcastTensorB_30 > multiplyTensors_247 size:= 256*char defined in Core0
extern char *const broadcastTensorB_30__multipl__3;  // broadcastTensorB_30 > multiplyTensors_245 size:= 256*char defined in Core0
extern char *const broadcastTensorB_30__multipl__2;  // broadcastTensorB_30 > multiplyTensors_244 size:= 256*char defined in Core0
extern char *const broadcastTensorB_30__multipl__4;  // broadcastTensorB_30 > multiplyTensors_243 size:= 256*char defined in Core0
extern char *const broadcastTensorB_30__multipl__6;  // broadcastTensorB_30 > multiplyTensors_241 size:= 256*char defined in Core0
extern char *const broadcastTensorB_30__multipl__0;  // broadcastTensorB_30 > multiplyTensors_240 size:= 256*char defined in Core0
extern char *const broadcastTensorB_31__multipl__1;  // broadcastTensorB_31 > multiplyTensors_250 size:= 256*char defined in Core0
extern char *const broadcastTensorB_31__multipl__5;  // broadcastTensorB_31 > multiplyTensors_248 size:= 256*char defined in Core0
extern char *const broadcastTensorB_4__multiply__0;  // broadcastTensorB_4 > multiplyTensors_32 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__0;  // broadcastTensorB_5 > multiplyTensors_47 size:= 256*char defined in Core0
extern char *const broadcastTensorB_6__multiply__4;  // broadcastTensorB_6 > multiplyTensors_51 size:= 256*char defined in Core0
extern char *const broadcastTensorB_6__multiply__1;  // broadcastTensorB_6 > multiplyTensors_50 size:= 256*char defined in Core0
extern char *const broadcastTensorB_9__multiply__7;  // broadcastTensorB_9 > multiplyTensors_79 size:= 256*char defined in Core0
extern char *const broadcastTensorB_9__multiply__4;  // broadcastTensorB_9 > multiplyTensors_75 size:= 256*char defined in Core0
extern int *const arrayA_872__arrayA__0;  // explode_generateTensors_arrayA_arrayA_872 > multiplyTensors_109_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__14;  // broadcastTensorB_13_output_320 > multiplyTensors_109_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_872__0;  // multiplyTensors_109_arrayC > implode_displayTensor_arrayC_arrayC_872 size:= 8*long defined in Core0
extern char *const multiplyTensors_109__implode__0;  // multiplyTensors_109 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_920__arrayA__0;  // explode_generateTensors_arrayA_arrayA_920 > multiplyTensors_115_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__13;  // broadcastTensorB_14_output_192 > multiplyTensors_115_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_920__0;  // multiplyTensors_115_arrayC > implode_displayTensor_arrayC_arrayC_920 size:= 8*long defined in Core0
extern char *const multiplyTensors_115__implode__0;  // multiplyTensors_115 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_936__arrayA__0;  // explode_generateTensors_arrayA_arrayA_936 > multiplyTensors_117_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__13;  // broadcastTensorB_14_output_320 > multiplyTensors_117_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_936__0;  // multiplyTensors_117_arrayC > implode_displayTensor_arrayC_arrayC_936 size:= 8*long defined in Core0
extern char *const multiplyTensors_117__implode__0;  // multiplyTensors_117 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_960__arrayA__0;  // explode_generateTensors_arrayA_arrayA_960 > multiplyTensors_120_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__28;  // broadcastTensorB_15_output_0 > multiplyTensors_120_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_960__0;  // multiplyTensors_120_arrayC > implode_displayTensor_arrayC_arrayC_960 size:= 8*long defined in Core0
extern char *const multiplyTensors_120__implode__0;  // multiplyTensors_120 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1328__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1328 > multiplyTensors_166_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__5;  // broadcastTensorB_20_output_384 > multiplyTensors_166_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1328__0;  // multiplyTensors_166_arrayC > implode_displayTensor_arrayC_arrayC_1328 size:= 8*long defined in Core0
extern char *const multiplyTensors_166__implode__0;  // multiplyTensors_166 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1344__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1344 > multiplyTensors_168_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__19;  // broadcastTensorB_21_output_0 > multiplyTensors_168_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1344__0;  // multiplyTensors_168_arrayC > implode_displayTensor_arrayC_arrayC_1344 size:= 8*long defined in Core0
extern char *const multiplyTensors_168__implode__0;  // multiplyTensors_168 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1384__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1384 > multiplyTensors_173_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__19;  // broadcastTensorB_21_output_320 > multiplyTensors_173_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1384__0;  // multiplyTensors_173_arrayC > implode_displayTensor_arrayC_arrayC_1384 size:= 8*long defined in Core0
extern char *const multiplyTensors_173__implode__0;  // multiplyTensors_173 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1464__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1464 > multiplyTensors_183_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__20;  // broadcastTensorB_22_output_448 > multiplyTensors_183_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1464__0;  // multiplyTensors_183_arrayC > implode_displayTensor_arrayC_arrayC_1464 size:= 8*long defined in Core0
extern char *const multiplyTensors_183__implode__0;  // multiplyTensors_183 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1512__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1512 > multiplyTensors_189_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__7;  // broadcastTensorB_23_output_320 > multiplyTensors_189_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1512__0;  // multiplyTensors_189_arrayC > implode_displayTensor_arrayC_arrayC_1512 size:= 8*long defined in Core0
extern char *const multiplyTensors_189__implode__0;  // multiplyTensors_189 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1616__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1616 > multiplyTensors_202_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__5;  // broadcastTensorB_25_output_128 > multiplyTensors_202_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1616__0;  // multiplyTensors_202_arrayC > implode_displayTensor_arrayC_arrayC_1616 size:= 8*long defined in Core0
extern char *const multiplyTensors_202__implode__0;  // multiplyTensors_202 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1656__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1656 > multiplyTensors_207_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__16;  // broadcastTensorB_25_output_448 > multiplyTensors_207_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1656__0;  // multiplyTensors_207_arrayC > implode_displayTensor_arrayC_arrayC_1656 size:= 8*long defined in Core0
extern char *const multiplyTensors_207__implode__0;  // multiplyTensors_207 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1664__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1664 > multiplyTensors_208_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__25;  // broadcastTensorB_26_output_0 > multiplyTensors_208_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1664__0;  // multiplyTensors_208_arrayC > implode_displayTensor_arrayC_arrayC_1664 size:= 8*long defined in Core0
extern char *const multiplyTensors_208__implode__0;  // multiplyTensors_208 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1712__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1712 > multiplyTensors_214_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__7;  // broadcastTensorB_26_output_384 > multiplyTensors_214_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1712__0;  // multiplyTensors_214_arrayC > implode_displayTensor_arrayC_arrayC_1712 size:= 8*long defined in Core0
extern char *const multiplyTensors_214__implode__0;  // multiplyTensors_214 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1752__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1752 > multiplyTensors_219_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__7;  // broadcastTensorB_27_output_192 > multiplyTensors_219_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1752__0;  // multiplyTensors_219_arrayC > implode_displayTensor_arrayC_arrayC_1752 size:= 8*long defined in Core0
extern char *const multiplyTensors_219__implode__0;  // multiplyTensors_219 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_176__arrayA__0;  // explode_generateTensors_arrayA_arrayA_176 > multiplyTensors_22_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__28;  // broadcastTensorB_2_output_384 > multiplyTensors_22_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_176__0;  // multiplyTensors_22_arrayC > implode_displayTensor_arrayC_arrayC_176 size:= 8*long defined in Core0
extern char *const multiplyTensors_22__implode___0;  // multiplyTensors_22 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1792__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1792 > multiplyTensors_224_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__1;  // broadcastTensorB_28_output_0 > multiplyTensors_224_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1792__0;  // multiplyTensors_224_arrayC > implode_displayTensor_arrayC_arrayC_1792 size:= 8*long defined in Core0
extern char *const multiplyTensors_224__implode__0;  // multiplyTensors_224 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1824__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1824 > multiplyTensors_228_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__1;  // broadcastTensorB_28_output_256 > multiplyTensors_228_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1824__0;  // multiplyTensors_228_arrayC > implode_displayTensor_arrayC_arrayC_1824 size:= 8*long defined in Core0
extern char *const multiplyTensors_228__implode__0;  // multiplyTensors_228 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_192__arrayA__0;  // explode_generateTensors_arrayA_arrayA_192 > multiplyTensors_24_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__8;  // broadcastTensorB_3_output_0 > multiplyTensors_24_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_192__0;  // multiplyTensors_24_arrayC > implode_displayTensor_arrayC_arrayC_192 size:= 8*long defined in Core0
extern char *const multiplyTensors_24__implode___0;  // multiplyTensors_24 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1936__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1936 > multiplyTensors_242_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_1936__0;  // multiplyTensors_242_arrayC > implode_displayTensor_arrayC_arrayC_1936 size:= 8*long defined in Core0
extern char *const multiplyTensors_242__implode__0;  // multiplyTensors_242 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1968__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1968 > multiplyTensors_246_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_1968__0;  // multiplyTensors_246_arrayC > implode_displayTensor_arrayC_arrayC_1968 size:= 8*long defined in Core0
extern char *const multiplyTensors_246__implode__0;  // multiplyTensors_246 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1984__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1984 > multiplyTensors_248_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__14;  // broadcastTensorB_31_output_0 > multiplyTensors_248_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1984__0;  // multiplyTensors_248_arrayC > implode_displayTensor_arrayC_arrayC_1984 size:= 8*long defined in Core0
extern char *const multiplyTensors_248__implode__0;  // multiplyTensors_248 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_2000__arrayA__0;  // explode_generateTensors_arrayA_arrayA_2000 > multiplyTensors_250_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__1;  // broadcastTensorB_31_output_128 > multiplyTensors_250_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_2000__0;  // multiplyTensors_250_arrayC > implode_displayTensor_arrayC_arrayC_2000 size:= 8*long defined in Core0
extern char *const multiplyTensors_250__implode__0;  // multiplyTensors_250 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_256__arrayA__0;  // explode_generateTensors_arrayA_arrayA_256 > multiplyTensors_32_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__7;  // broadcastTensorB_4_output_0 > multiplyTensors_32_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_256__0;  // multiplyTensors_32_arrayC > implode_displayTensor_arrayC_arrayC_256 size:= 8*long defined in Core0
extern char *const multiplyTensors_32__implode___0;  // multiplyTensors_32 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_376__arrayA__0;  // explode_generateTensors_arrayA_arrayA_376 > multiplyTensors_47_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__4;  // broadcastTensorB_5_output_448 > multiplyTensors_47_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_376__0;  // multiplyTensors_47_arrayC > implode_displayTensor_arrayC_arrayC_376 size:= 8*long defined in Core0
extern char *const multiplyTensors_47__implode___0;  // multiplyTensors_47 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_400__arrayA__0;  // explode_generateTensors_arrayA_arrayA_400 > multiplyTensors_50_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__12;  // broadcastTensorB_6_output_128 > multiplyTensors_50_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_400__0;  // multiplyTensors_50_arrayC > implode_displayTensor_arrayC_arrayC_400 size:= 8*long defined in Core0
extern char *const multiplyTensors_50__implode___0;  // multiplyTensors_50 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_408__arrayA__0;  // explode_generateTensors_arrayA_arrayA_408 > multiplyTensors_51_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__18;  // broadcastTensorB_6_output_192 > multiplyTensors_51_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_408__0;  // multiplyTensors_51_arrayC > implode_displayTensor_arrayC_arrayC_408 size:= 8*long defined in Core0
extern char *const multiplyTensors_51__implode___0;  // multiplyTensors_51 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_56__arrayA__0;  // explode_generateTensors_arrayA_arrayA_56 > multiplyTensors_7_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__19;  // broadcastTensorB_0_output_448 > multiplyTensors_7_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_56__0;  // multiplyTensors_7_arrayC > implode_displayTensor_arrayC_arrayC_56 size:= 8*long defined in Core0
extern char *const multiplyTensors_7__implode_d__0;  // multiplyTensors_7 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_600__arrayA__0;  // explode_generateTensors_arrayA_arrayA_600 > multiplyTensors_75_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__16;  // broadcastTensorB_9_output_192 > multiplyTensors_75_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_600__0;  // multiplyTensors_75_arrayC > implode_displayTensor_arrayC_arrayC_600 size:= 8*long defined in Core0
extern char *const multiplyTensors_75__implode___0;  // multiplyTensors_75 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_632__arrayA__0;  // explode_generateTensors_arrayA_arrayA_632 > multiplyTensors_79_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__27;  // broadcastTensorB_9_output_448 > multiplyTensors_79_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_632__0;  // multiplyTensors_79_arrayC > implode_displayTensor_arrayC_arrayC_632 size:= 8*long defined in Core0
extern char *const multiplyTensors_79__implode___0;  // multiplyTensors_79 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_64__arrayA__0;  // explode_generateTensors_arrayA_arrayA_64 > multiplyTensors_8_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_64__0;  // multiplyTensors_8_arrayC > implode_displayTensor_arrayC_arrayC_64 size:= 8*long defined in Core0
extern char *const multiplyTensors_8__implode_d__0;  // multiplyTensors_8 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_728__arrayA__0;  // explode_generateTensors_arrayA_arrayA_728 > multiplyTensors_91_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__25;  // broadcastTensorB_11_output_192 > multiplyTensors_91_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_728__0;  // multiplyTensors_91_arrayC > implode_displayTensor_arrayC_arrayC_728 size:= 8*long defined in Core0
extern char *const multiplyTensors_91__implode___0;  // multiplyTensors_91 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_784__arrayA__0;  // explode_generateTensors_arrayA_arrayA_784 > multiplyTensors_98_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_784__0;  // multiplyTensors_98_arrayC > implode_displayTensor_arrayC_arrayC_784 size:= 8*long defined in Core0
extern char *const multiplyTensors_98__implode___0;  // multiplyTensors_98 > implode_displayTensor_arrayC size:= 32*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__196 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__196 
		cache_inv(explode_generateTensors_arra__196, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__273 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__273 
		cache_inv(explode_generateTensors_arra__273, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__172 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__172 
		cache_inv(explode_generateTensors_arra__172, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__109 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__109 
		cache_inv(explode_generateTensors_arra__109, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__190 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__190 
		cache_inv(explode_generateTensors_arra__190, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__102 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__102 
		cache_inv(explode_generateTensors_arra__102, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__81 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__81 
		cache_inv(explode_generateTensors_arra__81, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__178 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__178 
		cache_inv(explode_generateTensors_arra__178, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__208 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__208 
		cache_inv(explode_generateTensors_arra__208, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__49 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__49 
		cache_inv(explode_generateTensors_arra__49, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__224 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__224 
		cache_inv(explode_generateTensors_arra__224, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__118 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__118 
		cache_inv(explode_generateTensors_arra__118, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__214 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__214 
		cache_inv(explode_generateTensors_arra__214, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__276 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__276 
		cache_inv(explode_generateTensors_arra__276, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__221 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__221 
		cache_inv(explode_generateTensors_arra__221, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__1 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__1 
		cache_inv(explode_generateTensors_arra__1, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__83 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__83 
		cache_inv(explode_generateTensors_arra__83, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__46 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__46 
		cache_inv(explode_generateTensors_arra__46, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__85 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__85 
		cache_inv(explode_generateTensors_arra__85, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__135 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__135 
		cache_inv(explode_generateTensors_arra__135, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__79 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__79 
		cache_inv(explode_generateTensors_arra__79, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__249 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__249 
		cache_inv(explode_generateTensors_arra__249, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__230 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__230 
		cache_inv(explode_generateTensors_arra__230, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__108 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__108 
		cache_inv(explode_generateTensors_arra__108, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__107 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__107 
		cache_inv(explode_generateTensors_arra__107, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__225 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__225 
		cache_inv(explode_generateTensors_arra__225, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__239 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__239 
		cache_inv(explode_generateTensors_arra__239, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__89 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__89 
		cache_inv(explode_generateTensors_arra__89, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__57 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__57 
		cache_inv(explode_generateTensors_arra__57, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__152 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__152 
		cache_inv(explode_generateTensors_arra__152, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__235 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__235 
		cache_inv(explode_generateTensors_arra__235, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__2 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__2 
		cache_inv(explode_generateTensors_arra__2, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__209 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__209 
		cache_inv(explode_generateTensors_arra__209, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__38 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__38 
		cache_inv(explode_generateTensors_arra__38, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__268 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__268 
		cache_inv(explode_generateTensors_arra__268, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__223 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__223 
		cache_inv(explode_generateTensors_arra__223, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: broadcastTensorB_0__multiply__4 
		receiveEnd(3); // Core3 > Core2: broadcastTensorB_0__multiply__4 
		cache_inv(broadcastTensorB_0__multiply__4, 256*sizeof(char));
		// Broadcast broadcastTensorB_1
		{
			cache_wb(arrayB_64__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_64__input__0) + 0, 256);
		cache_inv(arrayB_64__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_1__multiply__5, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_1__multiply__5 
		sendEnd(); // Core2 > Core7: broadcastTensorB_1__multiply__5 
		cache_wbInv(broadcastTensorB_1__multiply__1, 256*sizeof(char));
		sendStart(3); // Core2 > Core3: broadcastTensorB_1__multiply__1 
		sendEnd(); // Core2 > Core3: broadcastTensorB_1__multiply__1 
		cache_wbInv(broadcastTensorB_1__multiply__3, 256*sizeof(char));
		sendStart(3); // Core2 > Core3: broadcastTensorB_1__multiply__3 
		sendEnd(); // Core2 > Core3: broadcastTensorB_1__multiply__3 
		cache_wbInv(broadcastTensorB_1__multiply__2, 256*sizeof(char));
		sendStart(1); // Core2 > Core1: broadcastTensorB_1__multiply__2 
		sendEnd(); // Core2 > Core1: broadcastTensorB_1__multiply__2 
		cache_wbInv(broadcastTensorB_1__multiply__4, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: broadcastTensorB_1__multiply__4 
		sendEnd(); // Core2 > Core4: broadcastTensorB_1__multiply__4 
		cache_wbInv(broadcastTensorB_1__multiply__7, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: broadcastTensorB_1__multiply__7 
		sendEnd(); // Core2 > Core4: broadcastTensorB_1__multiply__7 
		cache_wbInv(broadcastTensorB_1__multiply__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: broadcastTensorB_1__multiply__0 
		sendEnd(); // Core2 > Core6: broadcastTensorB_1__multiply__0 
		// Broadcast broadcastTensorB_10
		{
			cache_wb(arrayB_640__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_640__input__0) + 0, 256);
		cache_inv(arrayB_640__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_10__multipl__2, 256*sizeof(char));
		sendStart(3); // Core2 > Core3: broadcastTensorB_10__multipl__2 
		sendEnd(); // Core2 > Core3: broadcastTensorB_10__multipl__2 
		cache_wbInv(broadcastTensorB_10__multipl__4, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_10__multipl__4 
		sendEnd(); // Core2 > Core7: broadcastTensorB_10__multipl__4 
		cache_wbInv(broadcastTensorB_10__multipl__1, 256*sizeof(char));
		sendStart(1); // Core2 > Core1: broadcastTensorB_10__multipl__1 
		sendEnd(); // Core2 > Core1: broadcastTensorB_10__multipl__1 
		cache_wbInv(broadcastTensorB_10__multipl__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: broadcastTensorB_10__multipl__0 
		sendEnd(); // Core2 > Core5: broadcastTensorB_10__multipl__0 
		cache_wbInv(broadcastTensorB_10__multipl__7, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_10__multipl__7 
		sendEnd(); // Core2 > Core7: broadcastTensorB_10__multipl__7 
		cache_wbInv(broadcastTensorB_10__multipl__6, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: broadcastTensorB_10__multipl__6 
		sendEnd(); // Core2 > Core6: broadcastTensorB_10__multipl__6 
		cache_wbInv(broadcastTensorB_10__multipl__5, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: broadcastTensorB_10__multipl__5 
		sendEnd(); // Core2 > Core5: broadcastTensorB_10__multipl__5 
		cache_wbInv(broadcastTensorB_10__multipl__3, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: broadcastTensorB_10__multipl__3 
		sendEnd(); // Core2 > Core5: broadcastTensorB_10__multipl__3 
		receiveStart(); // Core1 > Core2: broadcastTensorB_11__multipl__6 
		receiveEnd(1); // Core1 > Core2: broadcastTensorB_11__multipl__6 
		cache_inv(broadcastTensorB_11__multipl__6, 256*sizeof(char));
		// Broadcast broadcastTensorB_12
		{
			cache_wb(arrayB_768__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_768__input__0) + 0, 256);
		cache_inv(arrayB_768__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_12__multipl__4, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_12__multipl__4 
		sendEnd(); // Core2 > Core7: broadcastTensorB_12__multipl__4 
		cache_wbInv(broadcastTensorB_12__multipl__7, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_12__multipl__7 
		sendEnd(); // Core2 > Core7: broadcastTensorB_12__multipl__7 
		cache_wbInv(broadcastTensorB_12__multipl__3, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: broadcastTensorB_12__multipl__3 
		sendEnd(); // Core2 > Core6: broadcastTensorB_12__multipl__3 
		cache_wbInv(broadcastTensorB_12__multipl__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: broadcastTensorB_12__multipl__0 
		sendEnd(); // Core2 > Core6: broadcastTensorB_12__multipl__0 
		cache_wbInv(broadcastTensorB_12__multipl__2, 256*sizeof(char));
		sendStart(3); // Core2 > Core3: broadcastTensorB_12__multipl__2 
		sendEnd(); // Core2 > Core3: broadcastTensorB_12__multipl__2 
		cache_wbInv(broadcastTensorB_12__multipl__6, 256*sizeof(char));
		sendStart(1); // Core2 > Core1: broadcastTensorB_12__multipl__6 
		sendEnd(); // Core2 > Core1: broadcastTensorB_12__multipl__6 
		cache_wbInv(broadcastTensorB_12__multipl__1, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: broadcastTensorB_12__multipl__1 
		sendEnd(); // Core2 > Core0: broadcastTensorB_12__multipl__1 
		receiveStart(); // Core0 > Core2: broadcastTensorB_13__multipl__2 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_13__multipl__2 
		cache_inv(broadcastTensorB_13__multipl__2, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_14__multipl__0 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_14__multipl__0 
		cache_inv(broadcastTensorB_14__multipl__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_14__multipl__2 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_14__multipl__2 
		cache_inv(broadcastTensorB_14__multipl__2, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_15__multipl__7 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_15__multipl__7 
		cache_inv(broadcastTensorB_15__multipl__7, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_2__multiply__7 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_2__multiply__7 
		cache_inv(broadcastTensorB_2__multiply__7, 256*sizeof(char));
		receiveStart(); // Core4 > Core2: broadcastTensorB_20__multipl__2 
		receiveEnd(4); // Core4 > Core2: broadcastTensorB_20__multipl__2 
		cache_inv(broadcastTensorB_20__multipl__2, 256*sizeof(char));
		receiveStart(); // Core6 > Core2: broadcastTensorB_21__multipl__2 
		receiveEnd(6); // Core6 > Core2: broadcastTensorB_21__multipl__2 
		cache_inv(broadcastTensorB_21__multipl__2, 256*sizeof(char));
		receiveStart(); // Core6 > Core2: broadcastTensorB_21__multipl__6 
		receiveEnd(6); // Core6 > Core2: broadcastTensorB_21__multipl__6 
		cache_inv(broadcastTensorB_21__multipl__6, 256*sizeof(char));
		receiveStart(); // Core4 > Core2: broadcastTensorB_22__multipl__7 
		receiveEnd(4); // Core4 > Core2: broadcastTensorB_22__multipl__7 
		cache_inv(broadcastTensorB_22__multipl__7, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: broadcastTensorB_23__multipl__2 
		receiveEnd(1); // Core1 > Core2: broadcastTensorB_23__multipl__2 
		cache_inv(broadcastTensorB_23__multipl__2, 256*sizeof(char));
		receiveStart(); // Core6 > Core2: broadcastTensorB_25__multipl__6 
		receiveEnd(6); // Core6 > Core2: broadcastTensorB_25__multipl__6 
		cache_inv(broadcastTensorB_25__multipl__6, 256*sizeof(char));
		receiveStart(); // Core6 > Core2: broadcastTensorB_25__multipl__1 
		receiveEnd(6); // Core6 > Core2: broadcastTensorB_25__multipl__1 
		cache_inv(broadcastTensorB_25__multipl__1, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_26__multipl__4 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_26__multipl__4 
		cache_inv(broadcastTensorB_26__multipl__4, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_26__multipl__6 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_26__multipl__6 
		cache_inv(broadcastTensorB_26__multipl__6, 256*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_27__multipl__0 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_27__multipl__0 
		cache_inv(broadcastTensorB_27__multipl__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_28__multipl__0 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_28__multipl__0 
		cache_inv(broadcastTensorB_28__multipl__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_28__multipl__5 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_28__multipl__5 
		cache_inv(broadcastTensorB_28__multipl__5, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: broadcastTensorB_3__multiply__3 
		receiveEnd(1); // Core1 > Core2: broadcastTensorB_3__multiply__3 
		cache_inv(broadcastTensorB_3__multiply__3, 256*sizeof(char));
		// Broadcast broadcastTensorB_30
		{
			cache_wb(arrayB_1920__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_1920__input__0) + 0, 256);
		cache_inv(arrayB_1920__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_30__multipl__7, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_30__multipl__7 
		sendEnd(); // Core2 > Core7: broadcastTensorB_30__multipl__7 
		cache_wbInv(broadcastTensorB_30__multipl__3, 256*sizeof(char));
		sendStart(3); // Core2 > Core3: broadcastTensorB_30__multipl__3 
		sendEnd(); // Core2 > Core3: broadcastTensorB_30__multipl__3 
		cache_wbInv(broadcastTensorB_30__multipl__2, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: broadcastTensorB_30__multipl__2 
		sendEnd(); // Core2 > Core0: broadcastTensorB_30__multipl__2 
		cache_wbInv(broadcastTensorB_30__multipl__4, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: broadcastTensorB_30__multipl__4 
		sendEnd(); // Core2 > Core0: broadcastTensorB_30__multipl__4 
		cache_wbInv(broadcastTensorB_30__multipl__6, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: broadcastTensorB_30__multipl__6 
		sendEnd(); // Core2 > Core0: broadcastTensorB_30__multipl__6 
		cache_wbInv(broadcastTensorB_30__multipl__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: broadcastTensorB_30__multipl__0 
		sendEnd(); // Core2 > Core5: broadcastTensorB_30__multipl__0 
		receiveStart(); // Core7 > Core2: broadcastTensorB_31__multipl__1 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_31__multipl__1 
		cache_inv(broadcastTensorB_31__multipl__1, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_31__multipl__5 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_31__multipl__5 
		cache_inv(broadcastTensorB_31__multipl__5, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: broadcastTensorB_4__multiply__0 
		receiveEnd(3); // Core3 > Core2: broadcastTensorB_4__multiply__0 
		cache_inv(broadcastTensorB_4__multiply__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_5__multiply__0 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_5__multiply__0 
		cache_inv(broadcastTensorB_5__multiply__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_6__multiply__4 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_6__multiply__4 
		cache_inv(broadcastTensorB_6__multiply__4, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_6__multiply__1 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_6__multiply__1 
		cache_inv(broadcastTensorB_6__multiply__1, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_9__multiply__7 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_9__multiply__7 
		cache_inv(broadcastTensorB_9__multiply__7, 256*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_9__multiply__4 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_9__multiply__4 
		cache_inv(broadcastTensorB_9__multiply__4, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_872__arrayA__0,output_320__arrayB__14,arrayC__arrayC_872__0); // multiplyTensors_109
		cache_inv(arrayA_872__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__14, 64*sizeof(int));
		cache_wbInv(multiplyTensors_109__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_109__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_109__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_920__arrayA__0,output_192__arrayB__13,arrayC__arrayC_920__0); // multiplyTensors_115
		cache_inv(arrayA_920__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__13, 64*sizeof(int));
		cache_wbInv(multiplyTensors_115__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_115__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_115__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_936__arrayA__0,output_320__arrayB__13,arrayC__arrayC_936__0); // multiplyTensors_117
		cache_inv(arrayA_936__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__13, 64*sizeof(int));
		cache_wbInv(multiplyTensors_117__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_117__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_117__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_960__arrayA__0,output_0__arrayB__28,arrayC__arrayC_960__0); // multiplyTensors_120
		cache_inv(arrayA_960__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__28, 64*sizeof(int));
		cache_wbInv(multiplyTensors_120__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_120__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_120__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1328__arrayA__0,output_384__arrayB__5,arrayC__arrayC_1328__0); // multiplyTensors_166
		cache_inv(arrayA_1328__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__5, 64*sizeof(int));
		cache_wbInv(multiplyTensors_166__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_166__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_166__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1344__arrayA__0,output_0__arrayB__19,arrayC__arrayC_1344__0); // multiplyTensors_168
		cache_inv(arrayA_1344__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__19, 64*sizeof(int));
		cache_wbInv(multiplyTensors_168__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_168__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_168__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1384__arrayA__0,output_320__arrayB__19,arrayC__arrayC_1384__0); // multiplyTensors_173
		cache_inv(arrayA_1384__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__19, 64*sizeof(int));
		cache_wbInv(multiplyTensors_173__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_173__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_173__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1464__arrayA__0,output_448__arrayB__20,arrayC__arrayC_1464__0); // multiplyTensors_183
		cache_inv(arrayA_1464__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__20, 64*sizeof(int));
		cache_wbInv(multiplyTensors_183__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_183__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_183__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1512__arrayA__0,output_320__arrayB__7,arrayC__arrayC_1512__0); // multiplyTensors_189
		cache_inv(arrayA_1512__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__7, 64*sizeof(int));
		cache_wbInv(multiplyTensors_189__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_189__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_189__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1616__arrayA__0,output_128__arrayB__5,arrayC__arrayC_1616__0); // multiplyTensors_202
		cache_inv(arrayA_1616__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__5, 64*sizeof(int));
		cache_wbInv(multiplyTensors_202__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_202__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_202__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1656__arrayA__0,output_448__arrayB__16,arrayC__arrayC_1656__0); // multiplyTensors_207
		cache_inv(arrayA_1656__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__16, 64*sizeof(int));
		cache_wbInv(multiplyTensors_207__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_207__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_207__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1664__arrayA__0,output_0__arrayB__25,arrayC__arrayC_1664__0); // multiplyTensors_208
		cache_inv(arrayA_1664__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__25, 64*sizeof(int));
		cache_wbInv(multiplyTensors_208__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_208__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_208__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1712__arrayA__0,output_384__arrayB__7,arrayC__arrayC_1712__0); // multiplyTensors_214
		cache_inv(arrayA_1712__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__7, 64*sizeof(int));
		cache_wbInv(multiplyTensors_214__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_214__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_214__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1752__arrayA__0,output_192__arrayB__7,arrayC__arrayC_1752__0); // multiplyTensors_219
		cache_inv(arrayA_1752__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__7, 64*sizeof(int));
		cache_wbInv(multiplyTensors_219__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_219__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_219__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_176__arrayA__0,output_384__arrayB__28,arrayC__arrayC_176__0); // multiplyTensors_22
		cache_inv(arrayA_176__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__28, 64*sizeof(int));
		cache_wbInv(multiplyTensors_22__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_22__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_22__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1792__arrayA__0,output_0__arrayB__1,arrayC__arrayC_1792__0); // multiplyTensors_224
		cache_inv(arrayA_1792__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__1, 64*sizeof(int));
		cache_wbInv(multiplyTensors_224__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_224__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_224__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1824__arrayA__0,output_256__arrayB__1,arrayC__arrayC_1824__0); // multiplyTensors_228
		cache_inv(arrayA_1824__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__1, 64*sizeof(int));
		cache_wbInv(multiplyTensors_228__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_228__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_228__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_192__arrayA__0,output_0__arrayB__8,arrayC__arrayC_192__0); // multiplyTensors_24
		cache_inv(arrayA_192__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__8, 64*sizeof(int));
		cache_wbInv(multiplyTensors_24__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_24__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_24__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1936__arrayA__0,output_128__arrayB__18,arrayC__arrayC_1936__0); // multiplyTensors_242
		cache_inv(arrayA_1936__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__18, 64*sizeof(int));
		cache_wbInv(multiplyTensors_242__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_242__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_242__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1968__arrayA__0,output_384__arrayB__4,arrayC__arrayC_1968__0); // multiplyTensors_246
		cache_inv(arrayA_1968__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__4, 64*sizeof(int));
		cache_wbInv(multiplyTensors_246__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_246__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_246__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1984__arrayA__0,output_0__arrayB__14,arrayC__arrayC_1984__0); // multiplyTensors_248
		cache_inv(arrayA_1984__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__14, 64*sizeof(int));
		cache_wbInv(multiplyTensors_248__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_248__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_248__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_2000__arrayA__0,output_128__arrayB__1,arrayC__arrayC_2000__0); // multiplyTensors_250
		cache_inv(arrayA_2000__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__1, 64*sizeof(int));
		cache_wbInv(multiplyTensors_250__implode__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_250__implode__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_250__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_256__arrayA__0,output_0__arrayB__7,arrayC__arrayC_256__0); // multiplyTensors_32
		cache_inv(arrayA_256__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__7, 64*sizeof(int));
		cache_wbInv(multiplyTensors_32__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_32__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_32__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_376__arrayA__0,output_448__arrayB__4,arrayC__arrayC_376__0); // multiplyTensors_47
		cache_inv(arrayA_376__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__4, 64*sizeof(int));
		cache_wbInv(multiplyTensors_47__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_47__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_47__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_400__arrayA__0,output_128__arrayB__12,arrayC__arrayC_400__0); // multiplyTensors_50
		cache_inv(arrayA_400__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__12, 64*sizeof(int));
		cache_wbInv(multiplyTensors_50__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_50__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_50__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_408__arrayA__0,output_192__arrayB__18,arrayC__arrayC_408__0); // multiplyTensors_51
		cache_inv(arrayA_408__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__18, 64*sizeof(int));
		cache_wbInv(multiplyTensors_51__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_51__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_51__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_56__arrayA__0,output_448__arrayB__19,arrayC__arrayC_56__0); // multiplyTensors_7
		cache_inv(arrayA_56__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__19, 64*sizeof(int));
		cache_wbInv(multiplyTensors_7__implode_d__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_7__implode_d__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_7__implode_d__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_600__arrayA__0,output_192__arrayB__16,arrayC__arrayC_600__0); // multiplyTensors_75
		cache_inv(arrayA_600__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__16, 64*sizeof(int));
		cache_wbInv(multiplyTensors_75__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_75__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_75__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_632__arrayA__0,output_448__arrayB__27,arrayC__arrayC_632__0); // multiplyTensors_79
		cache_inv(arrayA_632__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__27, 64*sizeof(int));
		cache_wbInv(multiplyTensors_79__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_79__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_79__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_64__arrayA__0,output_0__arrayB__21,arrayC__arrayC_64__0); // multiplyTensors_8
		cache_inv(arrayA_64__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__21, 64*sizeof(int));
		cache_wbInv(multiplyTensors_8__implode_d__0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_8__implode_d__0 
		sendEnd(); // Core2 > Core7: multiplyTensors_8__implode_d__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_728__arrayA__0,output_192__arrayB__25,arrayC__arrayC_728__0); // multiplyTensors_91
		cache_inv(arrayA_728__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__25, 64*sizeof(int));
		cache_wbInv(multiplyTensors_91__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_91__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_91__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_784__arrayA__0,output_128__arrayB__17,arrayC__arrayC_784__0); // multiplyTensors_98
		cache_inv(arrayA_784__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__17, 64*sizeof(int));
		cache_wbInv(multiplyTensors_98__implode___0, 32*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_98__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_98__implode___0 
	}
}
