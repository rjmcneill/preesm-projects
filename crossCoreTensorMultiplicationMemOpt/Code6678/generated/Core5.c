/** 
 * @file Core5.c
 * @generated by C6678CPrinter
 * @date Tue Apr 21 00:59:48 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__256;  // explode_generateTensors_arrayA > multiplyTensors_255 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__104;  // explode_generateTensors_arrayA > multiplyTensors_240 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__26;  // explode_generateTensors_arrayA > multiplyTensors_237 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__127;  // explode_generateTensors_arrayA > multiplyTensors_232 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__24;  // explode_generateTensors_arrayA > multiplyTensors_231 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__205;  // explode_generateTensors_arrayA > multiplyTensors_227 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__115;  // explode_generateTensors_arrayA > multiplyTensors_209 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__158;  // explode_generateTensors_arrayA > multiplyTensors_200 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__185;  // explode_generateTensors_arrayA > multiplyTensors_194 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__110;  // explode_generateTensors_arrayA > multiplyTensors_191 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__22;  // explode_generateTensors_arrayA > multiplyTensors_190 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__47;  // explode_generateTensors_arrayA > multiplyTensors_187 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__151;  // explode_generateTensors_arrayA > multiplyTensors_177 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__121;  // explode_generateTensors_arrayA > multiplyTensors_163 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__40;  // explode_generateTensors_arrayA > multiplyTensors_151 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__229;  // explode_generateTensors_arrayA > multiplyTensors_148 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__165;  // explode_generateTensors_arrayA > multiplyTensors_140 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__222;  // explode_generateTensors_arrayA > multiplyTensors_128 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__270;  // explode_generateTensors_arrayA > multiplyTensors_106 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__261;  // explode_generateTensors_arrayA > multiplyTensors_92 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__51;  // explode_generateTensors_arrayA > multiplyTensors_84 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__44;  // explode_generateTensors_arrayA > multiplyTensors_81 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__149;  // explode_generateTensors_arrayA > multiplyTensors_80 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__204;  // explode_generateTensors_arrayA > multiplyTensors_72 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__142;  // explode_generateTensors_arrayA > multiplyTensors_65 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__53;  // explode_generateTensors_arrayA > multiplyTensors_62 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__15;  // explode_generateTensors_arrayA > multiplyTensors_61 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__278;  // explode_generateTensors_arrayA > multiplyTensors_44 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__45;  // explode_generateTensors_arrayA > multiplyTensors_38 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__247;  // explode_generateTensors_arrayA > multiplyTensors_28 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__176;  // explode_generateTensors_arrayA > multiplyTensors_26 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__33;  // explode_generateTensors_arrayA > multiplyTensors_18 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__192;  // explode_generateTensors_arrayB > broadcastTensorB_28 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__201;  // explode_generateTensors_arrayB > broadcastTensorB_27 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__280;  // explode_generateTensors_arrayB > broadcastTensorB_17 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__203;  // explode_generateTensors_arrayB > broadcastTensorB_5 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__0;  // broadcastTensorB_10 > multiplyTensors_84 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__5;  // broadcastTensorB_10 > multiplyTensors_81 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__3;  // broadcastTensorB_10 > multiplyTensors_80 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__5;  // broadcastTensorB_11 > multiplyTensors_92 size:= 256*char defined in Core0
extern char *const broadcastTensorB_13__multipl__7;  // broadcastTensorB_13 > multiplyTensors_106 size:= 256*char defined in Core0
extern char *const broadcastTensorB_16__multipl__6;  // broadcastTensorB_16 > multiplyTensors_128 size:= 256*char defined in Core0
extern int *const output_0__arrayB__3;  // broadcastTensorB_17_output_0 > multiplyTensors_136_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__6;  // broadcastTensorB_17_output_64 > multiplyTensors_137_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__22;  // broadcastTensorB_17_output_128 > multiplyTensors_138_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__5;  // broadcastTensorB_17_output_192 > multiplyTensors_139_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__30;  // broadcastTensorB_17_output_256 > multiplyTensors_140_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__22;  // broadcastTensorB_17_output_320 > multiplyTensors_141_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__19;  // broadcastTensorB_17_output_384 > multiplyTensors_142_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__0;  // broadcastTensorB_17_output_448 > multiplyTensors_143_arrayB size:= 64*int defined in Core0
extern int *const arrayB_1088__input__0;  // explode_generateTensors_arrayB_arrayB_1088 > broadcastTensorB_17_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_17__multipl__0;  // broadcastTensorB_17 > multiplyTensors_143 size:= 256*char defined in Core0
extern char *const broadcastTensorB_17__multipl__4;  // broadcastTensorB_17 > multiplyTensors_142 size:= 256*char defined in Core0
extern char *const broadcastTensorB_17__multipl__6;  // broadcastTensorB_17 > multiplyTensors_141 size:= 256*char defined in Core0
extern char *const broadcastTensorB_17__multipl__2;  // broadcastTensorB_17 > multiplyTensors_139 size:= 256*char defined in Core0
extern char *const broadcastTensorB_17__multipl__5;  // broadcastTensorB_17 > multiplyTensors_138 size:= 256*char defined in Core0
extern char *const broadcastTensorB_17__multipl__3;  // broadcastTensorB_17 > multiplyTensors_137 size:= 256*char defined in Core0
extern char *const broadcastTensorB_17__multipl__1;  // broadcastTensorB_17 > multiplyTensors_136 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__1;  // broadcastTensorB_18 > multiplyTensors_151 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__6;  // broadcastTensorB_18 > multiplyTensors_148 size:= 256*char defined in Core0
extern char *const broadcastTensorB_2__multiply__3;  // broadcastTensorB_2 > multiplyTensors_18 size:= 256*char defined in Core0
extern char *const broadcastTensorB_20__multipl__1;  // broadcastTensorB_20 > multiplyTensors_163 size:= 256*char defined in Core0
extern char *const broadcastTensorB_22__multipl__0;  // broadcastTensorB_22 > multiplyTensors_177 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__7;  // broadcastTensorB_23 > multiplyTensors_191 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__3;  // broadcastTensorB_23 > multiplyTensors_190 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__5;  // broadcastTensorB_23 > multiplyTensors_187 size:= 256*char defined in Core0
extern char *const broadcastTensorB_24__multipl__6;  // broadcastTensorB_24 > multiplyTensors_194 size:= 256*char defined in Core0
extern char *const broadcastTensorB_25__multipl__0;  // broadcastTensorB_25 > multiplyTensors_200 size:= 256*char defined in Core0
extern char *const broadcastTensorB_26__multipl__3;  // broadcastTensorB_26 > multiplyTensors_209 size:= 256*char defined in Core0
extern int *const output_0__arrayB__23;  // broadcastTensorB_27_output_0 > multiplyTensors_216_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__16;  // broadcastTensorB_27_output_64 > multiplyTensors_217_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__21;  // broadcastTensorB_27_output_128 > multiplyTensors_218_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__7;  // broadcastTensorB_27_output_192 > multiplyTensors_219_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__26;  // broadcastTensorB_27_output_256 > multiplyTensors_220_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__25;  // broadcastTensorB_27_output_320 > multiplyTensors_221_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__27;  // broadcastTensorB_27_output_384 > multiplyTensors_222_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__9;  // broadcastTensorB_27_output_448 > multiplyTensors_223_arrayB size:= 64*int defined in Core0
extern int *const arrayB_1728__input__0;  // explode_generateTensors_arrayB_arrayB_1728 > broadcastTensorB_27_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_27__multipl__1;  // broadcastTensorB_27 > multiplyTensors_223 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__7;  // broadcastTensorB_27 > multiplyTensors_222 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__4;  // broadcastTensorB_27 > multiplyTensors_221 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__6;  // broadcastTensorB_27 > multiplyTensors_220 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__0;  // broadcastTensorB_27 > multiplyTensors_219 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__3;  // broadcastTensorB_27 > multiplyTensors_218 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__2;  // broadcastTensorB_27 > multiplyTensors_217 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__5;  // broadcastTensorB_27 > multiplyTensors_216 size:= 256*char defined in Core0
extern int *const output_0__arrayB__1;  // broadcastTensorB_28_output_0 > multiplyTensors_224_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__2;  // broadcastTensorB_28_output_64 > multiplyTensors_225_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__2;  // broadcastTensorB_28_output_128 > multiplyTensors_226_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__3;  // broadcastTensorB_28_output_192 > multiplyTensors_227_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__1;  // broadcastTensorB_28_output_256 > multiplyTensors_228_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__28;  // broadcastTensorB_28_output_320 > multiplyTensors_229_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__2;  // broadcastTensorB_28_output_384 > multiplyTensors_230_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__12;  // broadcastTensorB_28_output_448 > multiplyTensors_231_arrayB size:= 64*int defined in Core0
extern int *const arrayB_1792__input__0;  // explode_generateTensors_arrayB_arrayB_1792 > broadcastTensorB_28_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_28__multipl__1;  // broadcastTensorB_28 > multiplyTensors_230 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__7;  // broadcastTensorB_28 > multiplyTensors_229 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__0;  // broadcastTensorB_28 > multiplyTensors_228 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__2;  // broadcastTensorB_28 > multiplyTensors_226 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__3;  // broadcastTensorB_28 > multiplyTensors_225 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__5;  // broadcastTensorB_28 > multiplyTensors_224 size:= 256*char defined in Core0
extern char *const broadcastTensorB_29__multipl__1;  // broadcastTensorB_29 > multiplyTensors_237 size:= 256*char defined in Core0
extern char *const broadcastTensorB_29__multipl__2;  // broadcastTensorB_29 > multiplyTensors_232 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__5;  // broadcastTensorB_3 > multiplyTensors_28 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__4;  // broadcastTensorB_3 > multiplyTensors_26 size:= 256*char defined in Core0
extern char *const broadcastTensorB_30__multipl__0;  // broadcastTensorB_30 > multiplyTensors_240 size:= 256*char defined in Core0
extern char *const broadcastTensorB_31__multipl__2;  // broadcastTensorB_31 > multiplyTensors_255 size:= 256*char defined in Core0
extern char *const broadcastTensorB_4__multiply__3;  // broadcastTensorB_4 > multiplyTensors_38 size:= 256*char defined in Core0
extern int *const output_0__arrayB__17;  // broadcastTensorB_5_output_0 > multiplyTensors_40_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__19;  // broadcastTensorB_5_output_64 > multiplyTensors_41_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__10;  // broadcastTensorB_5_output_128 > multiplyTensors_42_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__31;  // broadcastTensorB_5_output_192 > multiplyTensors_43_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__8;  // broadcastTensorB_5_output_256 > multiplyTensors_44_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__31;  // broadcastTensorB_5_output_320 > multiplyTensors_45_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__20;  // broadcastTensorB_5_output_384 > multiplyTensors_46_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__4;  // broadcastTensorB_5_output_448 > multiplyTensors_47_arrayB size:= 64*int defined in Core0
extern int *const arrayB_320__input__0;  // explode_generateTensors_arrayB_arrayB_320 > broadcastTensorB_5_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_5__multiply__0;  // broadcastTensorB_5 > multiplyTensors_47 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__4;  // broadcastTensorB_5 > multiplyTensors_46 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__7;  // broadcastTensorB_5 > multiplyTensors_45 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__6;  // broadcastTensorB_5 > multiplyTensors_43 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__1;  // broadcastTensorB_5 > multiplyTensors_42 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__3;  // broadcastTensorB_5 > multiplyTensors_41 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__5;  // broadcastTensorB_5 > multiplyTensors_40 size:= 256*char defined in Core0
extern char *const broadcastTensorB_7__multiply__7;  // broadcastTensorB_7 > multiplyTensors_62 size:= 256*char defined in Core0
extern char *const broadcastTensorB_7__multiply__3;  // broadcastTensorB_7 > multiplyTensors_61 size:= 256*char defined in Core0
extern char *const broadcastTensorB_8__multiply__4;  // broadcastTensorB_8 > multiplyTensors_65 size:= 256*char defined in Core0
extern char *const broadcastTensorB_9__multiply__6;  // broadcastTensorB_9 > multiplyTensors_72 size:= 256*char defined in Core0
extern int *const arrayA_848__arrayA__0;  // explode_generateTensors_arrayA_arrayA_848 > multiplyTensors_106_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__29;  // broadcastTensorB_13_output_128 > multiplyTensors_106_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_848__0;  // multiplyTensors_106_arrayC > implode_displayTensor_arrayC_arrayC_848 size:= 8*long defined in Core0
extern char *const multiplyTensors_106__implode__0;  // multiplyTensors_106 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1024__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1024 > multiplyTensors_128_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__20;  // broadcastTensorB_16_output_0 > multiplyTensors_128_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1024__0;  // multiplyTensors_128_arrayC > implode_displayTensor_arrayC_arrayC_1024 size:= 8*long defined in Core0
extern char *const multiplyTensors_128__implode__0;  // multiplyTensors_128 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1120__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1120 > multiplyTensors_140_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_1120__0;  // multiplyTensors_140_arrayC > implode_displayTensor_arrayC_arrayC_1120 size:= 8*long defined in Core0
extern char *const multiplyTensors_140__implode__0;  // multiplyTensors_140 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1184__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1184 > multiplyTensors_148_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__25;  // broadcastTensorB_18_output_256 > multiplyTensors_148_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1184__0;  // multiplyTensors_148_arrayC > implode_displayTensor_arrayC_arrayC_1184 size:= 8*long defined in Core0
extern char *const multiplyTensors_148__implode__0;  // multiplyTensors_148 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1208__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1208 > multiplyTensors_151_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__5;  // broadcastTensorB_18_output_448 > multiplyTensors_151_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1208__0;  // multiplyTensors_151_arrayC > implode_displayTensor_arrayC_arrayC_1208 size:= 8*long defined in Core0
extern char *const multiplyTensors_151__implode__0;  // multiplyTensors_151 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1304__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1304 > multiplyTensors_163_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__1;  // broadcastTensorB_20_output_192 > multiplyTensors_163_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1304__0;  // multiplyTensors_163_arrayC > implode_displayTensor_arrayC_arrayC_1304 size:= 8*long defined in Core0
extern char *const multiplyTensors_163__implode__0;  // multiplyTensors_163 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1416__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1416 > multiplyTensors_177_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__4;  // broadcastTensorB_22_output_64 > multiplyTensors_177_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1416__0;  // multiplyTensors_177_arrayC > implode_displayTensor_arrayC_arrayC_1416 size:= 8*long defined in Core0
extern char *const multiplyTensors_177__implode__0;  // multiplyTensors_177 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_144__arrayA__0;  // explode_generateTensors_arrayA_arrayA_144 > multiplyTensors_18_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__16;  // broadcastTensorB_2_output_128 > multiplyTensors_18_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_144__0;  // multiplyTensors_18_arrayC > implode_displayTensor_arrayC_arrayC_144 size:= 8*long defined in Core0
extern char *const multiplyTensors_18__implode___0;  // multiplyTensors_18 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1496__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1496 > multiplyTensors_187_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__22;  // broadcastTensorB_23_output_192 > multiplyTensors_187_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1496__0;  // multiplyTensors_187_arrayC > implode_displayTensor_arrayC_arrayC_1496 size:= 8*long defined in Core0
extern char *const multiplyTensors_187__implode__0;  // multiplyTensors_187 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1520__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1520 > multiplyTensors_190_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__6;  // broadcastTensorB_23_output_384 > multiplyTensors_190_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1520__0;  // multiplyTensors_190_arrayC > implode_displayTensor_arrayC_arrayC_1520 size:= 8*long defined in Core0
extern char *const multiplyTensors_190__implode__0;  // multiplyTensors_190 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1528__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1528 > multiplyTensors_191_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__22;  // broadcastTensorB_23_output_448 > multiplyTensors_191_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1528__0;  // multiplyTensors_191_arrayC > implode_displayTensor_arrayC_arrayC_1528 size:= 8*long defined in Core0
extern char *const multiplyTensors_191__implode__0;  // multiplyTensors_191 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1552__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1552 > multiplyTensors_194_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__26;  // broadcastTensorB_24_output_128 > multiplyTensors_194_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1552__0;  // multiplyTensors_194_arrayC > implode_displayTensor_arrayC_arrayC_1552 size:= 8*long defined in Core0
extern char *const multiplyTensors_194__implode__0;  // multiplyTensors_194 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1600__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1600 > multiplyTensors_200_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__0;  // broadcastTensorB_25_output_0 > multiplyTensors_200_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1600__0;  // multiplyTensors_200_arrayC > implode_displayTensor_arrayC_arrayC_1600 size:= 8*long defined in Core0
extern char *const multiplyTensors_200__implode__0;  // multiplyTensors_200 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1672__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1672 > multiplyTensors_209_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__7;  // broadcastTensorB_26_output_64 > multiplyTensors_209_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1672__0;  // multiplyTensors_209_arrayC > implode_displayTensor_arrayC_arrayC_1672 size:= 8*long defined in Core0
extern char *const multiplyTensors_209__implode__0;  // multiplyTensors_209 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1816__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1816 > multiplyTensors_227_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_1816__0;  // multiplyTensors_227_arrayC > implode_displayTensor_arrayC_arrayC_1816 size:= 8*long defined in Core0
extern char *const multiplyTensors_227__implode__0;  // multiplyTensors_227 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1848__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1848 > multiplyTensors_231_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_1848__0;  // multiplyTensors_231_arrayC > implode_displayTensor_arrayC_arrayC_1848 size:= 8*long defined in Core0
extern char *const multiplyTensors_231__implode__0;  // multiplyTensors_231 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1856__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1856 > multiplyTensors_232_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__11;  // broadcastTensorB_29_output_0 > multiplyTensors_232_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1856__0;  // multiplyTensors_232_arrayC > implode_displayTensor_arrayC_arrayC_1856 size:= 8*long defined in Core0
extern char *const multiplyTensors_232__implode__0;  // multiplyTensors_232 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1896__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1896 > multiplyTensors_237_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__10;  // broadcastTensorB_29_output_320 > multiplyTensors_237_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1896__0;  // multiplyTensors_237_arrayC > implode_displayTensor_arrayC_arrayC_1896 size:= 8*long defined in Core0
extern char *const multiplyTensors_237__implode__0;  // multiplyTensors_237 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1920__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1920 > multiplyTensors_240_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__6;  // broadcastTensorB_30_output_0 > multiplyTensors_240_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1920__0;  // multiplyTensors_240_arrayC > implode_displayTensor_arrayC_arrayC_1920 size:= 8*long defined in Core0
extern char *const multiplyTensors_240__implode__0;  // multiplyTensors_240 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_2040__arrayA__0;  // explode_generateTensors_arrayA_arrayA_2040 > multiplyTensors_255_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__8;  // broadcastTensorB_31_output_448 > multiplyTensors_255_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_2040__0;  // multiplyTensors_255_arrayC > implode_displayTensor_arrayC_arrayC_2040 size:= 8*long defined in Core0
extern char *const multiplyTensors_255__implode__0;  // multiplyTensors_255 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_208__arrayA__0;  // explode_generateTensors_arrayA_arrayA_208 > multiplyTensors_26_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__14;  // broadcastTensorB_3_output_128 > multiplyTensors_26_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_208__0;  // multiplyTensors_26_arrayC > implode_displayTensor_arrayC_arrayC_208 size:= 8*long defined in Core0
extern char *const multiplyTensors_26__implode___0;  // multiplyTensors_26 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_224__arrayA__0;  // explode_generateTensors_arrayA_arrayA_224 > multiplyTensors_28_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__14;  // broadcastTensorB_3_output_256 > multiplyTensors_28_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_224__0;  // multiplyTensors_28_arrayC > implode_displayTensor_arrayC_arrayC_224 size:= 8*long defined in Core0
extern char *const multiplyTensors_28__implode___0;  // multiplyTensors_28 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_304__arrayA__0;  // explode_generateTensors_arrayA_arrayA_304 > multiplyTensors_38_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__22;  // broadcastTensorB_4_output_384 > multiplyTensors_38_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_304__0;  // multiplyTensors_38_arrayC > implode_displayTensor_arrayC_arrayC_304 size:= 8*long defined in Core0
extern char *const multiplyTensors_38__implode___0;  // multiplyTensors_38 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_352__arrayA__0;  // explode_generateTensors_arrayA_arrayA_352 > multiplyTensors_44_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_352__0;  // multiplyTensors_44_arrayC > implode_displayTensor_arrayC_arrayC_352 size:= 8*long defined in Core0
extern char *const multiplyTensors_44__implode___0;  // multiplyTensors_44 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_488__arrayA__0;  // explode_generateTensors_arrayA_arrayA_488 > multiplyTensors_61_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__26;  // broadcastTensorB_7_output_320 > multiplyTensors_61_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_488__0;  // multiplyTensors_61_arrayC > implode_displayTensor_arrayC_arrayC_488 size:= 8*long defined in Core0
extern char *const multiplyTensors_61__implode___0;  // multiplyTensors_61 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_496__arrayA__0;  // explode_generateTensors_arrayA_arrayA_496 > multiplyTensors_62_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__31;  // broadcastTensorB_7_output_384 > multiplyTensors_62_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_496__0;  // multiplyTensors_62_arrayC > implode_displayTensor_arrayC_arrayC_496 size:= 8*long defined in Core0
extern char *const multiplyTensors_62__implode___0;  // multiplyTensors_62 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_520__arrayA__0;  // explode_generateTensors_arrayA_arrayA_520 > multiplyTensors_65_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__9;  // broadcastTensorB_8_output_64 > multiplyTensors_65_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_520__0;  // multiplyTensors_65_arrayC > implode_displayTensor_arrayC_arrayC_520 size:= 8*long defined in Core0
extern char *const multiplyTensors_65__implode___0;  // multiplyTensors_65 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_576__arrayA__0;  // explode_generateTensors_arrayA_arrayA_576 > multiplyTensors_72_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__22;  // broadcastTensorB_9_output_0 > multiplyTensors_72_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_576__0;  // multiplyTensors_72_arrayC > implode_displayTensor_arrayC_arrayC_576 size:= 8*long defined in Core0
extern char *const multiplyTensors_72__implode___0;  // multiplyTensors_72 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_640__arrayA__0;  // explode_generateTensors_arrayA_arrayA_640 > multiplyTensors_80_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__13;  // broadcastTensorB_10_output_0 > multiplyTensors_80_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_640__0;  // multiplyTensors_80_arrayC > implode_displayTensor_arrayC_arrayC_640 size:= 8*long defined in Core0
extern char *const multiplyTensors_80__implode___0;  // multiplyTensors_80 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_648__arrayA__0;  // explode_generateTensors_arrayA_arrayA_648 > multiplyTensors_81_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__24;  // broadcastTensorB_10_output_64 > multiplyTensors_81_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_648__0;  // multiplyTensors_81_arrayC > implode_displayTensor_arrayC_arrayC_648 size:= 8*long defined in Core0
extern char *const multiplyTensors_81__implode___0;  // multiplyTensors_81 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_672__arrayA__0;  // explode_generateTensors_arrayA_arrayA_672 > multiplyTensors_84_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__2;  // broadcastTensorB_10_output_256 > multiplyTensors_84_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_672__0;  // multiplyTensors_84_arrayC > implode_displayTensor_arrayC_arrayC_672 size:= 8*long defined in Core0
extern char *const multiplyTensors_84__implode___0;  // multiplyTensors_84 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_736__arrayA__0;  // explode_generateTensors_arrayA_arrayA_736 > multiplyTensors_92_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__16;  // broadcastTensorB_11_output_256 > multiplyTensors_92_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_736__0;  // multiplyTensors_92_arrayC > implode_displayTensor_arrayC_arrayC_736 size:= 8*long defined in Core0
extern char *const multiplyTensors_92__implode___0;  // multiplyTensors_92 > implode_displayTensor_arrayC size:= 32*char defined in Core0

// Core Global Definitions

void core5(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__256 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__256 
		cache_inv(explode_generateTensors_arra__256, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__104 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__104 
		cache_inv(explode_generateTensors_arra__104, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__26 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__26 
		cache_inv(explode_generateTensors_arra__26, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__127 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__127 
		cache_inv(explode_generateTensors_arra__127, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__24 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__24 
		cache_inv(explode_generateTensors_arra__24, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__205 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__205 
		cache_inv(explode_generateTensors_arra__205, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__115 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__115 
		cache_inv(explode_generateTensors_arra__115, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__158 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__158 
		cache_inv(explode_generateTensors_arra__158, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__185 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__185 
		cache_inv(explode_generateTensors_arra__185, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__110 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__110 
		cache_inv(explode_generateTensors_arra__110, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__22 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__22 
		cache_inv(explode_generateTensors_arra__22, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__47 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__47 
		cache_inv(explode_generateTensors_arra__47, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__151 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__151 
		cache_inv(explode_generateTensors_arra__151, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__121 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__121 
		cache_inv(explode_generateTensors_arra__121, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__40 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__40 
		cache_inv(explode_generateTensors_arra__40, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__229 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__229 
		cache_inv(explode_generateTensors_arra__229, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__165 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__165 
		cache_inv(explode_generateTensors_arra__165, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__222 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__222 
		cache_inv(explode_generateTensors_arra__222, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__270 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__270 
		cache_inv(explode_generateTensors_arra__270, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__261 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__261 
		cache_inv(explode_generateTensors_arra__261, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__51 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__51 
		cache_inv(explode_generateTensors_arra__51, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__44 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__44 
		cache_inv(explode_generateTensors_arra__44, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__149 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__149 
		cache_inv(explode_generateTensors_arra__149, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__204 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__204 
		cache_inv(explode_generateTensors_arra__204, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__142 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__142 
		cache_inv(explode_generateTensors_arra__142, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__53 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__53 
		cache_inv(explode_generateTensors_arra__53, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__15 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__15 
		cache_inv(explode_generateTensors_arra__15, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__278 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__278 
		cache_inv(explode_generateTensors_arra__278, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__45 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__45 
		cache_inv(explode_generateTensors_arra__45, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__247 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__247 
		cache_inv(explode_generateTensors_arra__247, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__176 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__176 
		cache_inv(explode_generateTensors_arra__176, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__33 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__33 
		cache_inv(explode_generateTensors_arra__33, 32*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__192 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__192 
		cache_inv(explode_generateTensors_arra__192, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__201 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__201 
		cache_inv(explode_generateTensors_arra__201, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__280 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__280 
		cache_inv(explode_generateTensors_arra__280, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__203 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__203 
		cache_inv(explode_generateTensors_arra__203, 256*sizeof(char));
		receiveStart(); // Core2 > Core5: broadcastTensorB_10__multipl__0 
		receiveEnd(2); // Core2 > Core5: broadcastTensorB_10__multipl__0 
		cache_inv(broadcastTensorB_10__multipl__0, 256*sizeof(char));
		receiveStart(); // Core2 > Core5: broadcastTensorB_10__multipl__5 
		receiveEnd(2); // Core2 > Core5: broadcastTensorB_10__multipl__5 
		cache_inv(broadcastTensorB_10__multipl__5, 256*sizeof(char));
		receiveStart(); // Core2 > Core5: broadcastTensorB_10__multipl__3 
		receiveEnd(2); // Core2 > Core5: broadcastTensorB_10__multipl__3 
		cache_inv(broadcastTensorB_10__multipl__3, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: broadcastTensorB_11__multipl__5 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_11__multipl__5 
		cache_inv(broadcastTensorB_11__multipl__5, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: broadcastTensorB_13__multipl__7 
		receiveEnd(0); // Core0 > Core5: broadcastTensorB_13__multipl__7 
		cache_inv(broadcastTensorB_13__multipl__7, 256*sizeof(char));
		receiveStart(); // Core6 > Core5: broadcastTensorB_16__multipl__6 
		receiveEnd(6); // Core6 > Core5: broadcastTensorB_16__multipl__6 
		cache_inv(broadcastTensorB_16__multipl__6, 256*sizeof(char));
		// Broadcast broadcastTensorB_17
		{
			cache_wb(arrayB_1088__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_1088__input__0) + 0, 256);
		cache_inv(arrayB_1088__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_17__multipl__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: broadcastTensorB_17__multipl__0 
		sendEnd(); // Core5 > Core4: broadcastTensorB_17__multipl__0 
		cache_wbInv(broadcastTensorB_17__multipl__4, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: broadcastTensorB_17__multipl__4 
		sendEnd(); // Core5 > Core4: broadcastTensorB_17__multipl__4 
		cache_wbInv(broadcastTensorB_17__multipl__6, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: broadcastTensorB_17__multipl__6 
		sendEnd(); // Core5 > Core1: broadcastTensorB_17__multipl__6 
		cache_wbInv(broadcastTensorB_17__multipl__2, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: broadcastTensorB_17__multipl__2 
		sendEnd(); // Core5 > Core0: broadcastTensorB_17__multipl__2 
		cache_wbInv(broadcastTensorB_17__multipl__5, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: broadcastTensorB_17__multipl__5 
		sendEnd(); // Core5 > Core3: broadcastTensorB_17__multipl__5 
		cache_wbInv(broadcastTensorB_17__multipl__3, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: broadcastTensorB_17__multipl__3 
		sendEnd(); // Core5 > Core4: broadcastTensorB_17__multipl__3 
		cache_wbInv(broadcastTensorB_17__multipl__1, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: broadcastTensorB_17__multipl__1 
		sendEnd(); // Core5 > Core7: broadcastTensorB_17__multipl__1 
		receiveStart(); // Core1 > Core5: broadcastTensorB_18__multipl__1 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_18__multipl__1 
		cache_inv(broadcastTensorB_18__multipl__1, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: broadcastTensorB_18__multipl__6 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_18__multipl__6 
		cache_inv(broadcastTensorB_18__multipl__6, 256*sizeof(char));
		receiveStart(); // Core7 > Core5: broadcastTensorB_2__multiply__3 
		receiveEnd(7); // Core7 > Core5: broadcastTensorB_2__multiply__3 
		cache_inv(broadcastTensorB_2__multiply__3, 256*sizeof(char));
		receiveStart(); // Core4 > Core5: broadcastTensorB_20__multipl__1 
		receiveEnd(4); // Core4 > Core5: broadcastTensorB_20__multipl__1 
		cache_inv(broadcastTensorB_20__multipl__1, 256*sizeof(char));
		receiveStart(); // Core4 > Core5: broadcastTensorB_22__multipl__0 
		receiveEnd(4); // Core4 > Core5: broadcastTensorB_22__multipl__0 
		cache_inv(broadcastTensorB_22__multipl__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: broadcastTensorB_23__multipl__7 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_23__multipl__7 
		cache_inv(broadcastTensorB_23__multipl__7, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: broadcastTensorB_23__multipl__3 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_23__multipl__3 
		cache_inv(broadcastTensorB_23__multipl__3, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: broadcastTensorB_23__multipl__5 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_23__multipl__5 
		cache_inv(broadcastTensorB_23__multipl__5, 256*sizeof(char));
		receiveStart(); // Core3 > Core5: broadcastTensorB_24__multipl__6 
		receiveEnd(3); // Core3 > Core5: broadcastTensorB_24__multipl__6 
		cache_inv(broadcastTensorB_24__multipl__6, 256*sizeof(char));
		receiveStart(); // Core6 > Core5: broadcastTensorB_25__multipl__0 
		receiveEnd(6); // Core6 > Core5: broadcastTensorB_25__multipl__0 
		cache_inv(broadcastTensorB_25__multipl__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: broadcastTensorB_26__multipl__3 
		receiveEnd(0); // Core0 > Core5: broadcastTensorB_26__multipl__3 
		cache_inv(broadcastTensorB_26__multipl__3, 256*sizeof(char));
		// Broadcast broadcastTensorB_27
		{
			cache_wb(arrayB_1728__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_1728__input__0) + 0, 256);
		cache_inv(arrayB_1728__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_27__multipl__1, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: broadcastTensorB_27__multipl__1 
		sendEnd(); // Core5 > Core3: broadcastTensorB_27__multipl__1 
		cache_wbInv(broadcastTensorB_27__multipl__7, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: broadcastTensorB_27__multipl__7 
		sendEnd(); // Core5 > Core1: broadcastTensorB_27__multipl__7 
		cache_wbInv(broadcastTensorB_27__multipl__4, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: broadcastTensorB_27__multipl__4 
		sendEnd(); // Core5 > Core4: broadcastTensorB_27__multipl__4 
		cache_wbInv(broadcastTensorB_27__multipl__6, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: broadcastTensorB_27__multipl__6 
		sendEnd(); // Core5 > Core1: broadcastTensorB_27__multipl__6 
		cache_wbInv(broadcastTensorB_27__multipl__0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: broadcastTensorB_27__multipl__0 
		sendEnd(); // Core5 > Core2: broadcastTensorB_27__multipl__0 
		cache_wbInv(broadcastTensorB_27__multipl__3, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: broadcastTensorB_27__multipl__3 
		sendEnd(); // Core5 > Core4: broadcastTensorB_27__multipl__3 
		cache_wbInv(broadcastTensorB_27__multipl__2, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: broadcastTensorB_27__multipl__2 
		sendEnd(); // Core5 > Core1: broadcastTensorB_27__multipl__2 
		cache_wbInv(broadcastTensorB_27__multipl__5, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: broadcastTensorB_27__multipl__5 
		sendEnd(); // Core5 > Core1: broadcastTensorB_27__multipl__5 
		// Broadcast broadcastTensorB_28
		{
			cache_wb(arrayB_1792__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_1792__input__0) + 0, 256);
		cache_inv(arrayB_1792__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_28__multipl__1, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: broadcastTensorB_28__multipl__1 
		sendEnd(); // Core5 > Core4: broadcastTensorB_28__multipl__1 
		cache_wbInv(broadcastTensorB_28__multipl__7, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: broadcastTensorB_28__multipl__7 
		sendEnd(); // Core5 > Core6: broadcastTensorB_28__multipl__7 
		cache_wbInv(broadcastTensorB_28__multipl__0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: broadcastTensorB_28__multipl__0 
		sendEnd(); // Core5 > Core2: broadcastTensorB_28__multipl__0 
		cache_wbInv(broadcastTensorB_28__multipl__2, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: broadcastTensorB_28__multipl__2 
		sendEnd(); // Core5 > Core1: broadcastTensorB_28__multipl__2 
		cache_wbInv(broadcastTensorB_28__multipl__3, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: broadcastTensorB_28__multipl__3 
		sendEnd(); // Core5 > Core0: broadcastTensorB_28__multipl__3 
		cache_wbInv(broadcastTensorB_28__multipl__5, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: broadcastTensorB_28__multipl__5 
		sendEnd(); // Core5 > Core2: broadcastTensorB_28__multipl__5 
		receiveStart(); // Core4 > Core5: broadcastTensorB_29__multipl__1 
		receiveEnd(4); // Core4 > Core5: broadcastTensorB_29__multipl__1 
		cache_inv(broadcastTensorB_29__multipl__1, 256*sizeof(char));
		receiveStart(); // Core4 > Core5: broadcastTensorB_29__multipl__2 
		receiveEnd(4); // Core4 > Core5: broadcastTensorB_29__multipl__2 
		cache_inv(broadcastTensorB_29__multipl__2, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: broadcastTensorB_3__multiply__5 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_3__multiply__5 
		cache_inv(broadcastTensorB_3__multiply__5, 256*sizeof(char));
		receiveStart(); // Core1 > Core5: broadcastTensorB_3__multiply__4 
		receiveEnd(1); // Core1 > Core5: broadcastTensorB_3__multiply__4 
		cache_inv(broadcastTensorB_3__multiply__4, 256*sizeof(char));
		receiveStart(); // Core2 > Core5: broadcastTensorB_30__multipl__0 
		receiveEnd(2); // Core2 > Core5: broadcastTensorB_30__multipl__0 
		cache_inv(broadcastTensorB_30__multipl__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core5: broadcastTensorB_31__multipl__2 
		receiveEnd(7); // Core7 > Core5: broadcastTensorB_31__multipl__2 
		cache_inv(broadcastTensorB_31__multipl__2, 256*sizeof(char));
		receiveStart(); // Core3 > Core5: broadcastTensorB_4__multiply__3 
		receiveEnd(3); // Core3 > Core5: broadcastTensorB_4__multiply__3 
		cache_inv(broadcastTensorB_4__multiply__3, 256*sizeof(char));
		// Broadcast broadcastTensorB_5
		{
			cache_wb(arrayB_320__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_320__input__0) + 0, 256);
		cache_inv(arrayB_320__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_5__multiply__0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: broadcastTensorB_5__multiply__0 
		sendEnd(); // Core5 > Core2: broadcastTensorB_5__multiply__0 
		cache_wbInv(broadcastTensorB_5__multiply__4, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: broadcastTensorB_5__multiply__4 
		sendEnd(); // Core5 > Core6: broadcastTensorB_5__multiply__4 
		cache_wbInv(broadcastTensorB_5__multiply__7, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: broadcastTensorB_5__multiply__7 
		sendEnd(); // Core5 > Core7: broadcastTensorB_5__multiply__7 
		cache_wbInv(broadcastTensorB_5__multiply__6, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: broadcastTensorB_5__multiply__6 
		sendEnd(); // Core5 > Core3: broadcastTensorB_5__multiply__6 
		cache_wbInv(broadcastTensorB_5__multiply__1, 256*sizeof(char));
		sendStart(1); // Core5 > Core1: broadcastTensorB_5__multiply__1 
		sendEnd(); // Core5 > Core1: broadcastTensorB_5__multiply__1 
		cache_wbInv(broadcastTensorB_5__multiply__3, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: broadcastTensorB_5__multiply__3 
		sendEnd(); // Core5 > Core3: broadcastTensorB_5__multiply__3 
		cache_wbInv(broadcastTensorB_5__multiply__5, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: broadcastTensorB_5__multiply__5 
		sendEnd(); // Core5 > Core7: broadcastTensorB_5__multiply__5 
		receiveStart(); // Core4 > Core5: broadcastTensorB_7__multiply__7 
		receiveEnd(4); // Core4 > Core5: broadcastTensorB_7__multiply__7 
		cache_inv(broadcastTensorB_7__multiply__7, 256*sizeof(char));
		receiveStart(); // Core4 > Core5: broadcastTensorB_7__multiply__3 
		receiveEnd(4); // Core4 > Core5: broadcastTensorB_7__multiply__3 
		cache_inv(broadcastTensorB_7__multiply__3, 256*sizeof(char));
		receiveStart(); // Core3 > Core5: broadcastTensorB_8__multiply__4 
		receiveEnd(3); // Core3 > Core5: broadcastTensorB_8__multiply__4 
		cache_inv(broadcastTensorB_8__multiply__4, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: broadcastTensorB_9__multiply__6 
		receiveEnd(0); // Core0 > Core5: broadcastTensorB_9__multiply__6 
		cache_inv(broadcastTensorB_9__multiply__6, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_848__arrayA__0,output_128__arrayB__29,arrayC__arrayC_848__0); // multiplyTensors_106
		cache_inv(arrayA_848__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__29, 64*sizeof(int));
		cache_wbInv(multiplyTensors_106__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_106__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_106__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1024__arrayA__0,output_0__arrayB__20,arrayC__arrayC_1024__0); // multiplyTensors_128
		cache_inv(arrayA_1024__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__20, 64*sizeof(int));
		cache_wbInv(multiplyTensors_128__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_128__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_128__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1120__arrayA__0,output_256__arrayB__30,arrayC__arrayC_1120__0); // multiplyTensors_140
		cache_inv(arrayA_1120__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__30, 64*sizeof(int));
		cache_wbInv(multiplyTensors_140__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_140__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_140__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1184__arrayA__0,output_256__arrayB__25,arrayC__arrayC_1184__0); // multiplyTensors_148
		cache_inv(arrayA_1184__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__25, 64*sizeof(int));
		cache_wbInv(multiplyTensors_148__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_148__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_148__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1208__arrayA__0,output_448__arrayB__5,arrayC__arrayC_1208__0); // multiplyTensors_151
		cache_inv(arrayA_1208__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__5, 64*sizeof(int));
		cache_wbInv(multiplyTensors_151__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_151__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_151__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1304__arrayA__0,output_192__arrayB__1,arrayC__arrayC_1304__0); // multiplyTensors_163
		cache_inv(arrayA_1304__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__1, 64*sizeof(int));
		cache_wbInv(multiplyTensors_163__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_163__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_163__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1416__arrayA__0,output_64__arrayB__4,arrayC__arrayC_1416__0); // multiplyTensors_177
		cache_inv(arrayA_1416__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__4, 64*sizeof(int));
		cache_wbInv(multiplyTensors_177__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_177__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_177__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_144__arrayA__0,output_128__arrayB__16,arrayC__arrayC_144__0); // multiplyTensors_18
		cache_inv(arrayA_144__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__16, 64*sizeof(int));
		cache_wbInv(multiplyTensors_18__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_18__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_18__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1496__arrayA__0,output_192__arrayB__22,arrayC__arrayC_1496__0); // multiplyTensors_187
		cache_inv(arrayA_1496__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__22, 64*sizeof(int));
		cache_wbInv(multiplyTensors_187__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_187__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_187__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1520__arrayA__0,output_384__arrayB__6,arrayC__arrayC_1520__0); // multiplyTensors_190
		cache_inv(arrayA_1520__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__6, 64*sizeof(int));
		cache_wbInv(multiplyTensors_190__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_190__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_190__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1528__arrayA__0,output_448__arrayB__22,arrayC__arrayC_1528__0); // multiplyTensors_191
		cache_inv(arrayA_1528__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__22, 64*sizeof(int));
		cache_wbInv(multiplyTensors_191__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_191__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_191__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1552__arrayA__0,output_128__arrayB__26,arrayC__arrayC_1552__0); // multiplyTensors_194
		cache_inv(arrayA_1552__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__26, 64*sizeof(int));
		cache_wbInv(multiplyTensors_194__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_194__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_194__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1600__arrayA__0,output_0__arrayB__0,arrayC__arrayC_1600__0); // multiplyTensors_200
		cache_inv(arrayA_1600__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__0, 64*sizeof(int));
		cache_wbInv(multiplyTensors_200__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_200__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_200__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1672__arrayA__0,output_64__arrayB__7,arrayC__arrayC_1672__0); // multiplyTensors_209
		cache_inv(arrayA_1672__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__7, 64*sizeof(int));
		cache_wbInv(multiplyTensors_209__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_209__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_209__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1816__arrayA__0,output_192__arrayB__3,arrayC__arrayC_1816__0); // multiplyTensors_227
		cache_inv(arrayA_1816__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__3, 64*sizeof(int));
		cache_wbInv(multiplyTensors_227__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_227__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_227__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1848__arrayA__0,output_448__arrayB__12,arrayC__arrayC_1848__0); // multiplyTensors_231
		cache_inv(arrayA_1848__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__12, 64*sizeof(int));
		cache_wbInv(multiplyTensors_231__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_231__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_231__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1856__arrayA__0,output_0__arrayB__11,arrayC__arrayC_1856__0); // multiplyTensors_232
		cache_inv(arrayA_1856__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__11, 64*sizeof(int));
		cache_wbInv(multiplyTensors_232__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_232__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_232__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1896__arrayA__0,output_320__arrayB__10,arrayC__arrayC_1896__0); // multiplyTensors_237
		cache_inv(arrayA_1896__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__10, 64*sizeof(int));
		cache_wbInv(multiplyTensors_237__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_237__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_237__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1920__arrayA__0,output_0__arrayB__6,arrayC__arrayC_1920__0); // multiplyTensors_240
		cache_inv(arrayA_1920__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__6, 64*sizeof(int));
		cache_wbInv(multiplyTensors_240__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_240__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_240__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_2040__arrayA__0,output_448__arrayB__8,arrayC__arrayC_2040__0); // multiplyTensors_255
		cache_inv(arrayA_2040__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__8, 64*sizeof(int));
		cache_wbInv(multiplyTensors_255__implode__0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_255__implode__0 
		sendEnd(); // Core5 > Core7: multiplyTensors_255__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_208__arrayA__0,output_128__arrayB__14,arrayC__arrayC_208__0); // multiplyTensors_26
		cache_inv(arrayA_208__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__14, 64*sizeof(int));
		cache_wbInv(multiplyTensors_26__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_26__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_26__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_224__arrayA__0,output_256__arrayB__14,arrayC__arrayC_224__0); // multiplyTensors_28
		cache_inv(arrayA_224__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__14, 64*sizeof(int));
		cache_wbInv(multiplyTensors_28__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_28__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_28__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_304__arrayA__0,output_384__arrayB__22,arrayC__arrayC_304__0); // multiplyTensors_38
		cache_inv(arrayA_304__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__22, 64*sizeof(int));
		cache_wbInv(multiplyTensors_38__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_38__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_38__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_352__arrayA__0,output_256__arrayB__8,arrayC__arrayC_352__0); // multiplyTensors_44
		cache_inv(arrayA_352__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__8, 64*sizeof(int));
		cache_wbInv(multiplyTensors_44__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_44__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_44__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_488__arrayA__0,output_320__arrayB__26,arrayC__arrayC_488__0); // multiplyTensors_61
		cache_inv(arrayA_488__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__26, 64*sizeof(int));
		cache_wbInv(multiplyTensors_61__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_61__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_61__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_496__arrayA__0,output_384__arrayB__31,arrayC__arrayC_496__0); // multiplyTensors_62
		cache_inv(arrayA_496__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__31, 64*sizeof(int));
		cache_wbInv(multiplyTensors_62__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_62__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_62__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_520__arrayA__0,output_64__arrayB__9,arrayC__arrayC_520__0); // multiplyTensors_65
		cache_inv(arrayA_520__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__9, 64*sizeof(int));
		cache_wbInv(multiplyTensors_65__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_65__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_65__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_576__arrayA__0,output_0__arrayB__22,arrayC__arrayC_576__0); // multiplyTensors_72
		cache_inv(arrayA_576__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__22, 64*sizeof(int));
		cache_wbInv(multiplyTensors_72__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_72__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_72__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_640__arrayA__0,output_0__arrayB__13,arrayC__arrayC_640__0); // multiplyTensors_80
		cache_inv(arrayA_640__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__13, 64*sizeof(int));
		cache_wbInv(multiplyTensors_80__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_80__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_80__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_648__arrayA__0,output_64__arrayB__24,arrayC__arrayC_648__0); // multiplyTensors_81
		cache_inv(arrayA_648__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__24, 64*sizeof(int));
		cache_wbInv(multiplyTensors_81__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_81__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_81__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_672__arrayA__0,output_256__arrayB__2,arrayC__arrayC_672__0); // multiplyTensors_84
		cache_inv(arrayA_672__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__2, 64*sizeof(int));
		cache_wbInv(multiplyTensors_84__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_84__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_84__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_736__arrayA__0,output_256__arrayB__16,arrayC__arrayC_736__0); // multiplyTensors_92
		cache_inv(arrayA_736__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__16, 64*sizeof(int));
		cache_wbInv(multiplyTensors_92__implode___0, 32*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_92__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_92__implode___0 
	}
}
