/** 
 * @file Core1.c
 * @generated by C6678CPrinter
 * @date Tue Apr 21 00:59:48 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__132;  // explode_generateTensors_arrayA > multiplyTensors_226 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__137;  // explode_generateTensors_arrayA > multiplyTensors_222 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__87;  // explode_generateTensors_arrayA > multiplyTensors_220 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__114;  // explode_generateTensors_arrayA > multiplyTensors_217 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__92;  // explode_generateTensors_arrayA > multiplyTensors_216 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__191;  // explode_generateTensors_arrayA > multiplyTensors_199 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__27;  // explode_generateTensors_arrayA > multiplyTensors_193 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__159;  // explode_generateTensors_arrayA > multiplyTensors_188 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__116;  // explode_generateTensors_arrayA > multiplyTensors_182 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__252;  // explode_generateTensors_arrayA > multiplyTensors_176 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__65;  // explode_generateTensors_arrayA > multiplyTensors_175 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__5;  // explode_generateTensors_arrayA > multiplyTensors_165 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__277;  // explode_generateTensors_arrayA > multiplyTensors_164 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__250;  // explode_generateTensors_arrayA > multiplyTensors_158 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__174;  // explode_generateTensors_arrayA > multiplyTensors_157 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__103;  // explode_generateTensors_arrayA > multiplyTensors_152 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__166;  // explode_generateTensors_arrayA > multiplyTensors_141 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__245;  // explode_generateTensors_arrayA > multiplyTensors_131 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__146;  // explode_generateTensors_arrayA > multiplyTensors_130 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__77;  // explode_generateTensors_arrayA > multiplyTensors_126 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__3;  // explode_generateTensors_arrayA > multiplyTensors_125 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayA > multiplyTensors_104 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__124;  // explode_generateTensors_arrayA > multiplyTensors_97 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__143;  // explode_generateTensors_arrayA > multiplyTensors_85 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayA > multiplyTensors_69 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__217;  // explode_generateTensors_arrayA > multiplyTensors_57 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__97;  // explode_generateTensors_arrayA > multiplyTensors_42 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__181;  // explode_generateTensors_arrayA > multiplyTensors_36 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__63;  // explode_generateTensors_arrayA > multiplyTensors_21 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__285;  // explode_generateTensors_arrayA > multiplyTensors_17 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__254;  // explode_generateTensors_arrayA > multiplyTensors_16 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__199;  // explode_generateTensors_arrayA > multiplyTensors_12 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__95;  // explode_generateTensors_arrayB > broadcastTensorB_23 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__134;  // explode_generateTensors_arrayB > broadcastTensorB_18 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__48;  // explode_generateTensors_arrayB > broadcastTensorB_11 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__35;  // explode_generateTensors_arrayB > broadcastTensorB_3 size:= 256*char defined in Core0
extern char *const broadcastTensorB_1__multiply__2;  // broadcastTensorB_1 > multiplyTensors_12 size:= 256*char defined in Core0
extern char *const broadcastTensorB_10__multipl__1;  // broadcastTensorB_10 > multiplyTensors_85 size:= 256*char defined in Core0
extern int *const output_0__arrayB__31;  // broadcastTensorB_11_output_0 > multiplyTensors_88_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__14;  // broadcastTensorB_11_output_64 > multiplyTensors_89_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__0;  // broadcastTensorB_11_output_128 > multiplyTensors_90_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__25;  // broadcastTensorB_11_output_192 > multiplyTensors_91_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__16;  // broadcastTensorB_11_output_256 > multiplyTensors_92_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__6;  // broadcastTensorB_11_output_320 > multiplyTensors_93_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__17;  // broadcastTensorB_11_output_384 > multiplyTensors_94_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__7;  // broadcastTensorB_11_output_448 > multiplyTensors_95_arrayB size:= 64*int defined in Core0
extern int *const arrayB_704__input__0;  // explode_generateTensors_arrayB_arrayB_704 > broadcastTensorB_11_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_11__multipl__2;  // broadcastTensorB_11 > multiplyTensors_95 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__4;  // broadcastTensorB_11 > multiplyTensors_94 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__1;  // broadcastTensorB_11 > multiplyTensors_93 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__5;  // broadcastTensorB_11 > multiplyTensors_92 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__6;  // broadcastTensorB_11 > multiplyTensors_91 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__0;  // broadcastTensorB_11 > multiplyTensors_90 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__3;  // broadcastTensorB_11 > multiplyTensors_89 size:= 256*char defined in Core0
extern char *const broadcastTensorB_11__multipl__7;  // broadcastTensorB_11 > multiplyTensors_88 size:= 256*char defined in Core0
extern char *const broadcastTensorB_12__multipl__6;  // broadcastTensorB_12 > multiplyTensors_97 size:= 256*char defined in Core0
extern char *const broadcastTensorB_13__multipl__1;  // broadcastTensorB_13 > multiplyTensors_104 size:= 256*char defined in Core0
extern char *const broadcastTensorB_15__multipl__2;  // broadcastTensorB_15 > multiplyTensors_126 size:= 256*char defined in Core0
extern char *const broadcastTensorB_15__multipl__4;  // broadcastTensorB_15 > multiplyTensors_125 size:= 256*char defined in Core0
extern char *const broadcastTensorB_16__multipl__1;  // broadcastTensorB_16 > multiplyTensors_131 size:= 256*char defined in Core0
extern char *const broadcastTensorB_16__multipl__3;  // broadcastTensorB_16 > multiplyTensors_130 size:= 256*char defined in Core0
extern char *const broadcastTensorB_17__multipl__6;  // broadcastTensorB_17 > multiplyTensors_141 size:= 256*char defined in Core0
extern int *const output_0__arrayB__27;  // broadcastTensorB_18_output_0 > multiplyTensors_144_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__17;  // broadcastTensorB_18_output_64 > multiplyTensors_145_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__7;  // broadcastTensorB_18_output_128 > multiplyTensors_146_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__26;  // broadcastTensorB_18_output_192 > multiplyTensors_147_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__25;  // broadcastTensorB_18_output_256 > multiplyTensors_148_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__3;  // broadcastTensorB_18_output_320 > multiplyTensors_149_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__1;  // broadcastTensorB_18_output_384 > multiplyTensors_150_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__5;  // broadcastTensorB_18_output_448 > multiplyTensors_151_arrayB size:= 64*int defined in Core0
extern int *const arrayB_1152__input__0;  // explode_generateTensors_arrayB_arrayB_1152 > broadcastTensorB_18_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_18__multipl__1;  // broadcastTensorB_18 > multiplyTensors_151 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__0;  // broadcastTensorB_18 > multiplyTensors_150 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__2;  // broadcastTensorB_18 > multiplyTensors_149 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__6;  // broadcastTensorB_18 > multiplyTensors_148 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__5;  // broadcastTensorB_18 > multiplyTensors_147 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__3;  // broadcastTensorB_18 > multiplyTensors_146 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__4;  // broadcastTensorB_18 > multiplyTensors_145 size:= 256*char defined in Core0
extern char *const broadcastTensorB_18__multipl__7;  // broadcastTensorB_18 > multiplyTensors_144 size:= 256*char defined in Core0
extern char *const broadcastTensorB_19__multipl__7;  // broadcastTensorB_19 > multiplyTensors_158 size:= 256*char defined in Core0
extern char *const broadcastTensorB_19__multipl__3;  // broadcastTensorB_19 > multiplyTensors_157 size:= 256*char defined in Core0
extern char *const broadcastTensorB_19__multipl__2;  // broadcastTensorB_19 > multiplyTensors_152 size:= 256*char defined in Core0
extern char *const broadcastTensorB_2__multiply__1;  // broadcastTensorB_2 > multiplyTensors_21 size:= 256*char defined in Core0
extern char *const broadcastTensorB_2__multiply__5;  // broadcastTensorB_2 > multiplyTensors_17 size:= 256*char defined in Core0
extern char *const broadcastTensorB_2__multiply__0;  // broadcastTensorB_2 > multiplyTensors_16 size:= 256*char defined in Core0
extern char *const broadcastTensorB_20__multipl__0;  // broadcastTensorB_20 > multiplyTensors_165 size:= 256*char defined in Core0
extern char *const broadcastTensorB_20__multipl__6;  // broadcastTensorB_20 > multiplyTensors_164 size:= 256*char defined in Core0
extern char *const broadcastTensorB_21__multipl__3;  // broadcastTensorB_21 > multiplyTensors_175 size:= 256*char defined in Core0
extern char *const broadcastTensorB_22__multipl__6;  // broadcastTensorB_22 > multiplyTensors_182 size:= 256*char defined in Core0
extern char *const broadcastTensorB_22__multipl__3;  // broadcastTensorB_22 > multiplyTensors_176 size:= 256*char defined in Core0
extern int *const output_0__arrayB__9;  // broadcastTensorB_23_output_0 > multiplyTensors_184_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__0;  // broadcastTensorB_23_output_64 > multiplyTensors_185_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__6;  // broadcastTensorB_23_output_128 > multiplyTensors_186_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__22;  // broadcastTensorB_23_output_192 > multiplyTensors_187_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__19;  // broadcastTensorB_23_output_256 > multiplyTensors_188_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__7;  // broadcastTensorB_23_output_320 > multiplyTensors_189_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__6;  // broadcastTensorB_23_output_384 > multiplyTensors_190_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__22;  // broadcastTensorB_23_output_448 > multiplyTensors_191_arrayB size:= 64*int defined in Core0
extern int *const arrayB_1472__input__0;  // explode_generateTensors_arrayB_arrayB_1472 > broadcastTensorB_23_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_23__multipl__7;  // broadcastTensorB_23 > multiplyTensors_191 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__3;  // broadcastTensorB_23 > multiplyTensors_190 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__2;  // broadcastTensorB_23 > multiplyTensors_189 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__5;  // broadcastTensorB_23 > multiplyTensors_187 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__1;  // broadcastTensorB_23 > multiplyTensors_186 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__0;  // broadcastTensorB_23 > multiplyTensors_185 size:= 256*char defined in Core0
extern char *const broadcastTensorB_23__multipl__4;  // broadcastTensorB_23 > multiplyTensors_184 size:= 256*char defined in Core0
extern char *const broadcastTensorB_24__multipl__0;  // broadcastTensorB_24 > multiplyTensors_199 size:= 256*char defined in Core0
extern char *const broadcastTensorB_24__multipl__7;  // broadcastTensorB_24 > multiplyTensors_193 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__7;  // broadcastTensorB_27 > multiplyTensors_222 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__6;  // broadcastTensorB_27 > multiplyTensors_220 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__2;  // broadcastTensorB_27 > multiplyTensors_217 size:= 256*char defined in Core0
extern char *const broadcastTensorB_27__multipl__5;  // broadcastTensorB_27 > multiplyTensors_216 size:= 256*char defined in Core0
extern char *const broadcastTensorB_28__multipl__2;  // broadcastTensorB_28 > multiplyTensors_226 size:= 256*char defined in Core0
extern int *const output_0__arrayB__8;  // broadcastTensorB_3_output_0 > multiplyTensors_24_arrayB size:= 64*int defined in Core0
extern int *const output_64__arrayB__5;  // broadcastTensorB_3_output_64 > multiplyTensors_25_arrayB size:= 64*int defined in Core0
extern int *const output_128__arrayB__14;  // broadcastTensorB_3_output_128 > multiplyTensors_26_arrayB size:= 64*int defined in Core0
extern int *const output_192__arrayB__23;  // broadcastTensorB_3_output_192 > multiplyTensors_27_arrayB size:= 64*int defined in Core0
extern int *const output_256__arrayB__14;  // broadcastTensorB_3_output_256 > multiplyTensors_28_arrayB size:= 64*int defined in Core0
extern int *const output_320__arrayB__4;  // broadcastTensorB_3_output_320 > multiplyTensors_29_arrayB size:= 64*int defined in Core0
extern int *const output_384__arrayB__15;  // broadcastTensorB_3_output_384 > multiplyTensors_30_arrayB size:= 64*int defined in Core0
extern int *const output_448__arrayB__2;  // broadcastTensorB_3_output_448 > multiplyTensors_31_arrayB size:= 64*int defined in Core0
extern int *const arrayB_192__input__0;  // explode_generateTensors_arrayB_arrayB_192 > broadcastTensorB_3_input size:= 64*int defined in Core0
extern char *const broadcastTensorB_3__multiply__0;  // broadcastTensorB_3 > multiplyTensors_31 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__6;  // broadcastTensorB_3 > multiplyTensors_30 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__1;  // broadcastTensorB_3 > multiplyTensors_29 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__5;  // broadcastTensorB_3 > multiplyTensors_28 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__7;  // broadcastTensorB_3 > multiplyTensors_27 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__4;  // broadcastTensorB_3 > multiplyTensors_26 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__2;  // broadcastTensorB_3 > multiplyTensors_25 size:= 256*char defined in Core0
extern char *const broadcastTensorB_3__multiply__3;  // broadcastTensorB_3 > multiplyTensors_24 size:= 256*char defined in Core0
extern char *const broadcastTensorB_4__multiply__4;  // broadcastTensorB_4 > multiplyTensors_36 size:= 256*char defined in Core0
extern char *const broadcastTensorB_5__multiply__1;  // broadcastTensorB_5 > multiplyTensors_42 size:= 256*char defined in Core0
extern char *const broadcastTensorB_7__multiply__4;  // broadcastTensorB_7 > multiplyTensors_57 size:= 256*char defined in Core0
extern char *const broadcastTensorB_8__multiply__2;  // broadcastTensorB_8 > multiplyTensors_69 size:= 256*char defined in Core0
extern int *const arrayA_832__arrayA__0;  // explode_generateTensors_arrayA_arrayA_832 > multiplyTensors_104_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__4;  // broadcastTensorB_13_output_0 > multiplyTensors_104_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_832__0;  // multiplyTensors_104_arrayC > implode_displayTensor_arrayC_arrayC_832 size:= 8*long defined in Core0
extern char *const multiplyTensors_104__implode__0;  // multiplyTensors_104 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_96__arrayA__0;  // explode_generateTensors_arrayA_arrayA_96 > multiplyTensors_12_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__10;  // broadcastTensorB_1_output_256 > multiplyTensors_12_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_96__0;  // multiplyTensors_12_arrayC > implode_displayTensor_arrayC_arrayC_96 size:= 8*long defined in Core0
extern char *const multiplyTensors_12__implode___0;  // multiplyTensors_12 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1000__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1000 > multiplyTensors_125_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__27;  // broadcastTensorB_15_output_320 > multiplyTensors_125_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1000__0;  // multiplyTensors_125_arrayC > implode_displayTensor_arrayC_arrayC_1000 size:= 8*long defined in Core0
extern char *const multiplyTensors_125__implode__0;  // multiplyTensors_125 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1008__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1008 > multiplyTensors_126_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__24;  // broadcastTensorB_15_output_384 > multiplyTensors_126_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1008__0;  // multiplyTensors_126_arrayC > implode_displayTensor_arrayC_arrayC_1008 size:= 8*long defined in Core0
extern char *const multiplyTensors_126__implode__0;  // multiplyTensors_126 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1040__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1040 > multiplyTensors_130_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__24;  // broadcastTensorB_16_output_128 > multiplyTensors_130_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1040__0;  // multiplyTensors_130_arrayC > implode_displayTensor_arrayC_arrayC_1040 size:= 8*long defined in Core0
extern char *const multiplyTensors_130__implode__0;  // multiplyTensors_130 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1048__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1048 > multiplyTensors_131_arrayA size:= 8*int defined in Core0
extern int *const output_192__arrayB__8;  // broadcastTensorB_16_output_192 > multiplyTensors_131_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1048__0;  // multiplyTensors_131_arrayC > implode_displayTensor_arrayC_arrayC_1048 size:= 8*long defined in Core0
extern char *const multiplyTensors_131__implode__0;  // multiplyTensors_131 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1128__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1128 > multiplyTensors_141_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__22;  // broadcastTensorB_17_output_320 > multiplyTensors_141_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1128__0;  // multiplyTensors_141_arrayC > implode_displayTensor_arrayC_arrayC_1128 size:= 8*long defined in Core0
extern char *const multiplyTensors_141__implode__0;  // multiplyTensors_141 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1216__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1216 > multiplyTensors_152_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__18;  // broadcastTensorB_19_output_0 > multiplyTensors_152_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1216__0;  // multiplyTensors_152_arrayC > implode_displayTensor_arrayC_arrayC_1216 size:= 8*long defined in Core0
extern char *const multiplyTensors_152__implode__0;  // multiplyTensors_152 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1256__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1256 > multiplyTensors_157_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__24;  // broadcastTensorB_19_output_320 > multiplyTensors_157_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1256__0;  // multiplyTensors_157_arrayC > implode_displayTensor_arrayC_arrayC_1256 size:= 8*long defined in Core0
extern char *const multiplyTensors_157__implode__0;  // multiplyTensors_157 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1264__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1264 > multiplyTensors_158_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__29;  // broadcastTensorB_19_output_384 > multiplyTensors_158_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1264__0;  // multiplyTensors_158_arrayC > implode_displayTensor_arrayC_arrayC_1264 size:= 8*long defined in Core0
extern char *const multiplyTensors_158__implode__0;  // multiplyTensors_158 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_128__arrayA__0;  // explode_generateTensors_arrayA_arrayA_128 > multiplyTensors_16_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__2;  // broadcastTensorB_2_output_0 > multiplyTensors_16_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_128__0;  // multiplyTensors_16_arrayC > implode_displayTensor_arrayC_arrayC_128 size:= 8*long defined in Core0
extern char *const multiplyTensors_16__implode___0;  // multiplyTensors_16 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1312__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1312 > multiplyTensors_164_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__18;  // broadcastTensorB_20_output_256 > multiplyTensors_164_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1312__0;  // multiplyTensors_164_arrayC > implode_displayTensor_arrayC_arrayC_1312 size:= 8*long defined in Core0
extern char *const multiplyTensors_164__implode__0;  // multiplyTensors_164 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1320__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1320 > multiplyTensors_165_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__0;  // broadcastTensorB_20_output_320 > multiplyTensors_165_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1320__0;  // multiplyTensors_165_arrayC > implode_displayTensor_arrayC_arrayC_1320 size:= 8*long defined in Core0
extern char *const multiplyTensors_165__implode__0;  // multiplyTensors_165 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_136__arrayA__0;  // explode_generateTensors_arrayA_arrayA_136 > multiplyTensors_17_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__26;  // broadcastTensorB_2_output_64 > multiplyTensors_17_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_136__0;  // multiplyTensors_17_arrayC > implode_displayTensor_arrayC_arrayC_136 size:= 8*long defined in Core0
extern char *const multiplyTensors_17__implode___0;  // multiplyTensors_17 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1400__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1400 > multiplyTensors_175_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__15;  // broadcastTensorB_21_output_448 > multiplyTensors_175_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1400__0;  // multiplyTensors_175_arrayC > implode_displayTensor_arrayC_arrayC_1400 size:= 8*long defined in Core0
extern char *const multiplyTensors_175__implode__0;  // multiplyTensors_175 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1408__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1408 > multiplyTensors_176_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__10;  // broadcastTensorB_22_output_0 > multiplyTensors_176_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1408__0;  // multiplyTensors_176_arrayC > implode_displayTensor_arrayC_arrayC_1408 size:= 8*long defined in Core0
extern char *const multiplyTensors_176__implode__0;  // multiplyTensors_176 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1456__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1456 > multiplyTensors_182_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__21;  // broadcastTensorB_22_output_384 > multiplyTensors_182_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1456__0;  // multiplyTensors_182_arrayC > implode_displayTensor_arrayC_arrayC_1456 size:= 8*long defined in Core0
extern char *const multiplyTensors_182__implode__0;  // multiplyTensors_182 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1504__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1504 > multiplyTensors_188_arrayA size:= 8*int defined in Core0
extern long *const arrayC__arrayC_1504__0;  // multiplyTensors_188_arrayC > implode_displayTensor_arrayC_arrayC_1504 size:= 8*long defined in Core0
extern char *const multiplyTensors_188__implode__0;  // multiplyTensors_188 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1544__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1544 > multiplyTensors_193_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__31;  // broadcastTensorB_24_output_64 > multiplyTensors_193_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1544__0;  // multiplyTensors_193_arrayC > implode_displayTensor_arrayC_arrayC_1544 size:= 8*long defined in Core0
extern char *const multiplyTensors_193__implode__0;  // multiplyTensors_193 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1592__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1592 > multiplyTensors_199_arrayA size:= 8*int defined in Core0
extern int *const output_448__arrayB__1;  // broadcastTensorB_24_output_448 > multiplyTensors_199_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1592__0;  // multiplyTensors_199_arrayC > implode_displayTensor_arrayC_arrayC_1592 size:= 8*long defined in Core0
extern char *const multiplyTensors_199__implode__0;  // multiplyTensors_199 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_168__arrayA__0;  // explode_generateTensors_arrayA_arrayA_168 > multiplyTensors_21_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__11;  // broadcastTensorB_2_output_320 > multiplyTensors_21_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_168__0;  // multiplyTensors_21_arrayC > implode_displayTensor_arrayC_arrayC_168 size:= 8*long defined in Core0
extern char *const multiplyTensors_21__implode___0;  // multiplyTensors_21 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1728__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1728 > multiplyTensors_216_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayB__23;  // broadcastTensorB_27_output_0 > multiplyTensors_216_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1728__0;  // multiplyTensors_216_arrayC > implode_displayTensor_arrayC_arrayC_1728 size:= 8*long defined in Core0
extern char *const multiplyTensors_216__implode__0;  // multiplyTensors_216 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1736__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1736 > multiplyTensors_217_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__16;  // broadcastTensorB_27_output_64 > multiplyTensors_217_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1736__0;  // multiplyTensors_217_arrayC > implode_displayTensor_arrayC_arrayC_1736 size:= 8*long defined in Core0
extern char *const multiplyTensors_217__implode__0;  // multiplyTensors_217 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1760__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1760 > multiplyTensors_220_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__26;  // broadcastTensorB_27_output_256 > multiplyTensors_220_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1760__0;  // multiplyTensors_220_arrayC > implode_displayTensor_arrayC_arrayC_1760 size:= 8*long defined in Core0
extern char *const multiplyTensors_220__implode__0;  // multiplyTensors_220 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1776__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1776 > multiplyTensors_222_arrayA size:= 8*int defined in Core0
extern int *const output_384__arrayB__27;  // broadcastTensorB_27_output_384 > multiplyTensors_222_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1776__0;  // multiplyTensors_222_arrayC > implode_displayTensor_arrayC_arrayC_1776 size:= 8*long defined in Core0
extern char *const multiplyTensors_222__implode__0;  // multiplyTensors_222 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_1808__arrayA__0;  // explode_generateTensors_arrayA_arrayA_1808 > multiplyTensors_226_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__2;  // broadcastTensorB_28_output_128 > multiplyTensors_226_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_1808__0;  // multiplyTensors_226_arrayC > implode_displayTensor_arrayC_arrayC_1808 size:= 8*long defined in Core0
extern char *const multiplyTensors_226__implode__0;  // multiplyTensors_226 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_288__arrayA__0;  // explode_generateTensors_arrayA_arrayA_288 > multiplyTensors_36_arrayA size:= 8*int defined in Core0
extern int *const output_256__arrayB__21;  // broadcastTensorB_4_output_256 > multiplyTensors_36_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_288__0;  // multiplyTensors_36_arrayC > implode_displayTensor_arrayC_arrayC_288 size:= 8*long defined in Core0
extern char *const multiplyTensors_36__implode___0;  // multiplyTensors_36 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_336__arrayA__0;  // explode_generateTensors_arrayA_arrayA_336 > multiplyTensors_42_arrayA size:= 8*int defined in Core0
extern int *const output_128__arrayB__10;  // broadcastTensorB_5_output_128 > multiplyTensors_42_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_336__0;  // multiplyTensors_42_arrayC > implode_displayTensor_arrayC_arrayC_336 size:= 8*long defined in Core0
extern char *const multiplyTensors_42__implode___0;  // multiplyTensors_42 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_456__arrayA__0;  // explode_generateTensors_arrayA_arrayA_456 > multiplyTensors_57_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__28;  // broadcastTensorB_7_output_64 > multiplyTensors_57_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_456__0;  // multiplyTensors_57_arrayC > implode_displayTensor_arrayC_arrayC_456 size:= 8*long defined in Core0
extern char *const multiplyTensors_57__implode___0;  // multiplyTensors_57 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_552__arrayA__0;  // explode_generateTensors_arrayA_arrayA_552 > multiplyTensors_69_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__9;  // broadcastTensorB_8_output_320 > multiplyTensors_69_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_552__0;  // multiplyTensors_69_arrayC > implode_displayTensor_arrayC_arrayC_552 size:= 8*long defined in Core0
extern char *const multiplyTensors_69__implode___0;  // multiplyTensors_69 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_680__arrayA__0;  // explode_generateTensors_arrayA_arrayA_680 > multiplyTensors_85_arrayA size:= 8*int defined in Core0
extern int *const output_320__arrayB__2;  // broadcastTensorB_10_output_320 > multiplyTensors_85_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_680__0;  // multiplyTensors_85_arrayC > implode_displayTensor_arrayC_arrayC_680 size:= 8*long defined in Core0
extern char *const multiplyTensors_85__implode___0;  // multiplyTensors_85 > implode_displayTensor_arrayC size:= 32*char defined in Core0
extern int *const arrayA_776__arrayA__0;  // explode_generateTensors_arrayA_arrayA_776 > multiplyTensors_97_arrayA size:= 8*int defined in Core0
extern int *const output_64__arrayB__27;  // broadcastTensorB_12_output_64 > multiplyTensors_97_arrayB size:= 64*int defined in Core0
extern long *const arrayC__arrayC_776__0;  // multiplyTensors_97_arrayC > implode_displayTensor_arrayC_arrayC_776 size:= 8*long defined in Core0
extern char *const multiplyTensors_97__implode___0;  // multiplyTensors_97 > implode_displayTensor_arrayC size:= 32*char defined in Core0

// Core Global Definitions

void core1(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__132 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__132 
		cache_inv(explode_generateTensors_arra__132, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__137 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__137 
		cache_inv(explode_generateTensors_arra__137, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__87 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__87 
		cache_inv(explode_generateTensors_arra__87, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__114 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__114 
		cache_inv(explode_generateTensors_arra__114, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__92 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__92 
		cache_inv(explode_generateTensors_arra__92, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__191 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__191 
		cache_inv(explode_generateTensors_arra__191, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__27 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__27 
		cache_inv(explode_generateTensors_arra__27, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__159 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__159 
		cache_inv(explode_generateTensors_arra__159, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__116 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__116 
		cache_inv(explode_generateTensors_arra__116, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__252 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__252 
		cache_inv(explode_generateTensors_arra__252, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__65 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__65 
		cache_inv(explode_generateTensors_arra__65, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__5 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__5 
		cache_inv(explode_generateTensors_arra__5, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__277 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__277 
		cache_inv(explode_generateTensors_arra__277, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__250 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__250 
		cache_inv(explode_generateTensors_arra__250, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__174 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__174 
		cache_inv(explode_generateTensors_arra__174, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__103 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__103 
		cache_inv(explode_generateTensors_arra__103, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__166 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__166 
		cache_inv(explode_generateTensors_arra__166, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__245 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__245 
		cache_inv(explode_generateTensors_arra__245, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__146 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__146 
		cache_inv(explode_generateTensors_arra__146, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__77 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__77 
		cache_inv(explode_generateTensors_arra__77, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__3 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__3 
		cache_inv(explode_generateTensors_arra__3, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__13 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__124 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__124 
		cache_inv(explode_generateTensors_arra__124, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__143 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__143 
		cache_inv(explode_generateTensors_arra__143, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__12 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__217 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__217 
		cache_inv(explode_generateTensors_arra__217, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__97 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__97 
		cache_inv(explode_generateTensors_arra__97, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__181 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__181 
		cache_inv(explode_generateTensors_arra__181, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__63 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__63 
		cache_inv(explode_generateTensors_arra__63, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__285 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__285 
		cache_inv(explode_generateTensors_arra__285, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__254 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__254 
		cache_inv(explode_generateTensors_arra__254, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__199 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__199 
		cache_inv(explode_generateTensors_arra__199, 32*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__95 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__95 
		cache_inv(explode_generateTensors_arra__95, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__134 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__134 
		cache_inv(explode_generateTensors_arra__134, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__48 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__48 
		cache_inv(explode_generateTensors_arra__48, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__35 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__35 
		cache_inv(explode_generateTensors_arra__35, 256*sizeof(char));
		receiveStart(); // Core2 > Core1: broadcastTensorB_1__multiply__2 
		receiveEnd(2); // Core2 > Core1: broadcastTensorB_1__multiply__2 
		cache_inv(broadcastTensorB_1__multiply__2, 256*sizeof(char));
		receiveStart(); // Core2 > Core1: broadcastTensorB_10__multipl__1 
		receiveEnd(2); // Core2 > Core1: broadcastTensorB_10__multipl__1 
		cache_inv(broadcastTensorB_10__multipl__1, 256*sizeof(char));
		// Broadcast broadcastTensorB_11
		{
			cache_wb(arrayB_704__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_704__input__0) + 0, 256);
		cache_inv(arrayB_704__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_11__multipl__2, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: broadcastTensorB_11__multipl__2 
		sendEnd(); // Core1 > Core3: broadcastTensorB_11__multipl__2 
		cache_wbInv(broadcastTensorB_11__multipl__4, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: broadcastTensorB_11__multipl__4 
		sendEnd(); // Core1 > Core6: broadcastTensorB_11__multipl__4 
		cache_wbInv(broadcastTensorB_11__multipl__1, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: broadcastTensorB_11__multipl__1 
		sendEnd(); // Core1 > Core0: broadcastTensorB_11__multipl__1 
		cache_wbInv(broadcastTensorB_11__multipl__5, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_11__multipl__5 
		sendEnd(); // Core1 > Core5: broadcastTensorB_11__multipl__5 
		cache_wbInv(broadcastTensorB_11__multipl__6, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: broadcastTensorB_11__multipl__6 
		sendEnd(); // Core1 > Core2: broadcastTensorB_11__multipl__6 
		cache_wbInv(broadcastTensorB_11__multipl__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: broadcastTensorB_11__multipl__0 
		sendEnd(); // Core1 > Core6: broadcastTensorB_11__multipl__0 
		cache_wbInv(broadcastTensorB_11__multipl__3, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: broadcastTensorB_11__multipl__3 
		sendEnd(); // Core1 > Core3: broadcastTensorB_11__multipl__3 
		cache_wbInv(broadcastTensorB_11__multipl__7, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: broadcastTensorB_11__multipl__7 
		sendEnd(); // Core1 > Core3: broadcastTensorB_11__multipl__7 
		receiveStart(); // Core2 > Core1: broadcastTensorB_12__multipl__6 
		receiveEnd(2); // Core2 > Core1: broadcastTensorB_12__multipl__6 
		cache_inv(broadcastTensorB_12__multipl__6, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: broadcastTensorB_13__multipl__1 
		receiveEnd(0); // Core0 > Core1: broadcastTensorB_13__multipl__1 
		cache_inv(broadcastTensorB_13__multipl__1, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: broadcastTensorB_15__multipl__2 
		receiveEnd(0); // Core0 > Core1: broadcastTensorB_15__multipl__2 
		cache_inv(broadcastTensorB_15__multipl__2, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: broadcastTensorB_15__multipl__4 
		receiveEnd(0); // Core0 > Core1: broadcastTensorB_15__multipl__4 
		cache_inv(broadcastTensorB_15__multipl__4, 256*sizeof(char));
		receiveStart(); // Core6 > Core1: broadcastTensorB_16__multipl__1 
		receiveEnd(6); // Core6 > Core1: broadcastTensorB_16__multipl__1 
		cache_inv(broadcastTensorB_16__multipl__1, 256*sizeof(char));
		receiveStart(); // Core6 > Core1: broadcastTensorB_16__multipl__3 
		receiveEnd(6); // Core6 > Core1: broadcastTensorB_16__multipl__3 
		cache_inv(broadcastTensorB_16__multipl__3, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: broadcastTensorB_17__multipl__6 
		receiveEnd(5); // Core5 > Core1: broadcastTensorB_17__multipl__6 
		cache_inv(broadcastTensorB_17__multipl__6, 256*sizeof(char));
		// Broadcast broadcastTensorB_18
		{
			cache_wb(arrayB_1152__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_1152__input__0) + 0, 256);
		cache_inv(arrayB_1152__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_18__multipl__1, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_18__multipl__1 
		sendEnd(); // Core1 > Core5: broadcastTensorB_18__multipl__1 
		cache_wbInv(broadcastTensorB_18__multipl__0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: broadcastTensorB_18__multipl__0 
		sendEnd(); // Core1 > Core0: broadcastTensorB_18__multipl__0 
		cache_wbInv(broadcastTensorB_18__multipl__2, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: broadcastTensorB_18__multipl__2 
		sendEnd(); // Core1 > Core4: broadcastTensorB_18__multipl__2 
		cache_wbInv(broadcastTensorB_18__multipl__6, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_18__multipl__6 
		sendEnd(); // Core1 > Core5: broadcastTensorB_18__multipl__6 
		cache_wbInv(broadcastTensorB_18__multipl__5, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: broadcastTensorB_18__multipl__5 
		sendEnd(); // Core1 > Core6: broadcastTensorB_18__multipl__5 
		cache_wbInv(broadcastTensorB_18__multipl__3, 256*sizeof(char));
		sendStart(7); // Core1 > Core7: broadcastTensorB_18__multipl__3 
		sendEnd(); // Core1 > Core7: broadcastTensorB_18__multipl__3 
		cache_wbInv(broadcastTensorB_18__multipl__4, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: broadcastTensorB_18__multipl__4 
		sendEnd(); // Core1 > Core4: broadcastTensorB_18__multipl__4 
		cache_wbInv(broadcastTensorB_18__multipl__7, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: broadcastTensorB_18__multipl__7 
		sendEnd(); // Core1 > Core0: broadcastTensorB_18__multipl__7 
		receiveStart(); // Core6 > Core1: broadcastTensorB_19__multipl__7 
		receiveEnd(6); // Core6 > Core1: broadcastTensorB_19__multipl__7 
		cache_inv(broadcastTensorB_19__multipl__7, 256*sizeof(char));
		receiveStart(); // Core6 > Core1: broadcastTensorB_19__multipl__3 
		receiveEnd(6); // Core6 > Core1: broadcastTensorB_19__multipl__3 
		cache_inv(broadcastTensorB_19__multipl__3, 256*sizeof(char));
		receiveStart(); // Core6 > Core1: broadcastTensorB_19__multipl__2 
		receiveEnd(6); // Core6 > Core1: broadcastTensorB_19__multipl__2 
		cache_inv(broadcastTensorB_19__multipl__2, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: broadcastTensorB_2__multiply__1 
		receiveEnd(7); // Core7 > Core1: broadcastTensorB_2__multiply__1 
		cache_inv(broadcastTensorB_2__multiply__1, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: broadcastTensorB_2__multiply__5 
		receiveEnd(7); // Core7 > Core1: broadcastTensorB_2__multiply__5 
		cache_inv(broadcastTensorB_2__multiply__5, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: broadcastTensorB_2__multiply__0 
		receiveEnd(7); // Core7 > Core1: broadcastTensorB_2__multiply__0 
		cache_inv(broadcastTensorB_2__multiply__0, 256*sizeof(char));
		receiveStart(); // Core4 > Core1: broadcastTensorB_20__multipl__0 
		receiveEnd(4); // Core4 > Core1: broadcastTensorB_20__multipl__0 
		cache_inv(broadcastTensorB_20__multipl__0, 256*sizeof(char));
		receiveStart(); // Core4 > Core1: broadcastTensorB_20__multipl__6 
		receiveEnd(4); // Core4 > Core1: broadcastTensorB_20__multipl__6 
		cache_inv(broadcastTensorB_20__multipl__6, 256*sizeof(char));
		receiveStart(); // Core6 > Core1: broadcastTensorB_21__multipl__3 
		receiveEnd(6); // Core6 > Core1: broadcastTensorB_21__multipl__3 
		cache_inv(broadcastTensorB_21__multipl__3, 256*sizeof(char));
		receiveStart(); // Core4 > Core1: broadcastTensorB_22__multipl__6 
		receiveEnd(4); // Core4 > Core1: broadcastTensorB_22__multipl__6 
		cache_inv(broadcastTensorB_22__multipl__6, 256*sizeof(char));
		receiveStart(); // Core4 > Core1: broadcastTensorB_22__multipl__3 
		receiveEnd(4); // Core4 > Core1: broadcastTensorB_22__multipl__3 
		cache_inv(broadcastTensorB_22__multipl__3, 256*sizeof(char));
		// Broadcast broadcastTensorB_23
		{
			cache_wb(arrayB_1472__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_1472__input__0) + 0, 256);
		cache_inv(arrayB_1472__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_23__multipl__7, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_23__multipl__7 
		sendEnd(); // Core1 > Core5: broadcastTensorB_23__multipl__7 
		cache_wbInv(broadcastTensorB_23__multipl__3, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_23__multipl__3 
		sendEnd(); // Core1 > Core5: broadcastTensorB_23__multipl__3 
		cache_wbInv(broadcastTensorB_23__multipl__2, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: broadcastTensorB_23__multipl__2 
		sendEnd(); // Core1 > Core2: broadcastTensorB_23__multipl__2 
		cache_wbInv(broadcastTensorB_23__multipl__5, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_23__multipl__5 
		sendEnd(); // Core1 > Core5: broadcastTensorB_23__multipl__5 
		cache_wbInv(broadcastTensorB_23__multipl__1, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: broadcastTensorB_23__multipl__1 
		sendEnd(); // Core1 > Core6: broadcastTensorB_23__multipl__1 
		cache_wbInv(broadcastTensorB_23__multipl__0, 256*sizeof(char));
		sendStart(7); // Core1 > Core7: broadcastTensorB_23__multipl__0 
		sendEnd(); // Core1 > Core7: broadcastTensorB_23__multipl__0 
		cache_wbInv(broadcastTensorB_23__multipl__4, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: broadcastTensorB_23__multipl__4 
		sendEnd(); // Core1 > Core0: broadcastTensorB_23__multipl__4 
		receiveStart(); // Core3 > Core1: broadcastTensorB_24__multipl__0 
		receiveEnd(3); // Core3 > Core1: broadcastTensorB_24__multipl__0 
		cache_inv(broadcastTensorB_24__multipl__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: broadcastTensorB_24__multipl__7 
		receiveEnd(3); // Core3 > Core1: broadcastTensorB_24__multipl__7 
		cache_inv(broadcastTensorB_24__multipl__7, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: broadcastTensorB_27__multipl__7 
		receiveEnd(5); // Core5 > Core1: broadcastTensorB_27__multipl__7 
		cache_inv(broadcastTensorB_27__multipl__7, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: broadcastTensorB_27__multipl__6 
		receiveEnd(5); // Core5 > Core1: broadcastTensorB_27__multipl__6 
		cache_inv(broadcastTensorB_27__multipl__6, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: broadcastTensorB_27__multipl__2 
		receiveEnd(5); // Core5 > Core1: broadcastTensorB_27__multipl__2 
		cache_inv(broadcastTensorB_27__multipl__2, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: broadcastTensorB_27__multipl__5 
		receiveEnd(5); // Core5 > Core1: broadcastTensorB_27__multipl__5 
		cache_inv(broadcastTensorB_27__multipl__5, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: broadcastTensorB_28__multipl__2 
		receiveEnd(5); // Core5 > Core1: broadcastTensorB_28__multipl__2 
		cache_inv(broadcastTensorB_28__multipl__2, 256*sizeof(char));
		// Broadcast broadcastTensorB_3
		{
			cache_wb(arrayB_192__input__0, 64*sizeof(int));
		}
		cache_wb(((char*)arrayB_192__input__0) + 0, 256);
		cache_inv(arrayB_192__input__0, 64*sizeof(int));
		cache_wbInv(broadcastTensorB_3__multiply__0, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: broadcastTensorB_3__multiply__0 
		sendEnd(); // Core1 > Core3: broadcastTensorB_3__multiply__0 
		cache_wbInv(broadcastTensorB_3__multiply__6, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: broadcastTensorB_3__multiply__6 
		sendEnd(); // Core1 > Core0: broadcastTensorB_3__multiply__6 
		cache_wbInv(broadcastTensorB_3__multiply__1, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: broadcastTensorB_3__multiply__1 
		sendEnd(); // Core1 > Core3: broadcastTensorB_3__multiply__1 
		cache_wbInv(broadcastTensorB_3__multiply__5, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_3__multiply__5 
		sendEnd(); // Core1 > Core5: broadcastTensorB_3__multiply__5 
		cache_wbInv(broadcastTensorB_3__multiply__7, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: broadcastTensorB_3__multiply__7 
		sendEnd(); // Core1 > Core4: broadcastTensorB_3__multiply__7 
		cache_wbInv(broadcastTensorB_3__multiply__4, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: broadcastTensorB_3__multiply__4 
		sendEnd(); // Core1 > Core5: broadcastTensorB_3__multiply__4 
		cache_wbInv(broadcastTensorB_3__multiply__2, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: broadcastTensorB_3__multiply__2 
		sendEnd(); // Core1 > Core0: broadcastTensorB_3__multiply__2 
		cache_wbInv(broadcastTensorB_3__multiply__3, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: broadcastTensorB_3__multiply__3 
		sendEnd(); // Core1 > Core2: broadcastTensorB_3__multiply__3 
		receiveStart(); // Core3 > Core1: broadcastTensorB_4__multiply__4 
		receiveEnd(3); // Core3 > Core1: broadcastTensorB_4__multiply__4 
		cache_inv(broadcastTensorB_4__multiply__4, 256*sizeof(char));
		receiveStart(); // Core5 > Core1: broadcastTensorB_5__multiply__1 
		receiveEnd(5); // Core5 > Core1: broadcastTensorB_5__multiply__1 
		cache_inv(broadcastTensorB_5__multiply__1, 256*sizeof(char));
		receiveStart(); // Core4 > Core1: broadcastTensorB_7__multiply__4 
		receiveEnd(4); // Core4 > Core1: broadcastTensorB_7__multiply__4 
		cache_inv(broadcastTensorB_7__multiply__4, 256*sizeof(char));
		receiveStart(); // Core3 > Core1: broadcastTensorB_8__multiply__2 
		receiveEnd(3); // Core3 > Core1: broadcastTensorB_8__multiply__2 
		cache_inv(broadcastTensorB_8__multiply__2, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_832__arrayA__0,output_0__arrayB__4,arrayC__arrayC_832__0); // multiplyTensors_104
		cache_inv(arrayA_832__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__4, 64*sizeof(int));
		cache_wbInv(multiplyTensors_104__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_104__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_104__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_96__arrayA__0,output_256__arrayB__10,arrayC__arrayC_96__0); // multiplyTensors_12
		cache_inv(arrayA_96__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__10, 64*sizeof(int));
		cache_wbInv(multiplyTensors_12__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_12__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_12__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1000__arrayA__0,output_320__arrayB__27,arrayC__arrayC_1000__0); // multiplyTensors_125
		cache_inv(arrayA_1000__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__27, 64*sizeof(int));
		cache_wbInv(multiplyTensors_125__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_125__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_125__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1008__arrayA__0,output_384__arrayB__24,arrayC__arrayC_1008__0); // multiplyTensors_126
		cache_inv(arrayA_1008__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__24, 64*sizeof(int));
		cache_wbInv(multiplyTensors_126__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_126__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_126__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1040__arrayA__0,output_128__arrayB__24,arrayC__arrayC_1040__0); // multiplyTensors_130
		cache_inv(arrayA_1040__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__24, 64*sizeof(int));
		cache_wbInv(multiplyTensors_130__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_130__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_130__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1048__arrayA__0,output_192__arrayB__8,arrayC__arrayC_1048__0); // multiplyTensors_131
		cache_inv(arrayA_1048__arrayA__0, 8*sizeof(int));
		cache_inv(output_192__arrayB__8, 64*sizeof(int));
		cache_wbInv(multiplyTensors_131__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_131__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_131__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1128__arrayA__0,output_320__arrayB__22,arrayC__arrayC_1128__0); // multiplyTensors_141
		cache_inv(arrayA_1128__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__22, 64*sizeof(int));
		cache_wbInv(multiplyTensors_141__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_141__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_141__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1216__arrayA__0,output_0__arrayB__18,arrayC__arrayC_1216__0); // multiplyTensors_152
		cache_inv(arrayA_1216__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__18, 64*sizeof(int));
		cache_wbInv(multiplyTensors_152__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_152__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_152__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1256__arrayA__0,output_320__arrayB__24,arrayC__arrayC_1256__0); // multiplyTensors_157
		cache_inv(arrayA_1256__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__24, 64*sizeof(int));
		cache_wbInv(multiplyTensors_157__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_157__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_157__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1264__arrayA__0,output_384__arrayB__29,arrayC__arrayC_1264__0); // multiplyTensors_158
		cache_inv(arrayA_1264__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__29, 64*sizeof(int));
		cache_wbInv(multiplyTensors_158__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_158__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_158__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_128__arrayA__0,output_0__arrayB__2,arrayC__arrayC_128__0); // multiplyTensors_16
		cache_inv(arrayA_128__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__2, 64*sizeof(int));
		cache_wbInv(multiplyTensors_16__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_16__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_16__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1312__arrayA__0,output_256__arrayB__18,arrayC__arrayC_1312__0); // multiplyTensors_164
		cache_inv(arrayA_1312__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__18, 64*sizeof(int));
		cache_wbInv(multiplyTensors_164__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_164__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_164__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1320__arrayA__0,output_320__arrayB__0,arrayC__arrayC_1320__0); // multiplyTensors_165
		cache_inv(arrayA_1320__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__0, 64*sizeof(int));
		cache_wbInv(multiplyTensors_165__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_165__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_165__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_136__arrayA__0,output_64__arrayB__26,arrayC__arrayC_136__0); // multiplyTensors_17
		cache_inv(arrayA_136__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__26, 64*sizeof(int));
		cache_wbInv(multiplyTensors_17__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_17__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_17__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1400__arrayA__0,output_448__arrayB__15,arrayC__arrayC_1400__0); // multiplyTensors_175
		cache_inv(arrayA_1400__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__15, 64*sizeof(int));
		cache_wbInv(multiplyTensors_175__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_175__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_175__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1408__arrayA__0,output_0__arrayB__10,arrayC__arrayC_1408__0); // multiplyTensors_176
		cache_inv(arrayA_1408__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__10, 64*sizeof(int));
		cache_wbInv(multiplyTensors_176__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_176__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_176__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1456__arrayA__0,output_384__arrayB__21,arrayC__arrayC_1456__0); // multiplyTensors_182
		cache_inv(arrayA_1456__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__21, 64*sizeof(int));
		cache_wbInv(multiplyTensors_182__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_182__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_182__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1504__arrayA__0,output_256__arrayB__19,arrayC__arrayC_1504__0); // multiplyTensors_188
		cache_inv(arrayA_1504__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__19, 64*sizeof(int));
		cache_wbInv(multiplyTensors_188__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_188__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_188__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1544__arrayA__0,output_64__arrayB__31,arrayC__arrayC_1544__0); // multiplyTensors_193
		cache_inv(arrayA_1544__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__31, 64*sizeof(int));
		cache_wbInv(multiplyTensors_193__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_193__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_193__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1592__arrayA__0,output_448__arrayB__1,arrayC__arrayC_1592__0); // multiplyTensors_199
		cache_inv(arrayA_1592__arrayA__0, 8*sizeof(int));
		cache_inv(output_448__arrayB__1, 64*sizeof(int));
		cache_wbInv(multiplyTensors_199__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_199__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_199__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_168__arrayA__0,output_320__arrayB__11,arrayC__arrayC_168__0); // multiplyTensors_21
		cache_inv(arrayA_168__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__11, 64*sizeof(int));
		cache_wbInv(multiplyTensors_21__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_21__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_21__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1728__arrayA__0,output_0__arrayB__23,arrayC__arrayC_1728__0); // multiplyTensors_216
		cache_inv(arrayA_1728__arrayA__0, 8*sizeof(int));
		cache_inv(output_0__arrayB__23, 64*sizeof(int));
		cache_wbInv(multiplyTensors_216__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_216__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_216__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1736__arrayA__0,output_64__arrayB__16,arrayC__arrayC_1736__0); // multiplyTensors_217
		cache_inv(arrayA_1736__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__16, 64*sizeof(int));
		cache_wbInv(multiplyTensors_217__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_217__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_217__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1760__arrayA__0,output_256__arrayB__26,arrayC__arrayC_1760__0); // multiplyTensors_220
		cache_inv(arrayA_1760__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__26, 64*sizeof(int));
		cache_wbInv(multiplyTensors_220__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_220__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_220__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1776__arrayA__0,output_384__arrayB__27,arrayC__arrayC_1776__0); // multiplyTensors_222
		cache_inv(arrayA_1776__arrayA__0, 8*sizeof(int));
		cache_inv(output_384__arrayB__27, 64*sizeof(int));
		cache_wbInv(multiplyTensors_222__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_222__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_222__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_1808__arrayA__0,output_128__arrayB__2,arrayC__arrayC_1808__0); // multiplyTensors_226
		cache_inv(arrayA_1808__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__2, 64*sizeof(int));
		cache_wbInv(multiplyTensors_226__implode__0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_226__implode__0 
		sendEnd(); // Core1 > Core7: multiplyTensors_226__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_288__arrayA__0,output_256__arrayB__21,arrayC__arrayC_288__0); // multiplyTensors_36
		cache_inv(arrayA_288__arrayA__0, 8*sizeof(int));
		cache_inv(output_256__arrayB__21, 64*sizeof(int));
		cache_wbInv(multiplyTensors_36__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_36__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_36__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_336__arrayA__0,output_128__arrayB__10,arrayC__arrayC_336__0); // multiplyTensors_42
		cache_inv(arrayA_336__arrayA__0, 8*sizeof(int));
		cache_inv(output_128__arrayB__10, 64*sizeof(int));
		cache_wbInv(multiplyTensors_42__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_42__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_42__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_456__arrayA__0,output_64__arrayB__28,arrayC__arrayC_456__0); // multiplyTensors_57
		cache_inv(arrayA_456__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__28, 64*sizeof(int));
		cache_wbInv(multiplyTensors_57__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_57__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_57__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_552__arrayA__0,output_320__arrayB__9,arrayC__arrayC_552__0); // multiplyTensors_69
		cache_inv(arrayA_552__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__9, 64*sizeof(int));
		cache_wbInv(multiplyTensors_69__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_69__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_69__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_680__arrayA__0,output_320__arrayB__2,arrayC__arrayC_680__0); // multiplyTensors_85
		cache_inv(arrayA_680__arrayA__0, 8*sizeof(int));
		cache_inv(output_320__arrayB__2, 64*sizeof(int));
		cache_wbInv(multiplyTensors_85__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_85__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_85__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,32/*depthA*/,8/*rowsB*/,8/*columnsB*/,32/*depthB*/,arrayA_776__arrayA__0,output_64__arrayB__27,arrayC__arrayC_776__0); // multiplyTensors_97
		cache_inv(arrayA_776__arrayA__0, 8*sizeof(int));
		cache_inv(output_64__arrayB__27, 64*sizeof(int));
		cache_wbInv(multiplyTensors_97__implode___0, 32*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_97__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_97__implode___0 
	}
}
