/** 
 * @file Core1.c
 * @generated by C6678CPrinter
 * @date Mon Mar 30 14:58:31 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayA > multiplyTensors_10 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__0;  // explode_generateTensors_arrayA > multiplyTensors_8 size:= 131072*char defined in Core0
extern char *const broadcastTensorB_1__multiply__1;  // broadcastTensorB_1 > multiplyTensors_10 size:= 1048576*char defined in Core0
extern char *const broadcastTensorB_1__multiply__4;  // broadcastTensorB_1 > multiplyTensors_8 size:= 1048576*char defined in Core0
extern int *const arrayA_327680__arrayA__0;  // explode_generateTensors_arrayA_arrayA_327680 > multiplyTensors_10_arrayA size:= 32768*int defined in Core0
extern int *const output_524288__arrayB__0;  // broadcastTensorB_1_output_524288 > multiplyTensors_10_arrayB size:= 262144*int defined in Core0
extern long *const arrayC__arrayC_327680__0;  // multiplyTensors_10_arrayC > implode_displayTensor_arrayC_arrayC_327680 size:= 32768*long defined in Core0
extern char *const multiplyTensors_10__implode___0;  // multiplyTensors_10 > implode_displayTensor_arrayC size:= 131072*char defined in Core0
extern int *const arrayA_262144__arrayA__0;  // explode_generateTensors_arrayA_arrayA_262144 > multiplyTensors_8_arrayA size:= 32768*int defined in Core0
extern int *const output_0__arrayB__0;  // broadcastTensorB_1_output_0 > multiplyTensors_8_arrayB size:= 262144*int defined in Core0
extern long *const arrayC__arrayC_262144__0;  // multiplyTensors_8_arrayC > implode_displayTensor_arrayC_arrayC_262144 size:= 32768*long defined in Core0
extern char *const multiplyTensors_8__implode_d__0;  // multiplyTensors_8 > implode_displayTensor_arrayC size:= 131072*char defined in Core0

// Core Global Definitions

void core1(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__6 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 131072*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__0 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__0 
		cache_inv(explode_generateTensors_arra__0, 131072*sizeof(char));
		receiveStart(); // Core0 > Core1: broadcastTensorB_1__multiply__1 
		receiveEnd(0); // Core0 > Core1: broadcastTensorB_1__multiply__1 
		cache_inv(broadcastTensorB_1__multiply__1, 1048576*sizeof(char));
		receiveStart(); // Core0 > Core1: broadcastTensorB_1__multiply__4 
		receiveEnd(0); // Core0 > Core1: broadcastTensorB_1__multiply__4 
		cache_inv(broadcastTensorB_1__multiply__4, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,2/*depthA*/,512/*rowsB*/,512/*columnsB*/,2/*depthB*/,arrayA_327680__arrayA__0,output_524288__arrayB__0,arrayC__arrayC_327680__0); // multiplyTensors_10
		cache_inv(arrayA_327680__arrayA__0, 32768*sizeof(int));
		cache_inv(output_524288__arrayB__0, 262144*sizeof(int));
		cache_wbInv(multiplyTensors_10__implode___0, 131072*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_10__implode___0 
		sendEnd(); // Core1 > Core2: multiplyTensors_10__implode___0 
		multiply(512/*rowsA*/,512/*columnsA*/,2/*depthA*/,512/*rowsB*/,512/*columnsB*/,2/*depthB*/,arrayA_262144__arrayA__0,output_0__arrayB__0,arrayC__arrayC_262144__0); // multiplyTensors_8
		cache_inv(arrayA_262144__arrayA__0, 32768*sizeof(int));
		cache_inv(output_0__arrayB__0, 262144*sizeof(int));
		cache_wbInv(multiplyTensors_8__implode_d__0, 131072*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_8__implode_d__0 
		sendEnd(); // Core1 > Core2: multiplyTensors_8__implode_d__0 
	}
}
