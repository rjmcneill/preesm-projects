/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Thu Apr 02 22:24:30 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__59;  // explode_generateTensors_arrayA > multiplyTensors_126 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__132;  // explode_generateTensors_arrayA > multiplyTensors_120 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__141;  // explode_generateTensors_arrayA > multiplyTensors_113 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__91;  // explode_generateTensors_arrayA > multiplyTensors_100 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayA > multiplyTensors_95 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__121;  // explode_generateTensors_arrayA > multiplyTensors_93 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__115;  // explode_generateTensors_arrayA > multiplyTensors_89 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__117;  // explode_generateTensors_arrayA > multiplyTensors_82 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__46;  // explode_generateTensors_arrayA > multiplyTensors_79 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__80;  // explode_generateTensors_arrayA > multiplyTensors_62 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__73;  // explode_generateTensors_arrayA > multiplyTensors_58 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__136;  // explode_generateTensors_arrayA > multiplyTensors_50 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__72;  // explode_generateTensors_arrayA > multiplyTensors_49 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayA > multiplyTensors_30 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__120;  // explode_generateTensors_arrayA > multiplyTensors_22 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__36;  // explode_generateTensors_arrayA > multiplyTensors_14 size:= 2048*char defined in Core0
extern char *const explode_generateTensors_arra__83;  // explode_generateTensors_arrayB > broadcastTensorB_12 size:= 16384*char defined in Core0
extern char *const explode_generateTensors_arra__94;  // explode_generateTensors_arrayB > broadcastTensorB_2 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_1__multiply__5;  // broadcastTensorB_1 > multiplyTensors_14 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_10__multipl__4;  // broadcastTensorB_10 > multiplyTensors_82 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_11__multipl__4;  // broadcastTensorB_11 > multiplyTensors_95 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_11__multipl__0;  // broadcastTensorB_11 > multiplyTensors_93 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_11__multipl__6;  // broadcastTensorB_11 > multiplyTensors_89 size:= 16384*char defined in Core0
extern int *const output_0__arrayB__11;  // broadcastTensorB_12_output_0 > multiplyTensors_96_arrayB size:= 4096*int defined in Core0
extern int *const output_4096__arrayB__12;  // broadcastTensorB_12_output_4096 > multiplyTensors_97_arrayB size:= 4096*int defined in Core0
extern int *const output_8192__arrayB__6;  // broadcastTensorB_12_output_8192 > multiplyTensors_98_arrayB size:= 4096*int defined in Core0
extern int *const output_12288__arrayB__9;  // broadcastTensorB_12_output_12288 > multiplyTensors_99_arrayB size:= 4096*int defined in Core0
extern int *const output_16384__arrayB__10;  // broadcastTensorB_12_output_16384 > multiplyTensors_100_arrayB size:= 4096*int defined in Core0
extern int *const output_20480__arrayB__2;  // broadcastTensorB_12_output_20480 > multiplyTensors_101_arrayB size:= 4096*int defined in Core0
extern int *const output_24576__arrayB__9;  // broadcastTensorB_12_output_24576 > multiplyTensors_102_arrayB size:= 4096*int defined in Core0
extern int *const output_28672__arrayB__1;  // broadcastTensorB_12_output_28672 > multiplyTensors_103_arrayB size:= 4096*int defined in Core0
extern int *const arrayB_49152__input__0;  // explode_generateTensors_arrayB_arrayB_49152 > broadcastTensorB_12_input size:= 4096*int defined in Core0
extern char *const broadcastTensorB_12__multipl__0;  // broadcastTensorB_12 > multiplyTensors_103 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_12__multipl__3;  // broadcastTensorB_12 > multiplyTensors_102 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_12__multipl__1;  // broadcastTensorB_12 > multiplyTensors_101 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_12__multipl__4;  // broadcastTensorB_12 > multiplyTensors_99 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_12__multipl__2;  // broadcastTensorB_12 > multiplyTensors_98 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_12__multipl__6;  // broadcastTensorB_12 > multiplyTensors_97 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_12__multipl__7;  // broadcastTensorB_12 > multiplyTensors_96 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_14__multipl__1;  // broadcastTensorB_14 > multiplyTensors_113 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_15__multipl__4;  // broadcastTensorB_15 > multiplyTensors_126 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_15__multipl__3;  // broadcastTensorB_15 > multiplyTensors_120 size:= 16384*char defined in Core0
extern int *const output_0__arrayB__4;  // broadcastTensorB_2_output_0 > multiplyTensors_16_arrayB size:= 4096*int defined in Core0
extern int *const output_4096__arrayB__3;  // broadcastTensorB_2_output_4096 > multiplyTensors_17_arrayB size:= 4096*int defined in Core0
extern int *const output_8192__arrayB__11;  // broadcastTensorB_2_output_8192 > multiplyTensors_18_arrayB size:= 4096*int defined in Core0
extern int *const output_12288__arrayB__5;  // broadcastTensorB_2_output_12288 > multiplyTensors_19_arrayB size:= 4096*int defined in Core0
extern int *const output_16384__arrayB__8;  // broadcastTensorB_2_output_16384 > multiplyTensors_20_arrayB size:= 4096*int defined in Core0
extern int *const output_20480__arrayB__7;  // broadcastTensorB_2_output_20480 > multiplyTensors_21_arrayB size:= 4096*int defined in Core0
extern int *const output_24576__arrayB__6;  // broadcastTensorB_2_output_24576 > multiplyTensors_22_arrayB size:= 4096*int defined in Core0
extern int *const output_28672__arrayB__11;  // broadcastTensorB_2_output_28672 > multiplyTensors_23_arrayB size:= 4096*int defined in Core0
extern int *const arrayB_8192__input__0;  // explode_generateTensors_arrayB_arrayB_8192 > broadcastTensorB_2_input size:= 4096*int defined in Core0
extern char *const broadcastTensorB_2__multiply__6;  // broadcastTensorB_2 > multiplyTensors_23 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_2__multiply__2;  // broadcastTensorB_2 > multiplyTensors_21 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_2__multiply__7;  // broadcastTensorB_2 > multiplyTensors_20 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_2__multiply__3;  // broadcastTensorB_2 > multiplyTensors_19 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_2__multiply__5;  // broadcastTensorB_2 > multiplyTensors_18 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_2__multiply__0;  // broadcastTensorB_2 > multiplyTensors_17 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_2__multiply__1;  // broadcastTensorB_2 > multiplyTensors_16 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_3__multiply__1;  // broadcastTensorB_3 > multiplyTensors_30 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_6__multiply__5;  // broadcastTensorB_6 > multiplyTensors_50 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_6__multiply__7;  // broadcastTensorB_6 > multiplyTensors_49 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_7__multiply__5;  // broadcastTensorB_7 > multiplyTensors_62 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_7__multiply__1;  // broadcastTensorB_7 > multiplyTensors_58 size:= 16384*char defined in Core0
extern char *const broadcastTensorB_9__multiply__1;  // broadcastTensorB_9 > multiplyTensors_79 size:= 16384*char defined in Core0
extern int *const arrayA_51200__arrayA__0;  // explode_generateTensors_arrayA_arrayA_51200 > multiplyTensors_100_arrayA size:= 512*int defined in Core0
extern long *const arrayC__arrayC_51200__0;  // multiplyTensors_100_arrayC > implode_displayTensor_arrayC_arrayC_51200 size:= 512*long defined in Core0
extern char *const multiplyTensors_100__implode__0;  // multiplyTensors_100 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_57856__arrayA__0;  // explode_generateTensors_arrayA_arrayA_57856 > multiplyTensors_113_arrayA size:= 512*int defined in Core0
extern int *const output_4096__arrayB__0;  // broadcastTensorB_14_output_4096 > multiplyTensors_113_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_57856__0;  // multiplyTensors_113_arrayC > implode_displayTensor_arrayC_arrayC_57856 size:= 512*long defined in Core0
extern char *const multiplyTensors_113__implode__0;  // multiplyTensors_113 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_61440__arrayA__0;  // explode_generateTensors_arrayA_arrayA_61440 > multiplyTensors_120_arrayA size:= 512*int defined in Core0
extern int *const output_0__arrayB__6;  // broadcastTensorB_15_output_0 > multiplyTensors_120_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_61440__0;  // multiplyTensors_120_arrayC > implode_displayTensor_arrayC_arrayC_61440 size:= 512*long defined in Core0
extern char *const multiplyTensors_120__implode__0;  // multiplyTensors_120 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_64512__arrayA__0;  // explode_generateTensors_arrayA_arrayA_64512 > multiplyTensors_126_arrayA size:= 512*int defined in Core0
extern int *const output_24576__arrayB__7;  // broadcastTensorB_15_output_24576 > multiplyTensors_126_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_64512__0;  // multiplyTensors_126_arrayC > implode_displayTensor_arrayC_arrayC_64512 size:= 512*long defined in Core0
extern char *const multiplyTensors_126__implode__0;  // multiplyTensors_126 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_7168__arrayA__0;  // explode_generateTensors_arrayA_arrayA_7168 > multiplyTensors_14_arrayA size:= 512*int defined in Core0
extern int *const output_24576__arrayB__10;  // broadcastTensorB_1_output_24576 > multiplyTensors_14_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_7168__0;  // multiplyTensors_14_arrayC > implode_displayTensor_arrayC_arrayC_7168 size:= 512*long defined in Core0
extern char *const multiplyTensors_14__implode___0;  // multiplyTensors_14 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_11264__arrayA__0;  // explode_generateTensors_arrayA_arrayA_11264 > multiplyTensors_22_arrayA size:= 512*int defined in Core0
extern long *const arrayC__arrayC_11264__0;  // multiplyTensors_22_arrayC > implode_displayTensor_arrayC_arrayC_11264 size:= 512*long defined in Core0
extern char *const multiplyTensors_22__implode___0;  // multiplyTensors_22 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_15360__arrayA__0;  // explode_generateTensors_arrayA_arrayA_15360 > multiplyTensors_30_arrayA size:= 512*int defined in Core0
extern int *const output_24576__arrayB__3;  // broadcastTensorB_3_output_24576 > multiplyTensors_30_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_15360__0;  // multiplyTensors_30_arrayC > implode_displayTensor_arrayC_arrayC_15360 size:= 512*long defined in Core0
extern char *const multiplyTensors_30__implode___0;  // multiplyTensors_30 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_25088__arrayA__0;  // explode_generateTensors_arrayA_arrayA_25088 > multiplyTensors_49_arrayA size:= 512*int defined in Core0
extern int *const output_4096__arrayB__15;  // broadcastTensorB_6_output_4096 > multiplyTensors_49_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_25088__0;  // multiplyTensors_49_arrayC > implode_displayTensor_arrayC_arrayC_25088 size:= 512*long defined in Core0
extern char *const multiplyTensors_49__implode___0;  // multiplyTensors_49 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_25600__arrayA__0;  // explode_generateTensors_arrayA_arrayA_25600 > multiplyTensors_50_arrayA size:= 512*int defined in Core0
extern int *const output_8192__arrayB__12;  // broadcastTensorB_6_output_8192 > multiplyTensors_50_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_25600__0;  // multiplyTensors_50_arrayC > implode_displayTensor_arrayC_arrayC_25600 size:= 512*long defined in Core0
extern char *const multiplyTensors_50__implode___0;  // multiplyTensors_50 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_29696__arrayA__0;  // explode_generateTensors_arrayA_arrayA_29696 > multiplyTensors_58_arrayA size:= 512*int defined in Core0
extern int *const output_8192__arrayB__3;  // broadcastTensorB_7_output_8192 > multiplyTensors_58_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_29696__0;  // multiplyTensors_58_arrayC > implode_displayTensor_arrayC_arrayC_29696 size:= 512*long defined in Core0
extern char *const multiplyTensors_58__implode___0;  // multiplyTensors_58 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_31744__arrayA__0;  // explode_generateTensors_arrayA_arrayA_31744 > multiplyTensors_62_arrayA size:= 512*int defined in Core0
extern int *const output_24576__arrayB__5;  // broadcastTensorB_7_output_24576 > multiplyTensors_62_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_31744__0;  // multiplyTensors_62_arrayC > implode_displayTensor_arrayC_arrayC_31744 size:= 512*long defined in Core0
extern char *const multiplyTensors_62__implode___0;  // multiplyTensors_62 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_40448__arrayA__0;  // explode_generateTensors_arrayA_arrayA_40448 > multiplyTensors_79_arrayA size:= 512*int defined in Core0
extern int *const output_28672__arrayB__4;  // broadcastTensorB_9_output_28672 > multiplyTensors_79_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_40448__0;  // multiplyTensors_79_arrayC > implode_displayTensor_arrayC_arrayC_40448 size:= 512*long defined in Core0
extern char *const multiplyTensors_79__implode___0;  // multiplyTensors_79 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_41984__arrayA__0;  // explode_generateTensors_arrayA_arrayA_41984 > multiplyTensors_82_arrayA size:= 512*int defined in Core0
extern int *const output_8192__arrayB__9;  // broadcastTensorB_10_output_8192 > multiplyTensors_82_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_41984__0;  // multiplyTensors_82_arrayC > implode_displayTensor_arrayC_arrayC_41984 size:= 512*long defined in Core0
extern char *const multiplyTensors_82__implode___0;  // multiplyTensors_82 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_45568__arrayA__0;  // explode_generateTensors_arrayA_arrayA_45568 > multiplyTensors_89_arrayA size:= 512*int defined in Core0
extern int *const output_4096__arrayB__7;  // broadcastTensorB_11_output_4096 > multiplyTensors_89_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_45568__0;  // multiplyTensors_89_arrayC > implode_displayTensor_arrayC_arrayC_45568 size:= 512*long defined in Core0
extern char *const multiplyTensors_89__implode___0;  // multiplyTensors_89 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_47616__arrayA__0;  // explode_generateTensors_arrayA_arrayA_47616 > multiplyTensors_93_arrayA size:= 512*int defined in Core0
extern int *const output_20480__arrayB__0;  // broadcastTensorB_11_output_20480 > multiplyTensors_93_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_47616__0;  // multiplyTensors_93_arrayC > implode_displayTensor_arrayC_arrayC_47616 size:= 512*long defined in Core0
extern char *const multiplyTensors_93__implode___0;  // multiplyTensors_93 > implode_displayTensor_arrayC size:= 2048*char defined in Core0
extern int *const arrayA_48640__arrayA__0;  // explode_generateTensors_arrayA_arrayA_48640 > multiplyTensors_95_arrayA size:= 512*int defined in Core0
extern int *const output_28672__arrayB__5;  // broadcastTensorB_11_output_28672 > multiplyTensors_95_arrayB size:= 4096*int defined in Core0
extern long *const arrayC__arrayC_48640__0;  // multiplyTensors_95_arrayC > implode_displayTensor_arrayC_arrayC_48640 size:= 512*long defined in Core0
extern char *const multiplyTensors_95__implode___0;  // multiplyTensors_95 > implode_displayTensor_arrayC size:= 2048*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__59 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__59 
		cache_inv(explode_generateTensors_arra__59, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__132 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__132 
		cache_inv(explode_generateTensors_arra__132, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__141 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__141 
		cache_inv(explode_generateTensors_arra__141, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__91 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__91 
		cache_inv(explode_generateTensors_arra__91, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__13 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__121 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__121 
		cache_inv(explode_generateTensors_arra__121, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__115 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__115 
		cache_inv(explode_generateTensors_arra__115, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__117 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__117 
		cache_inv(explode_generateTensors_arra__117, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__46 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__46 
		cache_inv(explode_generateTensors_arra__46, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__80 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__80 
		cache_inv(explode_generateTensors_arra__80, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__73 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__73 
		cache_inv(explode_generateTensors_arra__73, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__136 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__136 
		cache_inv(explode_generateTensors_arra__136, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__72 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__72 
		cache_inv(explode_generateTensors_arra__72, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__12 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__120 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__120 
		cache_inv(explode_generateTensors_arra__120, 2048*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__36 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__36 
		cache_inv(explode_generateTensors_arra__36, 2048*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__83 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__83 
		cache_inv(explode_generateTensors_arra__83, 16384*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__94 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__94 
		cache_inv(explode_generateTensors_arra__94, 16384*sizeof(char));
		receiveStart(); // Core1 > Core2: broadcastTensorB_1__multiply__5 
		receiveEnd(1); // Core1 > Core2: broadcastTensorB_1__multiply__5 
		cache_inv(broadcastTensorB_1__multiply__5, 16384*sizeof(char));
		receiveStart(); // Core7 > Core2: broadcastTensorB_10__multipl__4 
		receiveEnd(7); // Core7 > Core2: broadcastTensorB_10__multipl__4 
		cache_inv(broadcastTensorB_10__multipl__4, 16384*sizeof(char));
		receiveStart(); // Core3 > Core2: broadcastTensorB_11__multipl__4 
		receiveEnd(3); // Core3 > Core2: broadcastTensorB_11__multipl__4 
		cache_inv(broadcastTensorB_11__multipl__4, 16384*sizeof(char));
		receiveStart(); // Core3 > Core2: broadcastTensorB_11__multipl__0 
		receiveEnd(3); // Core3 > Core2: broadcastTensorB_11__multipl__0 
		cache_inv(broadcastTensorB_11__multipl__0, 16384*sizeof(char));
		receiveStart(); // Core3 > Core2: broadcastTensorB_11__multipl__6 
		receiveEnd(3); // Core3 > Core2: broadcastTensorB_11__multipl__6 
		cache_inv(broadcastTensorB_11__multipl__6, 16384*sizeof(char));
		// Broadcast broadcastTensorB_12
		{
			cache_wb(arrayB_49152__input__0, 4096*sizeof(int));
		}
		cache_wb(((char*)arrayB_49152__input__0) + 0, 16384);
		cache_inv(arrayB_49152__input__0, 4096*sizeof(int));
		cache_wbInv(broadcastTensorB_12__multipl__0, 16384*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_12__multipl__0 
		sendEnd(); // Core2 > Core7: broadcastTensorB_12__multipl__0 
		cache_wbInv(broadcastTensorB_12__multipl__3, 16384*sizeof(char));
		sendStart(0); // Core2 > Core0: broadcastTensorB_12__multipl__3 
		sendEnd(); // Core2 > Core0: broadcastTensorB_12__multipl__3 
		cache_wbInv(broadcastTensorB_12__multipl__1, 16384*sizeof(char));
		sendStart(4); // Core2 > Core4: broadcastTensorB_12__multipl__1 
		sendEnd(); // Core2 > Core4: broadcastTensorB_12__multipl__1 
		cache_wbInv(broadcastTensorB_12__multipl__4, 16384*sizeof(char));
		sendStart(0); // Core2 > Core0: broadcastTensorB_12__multipl__4 
		sendEnd(); // Core2 > Core0: broadcastTensorB_12__multipl__4 
		cache_wbInv(broadcastTensorB_12__multipl__2, 16384*sizeof(char));
		sendStart(3); // Core2 > Core3: broadcastTensorB_12__multipl__2 
		sendEnd(); // Core2 > Core3: broadcastTensorB_12__multipl__2 
		cache_wbInv(broadcastTensorB_12__multipl__6, 16384*sizeof(char));
		sendStart(4); // Core2 > Core4: broadcastTensorB_12__multipl__6 
		sendEnd(); // Core2 > Core4: broadcastTensorB_12__multipl__6 
		cache_wbInv(broadcastTensorB_12__multipl__7, 16384*sizeof(char));
		sendStart(4); // Core2 > Core4: broadcastTensorB_12__multipl__7 
		sendEnd(); // Core2 > Core4: broadcastTensorB_12__multipl__7 
		receiveStart(); // Core6 > Core2: broadcastTensorB_14__multipl__1 
		receiveEnd(6); // Core6 > Core2: broadcastTensorB_14__multipl__1 
		cache_inv(broadcastTensorB_14__multipl__1, 16384*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_15__multipl__4 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_15__multipl__4 
		cache_inv(broadcastTensorB_15__multipl__4, 16384*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_15__multipl__3 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_15__multipl__3 
		cache_inv(broadcastTensorB_15__multipl__3, 16384*sizeof(char));
		// Broadcast broadcastTensorB_2
		{
			cache_wb(arrayB_8192__input__0, 4096*sizeof(int));
		}
		cache_wb(((char*)arrayB_8192__input__0) + 0, 16384);
		cache_inv(arrayB_8192__input__0, 4096*sizeof(int));
		cache_wbInv(broadcastTensorB_2__multiply__6, 16384*sizeof(char));
		sendStart(1); // Core2 > Core1: broadcastTensorB_2__multiply__6 
		sendEnd(); // Core2 > Core1: broadcastTensorB_2__multiply__6 
		cache_wbInv(broadcastTensorB_2__multiply__2, 16384*sizeof(char));
		sendStart(1); // Core2 > Core1: broadcastTensorB_2__multiply__2 
		sendEnd(); // Core2 > Core1: broadcastTensorB_2__multiply__2 
		cache_wbInv(broadcastTensorB_2__multiply__7, 16384*sizeof(char));
		sendStart(7); // Core2 > Core7: broadcastTensorB_2__multiply__7 
		sendEnd(); // Core2 > Core7: broadcastTensorB_2__multiply__7 
		cache_wbInv(broadcastTensorB_2__multiply__3, 16384*sizeof(char));
		sendStart(6); // Core2 > Core6: broadcastTensorB_2__multiply__3 
		sendEnd(); // Core2 > Core6: broadcastTensorB_2__multiply__3 
		cache_wbInv(broadcastTensorB_2__multiply__5, 16384*sizeof(char));
		sendStart(1); // Core2 > Core1: broadcastTensorB_2__multiply__5 
		sendEnd(); // Core2 > Core1: broadcastTensorB_2__multiply__5 
		cache_wbInv(broadcastTensorB_2__multiply__0, 16384*sizeof(char));
		sendStart(6); // Core2 > Core6: broadcastTensorB_2__multiply__0 
		sendEnd(); // Core2 > Core6: broadcastTensorB_2__multiply__0 
		cache_wbInv(broadcastTensorB_2__multiply__1, 16384*sizeof(char));
		sendStart(6); // Core2 > Core6: broadcastTensorB_2__multiply__1 
		sendEnd(); // Core2 > Core6: broadcastTensorB_2__multiply__1 
		receiveStart(); // Core0 > Core2: broadcastTensorB_3__multiply__1 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_3__multiply__1 
		cache_inv(broadcastTensorB_3__multiply__1, 16384*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_6__multiply__5 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_6__multiply__5 
		cache_inv(broadcastTensorB_6__multiply__5, 16384*sizeof(char));
		receiveStart(); // Core5 > Core2: broadcastTensorB_6__multiply__7 
		receiveEnd(5); // Core5 > Core2: broadcastTensorB_6__multiply__7 
		cache_inv(broadcastTensorB_6__multiply__7, 16384*sizeof(char));
		receiveStart(); // Core4 > Core2: broadcastTensorB_7__multiply__5 
		receiveEnd(4); // Core4 > Core2: broadcastTensorB_7__multiply__5 
		cache_inv(broadcastTensorB_7__multiply__5, 16384*sizeof(char));
		receiveStart(); // Core4 > Core2: broadcastTensorB_7__multiply__1 
		receiveEnd(4); // Core4 > Core2: broadcastTensorB_7__multiply__1 
		cache_inv(broadcastTensorB_7__multiply__1, 16384*sizeof(char));
		receiveStart(); // Core0 > Core2: broadcastTensorB_9__multiply__1 
		receiveEnd(0); // Core0 > Core2: broadcastTensorB_9__multiply__1 
		cache_inv(broadcastTensorB_9__multiply__1, 16384*sizeof(char));
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_51200__arrayA__0,output_16384__arrayB__10,arrayC__arrayC_51200__0); // multiplyTensors_100
		cache_inv(arrayA_51200__arrayA__0, 512*sizeof(int));
		cache_inv(output_16384__arrayB__10, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_100__implode__0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_100__implode__0 
		sendEnd(); // Core2 > Core5: multiplyTensors_100__implode__0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_57856__arrayA__0,output_4096__arrayB__0,arrayC__arrayC_57856__0); // multiplyTensors_113
		cache_inv(arrayA_57856__arrayA__0, 512*sizeof(int));
		cache_inv(output_4096__arrayB__0, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_113__implode__0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_113__implode__0 
		sendEnd(); // Core2 > Core5: multiplyTensors_113__implode__0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_61440__arrayA__0,output_0__arrayB__6,arrayC__arrayC_61440__0); // multiplyTensors_120
		cache_inv(arrayA_61440__arrayA__0, 512*sizeof(int));
		cache_inv(output_0__arrayB__6, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_120__implode__0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_120__implode__0 
		sendEnd(); // Core2 > Core5: multiplyTensors_120__implode__0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_64512__arrayA__0,output_24576__arrayB__7,arrayC__arrayC_64512__0); // multiplyTensors_126
		cache_inv(arrayA_64512__arrayA__0, 512*sizeof(int));
		cache_inv(output_24576__arrayB__7, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_126__implode__0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_126__implode__0 
		sendEnd(); // Core2 > Core5: multiplyTensors_126__implode__0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_7168__arrayA__0,output_24576__arrayB__10,arrayC__arrayC_7168__0); // multiplyTensors_14
		cache_inv(arrayA_7168__arrayA__0, 512*sizeof(int));
		cache_inv(output_24576__arrayB__10, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_14__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_14__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_14__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_11264__arrayA__0,output_24576__arrayB__6,arrayC__arrayC_11264__0); // multiplyTensors_22
		cache_inv(arrayA_11264__arrayA__0, 512*sizeof(int));
		cache_inv(output_24576__arrayB__6, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_22__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_22__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_22__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_15360__arrayA__0,output_24576__arrayB__3,arrayC__arrayC_15360__0); // multiplyTensors_30
		cache_inv(arrayA_15360__arrayA__0, 512*sizeof(int));
		cache_inv(output_24576__arrayB__3, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_30__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_30__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_30__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_25088__arrayA__0,output_4096__arrayB__15,arrayC__arrayC_25088__0); // multiplyTensors_49
		cache_inv(arrayA_25088__arrayA__0, 512*sizeof(int));
		cache_inv(output_4096__arrayB__15, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_49__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_49__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_49__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_25600__arrayA__0,output_8192__arrayB__12,arrayC__arrayC_25600__0); // multiplyTensors_50
		cache_inv(arrayA_25600__arrayA__0, 512*sizeof(int));
		cache_inv(output_8192__arrayB__12, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_50__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_50__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_50__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_29696__arrayA__0,output_8192__arrayB__3,arrayC__arrayC_29696__0); // multiplyTensors_58
		cache_inv(arrayA_29696__arrayA__0, 512*sizeof(int));
		cache_inv(output_8192__arrayB__3, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_58__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_58__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_58__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_31744__arrayA__0,output_24576__arrayB__5,arrayC__arrayC_31744__0); // multiplyTensors_62
		cache_inv(arrayA_31744__arrayA__0, 512*sizeof(int));
		cache_inv(output_24576__arrayB__5, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_62__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_62__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_62__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_40448__arrayA__0,output_28672__arrayB__4,arrayC__arrayC_40448__0); // multiplyTensors_79
		cache_inv(arrayA_40448__arrayA__0, 512*sizeof(int));
		cache_inv(output_28672__arrayB__4, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_79__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_79__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_79__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_41984__arrayA__0,output_8192__arrayB__9,arrayC__arrayC_41984__0); // multiplyTensors_82
		cache_inv(arrayA_41984__arrayA__0, 512*sizeof(int));
		cache_inv(output_8192__arrayB__9, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_82__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_82__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_82__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_45568__arrayA__0,output_4096__arrayB__7,arrayC__arrayC_45568__0); // multiplyTensors_89
		cache_inv(arrayA_45568__arrayA__0, 512*sizeof(int));
		cache_inv(output_4096__arrayB__7, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_89__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_89__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_89__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_47616__arrayA__0,output_20480__arrayB__0,arrayC__arrayC_47616__0); // multiplyTensors_93
		cache_inv(arrayA_47616__arrayA__0, 512*sizeof(int));
		cache_inv(output_20480__arrayB__0, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_93__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_93__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_93__implode___0 
		multiply(64/*rowsA*/,64/*columnsA*/,16/*depthA*/,64/*rowsB*/,64/*columnsB*/,16/*depthB*/,arrayA_48640__arrayA__0,output_28672__arrayB__5,arrayC__arrayC_48640__0); // multiplyTensors_95
		cache_inv(arrayA_48640__arrayA__0, 512*sizeof(int));
		cache_inv(output_28672__arrayB__5, 4096*sizeof(int));
		cache_wbInv(multiplyTensors_95__implode___0, 2048*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_95__implode___0 
		sendEnd(); // Core2 > Core5: multiplyTensors_95__implode___0 
	}
}
