/** 
 * @file Core6.c
 * @generated by C6678CPrinter
 * @date Fri Apr 17 16:12:31 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__25;  // explode_generateTensors_arrayA > transposeTensor_14 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__123;  // explode_generateTensors_arrayA > transposeTensor_2 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__9;  // explode_generateTensors_arrayB > multiplyTensors_119 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__110;  // explode_generateTensors_arrayB > multiplyTensors_112 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__119;  // explode_generateTensors_arrayB > multiplyTensors_101 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__27;  // explode_generateTensors_arrayB > multiplyTensors_100 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__75;  // explode_generateTensors_arrayB > multiplyTensors_81 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__120;  // explode_generateTensors_arrayB > multiplyTensors_64 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayB > multiplyTensors_50 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__91;  // explode_generateTensors_arrayB > multiplyTensors_40 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__32;  // explode_generateTensors_arrayB > multiplyTensors_36 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__69;  // explode_generateTensors_arrayB > multiplyTensors_26 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__58;  // explode_generateTensors_arrayB > multiplyTensors_23 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__52;  // explode_generateTensors_arrayB > multiplyTensors_22 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__117;  // explode_generateTensors_arrayB > multiplyTensors_21 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__3;  // explode_generateTensors_arrayB > multiplyTensors_20 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__64;  // explode_generateTensors_arrayB > multiplyTensors_17 size:= 32*char defined in Core0
extern char *const transposeTensor_12__explode___0;  // transposeTensor_12 > explode_transposeTensor_12_output size:= 256*char defined in Core0
extern int *const arrayA_896__input__0;  // explode_generateTensors_arrayA_arrayA_896 > transposeTensor_14_input size:= 64*int defined in Core0
extern int *const output__arrayA__14;  // transposeTensor_14_output > explode_transposeTensor_14_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_14__explode___0;  // transposeTensor_14 > explode_transposeTensor_14_output size:= 256*char defined in Core0
extern int *const arrayA_128__input__0;  // explode_generateTensors_arrayA_arrayA_128 > transposeTensor_2_input size:= 64*int defined in Core0
extern int *const output__arrayA__10;  // transposeTensor_2_output > explode_transposeTensor_2_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_10_o__1;  // explode_transposeTensor_10_output > multiplyTensors_81 size:= 32*char defined in Core0
extern int *const output_0__arrayA__7;  // explode_transposeTensor_12_output_output_0 > multiplyTensors_96_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__8;  // explode_transposeTensor_12_output_output_8 > multiplyTensors_97_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__13;  // explode_transposeTensor_12_output_output_16 > multiplyTensors_98_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__5;  // explode_transposeTensor_12_output_output_24 > multiplyTensors_99_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__9;  // explode_transposeTensor_12_output_output_32 > multiplyTensors_100_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__9;  // explode_transposeTensor_12_output_output_40 > multiplyTensors_101_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__6;  // explode_transposeTensor_12_output_output_48 > multiplyTensors_102_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__12;  // explode_transposeTensor_12_output_output_56 > multiplyTensors_103_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__12;  // transposeTensor_12_output > explode_transposeTensor_12_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_12_o__6;  // explode_transposeTensor_12_output > multiplyTensors_103 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__0;  // explode_transposeTensor_12_output > multiplyTensors_102 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__1;  // explode_transposeTensor_12_output > multiplyTensors_99 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__7;  // explode_transposeTensor_12_output > multiplyTensors_98 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__3;  // explode_transposeTensor_12_output > multiplyTensors_97 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__4;  // explode_transposeTensor_12_output > multiplyTensors_96 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__3;  // explode_transposeTensor_14_output > multiplyTensors_119 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__7;  // explode_transposeTensor_14_output > multiplyTensors_112 size:= 32*char defined in Core0
extern int *const output_0__arrayA__14;  // explode_transposeTensor_2_output_output_0 > multiplyTensors_16_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__1;  // explode_transposeTensor_2_output_output_8 > multiplyTensors_17_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__9;  // explode_transposeTensor_2_output_output_16 > multiplyTensors_18_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__10;  // explode_transposeTensor_2_output_output_24 > multiplyTensors_19_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__12;  // explode_transposeTensor_2_output_output_32 > multiplyTensors_20_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__10;  // explode_transposeTensor_2_output_output_40 > multiplyTensors_21_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__11;  // explode_transposeTensor_2_output_output_48 > multiplyTensors_22_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__1;  // explode_transposeTensor_2_output_output_56 > multiplyTensors_23_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_2_ou__4;  // explode_transposeTensor_2_output > multiplyTensors_19 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__2;  // explode_transposeTensor_2_output > multiplyTensors_18 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__7;  // explode_transposeTensor_2_output > multiplyTensors_16 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__0;  // explode_transposeTensor_3_output > multiplyTensors_26 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__6;  // explode_transposeTensor_4_output > multiplyTensors_36 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__0;  // explode_transposeTensor_5_output > multiplyTensors_40 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_6_ou__0;  // explode_transposeTensor_6_output > multiplyTensors_50 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_8_ou__4;  // explode_transposeTensor_8_output > multiplyTensors_64 size:= 32*char defined in Core0
extern int *const arrayB_800__arrayB__0;  // explode_generateTensors_arrayB_arrayB_800 > multiplyTensors_100_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__10;  // multiplyTensors_100_arrayC > implode_sumResults_12_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_100__implode__0;  // multiplyTensors_100 > implode_sumResults_12_input size:= 256*char defined in Core0
extern int *const arrayB_808__arrayB__0;  // explode_generateTensors_arrayB_arrayB_808 > multiplyTensors_101_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__6;  // multiplyTensors_101_arrayC > implode_sumResults_12_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_101__implode__0;  // multiplyTensors_101 > implode_sumResults_12_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__11;  // explode_transposeTensor_14_output_output_0 > multiplyTensors_112_arrayA size:= 8*int defined in Core0
extern int *const arrayB_896__arrayB__0;  // explode_generateTensors_arrayB_arrayB_896 > multiplyTensors_112_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__14;  // multiplyTensors_112_arrayC > implode_sumResults_14_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_113__implode__0;  // multiplyTensors_113 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_114__implode__0;  // multiplyTensors_114 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_115__implode__0;  // multiplyTensors_115 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_116__implode__0;  // multiplyTensors_116 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_117__implode__0;  // multiplyTensors_117 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_118__implode__0;  // multiplyTensors_118 > implode_sumResults_14_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__0;  // explode_transposeTensor_14_output_output_56 > multiplyTensors_119_arrayA size:= 8*int defined in Core0
extern int *const arrayB_952__arrayB__0;  // explode_generateTensors_arrayB_arrayB_952 > multiplyTensors_119_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__7;  // multiplyTensors_119_arrayC > implode_sumResults_14_input_input_448 size:= 64*long defined in Core0
extern int *const arrayB_136__arrayB__0;  // explode_generateTensors_arrayB_arrayB_136 > multiplyTensors_17_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__13;  // multiplyTensors_17_arrayC > implode_sumResults_2_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_17__implode___0;  // multiplyTensors_17 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const arrayB_160__arrayB__0;  // explode_generateTensors_arrayB_arrayB_160 > multiplyTensors_20_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__1;  // multiplyTensors_20_arrayC > implode_sumResults_2_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_20__implode___0;  // multiplyTensors_20 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const arrayB_168__arrayB__0;  // explode_generateTensors_arrayB_arrayB_168 > multiplyTensors_21_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__13;  // multiplyTensors_21_arrayC > implode_sumResults_2_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_21__implode___0;  // multiplyTensors_21 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const arrayB_176__arrayB__0;  // explode_generateTensors_arrayB_arrayB_176 > multiplyTensors_22_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__15;  // multiplyTensors_22_arrayC > implode_sumResults_2_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_22__implode___0;  // multiplyTensors_22 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const arrayB_184__arrayB__0;  // explode_generateTensors_arrayB_arrayB_184 > multiplyTensors_23_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__5;  // multiplyTensors_23_arrayC > implode_sumResults_2_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_23__implode___0;  // multiplyTensors_23 > implode_sumResults_2_input size:= 256*char defined in Core0
extern char *const multiplyTensors_24__implode___0;  // multiplyTensors_24 > implode_sumResults_3_input size:= 256*char defined in Core0
extern char *const multiplyTensors_25__implode___0;  // multiplyTensors_25 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__1;  // explode_transposeTensor_3_output_output_16 > multiplyTensors_26_arrayA size:= 8*int defined in Core0
extern int *const arrayB_208__arrayB__0;  // explode_generateTensors_arrayB_arrayB_208 > multiplyTensors_26_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__4;  // multiplyTensors_26_arrayC > implode_sumResults_3_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_27__implode___0;  // multiplyTensors_27 > implode_sumResults_3_input size:= 256*char defined in Core0
extern char *const multiplyTensors_28__implode___0;  // multiplyTensors_28 > implode_sumResults_3_input size:= 256*char defined in Core0
extern char *const multiplyTensors_29__implode___0;  // multiplyTensors_29 > implode_sumResults_3_input size:= 256*char defined in Core0
extern char *const multiplyTensors_30__implode___0;  // multiplyTensors_30 > implode_sumResults_3_input size:= 256*char defined in Core0
extern char *const multiplyTensors_31__implode___0;  // multiplyTensors_31 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__6;  // explode_transposeTensor_4_output_output_32 > multiplyTensors_36_arrayA size:= 8*int defined in Core0
extern int *const arrayB_288__arrayB__0;  // explode_generateTensors_arrayB_arrayB_288 > multiplyTensors_36_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__12;  // multiplyTensors_36_arrayC > implode_sumResults_4_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_36__implode___0;  // multiplyTensors_36 > implode_sumResults_4_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__2;  // explode_transposeTensor_5_output_output_0 > multiplyTensors_40_arrayA size:= 8*int defined in Core0
extern int *const arrayB_320__arrayB__0;  // explode_generateTensors_arrayB_arrayB_320 > multiplyTensors_40_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__15;  // multiplyTensors_40_arrayC > implode_sumResults_5_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_40__implode___0;  // multiplyTensors_40 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__2;  // explode_transposeTensor_6_output_output_16 > multiplyTensors_50_arrayA size:= 8*int defined in Core0
extern int *const arrayB_400__arrayB__0;  // explode_generateTensors_arrayB_arrayB_400 > multiplyTensors_50_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__3;  // multiplyTensors_50_arrayC > implode_sumResults_6_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_50__implode___0;  // multiplyTensors_50 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__4;  // explode_transposeTensor_8_output_output_0 > multiplyTensors_64_arrayA size:= 8*int defined in Core0
extern int *const arrayB_512__arrayB__0;  // explode_generateTensors_arrayB_arrayB_512 > multiplyTensors_64_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__5;  // multiplyTensors_64_arrayC > implode_sumResults_8_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_64__implode___0;  // multiplyTensors_64 > implode_sumResults_8_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__6;  // explode_transposeTensor_10_output_output_8 > multiplyTensors_81_arrayA size:= 8*int defined in Core0
extern int *const arrayB_648__arrayB__0;  // explode_generateTensors_arrayB_arrayB_648 > multiplyTensors_81_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__5;  // multiplyTensors_81_arrayC > implode_sumResults_10_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_81__implode___0;  // multiplyTensors_81 > implode_sumResults_10_input size:= 256*char defined in Core0
extern long *const arrayC__input_64__10;  // multiplyTensors_113_arrayC > implode_sumResults_14_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__1;  // multiplyTensors_114_arrayC > implode_sumResults_14_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__15;  // multiplyTensors_115_arrayC > implode_sumResults_14_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__3;  // multiplyTensors_116_arrayC > implode_sumResults_14_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__10;  // multiplyTensors_117_arrayC > implode_sumResults_14_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__0;  // multiplyTensors_118_arrayC > implode_sumResults_14_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input__15;  // implode_sumResults_14_input_arrayC > sumResults_14_input size:= 512*long defined in Core0
extern char *const implode_sumResults_2_input____0;  // implode_sumResults_2_input > sumResults_2 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__13;  // multiplyTensors_24_arrayC > implode_sumResults_3_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__6;  // multiplyTensors_25_arrayC > implode_sumResults_3_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_192__1;  // multiplyTensors_27_arrayC > implode_sumResults_3_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__8;  // multiplyTensors_28_arrayC > implode_sumResults_3_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__1;  // multiplyTensors_29_arrayC > implode_sumResults_3_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__7;  // multiplyTensors_30_arrayC > implode_sumResults_3_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__1;  // multiplyTensors_31_arrayC > implode_sumResults_3_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__5;  // implode_sumResults_3_input_arrayC > sumResults_3_input size:= 512*long defined in Core0
extern char *const implode_sumResults_3_input____0;  // implode_sumResults_3_input > sumResults_3 size:= 2048*char defined in Core0
extern long *const output__arrayC_896__0;  // sumResults_14_output > implode_displayTensor_arrayC_arrayC_896 size:= 64*long defined in Core0
extern char *const sumResults_14__implode_displ__0;  // sumResults_14 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__10;  // implode_sumResults_2_input_arrayC > sumResults_2_input size:= 512*long defined in Core0
extern long *const output__arrayC_128__0;  // sumResults_2_output > implode_displayTensor_arrayC_arrayC_128 size:= 64*long defined in Core0
extern char *const sumResults_2__implode_displa__0;  // sumResults_2 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core6(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core6: explode_generateTensors_arra__25 
		receiveEnd(0); // Core0 > Core6: explode_generateTensors_arra__25 
		cache_inv(explode_generateTensors_arra__25, 256*sizeof(char));
		receiveStart(); // Core0 > Core6: explode_generateTensors_arra__123 
		receiveEnd(0); // Core0 > Core6: explode_generateTensors_arra__123 
		cache_inv(explode_generateTensors_arra__123, 256*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__9 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__9 
		cache_inv(explode_generateTensors_arra__9, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__110 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__110 
		cache_inv(explode_generateTensors_arra__110, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__119 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__119 
		cache_inv(explode_generateTensors_arra__119, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__27 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__27 
		cache_inv(explode_generateTensors_arra__27, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__75 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__75 
		cache_inv(explode_generateTensors_arra__75, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__120 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__120 
		cache_inv(explode_generateTensors_arra__120, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__6 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__91 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__91 
		cache_inv(explode_generateTensors_arra__91, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__32 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__32 
		cache_inv(explode_generateTensors_arra__32, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__69 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__69 
		cache_inv(explode_generateTensors_arra__69, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__58 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__58 
		cache_inv(explode_generateTensors_arra__58, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__52 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__52 
		cache_inv(explode_generateTensors_arra__52, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__117 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__117 
		cache_inv(explode_generateTensors_arra__117, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__3 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__3 
		cache_inv(explode_generateTensors_arra__3, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_generateTensors_arra__64 
		receiveEnd(7); // Core7 > Core6: explode_generateTensors_arra__64 
		cache_inv(explode_generateTensors_arra__64, 32*sizeof(char));
		receiveStart(); // Core2 > Core6: transposeTensor_12__explode___0 
		receiveEnd(2); // Core2 > Core6: transposeTensor_12__explode___0 
		cache_inv(transposeTensor_12__explode___0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_896__input__0,output__arrayA__14); // transposeTensor_14
		cache_inv(arrayA_896__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_14__explode___0, 256*sizeof(char));
		sendStart(5); // Core6 > Core5: transposeTensor_14__explode___0 
		sendEnd(); // Core6 > Core5: transposeTensor_14__explode___0 
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_128__input__0,output__arrayA__10); // transposeTensor_2
		cache_inv(arrayA_128__input__0, 64*sizeof(int));
		receiveStart(); // Core4 > Core6: explode_transposeTensor_10_o__1 
		receiveEnd(4); // Core4 > Core6: explode_transposeTensor_10_o__1 
		cache_inv(explode_transposeTensor_10_o__1, 32*sizeof(char));
		// Fork explode_transposeTensor_12_output
		{
			memcpy((void*)(output_0__arrayA__7+0),(void*)( output__arrayA__12+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__8+0),(void*)( output__arrayA__12+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__13+0),(void*)( output__arrayA__12+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__5+0),(void*)( output__arrayA__12+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__9+0),(void*)( output__arrayA__12+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__9+0),(void*)( output__arrayA__12+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__6+0),(void*)( output__arrayA__12+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__12+0),(void*)( output__arrayA__12+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__12, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_12_o__6, 32*sizeof(char));
		sendStart(2); // Core6 > Core2: explode_transposeTensor_12_o__6 
		sendEnd(); // Core6 > Core2: explode_transposeTensor_12_o__6 
		cache_wbInv(explode_transposeTensor_12_o__0, 32*sizeof(char));
		sendStart(5); // Core6 > Core5: explode_transposeTensor_12_o__0 
		sendEnd(); // Core6 > Core5: explode_transposeTensor_12_o__0 
		cache_wbInv(explode_transposeTensor_12_o__1, 32*sizeof(char));
		sendStart(4); // Core6 > Core4: explode_transposeTensor_12_o__1 
		sendEnd(); // Core6 > Core4: explode_transposeTensor_12_o__1 
		cache_wbInv(explode_transposeTensor_12_o__7, 32*sizeof(char));
		sendStart(2); // Core6 > Core2: explode_transposeTensor_12_o__7 
		sendEnd(); // Core6 > Core2: explode_transposeTensor_12_o__7 
		cache_wbInv(explode_transposeTensor_12_o__3, 32*sizeof(char));
		sendStart(1); // Core6 > Core1: explode_transposeTensor_12_o__3 
		sendEnd(); // Core6 > Core1: explode_transposeTensor_12_o__3 
		cache_wbInv(explode_transposeTensor_12_o__4, 32*sizeof(char));
		sendStart(5); // Core6 > Core5: explode_transposeTensor_12_o__4 
		sendEnd(); // Core6 > Core5: explode_transposeTensor_12_o__4 
		receiveStart(); // Core5 > Core6: explode_transposeTensor_14_o__3 
		receiveEnd(5); // Core5 > Core6: explode_transposeTensor_14_o__3 
		cache_inv(explode_transposeTensor_14_o__3, 32*sizeof(char));
		receiveStart(); // Core5 > Core6: explode_transposeTensor_14_o__7 
		receiveEnd(5); // Core5 > Core6: explode_transposeTensor_14_o__7 
		cache_inv(explode_transposeTensor_14_o__7, 32*sizeof(char));
		// Fork explode_transposeTensor_2_output
		{
			memcpy((void*)(output_0__arrayA__14+0),(void*)( output__arrayA__10+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__1+0),(void*)( output__arrayA__10+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__9+0),(void*)( output__arrayA__10+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__10+0),(void*)( output__arrayA__10+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__12+0),(void*)( output__arrayA__10+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__10+0),(void*)( output__arrayA__10+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__11+0),(void*)( output__arrayA__10+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__1+0),(void*)( output__arrayA__10+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__10, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_2_ou__4, 32*sizeof(char));
		sendStart(3); // Core6 > Core3: explode_transposeTensor_2_ou__4 
		sendEnd(); // Core6 > Core3: explode_transposeTensor_2_ou__4 
		cache_wbInv(explode_transposeTensor_2_ou__2, 32*sizeof(char));
		sendStart(3); // Core6 > Core3: explode_transposeTensor_2_ou__2 
		sendEnd(); // Core6 > Core3: explode_transposeTensor_2_ou__2 
		cache_wbInv(explode_transposeTensor_2_ou__7, 32*sizeof(char));
		sendStart(3); // Core6 > Core3: explode_transposeTensor_2_ou__7 
		sendEnd(); // Core6 > Core3: explode_transposeTensor_2_ou__7 
		receiveStart(); // Core3 > Core6: explode_transposeTensor_3_ou__0 
		receiveEnd(3); // Core3 > Core6: explode_transposeTensor_3_ou__0 
		cache_inv(explode_transposeTensor_3_ou__0, 32*sizeof(char));
		receiveStart(); // Core7 > Core6: explode_transposeTensor_4_ou__6 
		receiveEnd(7); // Core7 > Core6: explode_transposeTensor_4_ou__6 
		cache_inv(explode_transposeTensor_4_ou__6, 32*sizeof(char));
		receiveStart(); // Core1 > Core6: explode_transposeTensor_5_ou__0 
		receiveEnd(1); // Core1 > Core6: explode_transposeTensor_5_ou__0 
		cache_inv(explode_transposeTensor_5_ou__0, 32*sizeof(char));
		receiveStart(); // Core3 > Core6: explode_transposeTensor_6_ou__0 
		receiveEnd(3); // Core3 > Core6: explode_transposeTensor_6_ou__0 
		cache_inv(explode_transposeTensor_6_ou__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core6: explode_transposeTensor_8_ou__4 
		receiveEnd(0); // Core0 > Core6: explode_transposeTensor_8_ou__4 
		cache_inv(explode_transposeTensor_8_ou__4, 32*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__9,arrayB_800__arrayB__0,arrayC__input_256__10); // multiplyTensors_100
		cache_inv(output_32__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_800__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_100__implode__0, 256*sizeof(char));
		sendStart(4); // Core6 > Core4: multiplyTensors_100__implode__0 
		sendEnd(); // Core6 > Core4: multiplyTensors_100__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__9,arrayB_808__arrayB__0,arrayC__input_320__6); // multiplyTensors_101
		cache_inv(output_40__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_808__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_101__implode__0, 256*sizeof(char));
		sendStart(4); // Core6 > Core4: multiplyTensors_101__implode__0 
		sendEnd(); // Core6 > Core4: multiplyTensors_101__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__11,arrayB_896__arrayB__0,arrayC__input_0__14); // multiplyTensors_112
		cache_inv(output_0__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_896__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core2 > Core6: multiplyTensors_113__implode__0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_113__implode__0 
		cache_inv(multiplyTensors_113__implode__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core6: multiplyTensors_114__implode__0 
		receiveEnd(1); // Core1 > Core6: multiplyTensors_114__implode__0 
		cache_inv(multiplyTensors_114__implode__0, 256*sizeof(char));
		receiveStart(); // Core1 > Core6: multiplyTensors_115__implode__0 
		receiveEnd(1); // Core1 > Core6: multiplyTensors_115__implode__0 
		cache_inv(multiplyTensors_115__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_116__implode__0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_116__implode__0 
		cache_inv(multiplyTensors_116__implode__0, 256*sizeof(char));
		receiveStart(); // Core2 > Core6: multiplyTensors_117__implode__0 
		receiveEnd(2); // Core2 > Core6: multiplyTensors_117__implode__0 
		cache_inv(multiplyTensors_117__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_118__implode__0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_118__implode__0 
		cache_inv(multiplyTensors_118__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__0,arrayB_952__arrayB__0,arrayC__input_448__7); // multiplyTensors_119
		cache_inv(output_56__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_952__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__1,arrayB_136__arrayB__0,arrayC__input_64__13); // multiplyTensors_17
		cache_inv(output_8__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_136__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_17__implode___0, 256*sizeof(char));
		sendStart(7); // Core6 > Core7: multiplyTensors_17__implode___0 
		sendEnd(); // Core6 > Core7: multiplyTensors_17__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__12,arrayB_160__arrayB__0,arrayC__input_256__1); // multiplyTensors_20
		cache_inv(output_32__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_160__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_20__implode___0, 256*sizeof(char));
		sendStart(7); // Core6 > Core7: multiplyTensors_20__implode___0 
		sendEnd(); // Core6 > Core7: multiplyTensors_20__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__10,arrayB_168__arrayB__0,arrayC__input_320__13); // multiplyTensors_21
		cache_inv(output_40__arrayA__10, 8*sizeof(int));
		cache_inv(arrayB_168__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_21__implode___0, 256*sizeof(char));
		sendStart(7); // Core6 > Core7: multiplyTensors_21__implode___0 
		sendEnd(); // Core6 > Core7: multiplyTensors_21__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__11,arrayB_176__arrayB__0,arrayC__input_384__15); // multiplyTensors_22
		cache_inv(output_48__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_176__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_22__implode___0, 256*sizeof(char));
		sendStart(7); // Core6 > Core7: multiplyTensors_22__implode___0 
		sendEnd(); // Core6 > Core7: multiplyTensors_22__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__1,arrayB_184__arrayB__0,arrayC__input_448__5); // multiplyTensors_23
		cache_inv(output_56__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_184__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_23__implode___0, 256*sizeof(char));
		sendStart(7); // Core6 > Core7: multiplyTensors_23__implode___0 
		sendEnd(); // Core6 > Core7: multiplyTensors_23__implode___0 
		receiveStart(); // Core5 > Core6: multiplyTensors_24__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_24__implode___0 
		cache_inv(multiplyTensors_24__implode___0, 256*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_25__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_25__implode___0 
		cache_inv(multiplyTensors_25__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__1,arrayB_208__arrayB__0,arrayC__input_128__4); // multiplyTensors_26
		cache_inv(output_16__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_208__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core5 > Core6: multiplyTensors_27__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_27__implode___0 
		cache_inv(multiplyTensors_27__implode___0, 256*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_28__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_28__implode___0 
		cache_inv(multiplyTensors_28__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core6: multiplyTensors_29__implode___0 
		receiveEnd(3); // Core3 > Core6: multiplyTensors_29__implode___0 
		cache_inv(multiplyTensors_29__implode___0, 256*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_30__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_30__implode___0 
		cache_inv(multiplyTensors_30__implode___0, 256*sizeof(char));
		receiveStart(); // Core5 > Core6: multiplyTensors_31__implode___0 
		receiveEnd(5); // Core5 > Core6: multiplyTensors_31__implode___0 
		cache_inv(multiplyTensors_31__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__6,arrayB_288__arrayB__0,arrayC__input_256__12); // multiplyTensors_36
		cache_inv(output_32__arrayA__6, 8*sizeof(int));
		cache_inv(arrayB_288__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_36__implode___0, 256*sizeof(char));
		sendStart(4); // Core6 > Core4: multiplyTensors_36__implode___0 
		sendEnd(); // Core6 > Core4: multiplyTensors_36__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__2,arrayB_320__arrayB__0,arrayC__input_0__15); // multiplyTensors_40
		cache_inv(output_0__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_320__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_40__implode___0, 256*sizeof(char));
		sendStart(3); // Core6 > Core3: multiplyTensors_40__implode___0 
		sendEnd(); // Core6 > Core3: multiplyTensors_40__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__2,arrayB_400__arrayB__0,arrayC__input_128__3); // multiplyTensors_50
		cache_inv(output_16__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_400__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_50__implode___0, 256*sizeof(char));
		sendStart(2); // Core6 > Core2: multiplyTensors_50__implode___0 
		sendEnd(); // Core6 > Core2: multiplyTensors_50__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__4,arrayB_512__arrayB__0,arrayC__input_0__5); // multiplyTensors_64
		cache_inv(output_0__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_512__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_64__implode___0, 256*sizeof(char));
		sendStart(7); // Core6 > Core7: multiplyTensors_64__implode___0 
		sendEnd(); // Core6 > Core7: multiplyTensors_64__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__6,arrayB_648__arrayB__0,arrayC__input_64__5); // multiplyTensors_81
		cache_inv(output_8__arrayA__6, 8*sizeof(int));
		cache_inv(arrayB_648__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_81__implode___0, 256*sizeof(char));
		sendStart(0); // Core6 > Core0: multiplyTensors_81__implode___0 
		sendEnd(); // Core6 > Core0: multiplyTensors_81__implode___0 
		// Join implode_sumResults_14_input
		{
			memcpy((void*)(arrayC__input__15+0),(void*)( arrayC__input_0__14+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+64),(void*)( arrayC__input_64__10+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+128),(void*)( arrayC__input_128__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+192),(void*)( arrayC__input_192__15+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+256),(void*)( arrayC__input_256__3+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+320),(void*)( arrayC__input_320__10+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+384),(void*)( arrayC__input_384__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__15+448),(void*)( arrayC__input_448__7+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__14, 64*sizeof(long));
		cache_inv(arrayC__input_64__10, 64*sizeof(long));
		cache_inv(arrayC__input_128__1, 64*sizeof(long));
		cache_inv(arrayC__input_192__15, 64*sizeof(long));
		cache_inv(arrayC__input_256__3, 64*sizeof(long));
		cache_inv(arrayC__input_320__10, 64*sizeof(long));
		cache_inv(arrayC__input_384__0, 64*sizeof(long));
		cache_inv(arrayC__input_448__7, 64*sizeof(long));
		receiveStart(); // Core7 > Core6: implode_sumResults_2_input____0 
		receiveEnd(7); // Core7 > Core6: implode_sumResults_2_input____0 
		cache_inv(implode_sumResults_2_input____0, 2048*sizeof(char));
		// Join implode_sumResults_3_input
		{
			memcpy((void*)(arrayC__input__5+0),(void*)( arrayC__input_0__13+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__5+64),(void*)( arrayC__input_64__6+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__5+128),(void*)( arrayC__input_128__4+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__5+192),(void*)( arrayC__input_192__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__5+256),(void*)( arrayC__input_256__8+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__5+320),(void*)( arrayC__input_320__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__5+384),(void*)( arrayC__input_384__7+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__5+448),(void*)( arrayC__input_448__1+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__13, 64*sizeof(long));
		cache_inv(arrayC__input_64__6, 64*sizeof(long));
		cache_inv(arrayC__input_128__4, 64*sizeof(long));
		cache_inv(arrayC__input_192__1, 64*sizeof(long));
		cache_inv(arrayC__input_256__8, 64*sizeof(long));
		cache_inv(arrayC__input_320__1, 64*sizeof(long));
		cache_inv(arrayC__input_384__7, 64*sizeof(long));
		cache_inv(arrayC__input_448__1, 64*sizeof(long));
		cache_wbInv(implode_sumResults_3_input____0, 2048*sizeof(char));
		sendStart(4); // Core6 > Core4: implode_sumResults_3_input____0 
		sendEnd(); // Core6 > Core4: implode_sumResults_3_input____0 
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__15,output__arrayC_896__0); // sumResults_14
		cache_inv(arrayC__input__15, 512*sizeof(long));
		cache_wbInv(sumResults_14__implode_displ__0, 256*sizeof(char));
		sendStart(4); // Core6 > Core4: sumResults_14__implode_displ__0 
		sendEnd(); // Core6 > Core4: sumResults_14__implode_displ__0 
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__10,output__arrayC_128__0); // sumResults_2
		cache_inv(arrayC__input__10, 512*sizeof(long));
		cache_wbInv(sumResults_2__implode_displa__0, 256*sizeof(char));
		sendStart(4); // Core6 > Core4: sumResults_2__implode_displa__0 
		sendEnd(); // Core6 > Core4: sumResults_2__implode_displa__0 
	}
}
