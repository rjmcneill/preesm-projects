/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Tue Mar 31 21:38:20 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__36;  // explode_generateTensors_arrayA > transposeTensor_6 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayA > transposeTensor_0 size:= 1048576*char defined in Core0
extern char *const explode_generateTensors_arra__49;  // explode_generateTensors_arrayB > multiplyTensors_53 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__71;  // explode_generateTensors_arrayB > multiplyTensors_48 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__34;  // explode_generateTensors_arrayB > multiplyTensors_30 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__38;  // explode_generateTensors_arrayB > multiplyTensors_21 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__50;  // explode_generateTensors_arrayB > multiplyTensors_12 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__3;  // explode_generateTensors_arrayB > multiplyTensors_6 size:= 131072*char defined in Core0
extern char *const explode_generateTensors_arra__64;  // explode_generateTensors_arrayB > multiplyTensors_2 size:= 131072*char defined in Core0
extern int *const arrayA_0__input__0;  // explode_generateTensors_arrayA_arrayA_0 > transposeTensor_0_input size:= 262144*int defined in Core0
extern int *const output__arrayA__0;  // transposeTensor_0_output > explode_transposeTensor_0_output_arrayA size:= 262144*int defined in Core0
extern char *const transposeTensor_0__explode_t__0;  // transposeTensor_0 > explode_transposeTensor_0_output size:= 1048576*char defined in Core0
extern int *const arrayA_1572864__input__0;  // explode_generateTensors_arrayA_arrayA_1572864 > transposeTensor_6_input size:= 262144*int defined in Core0
extern int *const output__arrayA__1;  // transposeTensor_6_output > explode_transposeTensor_6_output_arrayA size:= 262144*int defined in Core0
extern char *const transposeTensor_6__explode_t__0;  // transposeTensor_6 > explode_transposeTensor_6_output size:= 1048576*char defined in Core0
extern char *const explode_transposeTensor_0_ou__0;  // explode_transposeTensor_0_output > multiplyTensors_6 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_0_ou__2;  // explode_transposeTensor_0_output > multiplyTensors_2 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_1_ou__7;  // explode_transposeTensor_1_output > multiplyTensors_12 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_2_ou__3;  // explode_transposeTensor_2_output > multiplyTensors_21 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_3_ou__7;  // explode_transposeTensor_3_output > multiplyTensors_30 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_6_ou__6;  // explode_transposeTensor_6_output > multiplyTensors_53 size:= 131072*char defined in Core0
extern char *const explode_transposeTensor_6_ou__0;  // explode_transposeTensor_6_output > multiplyTensors_48 size:= 131072*char defined in Core0
extern char *const multiplyTensors_0__implode_s__0;  // multiplyTensors_0 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_1__implode_s__0;  // multiplyTensors_1 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern int *const output_131072__arrayA__6;  // explode_transposeTensor_1_output_output_131072 > multiplyTensors_12_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_393216__arrayB__0;  // explode_generateTensors_arrayB_arrayB_393216 > multiplyTensors_12_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1048576__4;  // multiplyTensors_12_arrayC > implode_sumResults_1_input_input_1048576 size:= 262144*long defined in Core0
extern char *const multiplyTensors_12__implode___0;  // multiplyTensors_12 > implode_sumResults_1_input size:= 1048576*char defined in Core0
extern int *const output_65536__arrayA__6;  // explode_transposeTensor_0_output_output_65536 > multiplyTensors_2_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_65536__arrayB__0;  // explode_generateTensors_arrayB_arrayB_65536 > multiplyTensors_2_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_524288__0;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_524288 size:= 262144*long defined in Core0
extern int *const output_163840__arrayA__4;  // explode_transposeTensor_2_output_output_163840 > multiplyTensors_21_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_688128__arrayB__0;  // explode_generateTensors_arrayB_arrayB_688128 > multiplyTensors_21_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1310720__1;  // multiplyTensors_21_arrayC > implode_sumResults_2_input_input_1310720 size:= 262144*long defined in Core0
extern char *const multiplyTensors_21__implode___0;  // multiplyTensors_21 > implode_sumResults_2_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern int *const output_196608__arrayA__5;  // explode_transposeTensor_3_output_output_196608 > multiplyTensors_30_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_983040__arrayB__0;  // explode_generateTensors_arrayB_arrayB_983040 > multiplyTensors_30_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1572864__2;  // multiplyTensors_30_arrayC > implode_sumResults_3_input_input_1572864 size:= 262144*long defined in Core0
extern char *const multiplyTensors_30__implode___0;  // multiplyTensors_30 > implode_sumResults_3_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_4__implode_s__0;  // multiplyTensors_4 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern int *const output_0__arrayA__2;  // explode_transposeTensor_6_output_output_0 > multiplyTensors_48_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_1572864__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1572864 > multiplyTensors_48_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_0__5;  // multiplyTensors_48_arrayC > implode_sumResults_6_input_input_0 size:= 262144*long defined in Core0
extern char *const multiplyTensors_48__implode___0;  // multiplyTensors_48 > implode_sumResults_6_input size:= 1048576*char defined in Core0
extern char *const multiplyTensors_5__implode_s__0;  // multiplyTensors_5 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern int *const output_163840__arrayA__7;  // explode_transposeTensor_6_output_output_163840 > multiplyTensors_53_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_1736704__arrayB__0;  // explode_generateTensors_arrayB_arrayB_1736704 > multiplyTensors_53_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1310720__2;  // multiplyTensors_53_arrayC > implode_sumResults_6_input_input_1310720 size:= 262144*long defined in Core0
extern char *const multiplyTensors_53__implode___0;  // multiplyTensors_53 > implode_sumResults_6_input size:= 1048576*char defined in Core0
extern int *const output_196608__arrayA__0;  // explode_transposeTensor_0_output_output_196608 > multiplyTensors_6_arrayA size:= 32768*int defined in Core0
extern int *const arrayB_196608__arrayB__0;  // explode_generateTensors_arrayB_arrayB_196608 > multiplyTensors_6_arrayB size:= 32768*int defined in Core0
extern long *const arrayC__input_1572864__6;  // multiplyTensors_6_arrayC > implode_sumResults_0_input_input_1572864 size:= 262144*long defined in Core0
extern char *const multiplyTensors_7__implode_s__0;  // multiplyTensors_7 > implode_sumResults_0_input size:= 1048576*char defined in Core0
extern long *const arrayC__input_0__0;  // multiplyTensors_0_arrayC > implode_sumResults_0_input_input_0 size:= 262144*long defined in Core0
extern long *const arrayC__input_262144__4;  // multiplyTensors_1_arrayC > implode_sumResults_0_input_input_262144 size:= 262144*long defined in Core0
extern long *const arrayC__input_786432__5;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_786432 size:= 262144*long defined in Core0
extern long *const arrayC__input_1048576__5;  // multiplyTensors_4_arrayC > implode_sumResults_0_input_input_1048576 size:= 262144*long defined in Core0
extern long *const arrayC__input_1310720__0;  // multiplyTensors_5_arrayC > implode_sumResults_0_input_input_1310720 size:= 262144*long defined in Core0
extern long *const arrayC__input_1835008__2;  // multiplyTensors_7_arrayC > implode_sumResults_0_input_input_1835008 size:= 262144*long defined in Core0
extern long *const arrayC__input__6;  // implode_sumResults_0_input_arrayC > sumResults_0_input size:= 2097152*long defined in Core0
extern long *const output__arrayC_0__0;  // sumResults_0_output > implode_displayTensor_arrayC_arrayC_0 size:= 262144*long defined in Core0
extern char *const sumResults_0__implode_displa__0;  // sumResults_0 > implode_displayTensor_arrayC size:= 1048576*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__36 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__36 
		cache_inv(explode_generateTensors_arra__36, 1048576*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__6 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 1048576*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__49 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__49 
		cache_inv(explode_generateTensors_arra__49, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__71 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__71 
		cache_inv(explode_generateTensors_arra__71, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__34 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__34 
		cache_inv(explode_generateTensors_arra__34, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__38 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__38 
		cache_inv(explode_generateTensors_arra__38, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__50 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__50 
		cache_inv(explode_generateTensors_arra__50, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__3 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__3 
		cache_inv(explode_generateTensors_arra__3, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__64 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__64 
		cache_inv(explode_generateTensors_arra__64, 131072*sizeof(char));
		transpose(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,arrayA_0__input__0,output__arrayA__0); // transposeTensor_0
		cache_inv(arrayA_0__input__0, 262144*sizeof(int));
		cache_wbInv(transposeTensor_0__explode_t__0, 1048576*sizeof(char));
		sendStart(1); // Core2 > Core1: transposeTensor_0__explode_t__0 
		sendEnd(); // Core2 > Core1: transposeTensor_0__explode_t__0 
		transpose(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,arrayA_1572864__input__0,output__arrayA__1); // transposeTensor_6
		cache_inv(arrayA_1572864__input__0, 262144*sizeof(int));
		cache_wbInv(transposeTensor_6__explode_t__0, 1048576*sizeof(char));
		sendStart(5); // Core2 > Core5: transposeTensor_6__explode_t__0 
		sendEnd(); // Core2 > Core5: transposeTensor_6__explode_t__0 
		receiveStart(); // Core1 > Core2: explode_transposeTensor_0_ou__0 
		receiveEnd(1); // Core1 > Core2: explode_transposeTensor_0_ou__0 
		cache_inv(explode_transposeTensor_0_ou__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core2: explode_transposeTensor_0_ou__2 
		receiveEnd(1); // Core1 > Core2: explode_transposeTensor_0_ou__2 
		cache_inv(explode_transposeTensor_0_ou__2, 131072*sizeof(char));
		receiveStart(); // Core3 > Core2: explode_transposeTensor_1_ou__7 
		receiveEnd(3); // Core3 > Core2: explode_transposeTensor_1_ou__7 
		cache_inv(explode_transposeTensor_1_ou__7, 131072*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_2_ou__3 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_2_ou__3 
		cache_inv(explode_transposeTensor_2_ou__3, 131072*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_transposeTensor_3_ou__7 
		receiveEnd(7); // Core7 > Core2: explode_transposeTensor_3_ou__7 
		cache_inv(explode_transposeTensor_3_ou__7, 131072*sizeof(char));
		receiveStart(); // Core5 > Core2: explode_transposeTensor_6_ou__6 
		receiveEnd(5); // Core5 > Core2: explode_transposeTensor_6_ou__6 
		cache_inv(explode_transposeTensor_6_ou__6, 131072*sizeof(char));
		receiveStart(); // Core5 > Core2: explode_transposeTensor_6_ou__0 
		receiveEnd(5); // Core5 > Core2: explode_transposeTensor_6_ou__0 
		cache_inv(explode_transposeTensor_6_ou__0, 131072*sizeof(char));
		receiveStart(); // Core1 > Core2: multiplyTensors_0__implode_s__0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_0__implode_s__0 
		cache_inv(multiplyTensors_0__implode_s__0, 1048576*sizeof(char));
		receiveStart(); // Core5 > Core2: multiplyTensors_1__implode_s__0 
		receiveEnd(5); // Core5 > Core2: multiplyTensors_1__implode_s__0 
		cache_inv(multiplyTensors_1__implode_s__0, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_131072__arrayA__6,arrayB_393216__arrayB__0,arrayC__input_1048576__4); // multiplyTensors_12
		cache_inv(output_131072__arrayA__6, 32768*sizeof(int));
		cache_inv(arrayB_393216__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_12__implode___0, 1048576*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_12__implode___0 
		sendEnd(); // Core2 > Core6: multiplyTensors_12__implode___0 
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_65536__arrayA__6,arrayB_65536__arrayB__0,arrayC__input_524288__0); // multiplyTensors_2
		cache_inv(output_65536__arrayA__6, 32768*sizeof(int));
		cache_inv(arrayB_65536__arrayB__0, 32768*sizeof(int));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_163840__arrayA__4,arrayB_688128__arrayB__0,arrayC__input_1310720__1); // multiplyTensors_21
		cache_inv(output_163840__arrayA__4, 32768*sizeof(int));
		cache_inv(arrayB_688128__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_21__implode___0, 1048576*sizeof(char));
		sendStart(4); // Core2 > Core4: multiplyTensors_21__implode___0 
		sendEnd(); // Core2 > Core4: multiplyTensors_21__implode___0 
		receiveStart(); // Core1 > Core2: multiplyTensors_3__implode_s__0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_3__implode_s__0 
		cache_inv(multiplyTensors_3__implode_s__0, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_196608__arrayA__5,arrayB_983040__arrayB__0,arrayC__input_1572864__2); // multiplyTensors_30
		cache_inv(output_196608__arrayA__5, 32768*sizeof(int));
		cache_inv(arrayB_983040__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_30__implode___0, 1048576*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_30__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_30__implode___0 
		receiveStart(); // Core0 > Core2: multiplyTensors_4__implode_s__0 
		receiveEnd(0); // Core0 > Core2: multiplyTensors_4__implode_s__0 
		cache_inv(multiplyTensors_4__implode_s__0, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_0__arrayA__2,arrayB_1572864__arrayB__0,arrayC__input_0__5); // multiplyTensors_48
		cache_inv(output_0__arrayA__2, 32768*sizeof(int));
		cache_inv(arrayB_1572864__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_48__implode___0, 1048576*sizeof(char));
		sendStart(3); // Core2 > Core3: multiplyTensors_48__implode___0 
		sendEnd(); // Core2 > Core3: multiplyTensors_48__implode___0 
		receiveStart(); // Core0 > Core2: multiplyTensors_5__implode_s__0 
		receiveEnd(0); // Core0 > Core2: multiplyTensors_5__implode_s__0 
		cache_inv(multiplyTensors_5__implode_s__0, 1048576*sizeof(char));
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_163840__arrayA__7,arrayB_1736704__arrayB__0,arrayC__input_1310720__2); // multiplyTensors_53
		cache_inv(output_163840__arrayA__7, 32768*sizeof(int));
		cache_inv(arrayB_1736704__arrayB__0, 32768*sizeof(int));
		cache_wbInv(multiplyTensors_53__implode___0, 1048576*sizeof(char));
		sendStart(3); // Core2 > Core3: multiplyTensors_53__implode___0 
		sendEnd(); // Core2 > Core3: multiplyTensors_53__implode___0 
		multiply(512/*rowsA*/,512/*columnsA*/,8/*depthA*/,512/*rowsB*/,512/*columnsB*/,8/*depthB*/,output_196608__arrayA__0,arrayB_196608__arrayB__0,arrayC__input_1572864__6); // multiplyTensors_6
		cache_inv(output_196608__arrayA__0, 32768*sizeof(int));
		cache_inv(arrayB_196608__arrayB__0, 32768*sizeof(int));
		receiveStart(); // Core0 > Core2: multiplyTensors_7__implode_s__0 
		receiveEnd(0); // Core0 > Core2: multiplyTensors_7__implode_s__0 
		cache_inv(multiplyTensors_7__implode_s__0, 1048576*sizeof(char));
		// Join implode_sumResults_0_input
		{
			memcpy((void*)(arrayC__input__6+0),(void*)( arrayC__input_0__0+0), 262144*sizeof(long));
			memcpy((void*)(arrayC__input__6+262144),(void*)( arrayC__input_262144__4+0), 262144*sizeof(long));
			memcpy((void*)(arrayC__input__6+524288),(void*)( arrayC__input_524288__0+0), 262144*sizeof(long));
			memcpy((void*)(arrayC__input__6+786432),(void*)( arrayC__input_786432__5+0), 262144*sizeof(long));
			memcpy((void*)(arrayC__input__6+1048576),(void*)( arrayC__input_1048576__5+0), 262144*sizeof(long));
			memcpy((void*)(arrayC__input__6+1310720),(void*)( arrayC__input_1310720__0+0), 262144*sizeof(long));
			memcpy((void*)(arrayC__input__6+1572864),(void*)( arrayC__input_1572864__6+0), 262144*sizeof(long));
			memcpy((void*)(arrayC__input__6+1835008),(void*)( arrayC__input_1835008__2+0), 262144*sizeof(long));
		}
		cache_inv(arrayC__input_0__0, 262144*sizeof(long));
		cache_inv(arrayC__input_262144__4, 262144*sizeof(long));
		cache_inv(arrayC__input_524288__0, 262144*sizeof(long));
		cache_inv(arrayC__input_786432__5, 262144*sizeof(long));
		cache_inv(arrayC__input_1048576__5, 262144*sizeof(long));
		cache_inv(arrayC__input_1310720__0, 262144*sizeof(long));
		cache_inv(arrayC__input_1572864__6, 262144*sizeof(long));
		cache_inv(arrayC__input_1835008__2, 262144*sizeof(long));
		sum(512/*rowsA*/,512/*columnsB*/,8/*depthA*/,arrayC__input__6,output__arrayC_0__0); // sumResults_0
		cache_inv(arrayC__input__6, 2097152*sizeof(long));
		cache_wbInv(sumResults_0__implode_displa__0, 1048576*sizeof(char));
		sendStart(6); // Core2 > Core6: sumResults_0__implode_displa__0 
		sendEnd(); // Core2 > Core6: sumResults_0__implode_displa__0 
	}
}
