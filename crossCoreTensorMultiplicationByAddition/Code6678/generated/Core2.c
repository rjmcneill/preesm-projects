/** 
 * @file Core2.c
 * @generated by C6678CPrinter
 * @date Fri Apr 17 16:12:31 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__109;  // explode_generateTensors_arrayA > transposeTensor_12 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__14;  // explode_generateTensors_arrayB > multiplyTensors_117 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__47;  // explode_generateTensors_arrayB > multiplyTensors_113 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__141;  // explode_generateTensors_arrayB > multiplyTensors_103 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__65;  // explode_generateTensors_arrayB > multiplyTensors_98 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__103;  // explode_generateTensors_arrayB > multiplyTensors_84 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__20;  // explode_generateTensors_arrayB > multiplyTensors_79 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__51;  // explode_generateTensors_arrayB > multiplyTensors_78 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__4;  // explode_generateTensors_arrayB > multiplyTensors_73 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__22;  // explode_generateTensors_arrayB > multiplyTensors_65 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__56;  // explode_generateTensors_arrayB > multiplyTensors_45 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__122;  // explode_generateTensors_arrayB > multiplyTensors_38 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__2;  // explode_generateTensors_arrayB > multiplyTensors_3 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__15;  // explode_generateTensors_arrayB > multiplyTensors_1 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__29;  // explode_generateTensors_arrayB > multiplyTensors_0 size:= 32*char defined in Core0
extern char *const transposeTensor_0__explode_t__0;  // transposeTensor_0 > explode_transposeTensor_0_output size:= 256*char defined in Core0
extern int *const arrayA_768__input__0;  // explode_generateTensors_arrayA_arrayA_768 > transposeTensor_12_input size:= 64*int defined in Core0
extern int *const output__arrayA__12;  // transposeTensor_12_output > explode_transposeTensor_12_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_12__explode___0;  // transposeTensor_12 > explode_transposeTensor_12_output size:= 256*char defined in Core0
extern char *const transposeTensor_9__explode_t__0;  // transposeTensor_9 > explode_transposeTensor_9_output size:= 256*char defined in Core0
extern int *const output_0__arrayA__3;  // explode_transposeTensor_0_output_output_0 > multiplyTensors_0_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__14;  // explode_transposeTensor_0_output_output_8 > multiplyTensors_1_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__3;  // explode_transposeTensor_0_output_output_16 > multiplyTensors_2_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__7;  // explode_transposeTensor_0_output_output_24 > multiplyTensors_3_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__15;  // explode_transposeTensor_0_output_output_32 > multiplyTensors_4_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__3;  // explode_transposeTensor_0_output_output_40 > multiplyTensors_5_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__4;  // explode_transposeTensor_0_output_output_48 > multiplyTensors_6_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__8;  // explode_transposeTensor_0_output_output_56 > multiplyTensors_7_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__13;  // transposeTensor_0_output > explode_transposeTensor_0_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_0_ou__4;  // explode_transposeTensor_0_output > multiplyTensors_7 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__2;  // explode_transposeTensor_0_output > multiplyTensors_6 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__1;  // explode_transposeTensor_0_output > multiplyTensors_5 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__7;  // explode_transposeTensor_0_output > multiplyTensors_4 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__0;  // explode_transposeTensor_0_output > multiplyTensors_2 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__2;  // explode_transposeTensor_10_output > multiplyTensors_84 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__6;  // explode_transposeTensor_12_output > multiplyTensors_103 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__7;  // explode_transposeTensor_12_output > multiplyTensors_98 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__2;  // explode_transposeTensor_14_output > multiplyTensors_117 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__5;  // explode_transposeTensor_14_output > multiplyTensors_113 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_4_ou__3;  // explode_transposeTensor_4_output > multiplyTensors_38 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__1;  // explode_transposeTensor_5_output > multiplyTensors_45 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_8_ou__5;  // explode_transposeTensor_8_output > multiplyTensors_65 size:= 32*char defined in Core0
extern int *const output_0__arrayA__6;  // explode_transposeTensor_9_output_output_0 > multiplyTensors_72_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__2;  // explode_transposeTensor_9_output_output_8 > multiplyTensors_73_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__11;  // explode_transposeTensor_9_output_output_16 > multiplyTensors_74_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__6;  // explode_transposeTensor_9_output_output_24 > multiplyTensors_75_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__7;  // explode_transposeTensor_9_output_output_32 > multiplyTensors_76_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__13;  // explode_transposeTensor_9_output_output_40 > multiplyTensors_77_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__7;  // explode_transposeTensor_9_output_output_48 > multiplyTensors_78_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__11;  // explode_transposeTensor_9_output_output_56 > multiplyTensors_79_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__0;  // transposeTensor_9_output > explode_transposeTensor_9_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_9_ou__6;  // explode_transposeTensor_9_output > multiplyTensors_77 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__3;  // explode_transposeTensor_9_output > multiplyTensors_76 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__1;  // explode_transposeTensor_9_output > multiplyTensors_75 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__5;  // explode_transposeTensor_9_output > multiplyTensors_74 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__4;  // explode_transposeTensor_9_output > multiplyTensors_72 size:= 32*char defined in Core0
extern int *const arrayB_0__arrayB__0;  // explode_generateTensors_arrayB_arrayB_0 > multiplyTensors_0_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__1;  // multiplyTensors_0_arrayC > implode_sumResults_0_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_0__implode_s__0;  // multiplyTensors_0 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const arrayB_8__arrayB__0;  // explode_generateTensors_arrayB_arrayB_8 > multiplyTensors_1_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__0;  // multiplyTensors_1_arrayC > implode_sumResults_0_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_1__implode_s__0;  // multiplyTensors_1 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__12;  // explode_transposeTensor_12_output_output_56 > multiplyTensors_103_arrayA size:= 8*int defined in Core0
extern int *const arrayB_824__arrayB__0;  // explode_generateTensors_arrayB_arrayB_824 > multiplyTensors_103_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__11;  // multiplyTensors_103_arrayC > implode_sumResults_12_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_103__implode__0;  // multiplyTensors_103 > implode_sumResults_12_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__10;  // explode_transposeTensor_14_output_output_8 > multiplyTensors_113_arrayA size:= 8*int defined in Core0
extern int *const arrayB_904__arrayB__0;  // explode_generateTensors_arrayB_arrayB_904 > multiplyTensors_113_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__10;  // multiplyTensors_113_arrayC > implode_sumResults_14_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_113__implode__0;  // multiplyTensors_113 > implode_sumResults_14_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__1;  // explode_transposeTensor_14_output_output_40 > multiplyTensors_117_arrayA size:= 8*int defined in Core0
extern int *const arrayB_936__arrayB__0;  // explode_generateTensors_arrayB_arrayB_936 > multiplyTensors_117_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__10;  // multiplyTensors_117_arrayC > implode_sumResults_14_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_117__implode__0;  // multiplyTensors_117 > implode_sumResults_14_input size:= 256*char defined in Core0
extern int *const arrayB_24__arrayB__0;  // explode_generateTensors_arrayB_arrayB_24 > multiplyTensors_3_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__12;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__1;  // explode_transposeTensor_4_output_output_48 > multiplyTensors_38_arrayA size:= 8*int defined in Core0
extern int *const arrayB_304__arrayB__0;  // explode_generateTensors_arrayB_arrayB_304 > multiplyTensors_38_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__14;  // multiplyTensors_38_arrayC > implode_sumResults_4_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_38__implode___0;  // multiplyTensors_38 > implode_sumResults_4_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__8;  // explode_transposeTensor_5_output_output_40 > multiplyTensors_45_arrayA size:= 8*int defined in Core0
extern int *const arrayB_360__arrayB__0;  // explode_generateTensors_arrayB_arrayB_360 > multiplyTensors_45_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__5;  // multiplyTensors_45_arrayC > implode_sumResults_5_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_45__implode___0;  // multiplyTensors_45 > implode_sumResults_5_input size:= 256*char defined in Core0
extern char *const multiplyTensors_48__implode___0;  // multiplyTensors_48 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_49__implode___0;  // multiplyTensors_49 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_50__implode___0;  // multiplyTensors_50 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_51__implode___0;  // multiplyTensors_51 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_52__implode___0;  // multiplyTensors_52 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_53__implode___0;  // multiplyTensors_53 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_54__implode___0;  // multiplyTensors_54 > implode_sumResults_6_input size:= 256*char defined in Core0
extern char *const multiplyTensors_55__implode___0;  // multiplyTensors_55 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__5;  // explode_transposeTensor_8_output_output_8 > multiplyTensors_65_arrayA size:= 8*int defined in Core0
extern int *const arrayB_520__arrayB__0;  // explode_generateTensors_arrayB_arrayB_520 > multiplyTensors_65_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__1;  // multiplyTensors_65_arrayC > implode_sumResults_8_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_65__implode___0;  // multiplyTensors_65 > implode_sumResults_8_input size:= 256*char defined in Core0
extern char *const multiplyTensors_72__implode___0;  // multiplyTensors_72 > implode_sumResults_9_input size:= 256*char defined in Core0
extern int *const arrayB_584__arrayB__0;  // explode_generateTensors_arrayB_arrayB_584 > multiplyTensors_73_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__8;  // multiplyTensors_73_arrayC > implode_sumResults_9_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_74__implode___0;  // multiplyTensors_74 > implode_sumResults_9_input size:= 256*char defined in Core0
extern char *const multiplyTensors_75__implode___0;  // multiplyTensors_75 > implode_sumResults_9_input size:= 256*char defined in Core0
extern char *const multiplyTensors_76__implode___0;  // multiplyTensors_76 > implode_sumResults_9_input size:= 256*char defined in Core0
extern char *const multiplyTensors_77__implode___0;  // multiplyTensors_77 > implode_sumResults_9_input size:= 256*char defined in Core0
extern int *const arrayB_624__arrayB__0;  // explode_generateTensors_arrayB_arrayB_624 > multiplyTensors_78_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__11;  // multiplyTensors_78_arrayC > implode_sumResults_9_input_input_384 size:= 64*long defined in Core0
extern int *const arrayB_632__arrayB__0;  // explode_generateTensors_arrayB_arrayB_632 > multiplyTensors_79_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__10;  // multiplyTensors_79_arrayC > implode_sumResults_9_input_input_448 size:= 64*long defined in Core0
extern int *const output_32__arrayA__5;  // explode_transposeTensor_10_output_output_32 > multiplyTensors_84_arrayA size:= 8*int defined in Core0
extern int *const arrayB_672__arrayB__0;  // explode_generateTensors_arrayB_arrayB_672 > multiplyTensors_84_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__13;  // multiplyTensors_84_arrayC > implode_sumResults_10_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_84__implode___0;  // multiplyTensors_84 > implode_sumResults_10_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__13;  // explode_transposeTensor_12_output_output_16 > multiplyTensors_98_arrayA size:= 8*int defined in Core0
extern int *const arrayB_784__arrayB__0;  // explode_generateTensors_arrayB_arrayB_784 > multiplyTensors_98_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__12;  // multiplyTensors_98_arrayC > implode_sumResults_12_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_98__implode___0;  // multiplyTensors_98 > implode_sumResults_12_input size:= 256*char defined in Core0
extern long *const arrayC__input_0__9;  // multiplyTensors_48_arrayC > implode_sumResults_6_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__9;  // multiplyTensors_49_arrayC > implode_sumResults_6_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__3;  // multiplyTensors_50_arrayC > implode_sumResults_6_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__4;  // multiplyTensors_51_arrayC > implode_sumResults_6_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__2;  // multiplyTensors_52_arrayC > implode_sumResults_6_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__7;  // multiplyTensors_53_arrayC > implode_sumResults_6_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__1;  // multiplyTensors_54_arrayC > implode_sumResults_6_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__14;  // multiplyTensors_55_arrayC > implode_sumResults_6_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__7;  // implode_sumResults_6_input_arrayC > sumResults_6_input size:= 512*long defined in Core0
extern char *const implode_sumResults_6_input____0;  // implode_sumResults_6_input > sumResults_6 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__4;  // multiplyTensors_72_arrayC > implode_sumResults_9_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_128__0;  // multiplyTensors_74_arrayC > implode_sumResults_9_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__2;  // multiplyTensors_75_arrayC > implode_sumResults_9_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__15;  // multiplyTensors_76_arrayC > implode_sumResults_9_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__15;  // multiplyTensors_77_arrayC > implode_sumResults_9_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input__4;  // implode_sumResults_9_input_arrayC > sumResults_9_input size:= 512*long defined in Core0
extern long *const output__arrayC_576__0;  // sumResults_9_output > implode_displayTensor_arrayC_arrayC_576 size:= 64*long defined in Core0
extern char *const sumResults_9__implode_displa__0;  // sumResults_9 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core2(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core2: explode_generateTensors_arra__109 
		receiveEnd(0); // Core0 > Core2: explode_generateTensors_arra__109 
		cache_inv(explode_generateTensors_arra__109, 256*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__14 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__14 
		cache_inv(explode_generateTensors_arra__14, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__47 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__47 
		cache_inv(explode_generateTensors_arra__47, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__141 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__141 
		cache_inv(explode_generateTensors_arra__141, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__65 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__65 
		cache_inv(explode_generateTensors_arra__65, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__103 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__103 
		cache_inv(explode_generateTensors_arra__103, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__20 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__20 
		cache_inv(explode_generateTensors_arra__20, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__51 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__51 
		cache_inv(explode_generateTensors_arra__51, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__4 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__4 
		cache_inv(explode_generateTensors_arra__4, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__22 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__22 
		cache_inv(explode_generateTensors_arra__22, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__56 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__56 
		cache_inv(explode_generateTensors_arra__56, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__122 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__122 
		cache_inv(explode_generateTensors_arra__122, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__2 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__2 
		cache_inv(explode_generateTensors_arra__2, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__15 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__15 
		cache_inv(explode_generateTensors_arra__15, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_generateTensors_arra__29 
		receiveEnd(7); // Core7 > Core2: explode_generateTensors_arra__29 
		cache_inv(explode_generateTensors_arra__29, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: transposeTensor_0__explode_t__0 
		receiveEnd(5); // Core5 > Core2: transposeTensor_0__explode_t__0 
		cache_inv(transposeTensor_0__explode_t__0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_768__input__0,output__arrayA__12); // transposeTensor_12
		cache_inv(arrayA_768__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_12__explode___0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: transposeTensor_12__explode___0 
		sendEnd(); // Core2 > Core6: transposeTensor_12__explode___0 
		receiveStart(); // Core1 > Core2: transposeTensor_9__explode_t__0 
		receiveEnd(1); // Core1 > Core2: transposeTensor_9__explode_t__0 
		cache_inv(transposeTensor_9__explode_t__0, 256*sizeof(char));
		// Fork explode_transposeTensor_0_output
		{
			memcpy((void*)(output_0__arrayA__3+0),(void*)( output__arrayA__13+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__14+0),(void*)( output__arrayA__13+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__3+0),(void*)( output__arrayA__13+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__7+0),(void*)( output__arrayA__13+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__15+0),(void*)( output__arrayA__13+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__3+0),(void*)( output__arrayA__13+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__4+0),(void*)( output__arrayA__13+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__8+0),(void*)( output__arrayA__13+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__13, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_0_ou__4, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_0_ou__4 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_0_ou__4 
		cache_wbInv(explode_transposeTensor_0_ou__2, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: explode_transposeTensor_0_ou__2 
		sendEnd(); // Core2 > Core5: explode_transposeTensor_0_ou__2 
		cache_wbInv(explode_transposeTensor_0_ou__1, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_0_ou__1 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_0_ou__1 
		cache_wbInv(explode_transposeTensor_0_ou__7, 32*sizeof(char));
		sendStart(5); // Core2 > Core5: explode_transposeTensor_0_ou__7 
		sendEnd(); // Core2 > Core5: explode_transposeTensor_0_ou__7 
		cache_wbInv(explode_transposeTensor_0_ou__0, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_0_ou__0 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_0_ou__0 
		receiveStart(); // Core4 > Core2: explode_transposeTensor_10_o__2 
		receiveEnd(4); // Core4 > Core2: explode_transposeTensor_10_o__2 
		cache_inv(explode_transposeTensor_10_o__2, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: explode_transposeTensor_12_o__6 
		receiveEnd(6); // Core6 > Core2: explode_transposeTensor_12_o__6 
		cache_inv(explode_transposeTensor_12_o__6, 32*sizeof(char));
		receiveStart(); // Core6 > Core2: explode_transposeTensor_12_o__7 
		receiveEnd(6); // Core6 > Core2: explode_transposeTensor_12_o__7 
		cache_inv(explode_transposeTensor_12_o__7, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: explode_transposeTensor_14_o__2 
		receiveEnd(5); // Core5 > Core2: explode_transposeTensor_14_o__2 
		cache_inv(explode_transposeTensor_14_o__2, 32*sizeof(char));
		receiveStart(); // Core5 > Core2: explode_transposeTensor_14_o__5 
		receiveEnd(5); // Core5 > Core2: explode_transposeTensor_14_o__5 
		cache_inv(explode_transposeTensor_14_o__5, 32*sizeof(char));
		receiveStart(); // Core7 > Core2: explode_transposeTensor_4_ou__3 
		receiveEnd(7); // Core7 > Core2: explode_transposeTensor_4_ou__3 
		cache_inv(explode_transposeTensor_4_ou__3, 32*sizeof(char));
		receiveStart(); // Core1 > Core2: explode_transposeTensor_5_ou__1 
		receiveEnd(1); // Core1 > Core2: explode_transposeTensor_5_ou__1 
		cache_inv(explode_transposeTensor_5_ou__1, 32*sizeof(char));
		receiveStart(); // Core0 > Core2: explode_transposeTensor_8_ou__5 
		receiveEnd(0); // Core0 > Core2: explode_transposeTensor_8_ou__5 
		cache_inv(explode_transposeTensor_8_ou__5, 32*sizeof(char));
		// Fork explode_transposeTensor_9_output
		{
			memcpy((void*)(output_0__arrayA__6+0),(void*)( output__arrayA__0+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__2+0),(void*)( output__arrayA__0+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__11+0),(void*)( output__arrayA__0+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__6+0),(void*)( output__arrayA__0+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__7+0),(void*)( output__arrayA__0+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__13+0),(void*)( output__arrayA__0+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__7+0),(void*)( output__arrayA__0+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__11+0),(void*)( output__arrayA__0+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__0, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_9_ou__6, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_9_ou__6 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_9_ou__6 
		cache_wbInv(explode_transposeTensor_9_ou__3, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_9_ou__3 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_9_ou__3 
		cache_wbInv(explode_transposeTensor_9_ou__1, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_9_ou__1 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_9_ou__1 
		cache_wbInv(explode_transposeTensor_9_ou__5, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_9_ou__5 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_9_ou__5 
		cache_wbInv(explode_transposeTensor_9_ou__4, 32*sizeof(char));
		sendStart(1); // Core2 > Core1: explode_transposeTensor_9_ou__4 
		sendEnd(); // Core2 > Core1: explode_transposeTensor_9_ou__4 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__3,arrayB_0__arrayB__0,arrayC__input_0__1); // multiplyTensors_0
		cache_inv(output_0__arrayA__3, 8*sizeof(int));
		cache_inv(arrayB_0__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_0__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_0__implode_s__0 
		sendEnd(); // Core2 > Core5: multiplyTensors_0__implode_s__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__14,arrayB_8__arrayB__0,arrayC__input_64__0); // multiplyTensors_1
		cache_inv(output_8__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_8__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_1__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_1__implode_s__0 
		sendEnd(); // Core2 > Core5: multiplyTensors_1__implode_s__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__12,arrayB_824__arrayB__0,arrayC__input_448__11); // multiplyTensors_103
		cache_inv(output_56__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_824__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_103__implode__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiplyTensors_103__implode__0 
		sendEnd(); // Core2 > Core4: multiplyTensors_103__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__10,arrayB_904__arrayB__0,arrayC__input_64__10); // multiplyTensors_113
		cache_inv(output_8__arrayA__10, 8*sizeof(int));
		cache_inv(arrayB_904__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_113__implode__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_113__implode__0 
		sendEnd(); // Core2 > Core6: multiplyTensors_113__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__1,arrayB_936__arrayB__0,arrayC__input_320__10); // multiplyTensors_117
		cache_inv(output_40__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_936__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_117__implode__0, 256*sizeof(char));
		sendStart(6); // Core2 > Core6: multiplyTensors_117__implode__0 
		sendEnd(); // Core2 > Core6: multiplyTensors_117__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__7,arrayB_24__arrayB__0,arrayC__input_192__12); // multiplyTensors_3
		cache_inv(output_24__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_24__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_3__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core2 > Core5: multiplyTensors_3__implode_s__0 
		sendEnd(); // Core2 > Core5: multiplyTensors_3__implode_s__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__1,arrayB_304__arrayB__0,arrayC__input_384__14); // multiplyTensors_38
		cache_inv(output_48__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_304__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_38__implode___0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiplyTensors_38__implode___0 
		sendEnd(); // Core2 > Core4: multiplyTensors_38__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__8,arrayB_360__arrayB__0,arrayC__input_320__5); // multiplyTensors_45
		cache_inv(output_40__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_360__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_45__implode___0, 256*sizeof(char));
		sendStart(3); // Core2 > Core3: multiplyTensors_45__implode___0 
		sendEnd(); // Core2 > Core3: multiplyTensors_45__implode___0 
		receiveStart(); // Core3 > Core2: multiplyTensors_48__implode___0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_48__implode___0 
		cache_inv(multiplyTensors_48__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: multiplyTensors_49__implode___0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_49__implode___0 
		cache_inv(multiplyTensors_49__implode___0, 256*sizeof(char));
		receiveStart(); // Core6 > Core2: multiplyTensors_50__implode___0 
		receiveEnd(6); // Core6 > Core2: multiplyTensors_50__implode___0 
		cache_inv(multiplyTensors_50__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: multiplyTensors_51__implode___0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_51__implode___0 
		cache_inv(multiplyTensors_51__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: multiplyTensors_52__implode___0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_52__implode___0 
		cache_inv(multiplyTensors_52__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: multiplyTensors_53__implode___0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_53__implode___0 
		cache_inv(multiplyTensors_53__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: multiplyTensors_54__implode___0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_54__implode___0 
		cache_inv(multiplyTensors_54__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core2: multiplyTensors_55__implode___0 
		receiveEnd(3); // Core3 > Core2: multiplyTensors_55__implode___0 
		cache_inv(multiplyTensors_55__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__5,arrayB_520__arrayB__0,arrayC__input_64__1); // multiplyTensors_65
		cache_inv(output_8__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_520__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_65__implode___0, 256*sizeof(char));
		sendStart(7); // Core2 > Core7: multiplyTensors_65__implode___0 
		sendEnd(); // Core2 > Core7: multiplyTensors_65__implode___0 
		receiveStart(); // Core1 > Core2: multiplyTensors_72__implode___0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_72__implode___0 
		cache_inv(multiplyTensors_72__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__2,arrayB_584__arrayB__0,arrayC__input_64__8); // multiplyTensors_73
		cache_inv(output_8__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_584__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core1 > Core2: multiplyTensors_74__implode___0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_74__implode___0 
		cache_inv(multiplyTensors_74__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: multiplyTensors_75__implode___0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_75__implode___0 
		cache_inv(multiplyTensors_75__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: multiplyTensors_76__implode___0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_76__implode___0 
		cache_inv(multiplyTensors_76__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core2: multiplyTensors_77__implode___0 
		receiveEnd(1); // Core1 > Core2: multiplyTensors_77__implode___0 
		cache_inv(multiplyTensors_77__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__7,arrayB_624__arrayB__0,arrayC__input_384__11); // multiplyTensors_78
		cache_inv(output_48__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_624__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__11,arrayB_632__arrayB__0,arrayC__input_448__10); // multiplyTensors_79
		cache_inv(output_56__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_632__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__5,arrayB_672__arrayB__0,arrayC__input_256__13); // multiplyTensors_84
		cache_inv(output_32__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_672__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_84__implode___0, 256*sizeof(char));
		sendStart(0); // Core2 > Core0: multiplyTensors_84__implode___0 
		sendEnd(); // Core2 > Core0: multiplyTensors_84__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__13,arrayB_784__arrayB__0,arrayC__input_128__12); // multiplyTensors_98
		cache_inv(output_16__arrayA__13, 8*sizeof(int));
		cache_inv(arrayB_784__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_98__implode___0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: multiplyTensors_98__implode___0 
		sendEnd(); // Core2 > Core4: multiplyTensors_98__implode___0 
		// Join implode_sumResults_6_input
		{
			memcpy((void*)(arrayC__input__7+0),(void*)( arrayC__input_0__9+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__7+64),(void*)( arrayC__input_64__9+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__7+128),(void*)( arrayC__input_128__3+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__7+192),(void*)( arrayC__input_192__4+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__7+256),(void*)( arrayC__input_256__2+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__7+320),(void*)( arrayC__input_320__7+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__7+384),(void*)( arrayC__input_384__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__7+448),(void*)( arrayC__input_448__14+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__9, 64*sizeof(long));
		cache_inv(arrayC__input_64__9, 64*sizeof(long));
		cache_inv(arrayC__input_128__3, 64*sizeof(long));
		cache_inv(arrayC__input_192__4, 64*sizeof(long));
		cache_inv(arrayC__input_256__2, 64*sizeof(long));
		cache_inv(arrayC__input_320__7, 64*sizeof(long));
		cache_inv(arrayC__input_384__1, 64*sizeof(long));
		cache_inv(arrayC__input_448__14, 64*sizeof(long));
		cache_wbInv(implode_sumResults_6_input____0, 2048*sizeof(char));
		sendStart(3); // Core2 > Core3: implode_sumResults_6_input____0 
		sendEnd(); // Core2 > Core3: implode_sumResults_6_input____0 
		// Join implode_sumResults_9_input
		{
			memcpy((void*)(arrayC__input__4+0),(void*)( arrayC__input_0__4+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__4+64),(void*)( arrayC__input_64__8+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__4+128),(void*)( arrayC__input_128__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__4+192),(void*)( arrayC__input_192__2+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__4+256),(void*)( arrayC__input_256__15+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__4+320),(void*)( arrayC__input_320__15+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__4+384),(void*)( arrayC__input_384__11+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__4+448),(void*)( arrayC__input_448__10+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__4, 64*sizeof(long));
		cache_inv(arrayC__input_64__8, 64*sizeof(long));
		cache_inv(arrayC__input_128__0, 64*sizeof(long));
		cache_inv(arrayC__input_192__2, 64*sizeof(long));
		cache_inv(arrayC__input_256__15, 64*sizeof(long));
		cache_inv(arrayC__input_320__15, 64*sizeof(long));
		cache_inv(arrayC__input_384__11, 64*sizeof(long));
		cache_inv(arrayC__input_448__10, 64*sizeof(long));
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__4,output__arrayC_576__0); // sumResults_9
		cache_inv(arrayC__input__4, 512*sizeof(long));
		cache_wbInv(sumResults_9__implode_displa__0, 256*sizeof(char));
		sendStart(4); // Core2 > Core4: sumResults_9__implode_displa__0 
		sendEnd(); // Core2 > Core4: sumResults_9__implode_displa__0 
	}
}
