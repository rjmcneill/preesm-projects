/** 
 * @file Core3.c
 * @generated by C6678CPrinter
 * @date Fri Apr 17 16:12:31 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__84;  // explode_generateTensors_arrayA > transposeTensor_6 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__107;  // explode_generateTensors_arrayA > transposeTensor_3 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__57;  // explode_generateTensors_arrayB > multiplyTensors_111 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__36;  // explode_generateTensors_arrayB > multiplyTensors_110 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__74;  // explode_generateTensors_arrayB > multiplyTensors_107 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__134;  // explode_generateTensors_arrayB > multiplyTensors_104 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__116;  // explode_generateTensors_arrayB > multiplyTensors_87 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__35;  // explode_generateTensors_arrayB > multiplyTensors_70 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__106;  // explode_generateTensors_arrayB > multiplyTensors_55 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__33;  // explode_generateTensors_arrayB > multiplyTensors_54 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__129;  // explode_generateTensors_arrayB > multiplyTensors_53 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__88;  // explode_generateTensors_arrayB > multiplyTensors_52 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__66;  // explode_generateTensors_arrayB > multiplyTensors_51 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__78;  // explode_generateTensors_arrayB > multiplyTensors_49 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__39;  // explode_generateTensors_arrayB > multiplyTensors_48 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__135;  // explode_generateTensors_arrayB > multiplyTensors_41 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__1;  // explode_generateTensors_arrayB > multiplyTensors_29 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__133;  // explode_generateTensors_arrayB > multiplyTensors_19 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__26;  // explode_generateTensors_arrayB > multiplyTensors_18 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__68;  // explode_generateTensors_arrayB > multiplyTensors_16 size:= 32*char defined in Core0
extern int *const arrayA_192__input__0;  // explode_generateTensors_arrayA_arrayA_192 > transposeTensor_3_input size:= 64*int defined in Core0
extern int *const output__arrayA__15;  // transposeTensor_3_output > explode_transposeTensor_3_output_arrayA size:= 64*int defined in Core0
extern int *const arrayA_384__input__0;  // explode_generateTensors_arrayA_arrayA_384 > transposeTensor_6_input size:= 64*int defined in Core0
extern int *const output__arrayA__3;  // transposeTensor_6_output > explode_transposeTensor_6_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_10_o__4;  // explode_transposeTensor_10_output > multiplyTensors_87 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__5;  // explode_transposeTensor_13_output > multiplyTensors_111 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__1;  // explode_transposeTensor_13_output > multiplyTensors_110 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__7;  // explode_transposeTensor_13_output > multiplyTensors_107 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__6;  // explode_transposeTensor_13_output > multiplyTensors_104 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__4;  // explode_transposeTensor_2_output > multiplyTensors_19 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__2;  // explode_transposeTensor_2_output > multiplyTensors_18 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_2_ou__7;  // explode_transposeTensor_2_output > multiplyTensors_16 size:= 32*char defined in Core0
extern int *const output_0__arrayA__5;  // explode_transposeTensor_3_output_output_0 > multiplyTensors_24_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__7;  // explode_transposeTensor_3_output_output_8 > multiplyTensors_25_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__1;  // explode_transposeTensor_3_output_output_16 > multiplyTensors_26_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__12;  // explode_transposeTensor_3_output_output_24 > multiplyTensors_27_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__4;  // explode_transposeTensor_3_output_output_32 > multiplyTensors_28_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__4;  // explode_transposeTensor_3_output_output_40 > multiplyTensors_29_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__13;  // explode_transposeTensor_3_output_output_48 > multiplyTensors_30_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__5;  // explode_transposeTensor_3_output_output_56 > multiplyTensors_31_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_3_ou__2;  // explode_transposeTensor_3_output > multiplyTensors_31 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__7;  // explode_transposeTensor_3_output > multiplyTensors_30 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__3;  // explode_transposeTensor_3_output > multiplyTensors_28 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__6;  // explode_transposeTensor_3_output > multiplyTensors_27 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__0;  // explode_transposeTensor_3_output > multiplyTensors_26 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__4;  // explode_transposeTensor_3_output > multiplyTensors_25 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__5;  // explode_transposeTensor_3_output > multiplyTensors_24 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__5;  // explode_transposeTensor_5_output > multiplyTensors_41 size:= 32*char defined in Core0
extern int *const output_0__arrayA__15;  // explode_transposeTensor_6_output_output_0 > multiplyTensors_48_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__4;  // explode_transposeTensor_6_output_output_8 > multiplyTensors_49_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__2;  // explode_transposeTensor_6_output_output_16 > multiplyTensors_50_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__4;  // explode_transposeTensor_6_output_output_24 > multiplyTensors_51_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__1;  // explode_transposeTensor_6_output_output_32 > multiplyTensors_52_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__11;  // explode_transposeTensor_6_output_output_40 > multiplyTensors_53_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__15;  // explode_transposeTensor_6_output_output_48 > multiplyTensors_54_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__10;  // explode_transposeTensor_6_output_output_56 > multiplyTensors_55_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_6_ou__0;  // explode_transposeTensor_6_output > multiplyTensors_50 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_8_ou__0;  // explode_transposeTensor_8_output > multiplyTensors_70 size:= 32*char defined in Core0
extern int *const output_0__arrayA__13;  // explode_transposeTensor_13_output_output_0 > multiplyTensors_104_arrayA size:= 8*int defined in Core0
extern int *const arrayB_832__arrayB__0;  // explode_generateTensors_arrayB_arrayB_832 > multiplyTensors_104_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__6;  // multiplyTensors_104_arrayC > implode_sumResults_13_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_105__implode__0;  // multiplyTensors_105 > implode_sumResults_13_input size:= 256*char defined in Core0
extern char *const multiplyTensors_106__implode__0;  // multiplyTensors_106 > implode_sumResults_13_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__15;  // explode_transposeTensor_13_output_output_24 > multiplyTensors_107_arrayA size:= 8*int defined in Core0
extern int *const arrayB_856__arrayB__0;  // explode_generateTensors_arrayB_arrayB_856 > multiplyTensors_107_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__11;  // multiplyTensors_107_arrayC > implode_sumResults_13_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_108__implode__0;  // multiplyTensors_108 > implode_sumResults_13_input size:= 256*char defined in Core0
extern char *const multiplyTensors_109__implode__0;  // multiplyTensors_109 > implode_sumResults_13_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__5;  // explode_transposeTensor_13_output_output_48 > multiplyTensors_110_arrayA size:= 8*int defined in Core0
extern int *const arrayB_880__arrayB__0;  // explode_generateTensors_arrayB_arrayB_880 > multiplyTensors_110_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__10;  // multiplyTensors_110_arrayC > implode_sumResults_13_input_input_384 size:= 64*long defined in Core0
extern int *const output_56__arrayA__14;  // explode_transposeTensor_13_output_output_56 > multiplyTensors_111_arrayA size:= 8*int defined in Core0
extern int *const arrayB_888__arrayB__0;  // explode_generateTensors_arrayB_arrayB_888 > multiplyTensors_111_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__9;  // multiplyTensors_111_arrayC > implode_sumResults_13_input_input_448 size:= 64*long defined in Core0
extern int *const output_0__arrayA__14;  // explode_transposeTensor_2_output_output_0 > multiplyTensors_16_arrayA size:= 8*int defined in Core0
extern int *const arrayB_128__arrayB__0;  // explode_generateTensors_arrayB_arrayB_128 > multiplyTensors_16_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__12;  // multiplyTensors_16_arrayC > implode_sumResults_2_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_16__implode___0;  // multiplyTensors_16 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__9;  // explode_transposeTensor_2_output_output_16 > multiplyTensors_18_arrayA size:= 8*int defined in Core0
extern int *const arrayB_144__arrayB__0;  // explode_generateTensors_arrayB_arrayB_144 > multiplyTensors_18_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__10;  // multiplyTensors_18_arrayC > implode_sumResults_2_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_18__implode___0;  // multiplyTensors_18 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__10;  // explode_transposeTensor_2_output_output_24 > multiplyTensors_19_arrayA size:= 8*int defined in Core0
extern int *const arrayB_152__arrayB__0;  // explode_generateTensors_arrayB_arrayB_152 > multiplyTensors_19_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__5;  // multiplyTensors_19_arrayC > implode_sumResults_2_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_19__implode___0;  // multiplyTensors_19 > implode_sumResults_2_input size:= 256*char defined in Core0
extern int *const arrayB_232__arrayB__0;  // explode_generateTensors_arrayB_arrayB_232 > multiplyTensors_29_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__1;  // multiplyTensors_29_arrayC > implode_sumResults_3_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_29__implode___0;  // multiplyTensors_29 > implode_sumResults_3_input size:= 256*char defined in Core0
extern char *const multiplyTensors_40__implode___0;  // multiplyTensors_40 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__12;  // explode_transposeTensor_5_output_output_8 > multiplyTensors_41_arrayA size:= 8*int defined in Core0
extern int *const arrayB_328__arrayB__0;  // explode_generateTensors_arrayB_arrayB_328 > multiplyTensors_41_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__15;  // multiplyTensors_41_arrayC > implode_sumResults_5_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_42__implode___0;  // multiplyTensors_42 > implode_sumResults_5_input size:= 256*char defined in Core0
extern char *const multiplyTensors_43__implode___0;  // multiplyTensors_43 > implode_sumResults_5_input size:= 256*char defined in Core0
extern char *const multiplyTensors_44__implode___0;  // multiplyTensors_44 > implode_sumResults_5_input size:= 256*char defined in Core0
extern char *const multiplyTensors_45__implode___0;  // multiplyTensors_45 > implode_sumResults_5_input size:= 256*char defined in Core0
extern char *const multiplyTensors_46__implode___0;  // multiplyTensors_46 > implode_sumResults_5_input size:= 256*char defined in Core0
extern char *const multiplyTensors_47__implode___0;  // multiplyTensors_47 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const arrayB_384__arrayB__0;  // explode_generateTensors_arrayB_arrayB_384 > multiplyTensors_48_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__9;  // multiplyTensors_48_arrayC > implode_sumResults_6_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_48__implode___0;  // multiplyTensors_48 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const arrayB_392__arrayB__0;  // explode_generateTensors_arrayB_arrayB_392 > multiplyTensors_49_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__9;  // multiplyTensors_49_arrayC > implode_sumResults_6_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_49__implode___0;  // multiplyTensors_49 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const arrayB_408__arrayB__0;  // explode_generateTensors_arrayB_arrayB_408 > multiplyTensors_51_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__4;  // multiplyTensors_51_arrayC > implode_sumResults_6_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_51__implode___0;  // multiplyTensors_51 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const arrayB_416__arrayB__0;  // explode_generateTensors_arrayB_arrayB_416 > multiplyTensors_52_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__2;  // multiplyTensors_52_arrayC > implode_sumResults_6_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_52__implode___0;  // multiplyTensors_52 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const arrayB_424__arrayB__0;  // explode_generateTensors_arrayB_arrayB_424 > multiplyTensors_53_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__7;  // multiplyTensors_53_arrayC > implode_sumResults_6_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_53__implode___0;  // multiplyTensors_53 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const arrayB_432__arrayB__0;  // explode_generateTensors_arrayB_arrayB_432 > multiplyTensors_54_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__1;  // multiplyTensors_54_arrayC > implode_sumResults_6_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_54__implode___0;  // multiplyTensors_54 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const arrayB_440__arrayB__0;  // explode_generateTensors_arrayB_arrayB_440 > multiplyTensors_55_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__14;  // multiplyTensors_55_arrayC > implode_sumResults_6_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_55__implode___0;  // multiplyTensors_55 > implode_sumResults_6_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__3;  // explode_transposeTensor_8_output_output_48 > multiplyTensors_70_arrayA size:= 8*int defined in Core0
extern int *const arrayB_560__arrayB__0;  // explode_generateTensors_arrayB_arrayB_560 > multiplyTensors_70_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__3;  // multiplyTensors_70_arrayC > implode_sumResults_8_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_70__implode___0;  // multiplyTensors_70 > implode_sumResults_8_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__9;  // explode_transposeTensor_10_output_output_56 > multiplyTensors_87_arrayA size:= 8*int defined in Core0
extern int *const arrayB_696__arrayB__0;  // explode_generateTensors_arrayB_arrayB_696 > multiplyTensors_87_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__8;  // multiplyTensors_87_arrayC > implode_sumResults_10_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_87__implode___0;  // multiplyTensors_87 > implode_sumResults_10_input size:= 256*char defined in Core0
extern long *const arrayC__input_64__2;  // multiplyTensors_105_arrayC > implode_sumResults_13_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__5;  // multiplyTensors_106_arrayC > implode_sumResults_13_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_256__4;  // multiplyTensors_108_arrayC > implode_sumResults_13_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__8;  // multiplyTensors_109_arrayC > implode_sumResults_13_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input__14;  // implode_sumResults_13_input_arrayC > sumResults_13_input size:= 512*long defined in Core0
extern char *const implode_sumResults_13_input___0;  // implode_sumResults_13_input > sumResults_13 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__15;  // multiplyTensors_40_arrayC > implode_sumResults_5_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_128__9;  // multiplyTensors_42_arrayC > implode_sumResults_5_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__3;  // multiplyTensors_43_arrayC > implode_sumResults_5_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__11;  // multiplyTensors_44_arrayC > implode_sumResults_5_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__5;  // multiplyTensors_45_arrayC > implode_sumResults_5_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__5;  // multiplyTensors_46_arrayC > implode_sumResults_5_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__12;  // multiplyTensors_47_arrayC > implode_sumResults_5_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__8;  // implode_sumResults_5_input_arrayC > sumResults_5_input size:= 512*long defined in Core0
extern char *const implode_sumResults_6_input____0;  // implode_sumResults_6_input > sumResults_6 size:= 2048*char defined in Core0
extern long *const output__arrayC_320__0;  // sumResults_5_output > implode_displayTensor_arrayC_arrayC_320 size:= 64*long defined in Core0
extern char *const sumResults_5__implode_displa__0;  // sumResults_5 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__7;  // implode_sumResults_6_input_arrayC > sumResults_6_input size:= 512*long defined in Core0
extern long *const output__arrayC_384__0;  // sumResults_6_output > implode_displayTensor_arrayC_arrayC_384 size:= 64*long defined in Core0
extern char *const sumResults_6__implode_displa__0;  // sumResults_6 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core3(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core3: explode_generateTensors_arra__84 
		receiveEnd(0); // Core0 > Core3: explode_generateTensors_arra__84 
		cache_inv(explode_generateTensors_arra__84, 256*sizeof(char));
		receiveStart(); // Core0 > Core3: explode_generateTensors_arra__107 
		receiveEnd(0); // Core0 > Core3: explode_generateTensors_arra__107 
		cache_inv(explode_generateTensors_arra__107, 256*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__57 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__57 
		cache_inv(explode_generateTensors_arra__57, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__36 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__36 
		cache_inv(explode_generateTensors_arra__36, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__74 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__74 
		cache_inv(explode_generateTensors_arra__74, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__134 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__134 
		cache_inv(explode_generateTensors_arra__134, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__116 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__116 
		cache_inv(explode_generateTensors_arra__116, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__35 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__35 
		cache_inv(explode_generateTensors_arra__35, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__106 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__106 
		cache_inv(explode_generateTensors_arra__106, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__33 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__33 
		cache_inv(explode_generateTensors_arra__33, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__129 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__129 
		cache_inv(explode_generateTensors_arra__129, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__88 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__88 
		cache_inv(explode_generateTensors_arra__88, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__66 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__66 
		cache_inv(explode_generateTensors_arra__66, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__78 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__78 
		cache_inv(explode_generateTensors_arra__78, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__39 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__39 
		cache_inv(explode_generateTensors_arra__39, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__135 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__135 
		cache_inv(explode_generateTensors_arra__135, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__1 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__1 
		cache_inv(explode_generateTensors_arra__1, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__133 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__133 
		cache_inv(explode_generateTensors_arra__133, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__26 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__26 
		cache_inv(explode_generateTensors_arra__26, 32*sizeof(char));
		receiveStart(); // Core7 > Core3: explode_generateTensors_arra__68 
		receiveEnd(7); // Core7 > Core3: explode_generateTensors_arra__68 
		cache_inv(explode_generateTensors_arra__68, 32*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_192__input__0,output__arrayA__15); // transposeTensor_3
		cache_inv(arrayA_192__input__0, 64*sizeof(int));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_384__input__0,output__arrayA__3); // transposeTensor_6
		cache_inv(arrayA_384__input__0, 64*sizeof(int));
		receiveStart(); // Core4 > Core3: explode_transposeTensor_10_o__4 
		receiveEnd(4); // Core4 > Core3: explode_transposeTensor_10_o__4 
		cache_inv(explode_transposeTensor_10_o__4, 32*sizeof(char));
		receiveStart(); // Core5 > Core3: explode_transposeTensor_13_o__5 
		receiveEnd(5); // Core5 > Core3: explode_transposeTensor_13_o__5 
		cache_inv(explode_transposeTensor_13_o__5, 32*sizeof(char));
		receiveStart(); // Core5 > Core3: explode_transposeTensor_13_o__1 
		receiveEnd(5); // Core5 > Core3: explode_transposeTensor_13_o__1 
		cache_inv(explode_transposeTensor_13_o__1, 32*sizeof(char));
		receiveStart(); // Core5 > Core3: explode_transposeTensor_13_o__7 
		receiveEnd(5); // Core5 > Core3: explode_transposeTensor_13_o__7 
		cache_inv(explode_transposeTensor_13_o__7, 32*sizeof(char));
		receiveStart(); // Core5 > Core3: explode_transposeTensor_13_o__6 
		receiveEnd(5); // Core5 > Core3: explode_transposeTensor_13_o__6 
		cache_inv(explode_transposeTensor_13_o__6, 32*sizeof(char));
		receiveStart(); // Core6 > Core3: explode_transposeTensor_2_ou__4 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_2_ou__4 
		cache_inv(explode_transposeTensor_2_ou__4, 32*sizeof(char));
		receiveStart(); // Core6 > Core3: explode_transposeTensor_2_ou__2 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_2_ou__2 
		cache_inv(explode_transposeTensor_2_ou__2, 32*sizeof(char));
		receiveStart(); // Core6 > Core3: explode_transposeTensor_2_ou__7 
		receiveEnd(6); // Core6 > Core3: explode_transposeTensor_2_ou__7 
		cache_inv(explode_transposeTensor_2_ou__7, 32*sizeof(char));
		// Fork explode_transposeTensor_3_output
		{
			memcpy((void*)(output_0__arrayA__5+0),(void*)( output__arrayA__15+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__7+0),(void*)( output__arrayA__15+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__1+0),(void*)( output__arrayA__15+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__12+0),(void*)( output__arrayA__15+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__4+0),(void*)( output__arrayA__15+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__4+0),(void*)( output__arrayA__15+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__13+0),(void*)( output__arrayA__15+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__5+0),(void*)( output__arrayA__15+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__15, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_3_ou__2, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_3_ou__2 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_3_ou__2 
		cache_wbInv(explode_transposeTensor_3_ou__7, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_3_ou__7 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_3_ou__7 
		cache_wbInv(explode_transposeTensor_3_ou__3, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_3_ou__3 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_3_ou__3 
		cache_wbInv(explode_transposeTensor_3_ou__6, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_3_ou__6 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_3_ou__6 
		cache_wbInv(explode_transposeTensor_3_ou__0, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_3_ou__0 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_3_ou__0 
		cache_wbInv(explode_transposeTensor_3_ou__4, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_3_ou__4 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_3_ou__4 
		cache_wbInv(explode_transposeTensor_3_ou__5, 32*sizeof(char));
		sendStart(5); // Core3 > Core5: explode_transposeTensor_3_ou__5 
		sendEnd(); // Core3 > Core5: explode_transposeTensor_3_ou__5 
		receiveStart(); // Core1 > Core3: explode_transposeTensor_5_ou__5 
		receiveEnd(1); // Core1 > Core3: explode_transposeTensor_5_ou__5 
		cache_inv(explode_transposeTensor_5_ou__5, 32*sizeof(char));
		// Fork explode_transposeTensor_6_output
		{
			memcpy((void*)(output_0__arrayA__15+0),(void*)( output__arrayA__3+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__4+0),(void*)( output__arrayA__3+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__2+0),(void*)( output__arrayA__3+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__4+0),(void*)( output__arrayA__3+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__1+0),(void*)( output__arrayA__3+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__11+0),(void*)( output__arrayA__3+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__15+0),(void*)( output__arrayA__3+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__10+0),(void*)( output__arrayA__3+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__3, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_6_ou__0, 32*sizeof(char));
		sendStart(6); // Core3 > Core6: explode_transposeTensor_6_ou__0 
		sendEnd(); // Core3 > Core6: explode_transposeTensor_6_ou__0 
		receiveStart(); // Core0 > Core3: explode_transposeTensor_8_ou__0 
		receiveEnd(0); // Core0 > Core3: explode_transposeTensor_8_ou__0 
		cache_inv(explode_transposeTensor_8_ou__0, 32*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__13,arrayB_832__arrayB__0,arrayC__input_0__6); // multiplyTensors_104
		cache_inv(output_0__arrayA__13, 8*sizeof(int));
		cache_inv(arrayB_832__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core5 > Core3: multiplyTensors_105__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_105__implode__0 
		cache_inv(multiplyTensors_105__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_106__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_106__implode__0 
		cache_inv(multiplyTensors_106__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__15,arrayB_856__arrayB__0,arrayC__input_192__11); // multiplyTensors_107
		cache_inv(output_24__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_856__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core5 > Core3: multiplyTensors_108__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_108__implode__0 
		cache_inv(multiplyTensors_108__implode__0, 256*sizeof(char));
		receiveStart(); // Core5 > Core3: multiplyTensors_109__implode__0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_109__implode__0 
		cache_inv(multiplyTensors_109__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__5,arrayB_880__arrayB__0,arrayC__input_384__10); // multiplyTensors_110
		cache_inv(output_48__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_880__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__14,arrayB_888__arrayB__0,arrayC__input_448__9); // multiplyTensors_111
		cache_inv(output_56__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_888__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__14,arrayB_128__arrayB__0,arrayC__input_0__12); // multiplyTensors_16
		cache_inv(output_0__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_128__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_16__implode___0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: multiplyTensors_16__implode___0 
		sendEnd(); // Core3 > Core7: multiplyTensors_16__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__9,arrayB_144__arrayB__0,arrayC__input_128__10); // multiplyTensors_18
		cache_inv(output_16__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_144__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_18__implode___0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: multiplyTensors_18__implode___0 
		sendEnd(); // Core3 > Core7: multiplyTensors_18__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__10,arrayB_152__arrayB__0,arrayC__input_192__5); // multiplyTensors_19
		cache_inv(output_24__arrayA__10, 8*sizeof(int));
		cache_inv(arrayB_152__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_19__implode___0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: multiplyTensors_19__implode___0 
		sendEnd(); // Core3 > Core7: multiplyTensors_19__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__4,arrayB_232__arrayB__0,arrayC__input_320__1); // multiplyTensors_29
		cache_inv(output_40__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_232__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_29__implode___0, 256*sizeof(char));
		sendStart(6); // Core3 > Core6: multiplyTensors_29__implode___0 
		sendEnd(); // Core3 > Core6: multiplyTensors_29__implode___0 
		receiveStart(); // Core6 > Core3: multiplyTensors_40__implode___0 
		receiveEnd(6); // Core6 > Core3: multiplyTensors_40__implode___0 
		cache_inv(multiplyTensors_40__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__12,arrayB_328__arrayB__0,arrayC__input_64__15); // multiplyTensors_41
		cache_inv(output_8__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_328__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core5 > Core3: multiplyTensors_42__implode___0 
		receiveEnd(5); // Core5 > Core3: multiplyTensors_42__implode___0 
		cache_inv(multiplyTensors_42__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core3: multiplyTensors_43__implode___0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_43__implode___0 
		cache_inv(multiplyTensors_43__implode___0, 256*sizeof(char));
		receiveStart(); // Core4 > Core3: multiplyTensors_44__implode___0 
		receiveEnd(4); // Core4 > Core3: multiplyTensors_44__implode___0 
		cache_inv(multiplyTensors_44__implode___0, 256*sizeof(char));
		receiveStart(); // Core2 > Core3: multiplyTensors_45__implode___0 
		receiveEnd(2); // Core2 > Core3: multiplyTensors_45__implode___0 
		cache_inv(multiplyTensors_45__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core3: multiplyTensors_46__implode___0 
		receiveEnd(1); // Core1 > Core3: multiplyTensors_46__implode___0 
		cache_inv(multiplyTensors_46__implode___0, 256*sizeof(char));
		receiveStart(); // Core4 > Core3: multiplyTensors_47__implode___0 
		receiveEnd(4); // Core4 > Core3: multiplyTensors_47__implode___0 
		cache_inv(multiplyTensors_47__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__15,arrayB_384__arrayB__0,arrayC__input_0__9); // multiplyTensors_48
		cache_inv(output_0__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_384__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_48__implode___0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_48__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_48__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__4,arrayB_392__arrayB__0,arrayC__input_64__9); // multiplyTensors_49
		cache_inv(output_8__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_392__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_49__implode___0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_49__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_49__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__4,arrayB_408__arrayB__0,arrayC__input_192__4); // multiplyTensors_51
		cache_inv(output_24__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_408__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_51__implode___0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_51__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_51__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__1,arrayB_416__arrayB__0,arrayC__input_256__2); // multiplyTensors_52
		cache_inv(output_32__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_416__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_52__implode___0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_52__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_52__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__11,arrayB_424__arrayB__0,arrayC__input_320__7); // multiplyTensors_53
		cache_inv(output_40__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_424__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_53__implode___0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_53__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_53__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__15,arrayB_432__arrayB__0,arrayC__input_384__1); // multiplyTensors_54
		cache_inv(output_48__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_432__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_54__implode___0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_54__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_54__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__10,arrayB_440__arrayB__0,arrayC__input_448__14); // multiplyTensors_55
		cache_inv(output_56__arrayA__10, 8*sizeof(int));
		cache_inv(arrayB_440__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_55__implode___0, 256*sizeof(char));
		sendStart(2); // Core3 > Core2: multiplyTensors_55__implode___0 
		sendEnd(); // Core3 > Core2: multiplyTensors_55__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__3,arrayB_560__arrayB__0,arrayC__input_384__3); // multiplyTensors_70
		cache_inv(output_48__arrayA__3, 8*sizeof(int));
		cache_inv(arrayB_560__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_70__implode___0, 256*sizeof(char));
		sendStart(7); // Core3 > Core7: multiplyTensors_70__implode___0 
		sendEnd(); // Core3 > Core7: multiplyTensors_70__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__9,arrayB_696__arrayB__0,arrayC__input_448__8); // multiplyTensors_87
		cache_inv(output_56__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_696__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_87__implode___0, 256*sizeof(char));
		sendStart(0); // Core3 > Core0: multiplyTensors_87__implode___0 
		sendEnd(); // Core3 > Core0: multiplyTensors_87__implode___0 
		// Join implode_sumResults_13_input
		{
			memcpy((void*)(arrayC__input__14+0),(void*)( arrayC__input_0__6+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__14+64),(void*)( arrayC__input_64__2+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__14+128),(void*)( arrayC__input_128__5+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__14+192),(void*)( arrayC__input_192__11+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__14+256),(void*)( arrayC__input_256__4+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__14+320),(void*)( arrayC__input_320__8+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__14+384),(void*)( arrayC__input_384__10+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__14+448),(void*)( arrayC__input_448__9+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__6, 64*sizeof(long));
		cache_inv(arrayC__input_64__2, 64*sizeof(long));
		cache_inv(arrayC__input_128__5, 64*sizeof(long));
		cache_inv(arrayC__input_192__11, 64*sizeof(long));
		cache_inv(arrayC__input_256__4, 64*sizeof(long));
		cache_inv(arrayC__input_320__8, 64*sizeof(long));
		cache_inv(arrayC__input_384__10, 64*sizeof(long));
		cache_inv(arrayC__input_448__9, 64*sizeof(long));
		cache_wbInv(implode_sumResults_13_input___0, 2048*sizeof(char));
		sendStart(5); // Core3 > Core5: implode_sumResults_13_input___0 
		sendEnd(); // Core3 > Core5: implode_sumResults_13_input___0 
		// Join implode_sumResults_5_input
		{
			memcpy((void*)(arrayC__input__8+0),(void*)( arrayC__input_0__15+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+64),(void*)( arrayC__input_64__15+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+128),(void*)( arrayC__input_128__9+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+192),(void*)( arrayC__input_192__3+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+256),(void*)( arrayC__input_256__11+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+320),(void*)( arrayC__input_320__5+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+384),(void*)( arrayC__input_384__5+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__8+448),(void*)( arrayC__input_448__12+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__15, 64*sizeof(long));
		cache_inv(arrayC__input_64__15, 64*sizeof(long));
		cache_inv(arrayC__input_128__9, 64*sizeof(long));
		cache_inv(arrayC__input_192__3, 64*sizeof(long));
		cache_inv(arrayC__input_256__11, 64*sizeof(long));
		cache_inv(arrayC__input_320__5, 64*sizeof(long));
		cache_inv(arrayC__input_384__5, 64*sizeof(long));
		cache_inv(arrayC__input_448__12, 64*sizeof(long));
		receiveStart(); // Core2 > Core3: implode_sumResults_6_input____0 
		receiveEnd(2); // Core2 > Core3: implode_sumResults_6_input____0 
		cache_inv(implode_sumResults_6_input____0, 2048*sizeof(char));
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__8,output__arrayC_320__0); // sumResults_5
		cache_inv(arrayC__input__8, 512*sizeof(long));
		cache_wbInv(sumResults_5__implode_displa__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: sumResults_5__implode_displa__0 
		sendEnd(); // Core3 > Core4: sumResults_5__implode_displa__0 
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__7,output__arrayC_384__0); // sumResults_6
		cache_inv(arrayC__input__7, 512*sizeof(long));
		cache_wbInv(sumResults_6__implode_displa__0, 256*sizeof(char));
		sendStart(4); // Core3 > Core4: sumResults_6__implode_displa__0 
		sendEnd(); // Core3 > Core4: sumResults_6__implode_displa__0 
	}
}
