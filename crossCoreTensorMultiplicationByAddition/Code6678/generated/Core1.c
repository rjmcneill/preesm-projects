/** 
 * @file Core1.c
 * @generated by C6678CPrinter
 * @date Fri Apr 17 16:12:31 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__94;  // explode_generateTensors_arrayA > transposeTensor_9 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__95;  // explode_generateTensors_arrayA > transposeTensor_5 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__142;  // explode_generateTensors_arrayA > transposeTensor_1 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__80;  // explode_generateTensors_arrayB > multiplyTensors_115 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__41;  // explode_generateTensors_arrayB > multiplyTensors_114 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__92;  // explode_generateTensors_arrayB > multiplyTensors_97 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__10;  // explode_generateTensors_arrayB > multiplyTensors_85 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__98;  // explode_generateTensors_arrayB > multiplyTensors_77 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__124;  // explode_generateTensors_arrayB > multiplyTensors_76 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__17;  // explode_generateTensors_arrayB > multiplyTensors_75 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__44;  // explode_generateTensors_arrayB > multiplyTensors_74 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__19;  // explode_generateTensors_arrayB > multiplyTensors_72 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__143;  // explode_generateTensors_arrayB > multiplyTensors_66 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__49;  // explode_generateTensors_arrayB > multiplyTensors_46 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__43;  // explode_generateTensors_arrayB > multiplyTensors_43 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__48;  // explode_generateTensors_arrayB > multiplyTensors_15 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__97;  // explode_generateTensors_arrayB > multiplyTensors_14 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__126;  // explode_generateTensors_arrayB > multiplyTensors_13 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__8;  // explode_generateTensors_arrayB > multiplyTensors_12 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__5;  // explode_generateTensors_arrayB > multiplyTensors_11 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__101;  // explode_generateTensors_arrayB > multiplyTensors_10 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__16;  // explode_generateTensors_arrayB > multiplyTensors_9 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__115;  // explode_generateTensors_arrayB > multiplyTensors_8 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__86;  // explode_generateTensors_arrayB > multiplyTensors_7 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__125;  // explode_generateTensors_arrayB > multiplyTensors_5 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__77;  // explode_generateTensors_arrayB > multiplyTensors_2 size:= 32*char defined in Core0
extern int *const arrayA_64__input__0;  // explode_generateTensors_arrayA_arrayA_64 > transposeTensor_1_input size:= 64*int defined in Core0
extern int *const output__arrayA__7;  // transposeTensor_1_output > explode_transposeTensor_1_output_arrayA size:= 64*int defined in Core0
extern int *const arrayA_320__input__0;  // explode_generateTensors_arrayA_arrayA_320 > transposeTensor_5_input size:= 64*int defined in Core0
extern int *const output__arrayA__2;  // transposeTensor_5_output > explode_transposeTensor_5_output_arrayA size:= 64*int defined in Core0
extern int *const arrayA_576__input__0;  // explode_generateTensors_arrayA_arrayA_576 > transposeTensor_9_input size:= 64*int defined in Core0
extern int *const output__arrayA__0;  // transposeTensor_9_output > explode_transposeTensor_9_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_9__explode_t__0;  // transposeTensor_9 > explode_transposeTensor_9_output size:= 256*char defined in Core0
extern char *const explode_transposeTensor_0_ou__4;  // explode_transposeTensor_0_output > multiplyTensors_7 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__1;  // explode_transposeTensor_0_output > multiplyTensors_5 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__0;  // explode_transposeTensor_0_output > multiplyTensors_2 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__0;  // explode_transposeTensor_10_output > multiplyTensors_85 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__3;  // explode_transposeTensor_12_output > multiplyTensors_97 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__1;  // explode_transposeTensor_14_output > multiplyTensors_115 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__4;  // explode_transposeTensor_14_output > multiplyTensors_114 size:= 32*char defined in Core0
extern int *const output_0__arrayA__0;  // explode_transposeTensor_1_output_output_0 > multiplyTensors_8_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__15;  // explode_transposeTensor_1_output_output_8 > multiplyTensors_9_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__10;  // explode_transposeTensor_1_output_output_16 > multiplyTensors_10_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__13;  // explode_transposeTensor_1_output_output_24 > multiplyTensors_11_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__11;  // explode_transposeTensor_1_output_output_32 > multiplyTensors_12_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__0;  // explode_transposeTensor_1_output_output_40 > multiplyTensors_13_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__12;  // explode_transposeTensor_1_output_output_48 > multiplyTensors_14_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__2;  // explode_transposeTensor_1_output_output_56 > multiplyTensors_15_arrayA size:= 8*int defined in Core0
extern int *const output_0__arrayA__2;  // explode_transposeTensor_5_output_output_0 > multiplyTensors_40_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__12;  // explode_transposeTensor_5_output_output_8 > multiplyTensors_41_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__15;  // explode_transposeTensor_5_output_output_16 > multiplyTensors_42_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__11;  // explode_transposeTensor_5_output_output_24 > multiplyTensors_43_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__3;  // explode_transposeTensor_5_output_output_32 > multiplyTensors_44_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__8;  // explode_transposeTensor_5_output_output_40 > multiplyTensors_45_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__9;  // explode_transposeTensor_5_output_output_48 > multiplyTensors_46_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__7;  // explode_transposeTensor_5_output_output_56 > multiplyTensors_47_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_5_ou__3;  // explode_transposeTensor_5_output > multiplyTensors_47 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__1;  // explode_transposeTensor_5_output > multiplyTensors_45 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__2;  // explode_transposeTensor_5_output > multiplyTensors_44 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__7;  // explode_transposeTensor_5_output > multiplyTensors_42 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__5;  // explode_transposeTensor_5_output > multiplyTensors_41 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__0;  // explode_transposeTensor_5_output > multiplyTensors_40 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_8_ou__1;  // explode_transposeTensor_8_output > multiplyTensors_66 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__6;  // explode_transposeTensor_9_output > multiplyTensors_77 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__3;  // explode_transposeTensor_9_output > multiplyTensors_76 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__1;  // explode_transposeTensor_9_output > multiplyTensors_75 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__5;  // explode_transposeTensor_9_output > multiplyTensors_74 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_9_ou__4;  // explode_transposeTensor_9_output > multiplyTensors_72 size:= 32*char defined in Core0
extern int *const arrayB_80__arrayB__0;  // explode_generateTensors_arrayB_arrayB_80 > multiplyTensors_10_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__14;  // multiplyTensors_10_arrayC > implode_sumResults_1_input_input_128 size:= 64*long defined in Core0
extern int *const arrayB_88__arrayB__0;  // explode_generateTensors_arrayB_arrayB_88 > multiplyTensors_11_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__10;  // multiplyTensors_11_arrayC > implode_sumResults_1_input_input_192 size:= 64*long defined in Core0
extern int *const output_16__arrayA__7;  // explode_transposeTensor_14_output_output_16 > multiplyTensors_114_arrayA size:= 8*int defined in Core0
extern int *const arrayB_912__arrayB__0;  // explode_generateTensors_arrayB_arrayB_912 > multiplyTensors_114_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__1;  // multiplyTensors_114_arrayC > implode_sumResults_14_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_114__implode__0;  // multiplyTensors_114 > implode_sumResults_14_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__0;  // explode_transposeTensor_14_output_output_24 > multiplyTensors_115_arrayA size:= 8*int defined in Core0
extern int *const arrayB_920__arrayB__0;  // explode_generateTensors_arrayB_arrayB_920 > multiplyTensors_115_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__15;  // multiplyTensors_115_arrayC > implode_sumResults_14_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_115__implode__0;  // multiplyTensors_115 > implode_sumResults_14_input size:= 256*char defined in Core0
extern int *const arrayB_96__arrayB__0;  // explode_generateTensors_arrayB_arrayB_96 > multiplyTensors_12_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__14;  // multiplyTensors_12_arrayC > implode_sumResults_1_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_120__implode__0;  // multiplyTensors_120 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_121__implode__0;  // multiplyTensors_121 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_122__implode__0;  // multiplyTensors_122 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_123__implode__0;  // multiplyTensors_123 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_124__implode__0;  // multiplyTensors_124 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_125__implode__0;  // multiplyTensors_125 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_126__implode__0;  // multiplyTensors_126 > implode_sumResults_15_input size:= 256*char defined in Core0
extern char *const multiplyTensors_127__implode__0;  // multiplyTensors_127 > implode_sumResults_15_input size:= 256*char defined in Core0
extern int *const arrayB_104__arrayB__0;  // explode_generateTensors_arrayB_arrayB_104 > multiplyTensors_13_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__4;  // multiplyTensors_13_arrayC > implode_sumResults_1_input_input_320 size:= 64*long defined in Core0
extern int *const arrayB_112__arrayB__0;  // explode_generateTensors_arrayB_arrayB_112 > multiplyTensors_14_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__4;  // multiplyTensors_14_arrayC > implode_sumResults_1_input_input_384 size:= 64*long defined in Core0
extern int *const arrayB_120__arrayB__0;  // explode_generateTensors_arrayB_arrayB_120 > multiplyTensors_15_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__3;  // multiplyTensors_15_arrayC > implode_sumResults_1_input_input_448 size:= 64*long defined in Core0
extern int *const output_16__arrayA__3;  // explode_transposeTensor_0_output_output_16 > multiplyTensors_2_arrayA size:= 8*int defined in Core0
extern int *const arrayB_16__arrayB__0;  // explode_generateTensors_arrayB_arrayB_16 > multiplyTensors_2_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__2;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_2__implode_s__0;  // multiplyTensors_2 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const arrayB_344__arrayB__0;  // explode_generateTensors_arrayB_arrayB_344 > multiplyTensors_43_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__3;  // multiplyTensors_43_arrayC > implode_sumResults_5_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_43__implode___0;  // multiplyTensors_43 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const arrayB_368__arrayB__0;  // explode_generateTensors_arrayB_arrayB_368 > multiplyTensors_46_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__5;  // multiplyTensors_46_arrayC > implode_sumResults_5_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_46__implode___0;  // multiplyTensors_46 > implode_sumResults_5_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__3;  // explode_transposeTensor_0_output_output_40 > multiplyTensors_5_arrayA size:= 8*int defined in Core0
extern int *const arrayB_40__arrayB__0;  // explode_generateTensors_arrayB_arrayB_40 > multiplyTensors_5_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__9;  // multiplyTensors_5_arrayC > implode_sumResults_0_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_5__implode_s__0;  // multiplyTensors_5 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__4;  // explode_transposeTensor_8_output_output_16 > multiplyTensors_66_arrayA size:= 8*int defined in Core0
extern int *const arrayB_528__arrayB__0;  // explode_generateTensors_arrayB_arrayB_528 > multiplyTensors_66_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__8;  // multiplyTensors_66_arrayC > implode_sumResults_8_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_66__implode___0;  // multiplyTensors_66 > implode_sumResults_8_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__8;  // explode_transposeTensor_0_output_output_56 > multiplyTensors_7_arrayA size:= 8*int defined in Core0
extern int *const arrayB_56__arrayB__0;  // explode_generateTensors_arrayB_arrayB_56 > multiplyTensors_7_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__15;  // multiplyTensors_7_arrayC > implode_sumResults_0_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_7__implode_s__0;  // multiplyTensors_7 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__6;  // explode_transposeTensor_9_output_output_0 > multiplyTensors_72_arrayA size:= 8*int defined in Core0
extern int *const arrayB_576__arrayB__0;  // explode_generateTensors_arrayB_arrayB_576 > multiplyTensors_72_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__4;  // multiplyTensors_72_arrayC > implode_sumResults_9_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_72__implode___0;  // multiplyTensors_72 > implode_sumResults_9_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__11;  // explode_transposeTensor_9_output_output_16 > multiplyTensors_74_arrayA size:= 8*int defined in Core0
extern int *const arrayB_592__arrayB__0;  // explode_generateTensors_arrayB_arrayB_592 > multiplyTensors_74_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__0;  // multiplyTensors_74_arrayC > implode_sumResults_9_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_74__implode___0;  // multiplyTensors_74 > implode_sumResults_9_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__6;  // explode_transposeTensor_9_output_output_24 > multiplyTensors_75_arrayA size:= 8*int defined in Core0
extern int *const arrayB_600__arrayB__0;  // explode_generateTensors_arrayB_arrayB_600 > multiplyTensors_75_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__2;  // multiplyTensors_75_arrayC > implode_sumResults_9_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_75__implode___0;  // multiplyTensors_75 > implode_sumResults_9_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__7;  // explode_transposeTensor_9_output_output_32 > multiplyTensors_76_arrayA size:= 8*int defined in Core0
extern int *const arrayB_608__arrayB__0;  // explode_generateTensors_arrayB_arrayB_608 > multiplyTensors_76_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__15;  // multiplyTensors_76_arrayC > implode_sumResults_9_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_76__implode___0;  // multiplyTensors_76 > implode_sumResults_9_input size:= 256*char defined in Core0
extern int *const output_40__arrayA__13;  // explode_transposeTensor_9_output_output_40 > multiplyTensors_77_arrayA size:= 8*int defined in Core0
extern int *const arrayB_616__arrayB__0;  // explode_generateTensors_arrayB_arrayB_616 > multiplyTensors_77_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__15;  // multiplyTensors_77_arrayC > implode_sumResults_9_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_77__implode___0;  // multiplyTensors_77 > implode_sumResults_9_input size:= 256*char defined in Core0
extern int *const arrayB_64__arrayB__0;  // explode_generateTensors_arrayB_arrayB_64 > multiplyTensors_8_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__10;  // multiplyTensors_8_arrayC > implode_sumResults_1_input_input_0 size:= 64*long defined in Core0
extern int *const output_40__arrayA__2;  // explode_transposeTensor_10_output_output_40 > multiplyTensors_85_arrayA size:= 8*int defined in Core0
extern int *const arrayB_680__arrayB__0;  // explode_generateTensors_arrayB_arrayB_680 > multiplyTensors_85_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__11;  // multiplyTensors_85_arrayC > implode_sumResults_10_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_85__implode___0;  // multiplyTensors_85 > implode_sumResults_10_input size:= 256*char defined in Core0
extern int *const arrayB_72__arrayB__0;  // explode_generateTensors_arrayB_arrayB_72 > multiplyTensors_9_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__7;  // multiplyTensors_9_arrayC > implode_sumResults_1_input_input_64 size:= 64*long defined in Core0
extern int *const output_8__arrayA__8;  // explode_transposeTensor_12_output_output_8 > multiplyTensors_97_arrayA size:= 8*int defined in Core0
extern int *const arrayB_776__arrayB__0;  // explode_generateTensors_arrayB_arrayB_776 > multiplyTensors_97_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__4;  // multiplyTensors_97_arrayC > implode_sumResults_12_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_97__implode___0;  // multiplyTensors_97 > implode_sumResults_12_input size:= 256*char defined in Core0
extern char *const implode_sumResults_11_input___0;  // implode_sumResults_11_input > sumResults_11 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__8;  // multiplyTensors_120_arrayC > implode_sumResults_15_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__14;  // multiplyTensors_121_arrayC > implode_sumResults_15_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__15;  // multiplyTensors_122_arrayC > implode_sumResults_15_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__14;  // multiplyTensors_123_arrayC > implode_sumResults_15_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__0;  // multiplyTensors_124_arrayC > implode_sumResults_15_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__12;  // multiplyTensors_125_arrayC > implode_sumResults_15_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__8;  // multiplyTensors_126_arrayC > implode_sumResults_15_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__4;  // multiplyTensors_127_arrayC > implode_sumResults_15_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__9;  // implode_sumResults_15_input_arrayC > sumResults_15_input size:= 512*long defined in Core0
extern char *const implode_sumResults_15_input___0;  // implode_sumResults_15_input > sumResults_15 size:= 2048*char defined in Core0
extern long *const arrayC__input__11;  // implode_sumResults_1_input_arrayC > sumResults_1_input size:= 512*long defined in Core0
extern long *const output__arrayC_64__0;  // sumResults_1_output > implode_displayTensor_arrayC_arrayC_64 size:= 64*long defined in Core0
extern char *const sumResults_1__implode_displa__0;  // sumResults_1 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__3;  // implode_sumResults_11_input_arrayC > sumResults_11_input size:= 512*long defined in Core0
extern long *const output__arrayC_704__0;  // sumResults_11_output > implode_displayTensor_arrayC_arrayC_704 size:= 64*long defined in Core0
extern char *const sumResults_11__implode_displ__0;  // sumResults_11 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core1(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__94 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__94 
		cache_inv(explode_generateTensors_arra__94, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__95 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__95 
		cache_inv(explode_generateTensors_arra__95, 256*sizeof(char));
		receiveStart(); // Core0 > Core1: explode_generateTensors_arra__142 
		receiveEnd(0); // Core0 > Core1: explode_generateTensors_arra__142 
		cache_inv(explode_generateTensors_arra__142, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__80 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__80 
		cache_inv(explode_generateTensors_arra__80, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__41 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__41 
		cache_inv(explode_generateTensors_arra__41, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__92 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__92 
		cache_inv(explode_generateTensors_arra__92, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__10 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__10 
		cache_inv(explode_generateTensors_arra__10, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__98 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__98 
		cache_inv(explode_generateTensors_arra__98, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__124 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__124 
		cache_inv(explode_generateTensors_arra__124, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__17 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__17 
		cache_inv(explode_generateTensors_arra__17, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__44 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__44 
		cache_inv(explode_generateTensors_arra__44, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__19 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__19 
		cache_inv(explode_generateTensors_arra__19, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__143 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__143 
		cache_inv(explode_generateTensors_arra__143, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__49 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__49 
		cache_inv(explode_generateTensors_arra__49, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__43 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__43 
		cache_inv(explode_generateTensors_arra__43, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__48 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__48 
		cache_inv(explode_generateTensors_arra__48, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__97 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__97 
		cache_inv(explode_generateTensors_arra__97, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__126 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__126 
		cache_inv(explode_generateTensors_arra__126, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__8 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__8 
		cache_inv(explode_generateTensors_arra__8, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__5 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__5 
		cache_inv(explode_generateTensors_arra__5, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__101 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__101 
		cache_inv(explode_generateTensors_arra__101, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__16 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__16 
		cache_inv(explode_generateTensors_arra__16, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__115 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__115 
		cache_inv(explode_generateTensors_arra__115, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__86 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__86 
		cache_inv(explode_generateTensors_arra__86, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__125 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__125 
		cache_inv(explode_generateTensors_arra__125, 32*sizeof(char));
		receiveStart(); // Core7 > Core1: explode_generateTensors_arra__77 
		receiveEnd(7); // Core7 > Core1: explode_generateTensors_arra__77 
		cache_inv(explode_generateTensors_arra__77, 32*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_64__input__0,output__arrayA__7); // transposeTensor_1
		cache_inv(arrayA_64__input__0, 64*sizeof(int));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_320__input__0,output__arrayA__2); // transposeTensor_5
		cache_inv(arrayA_320__input__0, 64*sizeof(int));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_576__input__0,output__arrayA__0); // transposeTensor_9
		cache_inv(arrayA_576__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_9__explode_t__0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: transposeTensor_9__explode_t__0 
		sendEnd(); // Core1 > Core2: transposeTensor_9__explode_t__0 
		receiveStart(); // Core2 > Core1: explode_transposeTensor_0_ou__4 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_0_ou__4 
		cache_inv(explode_transposeTensor_0_ou__4, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_0_ou__1 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_0_ou__1 
		cache_inv(explode_transposeTensor_0_ou__1, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_0_ou__0 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_0_ou__0 
		cache_inv(explode_transposeTensor_0_ou__0, 32*sizeof(char));
		receiveStart(); // Core4 > Core1: explode_transposeTensor_10_o__0 
		receiveEnd(4); // Core4 > Core1: explode_transposeTensor_10_o__0 
		cache_inv(explode_transposeTensor_10_o__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core1: explode_transposeTensor_12_o__3 
		receiveEnd(6); // Core6 > Core1: explode_transposeTensor_12_o__3 
		cache_inv(explode_transposeTensor_12_o__3, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_14_o__1 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_14_o__1 
		cache_inv(explode_transposeTensor_14_o__1, 32*sizeof(char));
		receiveStart(); // Core5 > Core1: explode_transposeTensor_14_o__4 
		receiveEnd(5); // Core5 > Core1: explode_transposeTensor_14_o__4 
		cache_inv(explode_transposeTensor_14_o__4, 32*sizeof(char));
		// Fork explode_transposeTensor_1_output
		{
			memcpy((void*)(output_0__arrayA__0+0),(void*)( output__arrayA__7+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__15+0),(void*)( output__arrayA__7+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__10+0),(void*)( output__arrayA__7+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__13+0),(void*)( output__arrayA__7+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__11+0),(void*)( output__arrayA__7+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__0+0),(void*)( output__arrayA__7+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__12+0),(void*)( output__arrayA__7+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__2+0),(void*)( output__arrayA__7+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__7, 64*sizeof(int));
		// Fork explode_transposeTensor_5_output
		{
			memcpy((void*)(output_0__arrayA__2+0),(void*)( output__arrayA__2+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__12+0),(void*)( output__arrayA__2+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__15+0),(void*)( output__arrayA__2+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__11+0),(void*)( output__arrayA__2+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__3+0),(void*)( output__arrayA__2+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__8+0),(void*)( output__arrayA__2+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__9+0),(void*)( output__arrayA__2+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__7+0),(void*)( output__arrayA__2+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__2, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_5_ou__3, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: explode_transposeTensor_5_ou__3 
		sendEnd(); // Core1 > Core4: explode_transposeTensor_5_ou__3 
		cache_wbInv(explode_transposeTensor_5_ou__1, 32*sizeof(char));
		sendStart(2); // Core1 > Core2: explode_transposeTensor_5_ou__1 
		sendEnd(); // Core1 > Core2: explode_transposeTensor_5_ou__1 
		cache_wbInv(explode_transposeTensor_5_ou__2, 32*sizeof(char));
		sendStart(4); // Core1 > Core4: explode_transposeTensor_5_ou__2 
		sendEnd(); // Core1 > Core4: explode_transposeTensor_5_ou__2 
		cache_wbInv(explode_transposeTensor_5_ou__7, 32*sizeof(char));
		sendStart(5); // Core1 > Core5: explode_transposeTensor_5_ou__7 
		sendEnd(); // Core1 > Core5: explode_transposeTensor_5_ou__7 
		cache_wbInv(explode_transposeTensor_5_ou__5, 32*sizeof(char));
		sendStart(3); // Core1 > Core3: explode_transposeTensor_5_ou__5 
		sendEnd(); // Core1 > Core3: explode_transposeTensor_5_ou__5 
		cache_wbInv(explode_transposeTensor_5_ou__0, 32*sizeof(char));
		sendStart(6); // Core1 > Core6: explode_transposeTensor_5_ou__0 
		sendEnd(); // Core1 > Core6: explode_transposeTensor_5_ou__0 
		receiveStart(); // Core0 > Core1: explode_transposeTensor_8_ou__1 
		receiveEnd(0); // Core0 > Core1: explode_transposeTensor_8_ou__1 
		cache_inv(explode_transposeTensor_8_ou__1, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_9_ou__6 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_9_ou__6 
		cache_inv(explode_transposeTensor_9_ou__6, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_9_ou__3 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_9_ou__3 
		cache_inv(explode_transposeTensor_9_ou__3, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_9_ou__1 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_9_ou__1 
		cache_inv(explode_transposeTensor_9_ou__1, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_9_ou__5 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_9_ou__5 
		cache_inv(explode_transposeTensor_9_ou__5, 32*sizeof(char));
		receiveStart(); // Core2 > Core1: explode_transposeTensor_9_ou__4 
		receiveEnd(2); // Core2 > Core1: explode_transposeTensor_9_ou__4 
		cache_inv(explode_transposeTensor_9_ou__4, 32*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__10,arrayB_80__arrayB__0,arrayC__input_128__14); // multiplyTensors_10
		cache_inv(output_16__arrayA__10, 8*sizeof(int));
		cache_inv(arrayB_80__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__13,arrayB_88__arrayB__0,arrayC__input_192__10); // multiplyTensors_11
		cache_inv(output_24__arrayA__13, 8*sizeof(int));
		cache_inv(arrayB_88__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__7,arrayB_912__arrayB__0,arrayC__input_128__1); // multiplyTensors_114
		cache_inv(output_16__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_912__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_114__implode__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiplyTensors_114__implode__0 
		sendEnd(); // Core1 > Core6: multiplyTensors_114__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__0,arrayB_920__arrayB__0,arrayC__input_192__15); // multiplyTensors_115
		cache_inv(output_24__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_920__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_115__implode__0, 256*sizeof(char));
		sendStart(6); // Core1 > Core6: multiplyTensors_115__implode__0 
		sendEnd(); // Core1 > Core6: multiplyTensors_115__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__11,arrayB_96__arrayB__0,arrayC__input_256__14); // multiplyTensors_12
		cache_inv(output_32__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_96__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core7 > Core1: multiplyTensors_120__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_120__implode__0 
		cache_inv(multiplyTensors_120__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiplyTensors_121__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_121__implode__0 
		cache_inv(multiplyTensors_121__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiplyTensors_122__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_122__implode__0 
		cache_inv(multiplyTensors_122__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiplyTensors_123__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_123__implode__0 
		cache_inv(multiplyTensors_123__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiplyTensors_124__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_124__implode__0 
		cache_inv(multiplyTensors_124__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiplyTensors_125__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_125__implode__0 
		cache_inv(multiplyTensors_125__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiplyTensors_126__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_126__implode__0 
		cache_inv(multiplyTensors_126__implode__0, 256*sizeof(char));
		receiveStart(); // Core7 > Core1: multiplyTensors_127__implode__0 
		receiveEnd(7); // Core7 > Core1: multiplyTensors_127__implode__0 
		cache_inv(multiplyTensors_127__implode__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__0,arrayB_104__arrayB__0,arrayC__input_320__4); // multiplyTensors_13
		cache_inv(output_40__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_104__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__12,arrayB_112__arrayB__0,arrayC__input_384__4); // multiplyTensors_14
		cache_inv(output_48__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_112__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__2,arrayB_120__arrayB__0,arrayC__input_448__3); // multiplyTensors_15
		cache_inv(output_56__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_120__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__3,arrayB_16__arrayB__0,arrayC__input_128__2); // multiplyTensors_2
		cache_inv(output_16__arrayA__3, 8*sizeof(int));
		cache_inv(arrayB_16__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_2__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiplyTensors_2__implode_s__0 
		sendEnd(); // Core1 > Core5: multiplyTensors_2__implode_s__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__11,arrayB_344__arrayB__0,arrayC__input_192__3); // multiplyTensors_43
		cache_inv(output_24__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_344__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_43__implode___0, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: multiplyTensors_43__implode___0 
		sendEnd(); // Core1 > Core3: multiplyTensors_43__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__9,arrayB_368__arrayB__0,arrayC__input_384__5); // multiplyTensors_46
		cache_inv(output_48__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_368__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_46__implode___0, 256*sizeof(char));
		sendStart(3); // Core1 > Core3: multiplyTensors_46__implode___0 
		sendEnd(); // Core1 > Core3: multiplyTensors_46__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__3,arrayB_40__arrayB__0,arrayC__input_320__9); // multiplyTensors_5
		cache_inv(output_40__arrayA__3, 8*sizeof(int));
		cache_inv(arrayB_40__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_5__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiplyTensors_5__implode_s__0 
		sendEnd(); // Core1 > Core5: multiplyTensors_5__implode_s__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__4,arrayB_528__arrayB__0,arrayC__input_128__8); // multiplyTensors_66
		cache_inv(output_16__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_528__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_66__implode___0, 256*sizeof(char));
		sendStart(7); // Core1 > Core7: multiplyTensors_66__implode___0 
		sendEnd(); // Core1 > Core7: multiplyTensors_66__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__8,arrayB_56__arrayB__0,arrayC__input_448__15); // multiplyTensors_7
		cache_inv(output_56__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_56__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_7__implode_s__0, 256*sizeof(char));
		sendStart(5); // Core1 > Core5: multiplyTensors_7__implode_s__0 
		sendEnd(); // Core1 > Core5: multiplyTensors_7__implode_s__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__6,arrayB_576__arrayB__0,arrayC__input_0__4); // multiplyTensors_72
		cache_inv(output_0__arrayA__6, 8*sizeof(int));
		cache_inv(arrayB_576__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_72__implode___0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_72__implode___0 
		sendEnd(); // Core1 > Core2: multiplyTensors_72__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__11,arrayB_592__arrayB__0,arrayC__input_128__0); // multiplyTensors_74
		cache_inv(output_16__arrayA__11, 8*sizeof(int));
		cache_inv(arrayB_592__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_74__implode___0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_74__implode___0 
		sendEnd(); // Core1 > Core2: multiplyTensors_74__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__6,arrayB_600__arrayB__0,arrayC__input_192__2); // multiplyTensors_75
		cache_inv(output_24__arrayA__6, 8*sizeof(int));
		cache_inv(arrayB_600__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_75__implode___0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_75__implode___0 
		sendEnd(); // Core1 > Core2: multiplyTensors_75__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__7,arrayB_608__arrayB__0,arrayC__input_256__15); // multiplyTensors_76
		cache_inv(output_32__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_608__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_76__implode___0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_76__implode___0 
		sendEnd(); // Core1 > Core2: multiplyTensors_76__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__13,arrayB_616__arrayB__0,arrayC__input_320__15); // multiplyTensors_77
		cache_inv(output_40__arrayA__13, 8*sizeof(int));
		cache_inv(arrayB_616__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_77__implode___0, 256*sizeof(char));
		sendStart(2); // Core1 > Core2: multiplyTensors_77__implode___0 
		sendEnd(); // Core1 > Core2: multiplyTensors_77__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__0,arrayB_64__arrayB__0,arrayC__input_0__10); // multiplyTensors_8
		cache_inv(output_0__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_64__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__2,arrayB_680__arrayB__0,arrayC__input_320__11); // multiplyTensors_85
		cache_inv(output_40__arrayA__2, 8*sizeof(int));
		cache_inv(arrayB_680__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_85__implode___0, 256*sizeof(char));
		sendStart(0); // Core1 > Core0: multiplyTensors_85__implode___0 
		sendEnd(); // Core1 > Core0: multiplyTensors_85__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__15,arrayB_72__arrayB__0,arrayC__input_64__7); // multiplyTensors_9
		cache_inv(output_8__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_72__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__8,arrayB_776__arrayB__0,arrayC__input_64__4); // multiplyTensors_97
		cache_inv(output_8__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_776__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_97__implode___0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: multiplyTensors_97__implode___0 
		sendEnd(); // Core1 > Core4: multiplyTensors_97__implode___0 
		receiveStart(); // Core0 > Core1: implode_sumResults_11_input___0 
		receiveEnd(0); // Core0 > Core1: implode_sumResults_11_input___0 
		cache_inv(implode_sumResults_11_input___0, 2048*sizeof(char));
		// Join implode_sumResults_15_input
		{
			memcpy((void*)(arrayC__input__9+0),(void*)( arrayC__input_0__8+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__9+64),(void*)( arrayC__input_64__14+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__9+128),(void*)( arrayC__input_128__15+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__9+192),(void*)( arrayC__input_192__14+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__9+256),(void*)( arrayC__input_256__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__9+320),(void*)( arrayC__input_320__12+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__9+384),(void*)( arrayC__input_384__8+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__9+448),(void*)( arrayC__input_448__4+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__8, 64*sizeof(long));
		cache_inv(arrayC__input_64__14, 64*sizeof(long));
		cache_inv(arrayC__input_128__15, 64*sizeof(long));
		cache_inv(arrayC__input_192__14, 64*sizeof(long));
		cache_inv(arrayC__input_256__0, 64*sizeof(long));
		cache_inv(arrayC__input_320__12, 64*sizeof(long));
		cache_inv(arrayC__input_384__8, 64*sizeof(long));
		cache_inv(arrayC__input_448__4, 64*sizeof(long));
		cache_wbInv(implode_sumResults_15_input___0, 2048*sizeof(char));
		sendStart(7); // Core1 > Core7: implode_sumResults_15_input___0 
		sendEnd(); // Core1 > Core7: implode_sumResults_15_input___0 
		// Join implode_sumResults_1_input
		{
			memcpy((void*)(arrayC__input__11+0),(void*)( arrayC__input_0__10+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__11+64),(void*)( arrayC__input_64__7+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__11+128),(void*)( arrayC__input_128__14+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__11+192),(void*)( arrayC__input_192__10+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__11+256),(void*)( arrayC__input_256__14+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__11+320),(void*)( arrayC__input_320__4+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__11+384),(void*)( arrayC__input_384__4+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__11+448),(void*)( arrayC__input_448__3+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__10, 64*sizeof(long));
		cache_inv(arrayC__input_64__7, 64*sizeof(long));
		cache_inv(arrayC__input_128__14, 64*sizeof(long));
		cache_inv(arrayC__input_192__10, 64*sizeof(long));
		cache_inv(arrayC__input_256__14, 64*sizeof(long));
		cache_inv(arrayC__input_320__4, 64*sizeof(long));
		cache_inv(arrayC__input_384__4, 64*sizeof(long));
		cache_inv(arrayC__input_448__3, 64*sizeof(long));
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__11,output__arrayC_64__0); // sumResults_1
		cache_inv(arrayC__input__11, 512*sizeof(long));
		cache_wbInv(sumResults_1__implode_displa__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: sumResults_1__implode_displa__0 
		sendEnd(); // Core1 > Core4: sumResults_1__implode_displa__0 
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__3,output__arrayC_704__0); // sumResults_11
		cache_inv(arrayC__input__3, 512*sizeof(long));
		cache_wbInv(sumResults_11__implode_displ__0, 256*sizeof(char));
		sendStart(4); // Core1 > Core4: sumResults_11__implode_displ__0 
		sendEnd(); // Core1 > Core4: sumResults_11__implode_displ__0 
	}
}
