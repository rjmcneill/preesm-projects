/** 
 * @file Core5.c
 * @generated by C6678CPrinter
 * @date Fri Apr 17 16:12:31 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__38;  // explode_generateTensors_arrayA > transposeTensor_13 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__23;  // explode_generateTensors_arrayA > transposeTensor_7 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__83;  // explode_generateTensors_arrayA > transposeTensor_0 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__121;  // explode_generateTensors_arrayB > multiplyTensors_118 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__34;  // explode_generateTensors_arrayB > multiplyTensors_116 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__46;  // explode_generateTensors_arrayB > multiplyTensors_109 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__76;  // explode_generateTensors_arrayB > multiplyTensors_108 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__82;  // explode_generateTensors_arrayB > multiplyTensors_106 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__11;  // explode_generateTensors_arrayB > multiplyTensors_105 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__90;  // explode_generateTensors_arrayB > multiplyTensors_102 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__127;  // explode_generateTensors_arrayB > multiplyTensors_96 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__12;  // explode_generateTensors_arrayB > multiplyTensors_80 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__30;  // explode_generateTensors_arrayB > multiplyTensors_67 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__31;  // explode_generateTensors_arrayB > multiplyTensors_58 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__73;  // explode_generateTensors_arrayB > multiplyTensors_42 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__63;  // explode_generateTensors_arrayB > multiplyTensors_31 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__42;  // explode_generateTensors_arrayB > multiplyTensors_30 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__81;  // explode_generateTensors_arrayB > multiplyTensors_28 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__138;  // explode_generateTensors_arrayB > multiplyTensors_27 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayB > multiplyTensors_25 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__60;  // explode_generateTensors_arrayB > multiplyTensors_24 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__99;  // explode_generateTensors_arrayB > multiplyTensors_6 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__111;  // explode_generateTensors_arrayB > multiplyTensors_4 size:= 32*char defined in Core0
extern int *const arrayA_0__input__0;  // explode_generateTensors_arrayA_arrayA_0 > transposeTensor_0_input size:= 64*int defined in Core0
extern int *const output__arrayA__13;  // transposeTensor_0_output > explode_transposeTensor_0_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_0__explode_t__0;  // transposeTensor_0 > explode_transposeTensor_0_output size:= 256*char defined in Core0
extern int *const arrayA_832__input__0;  // explode_generateTensors_arrayA_arrayA_832 > transposeTensor_13_input size:= 64*int defined in Core0
extern int *const output__arrayA__11;  // transposeTensor_13_output > explode_transposeTensor_13_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_14__explode___0;  // transposeTensor_14 > explode_transposeTensor_14_output size:= 256*char defined in Core0
extern int *const arrayA_448__input__0;  // explode_generateTensors_arrayA_arrayA_448 > transposeTensor_7_input size:= 64*int defined in Core0
extern int *const output__arrayA__4;  // transposeTensor_7_output > explode_transposeTensor_7_output_arrayA size:= 64*int defined in Core0
extern char *const transposeTensor_7__explode_t__0;  // transposeTensor_7 > explode_transposeTensor_7_output size:= 256*char defined in Core0
extern char *const explode_transposeTensor_0_ou__2;  // explode_transposeTensor_0_output > multiplyTensors_6 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__7;  // explode_transposeTensor_0_output > multiplyTensors_4 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_10_o__7;  // explode_transposeTensor_10_output > multiplyTensors_80 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__0;  // explode_transposeTensor_12_output > multiplyTensors_102 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_12_o__4;  // explode_transposeTensor_12_output > multiplyTensors_96 size:= 32*char defined in Core0
extern int *const output_0__arrayA__13;  // explode_transposeTensor_13_output_output_0 > multiplyTensors_104_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__9;  // explode_transposeTensor_13_output_output_8 > multiplyTensors_105_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__8;  // explode_transposeTensor_13_output_output_16 > multiplyTensors_106_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__15;  // explode_transposeTensor_13_output_output_24 > multiplyTensors_107_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__0;  // explode_transposeTensor_13_output_output_32 > multiplyTensors_108_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__14;  // explode_transposeTensor_13_output_output_40 > multiplyTensors_109_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__5;  // explode_transposeTensor_13_output_output_48 > multiplyTensors_110_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__14;  // explode_transposeTensor_13_output_output_56 > multiplyTensors_111_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_13_o__5;  // explode_transposeTensor_13_output > multiplyTensors_111 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__1;  // explode_transposeTensor_13_output > multiplyTensors_110 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__7;  // explode_transposeTensor_13_output > multiplyTensors_107 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_13_o__6;  // explode_transposeTensor_13_output > multiplyTensors_104 size:= 32*char defined in Core0
extern int *const output_0__arrayA__11;  // explode_transposeTensor_14_output_output_0 > multiplyTensors_112_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__10;  // explode_transposeTensor_14_output_output_8 > multiplyTensors_113_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__7;  // explode_transposeTensor_14_output_output_16 > multiplyTensors_114_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__0;  // explode_transposeTensor_14_output_output_24 > multiplyTensors_115_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__8;  // explode_transposeTensor_14_output_output_32 > multiplyTensors_116_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__1;  // explode_transposeTensor_14_output_output_40 > multiplyTensors_117_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__0;  // explode_transposeTensor_14_output_output_48 > multiplyTensors_118_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__0;  // explode_transposeTensor_14_output_output_56 > multiplyTensors_119_arrayA size:= 8*int defined in Core0
extern int *const output__arrayA__14;  // transposeTensor_14_output > explode_transposeTensor_14_output_arrayA size:= 64*int defined in Core0
extern char *const explode_transposeTensor_14_o__3;  // explode_transposeTensor_14_output > multiplyTensors_119 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__2;  // explode_transposeTensor_14_output > multiplyTensors_117 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__1;  // explode_transposeTensor_14_output > multiplyTensors_115 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__4;  // explode_transposeTensor_14_output > multiplyTensors_114 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__5;  // explode_transposeTensor_14_output > multiplyTensors_113 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_14_o__7;  // explode_transposeTensor_14_output > multiplyTensors_112 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__2;  // explode_transposeTensor_3_output > multiplyTensors_31 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__7;  // explode_transposeTensor_3_output > multiplyTensors_30 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__3;  // explode_transposeTensor_3_output > multiplyTensors_28 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__6;  // explode_transposeTensor_3_output > multiplyTensors_27 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__4;  // explode_transposeTensor_3_output > multiplyTensors_25 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_3_ou__5;  // explode_transposeTensor_3_output > multiplyTensors_24 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_5_ou__7;  // explode_transposeTensor_5_output > multiplyTensors_42 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_7_ou__0;  // explode_transposeTensor_7_output > multiplyTensors_58 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_8_ou__6;  // explode_transposeTensor_8_output > multiplyTensors_67 size:= 32*char defined in Core0
extern char *const multiplyTensors_0__implode_s__0;  // multiplyTensors_0 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_1__implode_s__0;  // multiplyTensors_1 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__6;  // explode_transposeTensor_12_output_output_48 > multiplyTensors_102_arrayA size:= 8*int defined in Core0
extern int *const arrayB_816__arrayB__0;  // explode_generateTensors_arrayB_arrayB_816 > multiplyTensors_102_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__2;  // multiplyTensors_102_arrayC > implode_sumResults_12_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_102__implode__0;  // multiplyTensors_102 > implode_sumResults_12_input size:= 256*char defined in Core0
extern int *const arrayB_840__arrayB__0;  // explode_generateTensors_arrayB_arrayB_840 > multiplyTensors_105_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__2;  // multiplyTensors_105_arrayC > implode_sumResults_13_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_105__implode__0;  // multiplyTensors_105 > implode_sumResults_13_input size:= 256*char defined in Core0
extern int *const arrayB_848__arrayB__0;  // explode_generateTensors_arrayB_arrayB_848 > multiplyTensors_106_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__5;  // multiplyTensors_106_arrayC > implode_sumResults_13_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_106__implode__0;  // multiplyTensors_106 > implode_sumResults_13_input size:= 256*char defined in Core0
extern int *const arrayB_864__arrayB__0;  // explode_generateTensors_arrayB_arrayB_864 > multiplyTensors_108_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__4;  // multiplyTensors_108_arrayC > implode_sumResults_13_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_108__implode__0;  // multiplyTensors_108 > implode_sumResults_13_input size:= 256*char defined in Core0
extern int *const arrayB_872__arrayB__0;  // explode_generateTensors_arrayB_arrayB_872 > multiplyTensors_109_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__8;  // multiplyTensors_109_arrayC > implode_sumResults_13_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_109__implode__0;  // multiplyTensors_109 > implode_sumResults_13_input size:= 256*char defined in Core0
extern int *const arrayB_928__arrayB__0;  // explode_generateTensors_arrayB_arrayB_928 > multiplyTensors_116_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__3;  // multiplyTensors_116_arrayC > implode_sumResults_14_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_116__implode__0;  // multiplyTensors_116 > implode_sumResults_14_input size:= 256*char defined in Core0
extern int *const arrayB_944__arrayB__0;  // explode_generateTensors_arrayB_arrayB_944 > multiplyTensors_118_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__0;  // multiplyTensors_118_arrayC > implode_sumResults_14_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_118__implode__0;  // multiplyTensors_118 > implode_sumResults_14_input size:= 256*char defined in Core0
extern char *const multiplyTensors_2__implode_s__0;  // multiplyTensors_2 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__5;  // explode_transposeTensor_3_output_output_0 > multiplyTensors_24_arrayA size:= 8*int defined in Core0
extern int *const arrayB_192__arrayB__0;  // explode_generateTensors_arrayB_arrayB_192 > multiplyTensors_24_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__13;  // multiplyTensors_24_arrayC > implode_sumResults_3_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_24__implode___0;  // multiplyTensors_24 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_8__arrayA__7;  // explode_transposeTensor_3_output_output_8 > multiplyTensors_25_arrayA size:= 8*int defined in Core0
extern int *const arrayB_200__arrayB__0;  // explode_generateTensors_arrayB_arrayB_200 > multiplyTensors_25_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_64__6;  // multiplyTensors_25_arrayC > implode_sumResults_3_input_input_64 size:= 64*long defined in Core0
extern char *const multiplyTensors_25__implode___0;  // multiplyTensors_25 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__12;  // explode_transposeTensor_3_output_output_24 > multiplyTensors_27_arrayA size:= 8*int defined in Core0
extern int *const arrayB_216__arrayB__0;  // explode_generateTensors_arrayB_arrayB_216 > multiplyTensors_27_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__1;  // multiplyTensors_27_arrayC > implode_sumResults_3_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_27__implode___0;  // multiplyTensors_27 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__4;  // explode_transposeTensor_3_output_output_32 > multiplyTensors_28_arrayA size:= 8*int defined in Core0
extern int *const arrayB_224__arrayB__0;  // explode_generateTensors_arrayB_arrayB_224 > multiplyTensors_28_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__8;  // multiplyTensors_28_arrayC > implode_sumResults_3_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_28__implode___0;  // multiplyTensors_28 > implode_sumResults_3_input size:= 256*char defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__13;  // explode_transposeTensor_3_output_output_48 > multiplyTensors_30_arrayA size:= 8*int defined in Core0
extern int *const arrayB_240__arrayB__0;  // explode_generateTensors_arrayB_arrayB_240 > multiplyTensors_30_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__7;  // multiplyTensors_30_arrayC > implode_sumResults_3_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_30__implode___0;  // multiplyTensors_30 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_56__arrayA__5;  // explode_transposeTensor_3_output_output_56 > multiplyTensors_31_arrayA size:= 8*int defined in Core0
extern int *const arrayB_248__arrayB__0;  // explode_generateTensors_arrayB_arrayB_248 > multiplyTensors_31_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_448__1;  // multiplyTensors_31_arrayC > implode_sumResults_3_input_input_448 size:= 64*long defined in Core0
extern char *const multiplyTensors_31__implode___0;  // multiplyTensors_31 > implode_sumResults_3_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__15;  // explode_transposeTensor_0_output_output_32 > multiplyTensors_4_arrayA size:= 8*int defined in Core0
extern int *const arrayB_32__arrayB__0;  // explode_generateTensors_arrayB_arrayB_32 > multiplyTensors_4_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__7;  // multiplyTensors_4_arrayC > implode_sumResults_0_input_input_256 size:= 64*long defined in Core0
extern int *const output_16__arrayA__15;  // explode_transposeTensor_5_output_output_16 > multiplyTensors_42_arrayA size:= 8*int defined in Core0
extern int *const arrayB_336__arrayB__0;  // explode_generateTensors_arrayB_arrayB_336 > multiplyTensors_42_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__9;  // multiplyTensors_42_arrayC > implode_sumResults_5_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_42__implode___0;  // multiplyTensors_42 > implode_sumResults_5_input size:= 256*char defined in Core0
extern char *const multiplyTensors_5__implode_s__0;  // multiplyTensors_5 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_56__implode___0;  // multiplyTensors_56 > implode_sumResults_7_input size:= 256*char defined in Core0
extern char *const multiplyTensors_57__implode___0;  // multiplyTensors_57 > implode_sumResults_7_input size:= 256*char defined in Core0
extern int *const output_16__arrayA__0;  // explode_transposeTensor_7_output_output_16 > multiplyTensors_58_arrayA size:= 8*int defined in Core0
extern int *const arrayB_464__arrayB__0;  // explode_generateTensors_arrayB_arrayB_464 > multiplyTensors_58_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_128__11;  // multiplyTensors_58_arrayC > implode_sumResults_7_input_input_128 size:= 64*long defined in Core0
extern char *const multiplyTensors_59__implode___0;  // multiplyTensors_59 > implode_sumResults_7_input size:= 256*char defined in Core0
extern int *const output_48__arrayA__4;  // explode_transposeTensor_0_output_output_48 > multiplyTensors_6_arrayA size:= 8*int defined in Core0
extern int *const arrayB_48__arrayB__0;  // explode_generateTensors_arrayB_arrayB_48 > multiplyTensors_6_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_384__13;  // multiplyTensors_6_arrayC > implode_sumResults_0_input_input_384 size:= 64*long defined in Core0
extern char *const multiplyTensors_60__implode___0;  // multiplyTensors_60 > implode_sumResults_7_input size:= 256*char defined in Core0
extern char *const multiplyTensors_61__implode___0;  // multiplyTensors_61 > implode_sumResults_7_input size:= 256*char defined in Core0
extern char *const multiplyTensors_62__implode___0;  // multiplyTensors_62 > implode_sumResults_7_input size:= 256*char defined in Core0
extern char *const multiplyTensors_63__implode___0;  // multiplyTensors_63 > implode_sumResults_7_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__9;  // explode_transposeTensor_8_output_output_24 > multiplyTensors_67_arrayA size:= 8*int defined in Core0
extern int *const arrayB_536__arrayB__0;  // explode_generateTensors_arrayB_arrayB_536 > multiplyTensors_67_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__6;  // multiplyTensors_67_arrayC > implode_sumResults_8_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_67__implode___0;  // multiplyTensors_67 > implode_sumResults_8_input size:= 256*char defined in Core0
extern char *const multiplyTensors_7__implode_s__0;  // multiplyTensors_7 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__12;  // explode_transposeTensor_10_output_output_0 > multiplyTensors_80_arrayA size:= 8*int defined in Core0
extern int *const arrayB_640__arrayB__0;  // explode_generateTensors_arrayB_arrayB_640 > multiplyTensors_80_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__7;  // multiplyTensors_80_arrayC > implode_sumResults_10_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_80__implode___0;  // multiplyTensors_80 > implode_sumResults_10_input size:= 256*char defined in Core0
extern int *const output_0__arrayA__7;  // explode_transposeTensor_12_output_output_0 > multiplyTensors_96_arrayA size:= 8*int defined in Core0
extern int *const arrayB_768__arrayB__0;  // explode_generateTensors_arrayB_arrayB_768 > multiplyTensors_96_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_0__2;  // multiplyTensors_96_arrayC > implode_sumResults_12_input_input_0 size:= 64*long defined in Core0
extern char *const multiplyTensors_96__implode___0;  // multiplyTensors_96 > implode_sumResults_12_input size:= 256*char defined in Core0
extern long *const arrayC__input_0__1;  // multiplyTensors_0_arrayC > implode_sumResults_0_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__0;  // multiplyTensors_1_arrayC > implode_sumResults_0_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__2;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__12;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_320__9;  // multiplyTensors_5_arrayC > implode_sumResults_0_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_448__15;  // multiplyTensors_7_arrayC > implode_sumResults_0_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__1;  // implode_sumResults_0_input_arrayC > sumResults_0_input size:= 512*long defined in Core0
extern char *const implode_sumResults_13_input___0;  // implode_sumResults_13_input > sumResults_13 size:= 2048*char defined in Core0
extern long *const arrayC__input_0__3;  // multiplyTensors_56_arrayC > implode_sumResults_7_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__12;  // multiplyTensors_57_arrayC > implode_sumResults_7_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_192__8;  // multiplyTensors_59_arrayC > implode_sumResults_7_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_256__5;  // multiplyTensors_60_arrayC > implode_sumResults_7_input_input_256 size:= 64*long defined in Core0
extern long *const arrayC__input_320__14;  // multiplyTensors_61_arrayC > implode_sumResults_7_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__12;  // multiplyTensors_62_arrayC > implode_sumResults_7_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__6;  // multiplyTensors_63_arrayC > implode_sumResults_7_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__6;  // implode_sumResults_7_input_arrayC > sumResults_7_input size:= 512*long defined in Core0
extern char *const implode_sumResults_7_input____0;  // implode_sumResults_7_input > sumResults_7 size:= 2048*char defined in Core0
extern long *const output__arrayC_0__0;  // sumResults_0_output > implode_displayTensor_arrayC_arrayC_0 size:= 64*long defined in Core0
extern char *const sumResults_0__implode_displa__0;  // sumResults_0 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const arrayC__input__14;  // implode_sumResults_13_input_arrayC > sumResults_13_input size:= 512*long defined in Core0
extern long *const output__arrayC_832__0;  // sumResults_13_output > implode_displayTensor_arrayC_arrayC_832 size:= 64*long defined in Core0
extern char *const sumResults_13__implode_displ__0;  // sumResults_13 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core5(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__38 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__38 
		cache_inv(explode_generateTensors_arra__38, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__23 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__23 
		cache_inv(explode_generateTensors_arra__23, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_generateTensors_arra__83 
		receiveEnd(0); // Core0 > Core5: explode_generateTensors_arra__83 
		cache_inv(explode_generateTensors_arra__83, 256*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__121 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__121 
		cache_inv(explode_generateTensors_arra__121, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__34 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__34 
		cache_inv(explode_generateTensors_arra__34, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__46 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__46 
		cache_inv(explode_generateTensors_arra__46, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__76 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__76 
		cache_inv(explode_generateTensors_arra__76, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__82 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__82 
		cache_inv(explode_generateTensors_arra__82, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__11 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__11 
		cache_inv(explode_generateTensors_arra__11, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__90 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__90 
		cache_inv(explode_generateTensors_arra__90, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__127 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__127 
		cache_inv(explode_generateTensors_arra__127, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__12 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__12 
		cache_inv(explode_generateTensors_arra__12, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__30 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__30 
		cache_inv(explode_generateTensors_arra__30, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__31 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__31 
		cache_inv(explode_generateTensors_arra__31, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__73 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__73 
		cache_inv(explode_generateTensors_arra__73, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__63 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__63 
		cache_inv(explode_generateTensors_arra__63, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__42 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__42 
		cache_inv(explode_generateTensors_arra__42, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__81 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__81 
		cache_inv(explode_generateTensors_arra__81, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__138 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__138 
		cache_inv(explode_generateTensors_arra__138, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__13 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__60 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__60 
		cache_inv(explode_generateTensors_arra__60, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__99 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__99 
		cache_inv(explode_generateTensors_arra__99, 32*sizeof(char));
		receiveStart(); // Core7 > Core5: explode_generateTensors_arra__111 
		receiveEnd(7); // Core7 > Core5: explode_generateTensors_arra__111 
		cache_inv(explode_generateTensors_arra__111, 32*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_0__input__0,output__arrayA__13); // transposeTensor_0
		cache_inv(arrayA_0__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_0__explode_t__0, 256*sizeof(char));
		sendStart(2); // Core5 > Core2: transposeTensor_0__explode_t__0 
		sendEnd(); // Core5 > Core2: transposeTensor_0__explode_t__0 
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_832__input__0,output__arrayA__11); // transposeTensor_13
		cache_inv(arrayA_832__input__0, 64*sizeof(int));
		receiveStart(); // Core6 > Core5: transposeTensor_14__explode___0 
		receiveEnd(6); // Core6 > Core5: transposeTensor_14__explode___0 
		cache_inv(transposeTensor_14__explode___0, 256*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,arrayA_448__input__0,output__arrayA__4); // transposeTensor_7
		cache_inv(arrayA_448__input__0, 64*sizeof(int));
		cache_wbInv(transposeTensor_7__explode_t__0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: transposeTensor_7__explode_t__0 
		sendEnd(); // Core5 > Core0: transposeTensor_7__explode_t__0 
		receiveStart(); // Core2 > Core5: explode_transposeTensor_0_ou__2 
		receiveEnd(2); // Core2 > Core5: explode_transposeTensor_0_ou__2 
		cache_inv(explode_transposeTensor_0_ou__2, 32*sizeof(char));
		receiveStart(); // Core2 > Core5: explode_transposeTensor_0_ou__7 
		receiveEnd(2); // Core2 > Core5: explode_transposeTensor_0_ou__7 
		cache_inv(explode_transposeTensor_0_ou__7, 32*sizeof(char));
		receiveStart(); // Core4 > Core5: explode_transposeTensor_10_o__7 
		receiveEnd(4); // Core4 > Core5: explode_transposeTensor_10_o__7 
		cache_inv(explode_transposeTensor_10_o__7, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_12_o__0 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_12_o__0 
		cache_inv(explode_transposeTensor_12_o__0, 32*sizeof(char));
		receiveStart(); // Core6 > Core5: explode_transposeTensor_12_o__4 
		receiveEnd(6); // Core6 > Core5: explode_transposeTensor_12_o__4 
		cache_inv(explode_transposeTensor_12_o__4, 32*sizeof(char));
		// Fork explode_transposeTensor_13_output
		{
			memcpy((void*)(output_0__arrayA__13+0),(void*)( output__arrayA__11+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__9+0),(void*)( output__arrayA__11+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__8+0),(void*)( output__arrayA__11+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__15+0),(void*)( output__arrayA__11+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__0+0),(void*)( output__arrayA__11+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__14+0),(void*)( output__arrayA__11+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__5+0),(void*)( output__arrayA__11+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__14+0),(void*)( output__arrayA__11+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__11, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_13_o__5, 32*sizeof(char));
		sendStart(3); // Core5 > Core3: explode_transposeTensor_13_o__5 
		sendEnd(); // Core5 > Core3: explode_transposeTensor_13_o__5 
		cache_wbInv(explode_transposeTensor_13_o__1, 32*sizeof(char));
		sendStart(3); // Core5 > Core3: explode_transposeTensor_13_o__1 
		sendEnd(); // Core5 > Core3: explode_transposeTensor_13_o__1 
		cache_wbInv(explode_transposeTensor_13_o__7, 32*sizeof(char));
		sendStart(3); // Core5 > Core3: explode_transposeTensor_13_o__7 
		sendEnd(); // Core5 > Core3: explode_transposeTensor_13_o__7 
		cache_wbInv(explode_transposeTensor_13_o__6, 32*sizeof(char));
		sendStart(3); // Core5 > Core3: explode_transposeTensor_13_o__6 
		sendEnd(); // Core5 > Core3: explode_transposeTensor_13_o__6 
		// Fork explode_transposeTensor_14_output
		{
			memcpy((void*)(output_0__arrayA__11+0),(void*)( output__arrayA__14+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__10+0),(void*)( output__arrayA__14+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__7+0),(void*)( output__arrayA__14+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__0+0),(void*)( output__arrayA__14+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__8+0),(void*)( output__arrayA__14+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__1+0),(void*)( output__arrayA__14+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__0+0),(void*)( output__arrayA__14+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__0+0),(void*)( output__arrayA__14+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__14, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_14_o__3, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_14_o__3 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_14_o__3 
		cache_wbInv(explode_transposeTensor_14_o__2, 32*sizeof(char));
		sendStart(2); // Core5 > Core2: explode_transposeTensor_14_o__2 
		sendEnd(); // Core5 > Core2: explode_transposeTensor_14_o__2 
		cache_wbInv(explode_transposeTensor_14_o__1, 32*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_14_o__1 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_14_o__1 
		cache_wbInv(explode_transposeTensor_14_o__4, 32*sizeof(char));
		sendStart(1); // Core5 > Core1: explode_transposeTensor_14_o__4 
		sendEnd(); // Core5 > Core1: explode_transposeTensor_14_o__4 
		cache_wbInv(explode_transposeTensor_14_o__5, 32*sizeof(char));
		sendStart(2); // Core5 > Core2: explode_transposeTensor_14_o__5 
		sendEnd(); // Core5 > Core2: explode_transposeTensor_14_o__5 
		cache_wbInv(explode_transposeTensor_14_o__7, 32*sizeof(char));
		sendStart(6); // Core5 > Core6: explode_transposeTensor_14_o__7 
		sendEnd(); // Core5 > Core6: explode_transposeTensor_14_o__7 
		receiveStart(); // Core3 > Core5: explode_transposeTensor_3_ou__2 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_3_ou__2 
		cache_inv(explode_transposeTensor_3_ou__2, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_3_ou__7 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_3_ou__7 
		cache_inv(explode_transposeTensor_3_ou__7, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_3_ou__3 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_3_ou__3 
		cache_inv(explode_transposeTensor_3_ou__3, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_3_ou__6 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_3_ou__6 
		cache_inv(explode_transposeTensor_3_ou__6, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_3_ou__4 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_3_ou__4 
		cache_inv(explode_transposeTensor_3_ou__4, 32*sizeof(char));
		receiveStart(); // Core3 > Core5: explode_transposeTensor_3_ou__5 
		receiveEnd(3); // Core3 > Core5: explode_transposeTensor_3_ou__5 
		cache_inv(explode_transposeTensor_3_ou__5, 32*sizeof(char));
		receiveStart(); // Core1 > Core5: explode_transposeTensor_5_ou__7 
		receiveEnd(1); // Core1 > Core5: explode_transposeTensor_5_ou__7 
		cache_inv(explode_transposeTensor_5_ou__7, 32*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_transposeTensor_7_ou__0 
		receiveEnd(0); // Core0 > Core5: explode_transposeTensor_7_ou__0 
		cache_inv(explode_transposeTensor_7_ou__0, 32*sizeof(char));
		receiveStart(); // Core0 > Core5: explode_transposeTensor_8_ou__6 
		receiveEnd(0); // Core0 > Core5: explode_transposeTensor_8_ou__6 
		cache_inv(explode_transposeTensor_8_ou__6, 32*sizeof(char));
		receiveStart(); // Core2 > Core5: multiplyTensors_0__implode_s__0 
		receiveEnd(2); // Core2 > Core5: multiplyTensors_0__implode_s__0 
		cache_inv(multiplyTensors_0__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core2 > Core5: multiplyTensors_1__implode_s__0 
		receiveEnd(2); // Core2 > Core5: multiplyTensors_1__implode_s__0 
		cache_inv(multiplyTensors_1__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__6,arrayB_816__arrayB__0,arrayC__input_384__2); // multiplyTensors_102
		cache_inv(output_48__arrayA__6, 8*sizeof(int));
		cache_inv(arrayB_816__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_102__implode__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_102__implode__0 
		sendEnd(); // Core5 > Core4: multiplyTensors_102__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__9,arrayB_840__arrayB__0,arrayC__input_64__2); // multiplyTensors_105
		cache_inv(output_8__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_840__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_105__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_105__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_105__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__8,arrayB_848__arrayB__0,arrayC__input_128__5); // multiplyTensors_106
		cache_inv(output_16__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_848__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_106__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_106__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_106__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__0,arrayB_864__arrayB__0,arrayC__input_256__4); // multiplyTensors_108
		cache_inv(output_32__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_864__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_108__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_108__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_108__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_40__arrayA__14,arrayB_872__arrayB__0,arrayC__input_320__8); // multiplyTensors_109
		cache_inv(output_40__arrayA__14, 8*sizeof(int));
		cache_inv(arrayB_872__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_109__implode__0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_109__implode__0 
		sendEnd(); // Core5 > Core3: multiplyTensors_109__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__8,arrayB_928__arrayB__0,arrayC__input_256__3); // multiplyTensors_116
		cache_inv(output_32__arrayA__8, 8*sizeof(int));
		cache_inv(arrayB_928__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_116__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_116__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_116__implode__0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__0,arrayB_944__arrayB__0,arrayC__input_384__0); // multiplyTensors_118
		cache_inv(output_48__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_944__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_118__implode__0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_118__implode__0 
		sendEnd(); // Core5 > Core6: multiplyTensors_118__implode__0 
		receiveStart(); // Core1 > Core5: multiplyTensors_2__implode_s__0 
		receiveEnd(1); // Core1 > Core5: multiplyTensors_2__implode_s__0 
		cache_inv(multiplyTensors_2__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__5,arrayB_192__arrayB__0,arrayC__input_0__13); // multiplyTensors_24
		cache_inv(output_0__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_192__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_24__implode___0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_24__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_24__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_8__arrayA__7,arrayB_200__arrayB__0,arrayC__input_64__6); // multiplyTensors_25
		cache_inv(output_8__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_200__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_25__implode___0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_25__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_25__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__12,arrayB_216__arrayB__0,arrayC__input_192__1); // multiplyTensors_27
		cache_inv(output_24__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_216__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_27__implode___0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_27__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_27__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__4,arrayB_224__arrayB__0,arrayC__input_256__8); // multiplyTensors_28
		cache_inv(output_32__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_224__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_28__implode___0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_28__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_28__implode___0 
		receiveStart(); // Core2 > Core5: multiplyTensors_3__implode_s__0 
		receiveEnd(2); // Core2 > Core5: multiplyTensors_3__implode_s__0 
		cache_inv(multiplyTensors_3__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__13,arrayB_240__arrayB__0,arrayC__input_384__7); // multiplyTensors_30
		cache_inv(output_48__arrayA__13, 8*sizeof(int));
		cache_inv(arrayB_240__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_30__implode___0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_30__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_30__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_56__arrayA__5,arrayB_248__arrayB__0,arrayC__input_448__1); // multiplyTensors_31
		cache_inv(output_56__arrayA__5, 8*sizeof(int));
		cache_inv(arrayB_248__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_31__implode___0, 256*sizeof(char));
		sendStart(6); // Core5 > Core6: multiplyTensors_31__implode___0 
		sendEnd(); // Core5 > Core6: multiplyTensors_31__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_32__arrayA__15,arrayB_32__arrayB__0,arrayC__input_256__7); // multiplyTensors_4
		cache_inv(output_32__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_32__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__15,arrayB_336__arrayB__0,arrayC__input_128__9); // multiplyTensors_42
		cache_inv(output_16__arrayA__15, 8*sizeof(int));
		cache_inv(arrayB_336__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_42__implode___0, 256*sizeof(char));
		sendStart(3); // Core5 > Core3: multiplyTensors_42__implode___0 
		sendEnd(); // Core5 > Core3: multiplyTensors_42__implode___0 
		receiveStart(); // Core1 > Core5: multiplyTensors_5__implode_s__0 
		receiveEnd(1); // Core1 > Core5: multiplyTensors_5__implode_s__0 
		cache_inv(multiplyTensors_5__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_56__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_56__implode___0 
		cache_inv(multiplyTensors_56__implode___0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_57__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_57__implode___0 
		cache_inv(multiplyTensors_57__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_16__arrayA__0,arrayB_464__arrayB__0,arrayC__input_128__11); // multiplyTensors_58
		cache_inv(output_16__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_464__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core0 > Core5: multiplyTensors_59__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_59__implode___0 
		cache_inv(multiplyTensors_59__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_48__arrayA__4,arrayB_48__arrayB__0,arrayC__input_384__13); // multiplyTensors_6
		cache_inv(output_48__arrayA__4, 8*sizeof(int));
		cache_inv(arrayB_48__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core0 > Core5: multiplyTensors_60__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_60__implode___0 
		cache_inv(multiplyTensors_60__implode___0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_61__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_61__implode___0 
		cache_inv(multiplyTensors_61__implode___0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_62__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_62__implode___0 
		cache_inv(multiplyTensors_62__implode___0, 256*sizeof(char));
		receiveStart(); // Core0 > Core5: multiplyTensors_63__implode___0 
		receiveEnd(0); // Core0 > Core5: multiplyTensors_63__implode___0 
		cache_inv(multiplyTensors_63__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_24__arrayA__9,arrayB_536__arrayB__0,arrayC__input_192__6); // multiplyTensors_67
		cache_inv(output_24__arrayA__9, 8*sizeof(int));
		cache_inv(arrayB_536__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_67__implode___0, 256*sizeof(char));
		sendStart(7); // Core5 > Core7: multiplyTensors_67__implode___0 
		sendEnd(); // Core5 > Core7: multiplyTensors_67__implode___0 
		receiveStart(); // Core1 > Core5: multiplyTensors_7__implode_s__0 
		receiveEnd(1); // Core1 > Core5: multiplyTensors_7__implode_s__0 
		cache_inv(multiplyTensors_7__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__12,arrayB_640__arrayB__0,arrayC__input_0__7); // multiplyTensors_80
		cache_inv(output_0__arrayA__12, 8*sizeof(int));
		cache_inv(arrayB_640__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_80__implode___0, 256*sizeof(char));
		sendStart(0); // Core5 > Core0: multiplyTensors_80__implode___0 
		sendEnd(); // Core5 > Core0: multiplyTensors_80__implode___0 
		multiply(8/*rowsA*/,8/*columnsA*/,16/*depthA*/,8/*rowsB*/,8/*columnsB*/,16/*depthB*/,output_0__arrayA__7,arrayB_768__arrayB__0,arrayC__input_0__2); // multiplyTensors_96
		cache_inv(output_0__arrayA__7, 8*sizeof(int));
		cache_inv(arrayB_768__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_96__implode___0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: multiplyTensors_96__implode___0 
		sendEnd(); // Core5 > Core4: multiplyTensors_96__implode___0 
		// Join implode_sumResults_0_input
		{
			memcpy((void*)(arrayC__input__1+0),(void*)( arrayC__input_0__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+64),(void*)( arrayC__input_64__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+128),(void*)( arrayC__input_128__2+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+192),(void*)( arrayC__input_192__12+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+256),(void*)( arrayC__input_256__7+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+320),(void*)( arrayC__input_320__9+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+384),(void*)( arrayC__input_384__13+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+448),(void*)( arrayC__input_448__15+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__1, 64*sizeof(long));
		cache_inv(arrayC__input_64__0, 64*sizeof(long));
		cache_inv(arrayC__input_128__2, 64*sizeof(long));
		cache_inv(arrayC__input_192__12, 64*sizeof(long));
		cache_inv(arrayC__input_256__7, 64*sizeof(long));
		cache_inv(arrayC__input_320__9, 64*sizeof(long));
		cache_inv(arrayC__input_384__13, 64*sizeof(long));
		cache_inv(arrayC__input_448__15, 64*sizeof(long));
		receiveStart(); // Core3 > Core5: implode_sumResults_13_input___0 
		receiveEnd(3); // Core3 > Core5: implode_sumResults_13_input___0 
		cache_inv(implode_sumResults_13_input___0, 2048*sizeof(char));
		// Join implode_sumResults_7_input
		{
			memcpy((void*)(arrayC__input__6+0),(void*)( arrayC__input_0__3+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__6+64),(void*)( arrayC__input_64__12+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__6+128),(void*)( arrayC__input_128__11+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__6+192),(void*)( arrayC__input_192__8+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__6+256),(void*)( arrayC__input_256__5+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__6+320),(void*)( arrayC__input_320__14+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__6+384),(void*)( arrayC__input_384__12+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__6+448),(void*)( arrayC__input_448__6+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__3, 64*sizeof(long));
		cache_inv(arrayC__input_64__12, 64*sizeof(long));
		cache_inv(arrayC__input_128__11, 64*sizeof(long));
		cache_inv(arrayC__input_192__8, 64*sizeof(long));
		cache_inv(arrayC__input_256__5, 64*sizeof(long));
		cache_inv(arrayC__input_320__14, 64*sizeof(long));
		cache_inv(arrayC__input_384__12, 64*sizeof(long));
		cache_inv(arrayC__input_448__6, 64*sizeof(long));
		cache_wbInv(implode_sumResults_7_input____0, 2048*sizeof(char));
		sendStart(4); // Core5 > Core4: implode_sumResults_7_input____0 
		sendEnd(); // Core5 > Core4: implode_sumResults_7_input____0 
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__1,output__arrayC_0__0); // sumResults_0
		cache_inv(arrayC__input__1, 512*sizeof(long));
		cache_wbInv(sumResults_0__implode_displa__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: sumResults_0__implode_displa__0 
		sendEnd(); // Core5 > Core4: sumResults_0__implode_displa__0 
		sum(8/*rowsA*/,8/*columnsB*/,16/*depthA*/,arrayC__input__14,output__arrayC_832__0); // sumResults_13
		cache_inv(arrayC__input__14, 512*sizeof(long));
		cache_wbInv(sumResults_13__implode_displ__0, 256*sizeof(char));
		sendStart(4); // Core5 > Core4: sumResults_13__implode_displ__0 
		sendEnd(); // Core5 > Core4: sumResults_13__implode_displ__0 
	}
}
