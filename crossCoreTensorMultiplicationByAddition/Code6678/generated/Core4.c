/** 
 * @file Core4.c
 * @generated by C6678CPrinter
 * @date Mon Mar 30 19:16:34 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const explode_generateTensors_arra__6;  // explode_generateTensors_arrayB > multiplyTensors_12 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__13;  // explode_generateTensors_arrayB > multiplyTensors_3 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__4;  // explode_transposeTensor_0_output > multiplyTensors_3 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_1_ou__4;  // explode_transposeTensor_1_output > multiplyTensors_12 size:= 32*char defined in Core0
extern char *const multiplyTensors_10__implode___0;  // multiplyTensors_10 > implode_sumResults_1_input size:= 256*char defined in Core0
extern char *const multiplyTensors_11__implode___0;  // multiplyTensors_11 > implode_sumResults_1_input size:= 256*char defined in Core0
extern int *const output_32__arrayA__0;  // explode_transposeTensor_1_output_output_32 > multiplyTensors_12_arrayA size:= 8*int defined in Core0
extern int *const arrayB_96__arrayB__0;  // explode_generateTensors_arrayB_arrayB_96 > multiplyTensors_12_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__0;  // multiplyTensors_12_arrayC > implode_sumResults_1_input_input_256 size:= 64*long defined in Core0
extern char *const multiplyTensors_13__implode___0;  // multiplyTensors_13 > implode_sumResults_1_input size:= 256*char defined in Core0
extern char *const multiplyTensors_14__implode___0;  // multiplyTensors_14 > implode_sumResults_1_input size:= 256*char defined in Core0
extern char *const multiplyTensors_15__implode___0;  // multiplyTensors_15 > implode_sumResults_1_input size:= 256*char defined in Core0
extern int *const output_24__arrayA__1;  // explode_transposeTensor_0_output_output_24 > multiplyTensors_3_arrayA size:= 8*int defined in Core0
extern int *const arrayB_24__arrayB__0;  // explode_generateTensors_arrayB_arrayB_24 > multiplyTensors_3_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_192__1;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_192 size:= 64*long defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_8__implode_s__0;  // multiplyTensors_8 > implode_sumResults_1_input size:= 256*char defined in Core0
extern char *const multiplyTensors_9__implode_s__0;  // multiplyTensors_9 > implode_sumResults_1_input size:= 256*char defined in Core0
extern long *const arrayC__input_0__1;  // multiplyTensors_8_arrayC > implode_sumResults_1_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__1;  // multiplyTensors_9_arrayC > implode_sumResults_1_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__0;  // multiplyTensors_10_arrayC > implode_sumResults_1_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__0;  // multiplyTensors_11_arrayC > implode_sumResults_1_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_320__0;  // multiplyTensors_13_arrayC > implode_sumResults_1_input_input_320 size:= 64*long defined in Core0
extern long *const arrayC__input_384__0;  // multiplyTensors_14_arrayC > implode_sumResults_1_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__0;  // multiplyTensors_15_arrayC > implode_sumResults_1_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__0;  // implode_sumResults_1_input_arrayC > sumResults_1_input size:= 512*long defined in Core0
extern char *const sumResults_0__implode_displa__0;  // sumResults_0 > implode_displayTensor_arrayC size:= 256*char defined in Core0
extern long *const output__arrayC_64__0;  // sumResults_1_output > implode_displayTensor_arrayC_arrayC_64 size:= 64*long defined in Core0
extern long *const output__arrayC_0__0;  // sumResults_0_output > implode_displayTensor_arrayC_arrayC_0 size:= 64*long defined in Core0
extern long *const output__arrayC__0;  // implode_displayTensor_arrayC_output > displayTensor_arrayC size:= 128*long defined in Core0
extern char *const implode_displayTensor_arrayC__0;  // implode_displayTensor_arrayC > displayTensor size:= 512*char defined in Core0

// Core Global Definitions

void core4(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core4: explode_generateTensors_arra__6 
		receiveEnd(0); // Core0 > Core4: explode_generateTensors_arra__6 
		cache_inv(explode_generateTensors_arra__6, 32*sizeof(char));
		receiveStart(); // Core0 > Core4: explode_generateTensors_arra__13 
		receiveEnd(0); // Core0 > Core4: explode_generateTensors_arra__13 
		cache_inv(explode_generateTensors_arra__13, 32*sizeof(char));
		receiveStart(); // Core7 > Core4: explode_transposeTensor_0_ou__4 
		receiveEnd(7); // Core7 > Core4: explode_transposeTensor_0_ou__4 
		cache_inv(explode_transposeTensor_0_ou__4, 32*sizeof(char));
		receiveStart(); // Core0 > Core4: explode_transposeTensor_1_ou__4 
		receiveEnd(0); // Core0 > Core4: explode_transposeTensor_1_ou__4 
		cache_inv(explode_transposeTensor_1_ou__4, 32*sizeof(char));
		receiveStart(); // Core6 > Core4: multiplyTensors_10__implode___0 
		receiveEnd(6); // Core6 > Core4: multiplyTensors_10__implode___0 
		cache_inv(multiplyTensors_10__implode___0, 256*sizeof(char));
		receiveStart(); // Core1 > Core4: multiplyTensors_11__implode___0 
		receiveEnd(1); // Core1 > Core4: multiplyTensors_11__implode___0 
		cache_inv(multiplyTensors_11__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,output_32__arrayA__0,arrayB_96__arrayB__0,arrayC__input_256__0); // multiplyTensors_12
		cache_inv(output_32__arrayA__0, 8*sizeof(int));
		cache_inv(arrayB_96__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core5 > Core4: multiplyTensors_13__implode___0 
		receiveEnd(5); // Core5 > Core4: multiplyTensors_13__implode___0 
		cache_inv(multiplyTensors_13__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core4: multiplyTensors_14__implode___0 
		receiveEnd(3); // Core3 > Core4: multiplyTensors_14__implode___0 
		cache_inv(multiplyTensors_14__implode___0, 256*sizeof(char));
		receiveStart(); // Core3 > Core4: multiplyTensors_15__implode___0 
		receiveEnd(3); // Core3 > Core4: multiplyTensors_15__implode___0 
		cache_inv(multiplyTensors_15__implode___0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,output_24__arrayA__1,arrayB_24__arrayB__0,arrayC__input_192__1); // multiplyTensors_3
		cache_inv(output_24__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_24__arrayB__0, 8*sizeof(int));
		cache_wbInv(multiplyTensors_3__implode_s__0, 256*sizeof(char));
		sendStart(7); // Core4 > Core7: multiplyTensors_3__implode_s__0 
		sendEnd(); // Core4 > Core7: multiplyTensors_3__implode_s__0 
		receiveStart(); // Core2 > Core4: multiplyTensors_8__implode_s__0 
		receiveEnd(2); // Core2 > Core4: multiplyTensors_8__implode_s__0 
		cache_inv(multiplyTensors_8__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core2 > Core4: multiplyTensors_9__implode_s__0 
		receiveEnd(2); // Core2 > Core4: multiplyTensors_9__implode_s__0 
		cache_inv(multiplyTensors_9__implode_s__0, 256*sizeof(char));
		// Join implode_sumResults_1_input
		{
			memcpy((void*)(arrayC__input__0+0),(void*)( arrayC__input_0__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__0+64),(void*)( arrayC__input_64__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__0+128),(void*)( arrayC__input_128__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__0+192),(void*)( arrayC__input_192__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__0+256),(void*)( arrayC__input_256__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__0+320),(void*)( arrayC__input_320__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__0+384),(void*)( arrayC__input_384__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__0+448),(void*)( arrayC__input_448__0+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__1, 64*sizeof(long));
		cache_inv(arrayC__input_64__1, 64*sizeof(long));
		cache_inv(arrayC__input_128__0, 64*sizeof(long));
		cache_inv(arrayC__input_192__0, 64*sizeof(long));
		cache_inv(arrayC__input_256__0, 64*sizeof(long));
		cache_inv(arrayC__input_320__0, 64*sizeof(long));
		cache_inv(arrayC__input_384__0, 64*sizeof(long));
		cache_inv(arrayC__input_448__0, 64*sizeof(long));
		receiveStart(); // Core7 > Core4: sumResults_0__implode_displa__0 
		receiveEnd(7); // Core7 > Core4: sumResults_0__implode_displa__0 
		cache_inv(sumResults_0__implode_displa__0, 256*sizeof(char));
		sum(8/*rowsA*/,8/*columnsB*/,2/*depthA*/,arrayC__input__0,output__arrayC_64__0); // sumResults_1
		cache_inv(arrayC__input__0, 512*sizeof(long));
		// Join implode_displayTensor_arrayC
		{
			memcpy((void*)(output__arrayC__0+0),(void*)( output__arrayC_0__0+0), 64*sizeof(long));
			memcpy((void*)(output__arrayC__0+64),(void*)( output__arrayC_64__0+0), 64*sizeof(long));
		}
		cache_inv(output__arrayC_0__0, 64*sizeof(long));
		cache_inv(output__arrayC_64__0, 64*sizeof(long));
		cache_wbInv(implode_displayTensor_arrayC__0, 512*sizeof(char));
		sendStart(0); // Core4 > Core0: implode_displayTensor_arrayC__0 
		sendEnd(); // Core4 > Core0: implode_displayTensor_arrayC__0 
	}
}
