/** 
 * @file Core7.c
 * @generated by C6678CPrinter
 * @date Mon Mar 30 19:16:34 BST 2015
 */
 

#include "cores.h"
#include "utils.h"
#include "communication.h"
#include "fifo.h"
#include "cache.h"

// Core Global Declaration
extern char *const generateTensors__explode_gen__0;  // generateTensors > explode_generateTensors_arrayA size:= 512*char defined in Core0
extern int *const arrayA_0__input__0;  // explode_generateTensors_arrayA_arrayA_0 > transposeTensor_0_input size:= 64*int defined in Core0
extern int *const arrayA_64__input__0;  // explode_generateTensors_arrayA_arrayA_64 > transposeTensor_1_input size:= 64*int defined in Core0
extern int *const arrayA__input__0;  // generateTensors_arrayA > explode_generateTensors_arrayA_input size:= 128*int defined in Core0
extern char *const explode_generateTensors_arra__4;  // explode_generateTensors_arrayA > transposeTensor_1 size:= 256*char defined in Core0
extern char *const explode_generateTensors_arra__11;  // explode_generateTensors_arrayB > multiplyTensors_5 size:= 32*char defined in Core0
extern char *const explode_generateTensors_arra__17;  // explode_generateTensors_arrayB > multiplyTensors_4 size:= 32*char defined in Core0
extern int *const output__arrayA__0;  // transposeTensor_0_output > explode_transposeTensor_0_output_arrayA size:= 64*int defined in Core0
extern int *const output_0__arrayA__1;  // explode_transposeTensor_0_output_output_0 > multiplyTensors_0_arrayA size:= 8*int defined in Core0
extern int *const output_8__arrayA__1;  // explode_transposeTensor_0_output_output_8 > multiplyTensors_1_arrayA size:= 8*int defined in Core0
extern int *const output_16__arrayA__1;  // explode_transposeTensor_0_output_output_16 > multiplyTensors_2_arrayA size:= 8*int defined in Core0
extern int *const output_24__arrayA__1;  // explode_transposeTensor_0_output_output_24 > multiplyTensors_3_arrayA size:= 8*int defined in Core0
extern int *const output_32__arrayA__1;  // explode_transposeTensor_0_output_output_32 > multiplyTensors_4_arrayA size:= 8*int defined in Core0
extern int *const output_40__arrayA__1;  // explode_transposeTensor_0_output_output_40 > multiplyTensors_5_arrayA size:= 8*int defined in Core0
extern int *const output_48__arrayA__1;  // explode_transposeTensor_0_output_output_48 > multiplyTensors_6_arrayA size:= 8*int defined in Core0
extern int *const output_56__arrayA__0;  // explode_transposeTensor_0_output_output_56 > multiplyTensors_7_arrayA size:= 8*int defined in Core0
extern char *const explode_transposeTensor_0_ou__2;  // explode_transposeTensor_0_output > multiplyTensors_7 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__0;  // explode_transposeTensor_0_output > multiplyTensors_6 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__4;  // explode_transposeTensor_0_output > multiplyTensors_3 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__7;  // explode_transposeTensor_0_output > multiplyTensors_2 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__6;  // explode_transposeTensor_0_output > multiplyTensors_1 size:= 32*char defined in Core0
extern char *const explode_transposeTensor_0_ou__5;  // explode_transposeTensor_0_output > multiplyTensors_0 size:= 32*char defined in Core0
extern char *const multiplyTensors_0__implode_s__0;  // multiplyTensors_0 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_1__implode_s__0;  // multiplyTensors_1 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_2__implode_s__0;  // multiplyTensors_2 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_3__implode_s__0;  // multiplyTensors_3 > implode_sumResults_0_input size:= 256*char defined in Core0
extern int *const arrayB_32__arrayB__0;  // explode_generateTensors_arrayB_arrayB_32 > multiplyTensors_4_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_256__1;  // multiplyTensors_4_arrayC > implode_sumResults_0_input_input_256 size:= 64*long defined in Core0
extern int *const arrayB_40__arrayB__0;  // explode_generateTensors_arrayB_arrayB_40 > multiplyTensors_5_arrayB size:= 8*int defined in Core0
extern long *const arrayC__input_320__1;  // multiplyTensors_5_arrayC > implode_sumResults_0_input_input_320 size:= 64*long defined in Core0
extern char *const multiplyTensors_6__implode_s__0;  // multiplyTensors_6 > implode_sumResults_0_input size:= 256*char defined in Core0
extern char *const multiplyTensors_7__implode_s__0;  // multiplyTensors_7 > implode_sumResults_0_input size:= 256*char defined in Core0
extern long *const arrayC__input_0__0;  // multiplyTensors_0_arrayC > implode_sumResults_0_input_input_0 size:= 64*long defined in Core0
extern long *const arrayC__input_64__0;  // multiplyTensors_1_arrayC > implode_sumResults_0_input_input_64 size:= 64*long defined in Core0
extern long *const arrayC__input_128__1;  // multiplyTensors_2_arrayC > implode_sumResults_0_input_input_128 size:= 64*long defined in Core0
extern long *const arrayC__input_192__1;  // multiplyTensors_3_arrayC > implode_sumResults_0_input_input_192 size:= 64*long defined in Core0
extern long *const arrayC__input_384__1;  // multiplyTensors_6_arrayC > implode_sumResults_0_input_input_384 size:= 64*long defined in Core0
extern long *const arrayC__input_448__1;  // multiplyTensors_7_arrayC > implode_sumResults_0_input_input_448 size:= 64*long defined in Core0
extern long *const arrayC__input__1;  // implode_sumResults_0_input_arrayC > sumResults_0_input size:= 512*long defined in Core0
extern long *const output__arrayC_0__0;  // sumResults_0_output > implode_displayTensor_arrayC_arrayC_0 size:= 64*long defined in Core0
extern char *const sumResults_0__implode_displa__0;  // sumResults_0 > implode_displayTensor_arrayC size:= 256*char defined in Core0

// Core Global Definitions

void core7(void){
	// Initialisation(s)
	communicationInit();

	// Begin the execution loop 
	while(1){
		busy_barrier();
		receiveStart(); // Core0 > Core7: generateTensors__explode_gen__0 
		receiveEnd(0); // Core0 > Core7: generateTensors__explode_gen__0 
		cache_inv(generateTensors__explode_gen__0, 512*sizeof(char));
		// Fork explode_generateTensors_arrayA
		{
			memcpy((void*)(arrayA_0__input__0+0),(void*)( arrayA__input__0+0), 64*sizeof(int));
			memcpy((void*)(arrayA_64__input__0+0),(void*)( arrayA__input__0+64), 64*sizeof(int));
		}
		cache_inv(arrayA__input__0, 128*sizeof(int));
		cache_wbInv(explode_generateTensors_arra__4, 256*sizeof(char));
		sendStart(0); // Core7 > Core0: explode_generateTensors_arra__4 
		sendEnd(); // Core7 > Core0: explode_generateTensors_arra__4 
		receiveStart(); // Core0 > Core7: explode_generateTensors_arra__11 
		receiveEnd(0); // Core0 > Core7: explode_generateTensors_arra__11 
		cache_inv(explode_generateTensors_arra__11, 32*sizeof(char));
		receiveStart(); // Core0 > Core7: explode_generateTensors_arra__17 
		receiveEnd(0); // Core0 > Core7: explode_generateTensors_arra__17 
		cache_inv(explode_generateTensors_arra__17, 32*sizeof(char));
		transpose(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,arrayA_0__input__0,output__arrayA__0); // transposeTensor_0
		cache_inv(arrayA_0__input__0, 64*sizeof(int));
		// Fork explode_transposeTensor_0_output
		{
			memcpy((void*)(output_0__arrayA__1+0),(void*)( output__arrayA__0+0), 8*sizeof(int));
			memcpy((void*)(output_8__arrayA__1+0),(void*)( output__arrayA__0+8), 8*sizeof(int));
			memcpy((void*)(output_16__arrayA__1+0),(void*)( output__arrayA__0+16), 8*sizeof(int));
			memcpy((void*)(output_24__arrayA__1+0),(void*)( output__arrayA__0+24), 8*sizeof(int));
			memcpy((void*)(output_32__arrayA__1+0),(void*)( output__arrayA__0+32), 8*sizeof(int));
			memcpy((void*)(output_40__arrayA__1+0),(void*)( output__arrayA__0+40), 8*sizeof(int));
			memcpy((void*)(output_48__arrayA__1+0),(void*)( output__arrayA__0+48), 8*sizeof(int));
			memcpy((void*)(output_56__arrayA__0+0),(void*)( output__arrayA__0+56), 8*sizeof(int));
		}
		cache_inv(output__arrayA__0, 64*sizeof(int));
		cache_wbInv(explode_transposeTensor_0_ou__2, 32*sizeof(char));
		sendStart(6); // Core7 > Core6: explode_transposeTensor_0_ou__2 
		sendEnd(); // Core7 > Core6: explode_transposeTensor_0_ou__2 
		cache_wbInv(explode_transposeTensor_0_ou__0, 32*sizeof(char));
		sendStart(1); // Core7 > Core1: explode_transposeTensor_0_ou__0 
		sendEnd(); // Core7 > Core1: explode_transposeTensor_0_ou__0 
		cache_wbInv(explode_transposeTensor_0_ou__4, 32*sizeof(char));
		sendStart(4); // Core7 > Core4: explode_transposeTensor_0_ou__4 
		sendEnd(); // Core7 > Core4: explode_transposeTensor_0_ou__4 
		cache_wbInv(explode_transposeTensor_0_ou__7, 32*sizeof(char));
		sendStart(2); // Core7 > Core2: explode_transposeTensor_0_ou__7 
		sendEnd(); // Core7 > Core2: explode_transposeTensor_0_ou__7 
		cache_wbInv(explode_transposeTensor_0_ou__6, 32*sizeof(char));
		sendStart(3); // Core7 > Core3: explode_transposeTensor_0_ou__6 
		sendEnd(); // Core7 > Core3: explode_transposeTensor_0_ou__6 
		cache_wbInv(explode_transposeTensor_0_ou__5, 32*sizeof(char));
		sendStart(5); // Core7 > Core5: explode_transposeTensor_0_ou__5 
		sendEnd(); // Core7 > Core5: explode_transposeTensor_0_ou__5 
		receiveStart(); // Core5 > Core7: multiplyTensors_0__implode_s__0 
		receiveEnd(5); // Core5 > Core7: multiplyTensors_0__implode_s__0 
		cache_inv(multiplyTensors_0__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core3 > Core7: multiplyTensors_1__implode_s__0 
		receiveEnd(3); // Core3 > Core7: multiplyTensors_1__implode_s__0 
		cache_inv(multiplyTensors_1__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core2 > Core7: multiplyTensors_2__implode_s__0 
		receiveEnd(2); // Core2 > Core7: multiplyTensors_2__implode_s__0 
		cache_inv(multiplyTensors_2__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core4 > Core7: multiplyTensors_3__implode_s__0 
		receiveEnd(4); // Core4 > Core7: multiplyTensors_3__implode_s__0 
		cache_inv(multiplyTensors_3__implode_s__0, 256*sizeof(char));
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,output_32__arrayA__1,arrayB_32__arrayB__0,arrayC__input_256__1); // multiplyTensors_4
		cache_inv(output_32__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_32__arrayB__0, 8*sizeof(int));
		multiply(8/*rowsA*/,8/*columnsA*/,2/*depthA*/,8/*rowsB*/,8/*columnsB*/,2/*depthB*/,output_40__arrayA__1,arrayB_40__arrayB__0,arrayC__input_320__1); // multiplyTensors_5
		cache_inv(output_40__arrayA__1, 8*sizeof(int));
		cache_inv(arrayB_40__arrayB__0, 8*sizeof(int));
		receiveStart(); // Core1 > Core7: multiplyTensors_6__implode_s__0 
		receiveEnd(1); // Core1 > Core7: multiplyTensors_6__implode_s__0 
		cache_inv(multiplyTensors_6__implode_s__0, 256*sizeof(char));
		receiveStart(); // Core6 > Core7: multiplyTensors_7__implode_s__0 
		receiveEnd(6); // Core6 > Core7: multiplyTensors_7__implode_s__0 
		cache_inv(multiplyTensors_7__implode_s__0, 256*sizeof(char));
		// Join implode_sumResults_0_input
		{
			memcpy((void*)(arrayC__input__1+0),(void*)( arrayC__input_0__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+64),(void*)( arrayC__input_64__0+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+128),(void*)( arrayC__input_128__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+192),(void*)( arrayC__input_192__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+256),(void*)( arrayC__input_256__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+320),(void*)( arrayC__input_320__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+384),(void*)( arrayC__input_384__1+0), 64*sizeof(long));
			memcpy((void*)(arrayC__input__1+448),(void*)( arrayC__input_448__1+0), 64*sizeof(long));
		}
		cache_inv(arrayC__input_0__0, 64*sizeof(long));
		cache_inv(arrayC__input_64__0, 64*sizeof(long));
		cache_inv(arrayC__input_128__1, 64*sizeof(long));
		cache_inv(arrayC__input_192__1, 64*sizeof(long));
		cache_inv(arrayC__input_256__1, 64*sizeof(long));
		cache_inv(arrayC__input_320__1, 64*sizeof(long));
		cache_inv(arrayC__input_384__1, 64*sizeof(long));
		cache_inv(arrayC__input_448__1, 64*sizeof(long));
		sum(8/*rowsA*/,8/*columnsB*/,2/*depthA*/,arrayC__input__1,output__arrayC_0__0); // sumResults_0
		cache_inv(arrayC__input__1, 512*sizeof(long));
		cache_wbInv(sumResults_0__implode_displa__0, 256*sizeof(char));
		sendStart(4); // Core7 > Core4: sumResults_0__implode_displa__0 
		sendEnd(); // Core7 > Core4: sumResults_0__implode_displa__0 
	}
}
